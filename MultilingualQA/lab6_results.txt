18:39:50.935416: Start of log file 
18:39:51.077416: Using CUDA: True 

18:39:51.077738: dropout_prob: 0.25; batch_size: 32; lr: 5e-05; n_epochs: 40
18:39:54.707413: Loading tokenizer: bert-base-multilingual-cased
18:39:55.285390: -- Data Parsing ENGLISH; Type: VALIDATION--
18:39:56.766903: Unanswerable questions: 492
18:39:56.776740: Balance of labels: dict_keys([-100, 0, 1, 2]):dict_values([9975, 128193, 476, 2844])
18:39:56.776801: Entries skipped due to too long sequence length (>512): 7
18:39:56.776851: Failed to map answer and to context: 15
18:39:56.785324: Final length: 968 

18:39:56.786747: -- Data Parsing FINNISH; Type: VALIDATION--
18:39:59.189076: Unanswerable questions: 836
18:39:59.203815: Balance of labels: dict_keys([-100, 0, 1, 2]):dict_values([18414, 214528, 783, 6731])
18:39:59.203865: Entries skipped due to too long sequence length (>512): 15
18:39:59.203906: Failed to map answer and to context: 52
18:39:59.216138: Final length: 1619 

18:39:59.218043: -- Data Parsing JAPANESE; Type: VALIDATION--
18:40:00.901593: Unanswerable questions: 507
18:40:00.910386: Balance of labels: dict_keys([-100, 0, 1, 2]):dict_values([13219, 131603, 353, 2326])
18:40:00.910437: Entries skipped due to too long sequence length (>512): 41
18:40:00.910480: Failed to map answer and to context: 135
18:40:00.918037: Final length: 860 

18:40:00.922905: -- Data Parsing ENGLISH; Type: TRAIN--
18:40:01.600979: Failed Answer extraction: ['c', '.', '263', '##0', '261', '##0', '##BC']; Prompt: ['[CLS]', 'How', 'old', 'is', 'the', 'oldest', 'p', '##yramid', '?', 'The', 'earliest', 'known', 'Egyptian', 'p', '##yramid', '##s', 'are', 'found', 'at', 'Sa', '##q', '##qa', '##ra', ',', 'northwest', 'of', 'Memphis', '.', 'The', 'earliest', 'among', 'these', 'is', 'the', 'P', '##yramid', 'of', 'D', '##jos', '##er', ',', 'which', 'was', 'built', 'c', '.', '263', '##0', '[UNK]', '261', '##0', '##BC', 'during', 'the', 'Third', 'Dynasty', '.', '[', '6', ']', 'This', 'p', '##yramid', 'and', 'its', 'surrounding', 'complex', 'were', 'designed', 'by', 'the', 'architect', 'Im', '##hotep', ',', 'and', 'are', 'generally', 'considered', 'to', 'be', 'the', 'world', "'", 's', 'oldest', 'monumental', 'structures', 'constructed', 'of', 'dressed', 'maso', '##n', '##ry', '.', '[', '7', ']', '[SEP]']
18:40:01.674799: Failed Answer extraction: ['February', '9', ',', '198']; Prompt: ['[CLS]', 'When', 'did', 'Louis', 'Hamm', '##ett', 'die', '?', 'Louis', 'Pla', '##ck', 'Hamm', '##ett', '(', 'April', '7', ',', '1894', '[UNK]', 'February', '9', ',', '1987', ')', 'was', 'an', 'American', 'physical', 'che', '##mist', '.', 'He', 'is', 'known', 'for', 'the', 'Hamm', '##ett', 'equation', ',', 'which', 'relate', '##s', 'reaction', 'rates', 'to', 'e', '##quilibrium', 'constant', '##s', 'for', 'certain', 'classes', 'of', 'organic', 'reactions', 'involving', 'substitute', '##d', 'ar', '##oma', '##tic', 'compounds', '.', 'He', 'is', 'also', 'known', 'for', 'his', 'research', 'into', 'supera', '##cid', '##s', 'and', 'his', 'development', 'of', 'a', 'scheme', 'for', 'com', '##pari', '##ng', 'their', 'acid', '##ities', 'based', 'on', 'what', 'is', 'now', 'known', 'as', 'the', 'Hamm', '##ett', 'acid', '##ity', 'function', '.', 'The', 'Curt', '##in', '[UNK]', 'Hamm', '##ett', 'principle', 'bears', 'his', 'name', '.', '[SEP]']
18:40:01.702252: Failed Answer extraction: ['533', '4']; Prompt: ['[CLS]', 'When', 'did', 'the', 'Van', '##dal', 'War', 'end', '?', 'After', 'the', 'Vis', '##igo', '##ths', 'in', '##vaded', 'Iberia', 'in', '418', ',', 'the', 'Iranian', 'Alan', '##s', 'and', 'Si', '##ling', '##i', 'Van', '##dal', '##s', 'vol', '##unta', '##rily', 'subject', '##ed', 'themselves', 'to', 'the', 'rule', 'of', 'Has', '##ding', '##ian', 'leader', 'Gun', '##der', '##ic', ',', 'who', 'was', 'pushed', 'from', 'Gall', '##ae', '##cia', 'to', 'Ba', '##eti', '##ca', 'by', 'a', 'Roman', '-', 'Sue', '##bi', 'coalition', 'in', '419', '.', 'In', '429', ',', 'under', 'king', 'Gen', '##seri', '##c', '(', 'reign', '##ed', '428', '[UNK]', '477', ')', ',', 'the', 'Van', '##dal', '##s', 'entered', 'North', 'Africa', '.', 'By', '439', 'they', 'established', 'a', 'kingdom', 'which', 'included', 'the', 'Roman', 'province', 'of', 'Africa', 'as', 'well', 'as', 'Sicily', ',', 'Corsica', ',', 'Sardinia', ',', 'Malta', 'and', 'the', 'Bale', '##ari', '##c', 'Islands', '.', 'They', 'fe', '##nded', 'off', 'several', 'Roman', 'attempts', 'to', 'reca', '##ptur', '##e', 'the', 'African', 'province', ',', 'and', 'sac', '##ked', 'the', 'city', 'of', 'Rome', 'in', '455', '.', 'Their', 'kingdom', 'collapsed', 'in', 'the', 'Van', '##dali', '##c', 'War', 'of', '533', '[UNK]', '4', ',', 'in', 'which', 'Emperor', 'Justin', '##ian', 'I', "'", 's', 'forces', 're', '##con', '##quer', '##ed', 'the', 'province', 'for', 'the', 'Eastern', 'Roman', 'Empire', '.', '[SEP]']
18:40:01.712055: Failed Answer extraction: ['27', 'BC', 'AD', '476']; Prompt: ['[CLS]', 'When', 'did', 'the', 'Romans', 'con', '##quer', 'Jerusalem', '?', 'The', 'history', 'of', 'the', 'Jews', 'in', 'the', 'Roman', 'Empire', 'traces', 'the', 'interaction', 'of', 'Jews', 'and', 'Romans', 'during', 'the', 'period', 'of', 'the', 'Roman', 'Empire', '(', '27', 'BC', '[UNK]', 'AD', '476', ')', '.', 'Their', 'cultures', 'began', 'to', 'over', '##lap', 'in', 'the', 'centuries', 'just', 'before', 'the', 'Christian', 'Era', '.', 'Jews', ',', 'as', 'part', 'of', 'the', 'Jewish', 'dias', '##pora', ',', 'mig', '##rated', 'to', 'Rome', 'and', 'Roman', 'Europe', 'from', 'the', 'Land', 'of', 'Israel', ',', 'Asia', 'Minor', ',', 'Babylon', 'and', 'Alexandria', 'in', 'response', 'to', 'economic', 'hard', '##ship', 'and', 'in', '##ces', '##sant', 'warfare', 'over', 'the', 'land', 'of', 'Israel', 'between', 'the', 'Pt', '##ole', '##mai', '##c', 'and', 'Se', '##leu', '##cid', 'empire', '##s', '.', 'In', 'Rome', ',', 'Jewish', 'communities', 'enjoyed', 'pri', '##vile', '##ges', 'and', 'th', '##rive', '##d', 'economica', '##lly', ',', 'becoming', 'a', 'significant', 'part', 'of', 'the', 'Empire', "'", 's', 'population', '(', 'perhaps', 'as', 'much', 'as', 'ten', 'percent', ')', '.', '[', '1', ']', '[SEP]']
18:40:01.774623: Failed Answer extraction: ['n', '.', 'When', 'n', 'is', 'a', 'positive', 'inte', '##ger', ',', 'ex', '##ponenti', '##ation', 'correspond', '##s', 'to', 'repeated', 'multi', '##plication', 'of', 'the', 'base', ':', 'that', 'is', ',', 'b', '##n', 'is', 'the', 'product', 'of', 'multi', '##ply', '##ing', 'n', 'bas']; Prompt: ['[CLS]', 'What', 'is', 'ex', '##ponenti', '##ation', '?', 'Expo', '##nent', '##iation', 'is', 'a', 'mathematical', 'operation', ',', 'written', 'as', 'b', '##n', ',', 'involving', 'two', 'numbers', ',', 'the', 'base', 'b', 'and', 'the', 'ex', '##ponent', 'n', '.', 'When', 'n', 'is', 'a', 'positive', 'inte', '##ger', ',', 'ex', '##ponenti', '##ation', 'correspond', '##s', 'to', 'repeated', 'multi', '##plication', 'of', 'the', 'base', ':', 'that', 'is', ',', 'b', '##n', 'is', 'the', 'product', 'of', 'multi', '##ply', '##ing', 'n', 'bases', ':', '[SEP]']
18:40:01.819137: Failed Answer extraction: ['1911', '24', 'November', '1996']; Prompt: ['[CLS]', 'What', 'years', 'did', 'So', '##rley', 'Mac', '##L', '##ean', 'live', '?', 'So', '##rley', 'Mac', '##L', '##ean', '(', 'Scottish', 'Gaelic', ':', 'Som', '##hair', '##le', 'Mac', '##G', '##ill', '-', 'Ea', '##in', ';', '[', 'lower', '-', 'roman', '1', ']', '[', 'lower', '-', 'roman', '2', ']', '26', 'October', '1911', '[UNK]', '24', 'November', '1996', ')', 'was', 'a', 'Scottish', 'Gaelic', 'poet', ',', 'described', 'by', 'the', 'Scottish', 'Poetry', 'Library', 'as', '"', 'one', 'of', 'the', 'major', 'Scottish', 'poets', 'of', 'the', 'modern', 'era', '"', 'because', 'of', 'his', '"', 'master', '##y', 'of', 'his', 'chosen', 'medium', 'and', 'his', 'engagement', 'with', 'the', 'European', 'poet', '##ic', 'tradition', 'and', 'European', 'politics', '"', '.', '[', '2', ']', 'Nobel', 'Prize', 'Lau', '##reate', 'Sea', '##mus', 'He', '##ane', '##y', 'credited', 'Mac', '##L', '##ean', 'with', 'saving', 'Scottish', 'Gaelic', 'poetry', '.', '[', '3', ']', '[SEP]']
18:40:01.893226: Failed Answer extraction: ['February', '15', ',', '1820', 'March', '13', ',', '1906']; Prompt: ['[CLS]', 'When', 'did', 'Susan', 'B', '.', 'Anthony', 'live', '?', 'Susan', 'B', '.', 'Anthony', '(', 'February', '15', ',', '1820', '[UNK]', 'March', '13', ',', '1906', ')', 'was', 'an', 'American', 'social', 'reform', '##er', 'and', 'women', "'", 's', 'rights', 'activist', 'who', 'played', 'a', 'pi', '##vot', '##al', 'role', 'in', 'the', 'women', "'", 's', 'su', '##ffrage', 'movement', '.', 'Born', 'into', 'a', 'Qua', '##ker', 'family', 'committed', 'to', 'social', 'equality', ',', 'she', 'collected', 'anti', '-', 'slavery', 'petition', '##s', 'at', 'the', 'age', 'of', '17', '.', 'In', '1856', ',', 'she', 'became', 'the', 'New', 'York', 'state', 'agent', 'for', 'the', 'American', 'Anti', '-', 'Slave', '##ry', 'Society', '.', '[SEP]']
18:40:01.917465: Failed Answer extraction: ['Leon', 'Eli', '##ne']; Prompt: ['[CLS]', 'What', 'was', 'the', 'first', 'storm', 'to', 'develop', 'in', 'the', '1999', '[UNK]', '2000', 'South', '-', 'West', 'Indian', 'Ocean', 'tropical', 'c', '##yclone', 'season', '?', 'The', '1999', '[UNK]', '2000', 'South', '-', 'West', 'Indian', 'Ocean', 'tropical', 'c', '##yclone', 'season', 'was', 'the', 'first', 'on', 'record', 'in', 'which', 'two', 'storm', '##s', '[UNK]', 'Leon', '[UNK]', 'Eli', '##ne', 'and', 'Hu', '##dah', '[UNK]', 'struck', 'Mozambique', 'at', 'tropical', 'c', '##yclone', 'intensity', ',', 'or', 'with', 'maximum', 'sustained', 'winds', 'of', 'at', 'least', '120', '##km', '/', 'h', '(', '75', '##mp', '##h', ')', '.', '[', '1', ']', 'The', 'most', 'notable', 'storm', 'of', 'the', 'season', 'was', 'Eli', '##ne', ',', 'which', 'was', 'the', 'longest', '-', 'lasting', 'storm', 'on', 'record', 'in', 'the', 'basin', '.', 'It', 'lasted', 'for', '29', '##day', '##s', 'while', 'travers', '##ing', 'the', 'southern', 'Indian', 'Ocean', ',', 'making', 'the', 'strong', '##est', 'land', '##fall', 'in', 'decades', 'along', 'eastern', 'Madagascar', 'in', 'late', 'February', '.', 'The', 'storm', 'was', 'the', 'first', 'in', 'a', 'series', 'of', 'three', 'storm', '##s', 'that', 'struck', 'the', 'country', 'in', 'early', '2000', ',', 'along', 'with', 'Gloria', 'in', 'March', 'and', 'Hu', '##dah', 'in', 'April', '.', 'Collective', '##ly', ',', 'the', 'three', 'storm', '##s', 'killed', 'at', 'least', '316', '##pe', '##op', '##le', '.', 'The', 'season', 'started', 'on', 'November', '##1', ',', '1999', ',', 'and', 'ended', 'for', 'most', 'of', 'the', 'basin', 'on', 'April', '##30', ',', '2000', ';', 'for', 'Mauritius', 'and', 'the', 'Seychelles', ',', 'the', 'season', 'continued', 'until', 'May', '##15', '.', 'These', 'dates', 'conventional', '##ly', 'del', '##imit', 'the', 'period', 'of', 'each', 'year', 'when', 'most', 'tropical', 'c', '##yclone', '##s', 'form', 'in', 'the', 'basin', ';', '[', '2', ']', '[SEP]']
18:40:01.974347: Failed Answer extraction: ['October', '18', ',', '1130', 'April', '23', ',', '1200']; Prompt: ['[CLS]', 'What', 'years', 'did', 'Zhu', 'Xi', 'live', '?', 'Zhu', 'Xi', '(', '[', '[UNK]', ']', ';', 'Chinese', ':', '朱', '熹', ';', 'October', '18', ',', '1130', '[UNK]', 'April', '23', ',', '1200', ')', ',', 'also', 'known', 'by', 'his', 'courte', '##sy', 'name', 'Yuan', '##hu', '##i', '(', 'or', 'Z', '##hong', '##hu', '##i', ')', ',', 'and', 'self', '-', 'titled', 'Hui', "'", 'an', ',', 'was', 'a', 'Chinese', 'philosopher', ',', 'politician', ',', 'and', 'writer', 'of', 'the', 'Song', 'dynasty', '.', 'He', 'was', 'a', 'Con', '##fu', '##cian', 'scholar', 'who', 'was', 'the', 'leading', 'figure', 'of', 'the', 'School', 'of', 'Prin', '##ci', '##ple', 'and', 'the', 'most', 'influential', 'ratio', '##nalis', '##t', 'Neo', '-', 'Con', '##fu', '##cian', 'in', 'China', '.', 'His', 'contributions', 'to', 'Chinese', 'philosophy', 'including', 'his', 'ass', '##ign', '##ing', 'special', 'significance', 'to', 'the', 'Ana', '##lec', '##ts', ',', 'the', 'Men', '##cius', ',', 'the', 'Great', 'Learning', ',', 'and', 'the', 'Doc', '##trine', 'of', 'the', 'Mean', '(', 'the', 'Four', 'Books', ')', ',', 'his', 'emphasis', 'on', 'the', 'investigation', 'of', 'things', '(', 'ge', '##wu', ')', ',', 'and', 'the', 'synthesis', 'of', 'all', 'fundamental', 'Con', '##fu', '##cian', 'concepts', ',', 'formed', 'the', 'basis', 'of', 'Chinese', 'bureau', '##cra', '##cy', 'and', 'government', 'for', 'over', '700', 'years', '.', 'He', 'has', 'been', 'called', 'the', 'second', 'most', 'influential', 'think', '##er', 'in', 'Chinese', 'history', ',', 'after', 'Con', '##fu', '##cius', 'himself', '.', '[', '1', ']', '[SEP]']
18:40:18.871195: Unanswerable questions: 3670
18:40:18.931833: Balance of labels: dict_keys([-100, 0, 1, 2]):dict_values([73551, 921048, 3551, 18312])
18:40:18.931892: Entries skipped due to too long sequence length (>512): 60
18:40:18.931935: Failed to map answer and to context: 108
18:40:18.985393: Label counts: O: 921048, B: 3551, I: 18312
18:40:18.985575: Final length: 7221 

18:40:19.007997: Language: english; Class weights: [0.0032188  0.83488347 0.16189773 0.        ]
18:40:19.008200: Training model: lab6_bert-base-multilingual-cased_english.pt
18:40:19.008240: Loading model: bert-base-multilingual-cased
18:40:21.716611: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 1/40
18:43:08.986476: Evaluating Language: english
18:43:08.987806: ----------
18:43:13.670956: OBI: 
 [[2492  230  475]
 [   0   11    1]
 [   8    7  112]]
18:43:13.675145: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.78      0.87      3197
           1       0.04      0.92      0.08        12
           2       0.19      0.88      0.31       127

    accuracy                           0.78      3336
   macro avg       0.41      0.86      0.42      3336
weighted avg       0.96      0.78      0.85      3336
18:43:13.675189: ----------
18:43:13.675867: LR: 
 [[453 503]
 [  4   8]]
18:43:13.678634: LR: 
               precision    recall  f1-score   support

           0       0.99      0.47      0.64       956
           1       0.02      0.67      0.03        12

    accuracy                           0.48       968
   macro avg       0.50      0.57      0.34       968
weighted avg       0.98      0.48      0.63       968
18:43:13.680509: Validation Seq.Label F1: 0.42424950276451073; Log.Reg F1: 0.33589084694295934; train loss: 0.5910447239875793; Language: english 

18:43:13.680562: Evaluating Language: finnish
18:43:13.680605: ----------
18:43:21.401302: OBI: 
 [[5838  493  753]
 [   4   42    2]
 [ 186   28  197]]
18:43:21.409584: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.82      0.89      7084
           1       0.07      0.88      0.14        48
           2       0.21      0.48      0.29       411

    accuracy                           0.81      7543
   macro avg       0.42      0.73      0.44      7543
weighted avg       0.92      0.81      0.85      7543
18:43:21.409633: ----------
18:43:21.410674: LR: 
 [[1179  392]
 [  25   23]]
18:43:21.414574: LR: 
               precision    recall  f1-score   support

           0       0.98      0.75      0.85      1571
           1       0.06      0.48      0.10        48

    accuracy                           0.74      1619
   macro avg       0.52      0.61      0.47      1619
weighted avg       0.95      0.74      0.83      1619
18:43:21.416484: Validation Seq.Label F1: 0.4390099249322144; Log.Reg F1: 0.47454089078279144; train loss: 0.5910447239875793; Language: finnish 

18:43:21.416553: Evaluating Language: japanese
18:43:21.416604: ----------
18:43:26.106094: OBI: 
 [[3726  289  660]
 [   2   19    0]
 [  22   16  162]]
18:43:26.111218: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.80      0.88      4675
           1       0.06      0.90      0.11        21
           2       0.20      0.81      0.32       200

    accuracy                           0.80      4896
   macro avg       0.42      0.84      0.44      4896
weighted avg       0.96      0.80      0.86      4896
18:43:26.111261: ----------
18:43:26.111899: LR: 
 [[798  41]
 [ 17   4]]
18:43:26.114553: LR: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96       839
           1       0.09      0.19      0.12        21

    accuracy                           0.93       860
   macro avg       0.53      0.57      0.54       860
weighted avg       0.96      0.93      0.94       860
18:43:26.116173: Validation Seq.Label F1: 0.43722691786867324; Log.Reg F1: 0.5430728078853835; train loss: 0.5910447239875793; Language: japanese 

18:43:26.117436: Combined F1 SeqLab: 0.4335453580629762; train loss: 0.5910447239875793
18:43:26.767686: Combined F1 LogReg: 0.4593255173801032; train loss: 0.5910447239875793 

18:43:26.770017: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 2/40
18:46:13.494766: Evaluating Language: english
18:46:13.494890: ----------
18:46:18.122441: OBI: 
 [[2412  309 1270]
 [   0   13    0]
 [   3    7  114]]
18:46:18.128072: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.60      0.75      3991
           1       0.04      1.00      0.08        13
           2       0.08      0.92      0.15       124

    accuracy                           0.62      4128
   macro avg       0.37      0.84      0.33      4128
weighted avg       0.97      0.62      0.73      4128
18:46:18.128122: ----------
18:46:18.128952: LR: 
 [[388 567]
 [  2  11]]
18:46:18.132243: LR: 
               precision    recall  f1-score   support

           0       0.99      0.41      0.58       955
           1       0.02      0.85      0.04        13

    accuracy                           0.41       968
   macro avg       0.51      0.63      0.31       968
weighted avg       0.98      0.41      0.57       968
18:46:18.136881: Validation Seq.Label F1: 0.326753682331739; Log.Reg F1: 0.307088357581819; train loss: 0.3729100823402405; Language: english 

18:46:18.136953: Evaluating Language: finnish
18:46:18.137004: ----------
18:46:26.040624: OBI: 
 [[3957  384  935]
 [   2   26    1]
 [  57   29  239]]
18:46:26.046288: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.75      0.85      5276
           1       0.06      0.90      0.11        29
           2       0.20      0.74      0.32       325

    accuracy                           0.75      5630
   macro avg       0.42      0.79      0.43      5630
weighted avg       0.94      0.75      0.82      5630
18:46:26.046339: ----------
18:46:26.047205: LR: 
 [[1110  480]
 [   8   21]]
18:46:26.050495: LR: 
               precision    recall  f1-score   support

           0       0.99      0.70      0.82      1590
           1       0.04      0.72      0.08        29

    accuracy                           0.70      1619
   macro avg       0.52      0.71      0.45      1619
weighted avg       0.98      0.70      0.81      1619
18:46:26.052170: Validation Seq.Label F1: 0.42715938840260836; Log.Reg F1: 0.44951924416822264; train loss: 0.3729100823402405; Language: finnish 

18:46:26.052222: Evaluating Language: japanese
18:46:26.052265: ----------
18:46:30.729441: OBI: 
 [[2516  158  459]
 [   0   14    1]
 [   2    8  110]]
18:46:30.733452: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.80      0.89      3133
           1       0.08      0.93      0.14        15
           2       0.19      0.92      0.32       120

    accuracy                           0.81      3268
   macro avg       0.42      0.88      0.45      3268
weighted avg       0.97      0.81      0.87      3268
18:46:30.733494: ----------
18:46:30.734129: LR: 
 [[469 376]
 [  2  13]]
18:46:30.736808: LR: 
               precision    recall  f1-score   support

           0       1.00      0.56      0.71       845
           1       0.03      0.87      0.06        15

    accuracy                           0.56       860
   macro avg       0.51      0.71      0.39       860
weighted avg       0.98      0.56      0.70       860
18:46:30.738455: Validation Seq.Label F1: 0.45096406281883256; Log.Reg F1: 0.3885611965451864; train loss: 0.3729100823402405; Language: japanese 

18:46:30.739722: Combined F1 SeqLab: 0.4052166901679106; train loss: 0.3729100823402405
18:46:30.740973: Combined F1 LogReg: 0.3861565372145068; train loss: 0.3729100823402405 

18:46:30.741573: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 3/40
18:49:17.924903: Evaluating Language: english
18:49:17.925012: ----------
18:49:22.620889: OBI: 
 [[2049  135  352]
 [   0    7    0]
 [   3    6   96]]
18:49:22.624858: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.81      0.89      2536
           1       0.05      1.00      0.09         7
           2       0.21      0.91      0.35       105

    accuracy                           0.81      2648
   macro avg       0.42      0.91      0.44      2648
weighted avg       0.96      0.81      0.87      2648
18:49:22.624902: ----------
18:49:22.625580: LR: 
 [[474 487]
 [  0   7]]
18:49:22.628330: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       961
           1       0.01      1.00      0.03         7

    accuracy                           0.50       968
   macro avg       0.51      0.75      0.34       968
weighted avg       0.99      0.50      0.66       968
18:49:22.630249: Validation Seq.Label F1: 0.44357311286670215; Log.Reg F1: 0.34428564473839773; train loss: 0.2638080418109894; Language: english 

18:49:22.630303: Evaluating Language: finnish
18:49:22.630354: ----------
18:49:30.372853: OBI: 
 [[4266  314  713]
 [   2   33    0]
 [ 115   25  243]]
18:49:30.378510: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.81      0.88      5293
           1       0.09      0.94      0.16        35
           2       0.25      0.63      0.36       383

    accuracy                           0.80      5711
   macro avg       0.44      0.79      0.47      5711
weighted avg       0.92      0.80      0.84      5711
18:49:30.378554: ----------
18:49:30.379422: LR: 
 [[1048  536]
 [  13   22]]
18:49:30.382682: LR: 
               precision    recall  f1-score   support

           0       0.99      0.66      0.79      1584
           1       0.04      0.63      0.07        35

    accuracy                           0.66      1619
   macro avg       0.51      0.65      0.43      1619
weighted avg       0.97      0.66      0.78      1619
18:49:30.384367: Validation Seq.Label F1: 0.46896297308286533; Log.Reg F1: 0.4333187757613239; train loss: 0.2638080418109894; Language: finnish 

18:49:30.384418: Evaluating Language: japanese
18:49:30.384460: ----------
18:49:34.940346: OBI: 
 [[4234  203  516]
 [   3   21    1]
 [  34   11  149]]
18:49:34.945595: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.85      0.92      4953
           1       0.09      0.84      0.16        25
           2       0.22      0.77      0.35       194

    accuracy                           0.85      5172
   macro avg       0.43      0.82      0.48      5172
weighted avg       0.96      0.85      0.89      5172
18:49:34.945638: ----------
18:49:34.946268: LR: 
 [[457 378]
 [  6  19]]
18:49:34.948940: LR: 
               precision    recall  f1-score   support

           0       0.99      0.55      0.70       835
           1       0.05      0.76      0.09        25

    accuracy                           0.55       860
   macro avg       0.52      0.65      0.40       860
weighted avg       0.96      0.55      0.69       860
18:49:34.950615: Validation Seq.Label F1: 0.4753633284563719; Log.Reg F1: 0.3971038199490284; train loss: 0.2638080418109894; Language: japanese 

18:49:34.951899: Combined F1 SeqLab: 0.46283678571108156; train loss: 0.2638080418109894
18:49:35.556277: Combined F1 LogReg: 0.3932722595600225; train loss: 0.2638080418109894 

18:49:35.557086: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 4/40
18:52:22.132411: Evaluating Language: english
18:52:22.132574: ----------
18:52:26.697767: OBI: 
 [[3579  100  232]
 [   1   12    1]
 [  36    8  103]]
18:52:26.702426: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95      3911
           1       0.10      0.86      0.18        14
           2       0.31      0.70      0.43       147

    accuracy                           0.91      4072
   macro avg       0.47      0.82      0.52      4072
weighted avg       0.96      0.91      0.93      4072
18:52:26.702469: ----------
18:52:26.703162: LR: 
 [[474 480]
 [  3  11]]
18:52:26.705931: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.66       954
           1       0.02      0.79      0.04        14

    accuracy                           0.50       968
   macro avg       0.51      0.64      0.35       968
weighted avg       0.98      0.50      0.65       968
18:52:26.708303: Validation Seq.Label F1: 0.5188606658212896; Log.Reg F1: 0.3530190754924549; train loss: 0.18498976528644562; Language: english 

18:52:26.708373: Evaluating Language: finnish
18:52:26.708416: ----------
18:52:34.356110: OBI: 
 [[6172  250  491]
 [   3   25    0]
 [ 159   18  257]]
18:52:34.362861: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.89      0.93      6913
           1       0.09      0.89      0.16        28
           2       0.34      0.59      0.43       434

    accuracy                           0.88      7375
   macro avg       0.47      0.79      0.51      7375
weighted avg       0.93      0.88      0.90      7375
18:52:34.362908: ----------
18:52:34.363795: LR: 
 [[959 632]
 [  8  20]]
18:52:34.367108: LR: 
               precision    recall  f1-score   support

           0       0.99      0.60      0.75      1591
           1       0.03      0.71      0.06        28

    accuracy                           0.60      1619
   macro avg       0.51      0.66      0.40      1619
weighted avg       0.98      0.60      0.74      1619
18:52:34.368806: Validation Seq.Label F1: 0.5074843461851148; Log.Reg F1: 0.4043140321022858; train loss: 0.18498976528644562; Language: finnish 

18:52:34.368858: Evaluating Language: japanese
18:52:34.368899: ----------
18:52:38.982601: OBI: 
 [[5060  206  434]
 [   1   23    1]
 [  44    9  174]]
18:52:38.989448: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      5700
           1       0.10      0.92      0.17        25
           2       0.29      0.77      0.42       227

    accuracy                           0.88      5952
   macro avg       0.46      0.86      0.51      5952
weighted avg       0.96      0.88      0.91      5952
18:52:38.989498: ----------
18:52:38.990253: LR: 
 [[612 223]
 [  8  17]]
18:52:38.993465: LR: 
               precision    recall  f1-score   support

           0       0.99      0.73      0.84       835
           1       0.07      0.68      0.13        25

    accuracy                           0.73       860
   macro avg       0.53      0.71      0.48       860
weighted avg       0.96      0.73      0.82       860
18:52:38.995465: Validation Seq.Label F1: 0.5092587699633649; Log.Reg F1: 0.4847695000972574; train loss: 0.18498976528644562; Language: japanese 

18:52:38.996968: Combined F1 SeqLab: 0.5118923216667235; train loss: 0.18498976528644562
18:52:39.671639: Combined F1 LogReg: 0.4175698633925029; train loss: 0.18498976528644562 

18:52:39.672452: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 5/40
18:55:25.648294: Evaluating Language: english
18:55:25.648401: ----------
18:55:30.292360: OBI: 
 [[3309   79  312]
 [   1   12    0]
 [  30    3  102]]
18:55:30.296765: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      3700
           1       0.13      0.92      0.22        13
           2       0.25      0.76      0.37       135

    accuracy                           0.89      3848
   macro avg       0.45      0.86      0.51      3848
weighted avg       0.96      0.89      0.92      3848
18:55:30.296807: ----------
18:55:30.297483: LR: 
 [[463 492]
 [  2  11]]
18:55:30.300252: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65       955
           1       0.02      0.85      0.04        13

    accuracy                           0.49       968
   macro avg       0.51      0.67      0.35       968
weighted avg       0.98      0.49      0.64       968
18:55:30.302223: Validation Seq.Label F1: 0.511980194351977; Log.Reg F1: 0.34737416748553335; train loss: 0.1408357471227646; Language: english 

18:55:30.302280: Evaluating Language: finnish
18:55:30.302334: ----------
18:55:38.160418: OBI: 
 [[5248  169  636]
 [   3   30    3]
 [ 167    9  228]]
18:55:38.166545: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.87      0.92      6053
           1       0.14      0.83      0.25        36
           2       0.26      0.56      0.36       404

    accuracy                           0.85      6493
   macro avg       0.46      0.75      0.51      6493
weighted avg       0.92      0.85      0.88      6493
18:55:38.166588: ----------
18:55:38.167477: LR: 
 [[975 608]
 [ 11  25]]
18:55:38.170881: LR: 
               precision    recall  f1-score   support

           0       0.99      0.62      0.76      1583
           1       0.04      0.69      0.07        36

    accuracy                           0.62      1619
   macro avg       0.51      0.66      0.42      1619
weighted avg       0.97      0.62      0.74      1619
18:55:38.173335: Validation Seq.Label F1: 0.5065591035003495; Log.Reg F1: 0.4168943148183382; train loss: 0.1408357471227646; Language: finnish 

18:55:38.173404: Evaluating Language: japanese
18:55:38.173456: ----------
18:55:42.832974: OBI: 
 [[6412  123  467]
 [   4   28    2]
 [  81    6  161]]
18:55:42.839570: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95      7002
           1       0.18      0.82      0.29        34
           2       0.26      0.65      0.37       248

    accuracy                           0.91      7284
   macro avg       0.47      0.80      0.54      7284
weighted avg       0.96      0.91      0.93      7284
18:55:42.839613: ----------
18:55:42.840249: LR: 
 [[586 240]
 [ 11  23]]
18:55:42.842911: LR: 
               precision    recall  f1-score   support

           0       0.98      0.71      0.82       826
           1       0.09      0.68      0.15        34

    accuracy                           0.71       860
   macro avg       0.53      0.69      0.49       860
weighted avg       0.95      0.71      0.80       860
18:55:42.844896: Validation Seq.Label F1: 0.5366442033701162; Log.Reg F1: 0.4892471210110001; train loss: 0.1408357471227646; Language: japanese 

18:55:42.846188: Combined F1 SeqLab: 0.5185598151799888; train loss: 0.1408357471227646
18:55:43.470640: Combined F1 LogReg: 0.42183425946757463; train loss: 0.1408357471227646 

18:55:43.471977: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 6/40
18:58:28.576754: Evaluating Language: english
18:58:28.576893: ----------
18:58:33.266415: OBI: 
 [[2966   76  206]
 [   2    9    1]
 [  17    4   63]]
18:58:33.270763: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      3248
           1       0.10      0.75      0.18        12
           2       0.23      0.75      0.36        84

    accuracy                           0.91      3344
   macro avg       0.44      0.80      0.50      3344
weighted avg       0.97      0.91      0.93      3344
18:58:33.270815: ----------
18:58:33.271638: LR: 
 [[440 516]
 [  2  10]]
18:58:33.274917: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63       956
           1       0.02      0.83      0.04        12

    accuracy                           0.46       968
   macro avg       0.51      0.65      0.33       968
weighted avg       0.98      0.46      0.62       968
18:58:33.276914: Validation Seq.Label F1: 0.49528622423108887; Log.Reg F1: 0.3333226967893592; train loss: 0.11301716417074203; Language: english 

18:58:33.276978: Evaluating Language: finnish
18:58:33.277025: ----------
18:58:41.078092: OBI: 
 [[7059  233  463]
 [   7   35    1]
 [ 205   13  223]]
18:58:41.085804: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.91      0.94      7755
           1       0.12      0.81      0.22        43
           2       0.32      0.51      0.40       441

    accuracy                           0.89      8239
   macro avg       0.47      0.74      0.52      8239
weighted avg       0.93      0.89      0.91      8239
18:58:41.085849: ----------
18:58:41.086730: LR: 
 [[1065  511]
 [  17   26]]
18:58:41.090182: LR: 
               precision    recall  f1-score   support

           0       0.98      0.68      0.80      1576
           1       0.05      0.60      0.09        43

    accuracy                           0.67      1619
   macro avg       0.52      0.64      0.45      1619
weighted avg       0.96      0.67      0.78      1619
18:58:41.092277: Validation Seq.Label F1: 0.5170036210649345; Log.Reg F1: 0.4455047871098311; train loss: 0.11301716417074203; Language: finnish 

18:58:41.092336: Evaluating Language: japanese
18:58:41.092379: ----------
18:58:45.715821: OBI: 
 [[4463   69  169]
 [   3   17    1]
 [  50    3   89]]
18:58:45.720814: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      4701
           1       0.19      0.81      0.31        21
           2       0.34      0.63      0.44       142

    accuracy                           0.94      4864
   macro avg       0.51      0.80      0.57      4864
weighted avg       0.97      0.94      0.95      4864
18:58:45.720857: ----------
18:58:45.721498: LR: 
 [[647 192]
 [  5  16]]
18:58:45.724163: LR: 
               precision    recall  f1-score   support

           0       0.99      0.77      0.87       839
           1       0.08      0.76      0.14        21

    accuracy                           0.77       860
   macro avg       0.53      0.77      0.50       860
weighted avg       0.97      0.77      0.85       860
18:58:45.725845: Validation Seq.Label F1: 0.573803029454451; Log.Reg F1: 0.5038059506969035; train loss: 0.11301716417074203; Language: japanese 

18:58:45.727123: Combined F1 SeqLab: 0.5297329845366904; train loss: 0.11301716417074203
18:58:46.347067: Combined F1 LogReg: 0.43335857804298655; train loss: 0.11301716417074203 

18:58:46.348133: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 7/40
19:01:33.599920: Evaluating Language: english
19:01:33.600088: ----------
19:01:38.467606: OBI: 
 [[3696   51  279]
 [   2   11    5]
 [  25    5  214]]
19:01:38.472384: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95      4026
           1       0.16      0.61      0.26        18
           2       0.43      0.88      0.58       244

    accuracy                           0.91      4288
   macro avg       0.53      0.80      0.60      4288
weighted avg       0.96      0.91      0.93      4288
19:01:38.472427: ----------
19:01:38.473114: LR: 
 [[473 477]
 [  1  17]]
19:01:38.475873: LR: 
               precision    recall  f1-score   support

           0       1.00      0.50      0.66       950
           1       0.03      0.94      0.07        18

    accuracy                           0.51       968
   macro avg       0.52      0.72      0.37       968
weighted avg       0.98      0.51      0.65       968
19:01:38.480527: Validation Seq.Label F1: 0.596524158571748; Log.Reg F1: 0.3653660463483146; train loss: 0.08567851036787033; Language: english 

19:01:38.480586: Evaluating Language: finnish
19:01:38.480629: ----------
19:01:46.118135: OBI: 
 [[4175   93  221]
 [   9   17    1]
 [ 118   10  141]]
19:01:46.123173: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.93      0.95      4489
           1       0.14      0.63      0.23        27
           2       0.39      0.52      0.45       269

    accuracy                           0.91      4785
   macro avg       0.50      0.69      0.54      4785
weighted avg       0.93      0.91      0.92      4785
19:01:46.123216: ----------
19:01:46.124101: LR: 
 [[889 703]
 [  5  22]]
19:01:46.127443: LR: 
               precision    recall  f1-score   support

           0       0.99      0.56      0.72      1592
           1       0.03      0.81      0.06        27

    accuracy                           0.56      1619
   macro avg       0.51      0.69      0.39      1619
weighted avg       0.98      0.56      0.70      1619
19:01:46.129130: Validation Seq.Label F1: 0.5424433690783379; Log.Reg F1: 0.3868578935656699; train loss: 0.08567851036787033; Language: finnish 

19:01:46.129185: Evaluating Language: japanese
19:01:46.129227: ----------
19:01:50.714362: OBI: 
 [[5800   74  222]
 [   3   22    1]
 [  37    7  170]]
19:01:50.720220: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      6096
           1       0.21      0.85      0.34        26
           2       0.43      0.79      0.56       214

    accuracy                           0.95      6336
   macro avg       0.55      0.86      0.62      6336
weighted avg       0.97      0.95      0.96      6336
19:01:50.720265: ----------
19:01:50.720907: LR: 
 [[594 240]
 [  7  19]]
19:01:50.723534: LR: 
               precision    recall  f1-score   support

           0       0.99      0.71      0.83       834
           1       0.07      0.73      0.13        26

    accuracy                           0.71       860
   macro avg       0.53      0.72      0.48       860
weighted avg       0.96      0.71      0.81       860
19:01:50.725243: Validation Seq.Label F1: 0.624355644328737; Log.Reg F1: 0.48060394889663177; train loss: 0.08567851036787033; Language: japanese 

19:01:50.726526: Combined F1 SeqLab: 0.5887574064705945; train loss: 0.08567851036787033
19:01:51.444719: Combined F1 LogReg: 0.41397726722341577; train loss: 0.08567851036787033 

19:01:51.445533: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 8/40
19:04:37.664360: Evaluating Language: english
19:04:37.664461: ----------
19:04:42.373188: OBI: 
 [[2889   69  357]
 [   1   13    2]
 [  18    0  123]]
19:04:42.377324: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.87      0.93      3315
           1       0.16      0.81      0.27        16
           2       0.26      0.87      0.39       141

    accuracy                           0.87      3472
   macro avg       0.47      0.85      0.53      3472
weighted avg       0.96      0.87      0.90      3472
19:04:42.377368: ----------
19:04:42.378038: LR: 
 [[409 543]
 [  2  14]]
19:04:42.380790: LR: 
               precision    recall  f1-score   support

           0       1.00      0.43      0.60       952
           1       0.03      0.88      0.05        16

    accuracy                           0.44       968
   macro avg       0.51      0.65      0.32       968
weighted avg       0.98      0.44      0.59       968
19:04:42.382681: Validation Seq.Label F1: 0.5295535891079426; Log.Reg F1: 0.32450617734465725; train loss: 0.07533425092697144; Language: english 

19:04:42.382735: Evaluating Language: finnish
19:04:42.382777: ----------
19:04:50.070839: OBI: 
 [[5935  172  436]
 [   8   25    0]
 [ 175   11  210]]
19:04:50.077202: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.91      0.94      6543
           1       0.12      0.76      0.21        33
           2       0.33      0.53      0.40       396

    accuracy                           0.88      6972
   macro avg       0.47      0.73      0.52      6972
weighted avg       0.93      0.88      0.90      6972
19:04:50.077244: ----------
19:04:50.078117: LR: 
 [[811 775]
 [  6  27]]
19:04:50.081417: LR: 
               precision    recall  f1-score   support

           0       0.99      0.51      0.67      1586
           1       0.03      0.82      0.06        33

    accuracy                           0.52      1619
   macro avg       0.51      0.66      0.37      1619
weighted avg       0.97      0.52      0.66      1619
19:04:50.083197: Validation Seq.Label F1: 0.5160215263457144; Log.Reg F1: 0.36983012751027283; train loss: 0.07533425092697144; Language: finnish 

19:04:50.083247: Evaluating Language: japanese
19:04:50.083290: ----------
19:04:54.592944: OBI: 
 [[3441   90  363]
 [   2   17    3]
 [  10    2  136]]
19:04:54.597469: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.94      3894
           1       0.16      0.77      0.26        22
           2       0.27      0.92      0.42       148

    accuracy                           0.88      4064
   macro avg       0.47      0.86      0.54      4064
weighted avg       0.97      0.88      0.91      4064
19:04:54.597511: ----------
19:04:54.598141: LR: 
 [[530 308]
 [  3  19]]
19:04:54.600812: LR: 
               precision    recall  f1-score   support

           0       0.99      0.63      0.77       838
           1       0.06      0.86      0.11        22

    accuracy                           0.64       860
   macro avg       0.53      0.75      0.44       860
weighted avg       0.97      0.64      0.76       860
19:04:54.602764: Validation Seq.Label F1: 0.5382374613179522; Log.Reg F1: 0.4410204000593548; train loss: 0.07533425092697144; Language: japanese 

19:04:54.604043: Combined F1 SeqLab: 0.528016661402289; train loss: 0.07533425092697144
19:04:54.605321: Combined F1 LogReg: 0.3814785164844892; train loss: 0.07533425092697144 

19:04:54.605891: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 9/40
19:07:40.448351: Evaluating Language: english
19:07:40.448483: ----------
19:07:45.118457: OBI: 
 [[4488   81  296]
 [   2   17    2]
 [  23    2  113]]
19:07:45.123691: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.96      4865
           1       0.17      0.81      0.28        21
           2       0.27      0.82      0.41       138

    accuracy                           0.92      5024
   macro avg       0.48      0.85      0.55      5024
weighted avg       0.97      0.92      0.94      5024
19:07:45.123734: ----------
19:07:45.124431: LR: 
 [[430 517]
 [  1  20]]
19:07:45.127191: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62       947
           1       0.04      0.95      0.07        21

    accuracy                           0.46       968
   macro avg       0.52      0.70      0.35       968
weighted avg       0.98      0.46      0.61       968
19:07:45.131480: Validation Seq.Label F1: 0.5499276706487418; Log.Reg F1: 0.3478887380287259; train loss: 0.07140898704528809; Language: english 

19:07:45.131542: Evaluating Language: finnish
19:07:45.131586: ----------
19:07:52.972216: OBI: 
 [[6696  106  174]
 [   8   29    3]
 [ 272   15  178]]
19:07:52.978981: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.96      0.96      6976
           1       0.19      0.72      0.31        40
           2       0.50      0.38      0.43       465

    accuracy                           0.92      7481
   macro avg       0.55      0.69      0.57      7481
weighted avg       0.93      0.92      0.92      7481
19:07:52.979027: ----------
19:07:52.979904: LR: 
 [[1082  497]
 [  16   24]]
19:07:52.983185: LR: 
               precision    recall  f1-score   support

           0       0.99      0.69      0.81      1579
           1       0.05      0.60      0.09        40

    accuracy                           0.68      1619
   macro avg       0.52      0.64      0.45      1619
weighted avg       0.96      0.68      0.79      1619
19:07:52.984957: Validation Seq.Label F1: 0.5664239615597507; Log.Reg F1: 0.44696453648529066; train loss: 0.07140898704528809; Language: finnish 

19:07:52.985012: Evaluating Language: japanese
19:07:52.985055: ----------
19:07:57.524656: OBI: 
 [[4909   43  131]
 [   2   20    0]
 [  30    9  156]]
19:07:57.529896: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.97      0.98      5083
           1       0.28      0.91      0.43        22
           2       0.54      0.80      0.65       195

    accuracy                           0.96      5300
   macro avg       0.60      0.89      0.68      5300
weighted avg       0.97      0.96      0.96      5300
19:07:57.529939: ----------
19:07:57.530587: LR: 
 [[573 265]
 [  6  16]]
19:07:57.533256: LR: 
               precision    recall  f1-score   support

           0       0.99      0.68      0.81       838
           1       0.06      0.73      0.11        22

    accuracy                           0.68       860
   macro avg       0.52      0.71      0.46       860
weighted avg       0.97      0.68      0.79       860
19:07:57.534984: Validation Seq.Label F1: 0.6840947136953416; Log.Reg F1: 0.4571807216007415; train loss: 0.07140898704528809; Language: japanese 

19:07:57.536279: Combined F1 SeqLab: 0.6031147277481305; train loss: 0.07140898704528809
19:07:58.173893: Combined F1 LogReg: 0.4202451995070279; train loss: 0.07140898704528809 

19:07:58.174725: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 10/40
19:10:43.862864: Evaluating Language: english
19:10:43.862969: ----------
19:10:48.649581: OBI: 
 [[3578   72  203]
 [   1   13    4]
 [  38    4  119]]
19:10:48.654136: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      3853
           1       0.15      0.72      0.24        18
           2       0.37      0.74      0.49       161

    accuracy                           0.92      4032
   macro avg       0.50      0.80      0.56      4032
weighted avg       0.96      0.92      0.94      4032
19:10:48.654179: ----------
19:10:48.654854: LR: 
 [[507 443]
 [  1  17]]
19:10:48.657612: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.70       950
           1       0.04      0.94      0.07        18

    accuracy                           0.54       968
   macro avg       0.52      0.74      0.38       968
weighted avg       0.98      0.54      0.68       968
19:10:48.659568: Validation Seq.Label F1: 0.5632207379394867; Log.Reg F1: 0.38330147907088863; train loss: 0.0829157680273056; Language: english 

19:10:48.659623: Evaluating Language: finnish
19:10:48.659665: ----------
19:10:56.474711: OBI: 
 [[4062  124  270]
 [   5   16    1]
 [ 127   12  122]]
19:10:56.479692: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.91      0.94      4456
           1       0.11      0.73      0.18        22
           2       0.31      0.47      0.37       261

    accuracy                           0.89      4739
   macro avg       0.46      0.70      0.50      4739
weighted avg       0.93      0.89      0.90      4739
19:10:56.479738: ----------
19:10:56.480619: LR: 
 [[665 932]
 [  2  20]]
19:10:56.483907: LR: 
               precision    recall  f1-score   support

           0       1.00      0.42      0.59      1597
           1       0.02      0.91      0.04        22

    accuracy                           0.42      1619
   macro avg       0.51      0.66      0.31      1619
weighted avg       0.98      0.42      0.58      1619
19:10:56.485561: Validation Seq.Label F1: 0.49872916081246293; Log.Reg F1: 0.3142617960978371; train loss: 0.0829157680273056; Language: finnish 

19:10:56.485617: Evaluating Language: japanese
19:10:56.485661: ----------
19:11:01.004930: OBI: 
 [[5592  162  518]
 [   3   21    0]
 [  41    3  192]]
19:11:01.010942: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      6272
           1       0.11      0.88      0.20        24
           2       0.27      0.81      0.41       236

    accuracy                           0.89      6532
   macro avg       0.46      0.86      0.52      6532
weighted avg       0.96      0.89      0.92      6532
19:11:01.010984: ----------
19:11:01.011628: LR: 
 [[340 496]
 [  1  23]]
19:11:01.014306: LR: 
               precision    recall  f1-score   support

           0       1.00      0.41      0.58       836
           1       0.04      0.96      0.08        24

    accuracy                           0.42       860
   macro avg       0.52      0.68      0.33       860
weighted avg       0.97      0.42      0.56       860
19:11:01.016006: Validation Seq.Label F1: 0.5150400663958092; Log.Reg F1: 0.33122728289765; train loss: 0.0829157680273056; Language: japanese 

19:11:01.017294: Combined F1 SeqLab: 0.5263758623780802; train loss: 0.0829157680273056
19:11:01.018585: Combined F1 LogReg: 0.3441860026595742; train loss: 0.0829157680273056 

19:11:01.019160: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 11/40
19:13:46.909833: Evaluating Language: english
19:13:46.909951: ----------
19:13:51.465800: OBI: 
 [[3326   57  202]
 [   3    8    3]
 [  24    1   88]]
19:13:51.470215: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      3585
           1       0.12      0.57      0.20        14
           2       0.30      0.78      0.43       113

    accuracy                           0.92      3712
   macro avg       0.47      0.76      0.53      3712
weighted avg       0.97      0.92      0.94      3712
19:13:51.470256: ----------
19:13:51.470943: LR: 
 [[433 521]
 [  2  12]]
19:13:51.473700: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62       954
           1       0.02      0.86      0.04        14

    accuracy                           0.46       968
   macro avg       0.51      0.66      0.33       968
weighted avg       0.98      0.46      0.62       968
19:13:51.475669: Validation Seq.Label F1: 0.5307584275646223; Log.Reg F1: 0.33367290397389776; train loss: 0.06208081170916557; Language: english 

19:13:51.475728: Evaluating Language: finnish
19:13:51.475771: ----------
19:13:59.276934: OBI: 
 [[4472   75  155]
 [   9   14    1]
 [ 112    6  139]]
19:13:59.281998: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.95      0.96      4702
           1       0.15      0.58      0.24        24
           2       0.47      0.54      0.50       257

    accuracy                           0.93      4983
   macro avg       0.53      0.69      0.57      4983
weighted avg       0.94      0.93      0.94      4983
19:13:59.282041: ----------
19:13:59.282914: LR: 
 [[788 807]
 [  8  16]]
19:13:59.286218: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.66      1595
           1       0.02      0.67      0.04        24

    accuracy                           0.50      1619
   macro avg       0.50      0.58      0.35      1619
weighted avg       0.98      0.50      0.65      1619
19:13:59.287991: Validation Seq.Label F1: 0.5670516894302061; Log.Reg F1: 0.3484594186088426; train loss: 0.06208081170916557; Language: finnish 

19:13:59.288041: Evaluating Language: japanese
19:13:59.288083: ----------
19:14:04.017913: OBI: 
 [[3769   46  234]
 [   2   14    1]
 [  54    1  115]]
19:14:04.022486: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      4049
           1       0.23      0.82      0.36        17
           2       0.33      0.68      0.44       170

    accuracy                           0.92      4236
   macro avg       0.51      0.81      0.59      4236
weighted avg       0.96      0.92      0.93      4236
19:14:04.022529: ----------
19:14:04.023158: LR: 
 [[659 184]
 [  6  11]]
19:14:04.025780: LR: 
               precision    recall  f1-score   support

           0       0.99      0.78      0.87       843
           1       0.06      0.65      0.10        17

    accuracy                           0.78       860
   macro avg       0.52      0.71      0.49       860
weighted avg       0.97      0.78      0.86       860
19:14:04.027616: Validation Seq.Label F1: 0.5862033219792936; Log.Reg F1: 0.488889444972724; train loss: 0.06208081170916557; Language: japanese 

19:14:04.028878: Combined F1 SeqLab: 0.5618085265806257; train loss: 0.06208081170916557
19:14:04.030124: Combined F1 LogReg: 0.3965578825633255; train loss: 0.06208081170916557 

19:14:04.030700: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 12/40
19:16:51.604547: Evaluating Language: english
19:16:51.604677: ----------
19:16:56.227686: OBI: 
 [[2461   24  137]
 [   3    4    1]
 [   9    2  103]]
19:16:56.231392: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97      2622
           1       0.13      0.50      0.21         8
           2       0.43      0.90      0.58       114

    accuracy                           0.94      2744
   macro avg       0.52      0.78      0.59      2744
weighted avg       0.97      0.94      0.95      2744
19:16:56.231435: ----------
19:16:56.232123: LR: 
 [[459 501]
 [  2   6]]
19:16:56.234873: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65       960
           1       0.01      0.75      0.02         8

    accuracy                           0.48       968
   macro avg       0.50      0.61      0.33       968
weighted avg       0.99      0.48      0.64       968
19:16:56.236920: Validation Seq.Label F1: 0.5856177160755626; Log.Reg F1: 0.33466244884294527; train loss: 0.04604540020227432; Language: english 

19:16:56.236974: Evaluating Language: finnish
19:16:56.237016: ----------
19:17:04.033120: OBI: 
 [[6805   75  244]
 [   6   18    2]
 [ 208    4  205]]
19:17:04.039970: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.96      7124
           1       0.19      0.69      0.29        26
           2       0.45      0.49      0.47       417

    accuracy                           0.93      7567
   macro avg       0.54      0.71      0.58      7567
weighted avg       0.94      0.93      0.93      7567
19:17:04.040014: ----------
19:17:04.040895: LR: 
 [[1054  539]
 [   7   19]]
19:17:04.044192: LR: 
               precision    recall  f1-score   support

           0       0.99      0.66      0.79      1593
           1       0.03      0.73      0.07        26

    accuracy                           0.66      1619
   macro avg       0.51      0.70      0.43      1619
weighted avg       0.98      0.66      0.78      1619
19:17:04.048732: Validation Seq.Label F1: 0.5757822230762474; Log.Reg F1: 0.4296706444653199; train loss: 0.04604540020227432; Language: finnish 

19:17:04.048787: Evaluating Language: japanese
19:17:04.048830: ----------
19:17:08.618411: OBI: 
 [[3408   30  149]
 [   7    6    1]
 [  36    1   58]]
19:17:08.622797: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      3587
           1       0.16      0.43      0.24        14
           2       0.28      0.61      0.38        95

    accuracy                           0.94      3696
   macro avg       0.48      0.66      0.53      3696
weighted avg       0.97      0.94      0.95      3696
19:17:08.622840: ----------
19:17:08.623479: LR: 
 [[629 217]
 [  7   7]]
19:17:08.626126: LR: 
               precision    recall  f1-score   support

           0       0.99      0.74      0.85       846
           1       0.03      0.50      0.06        14

    accuracy                           0.74       860
   macro avg       0.51      0.62      0.45       860
weighted avg       0.97      0.74      0.84       860
19:17:08.627982: Validation Seq.Label F1: 0.5288631164906772; Log.Reg F1: 0.45383821544812253; train loss: 0.04604540020227432; Language: japanese 

19:17:08.629327: Combined F1 SeqLab: 0.5639649734325751; train loss: 0.04604540020227432
19:17:08.630626: Combined F1 LogReg: 0.40930222866969457; train loss: 0.04604540020227432 

19:17:08.631534: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 13/40
19:19:54.643512: Evaluating Language: english
19:19:54.643623: ----------
19:19:59.251958: OBI: 
 [[2230   39  127]
 [   1    8    2]
 [  19    2   52]]
19:19:59.255501: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      2396
           1       0.16      0.73      0.27        11
           2       0.29      0.71      0.41        73

    accuracy                           0.92      2480
   macro avg       0.48      0.79      0.55      2480
weighted avg       0.97      0.92      0.94      2480
19:19:59.255543: ----------
19:19:59.256210: LR: 
 [[416 541]
 [  0  11]]
19:19:59.258956: LR: 
               precision    recall  f1-score   support

           0       1.00      0.43      0.61       957
           1       0.02      1.00      0.04        11

    accuracy                           0.44       968
   macro avg       0.51      0.72      0.32       968
weighted avg       0.99      0.44      0.60       968
19:19:59.260905: Validation Seq.Label F1: 0.5453603491126243; Log.Reg F1: 0.32252434996681756; train loss: 0.0419505350291729; Language: english 

19:19:59.260967: Evaluating Language: finnish
19:19:59.261009: ----------
19:20:07.080641: OBI: 
 [[7679  104  344]
 [   5   21    2]
 [ 114   12  211]]
19:20:07.088083: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      8127
           1       0.15      0.75      0.25        28
           2       0.38      0.63      0.47       337

    accuracy                           0.93      8492
   macro avg       0.51      0.77      0.56      8492
weighted avg       0.96      0.93      0.94      8492
19:20:07.088127: ----------
19:20:07.089007: LR: 
 [[698 893]
 [  3  25]]
19:20:07.092327: LR: 
               precision    recall  f1-score   support

           0       1.00      0.44      0.61      1591
           1       0.03      0.89      0.05        28

    accuracy                           0.45      1619
   macro avg       0.51      0.67      0.33      1619
weighted avg       0.98      0.45      0.60      1619
19:20:07.094167: Validation Seq.Label F1: 0.5636589510415013; Log.Reg F1: 0.330964583125791; train loss: 0.0419505350291729; Language: finnish 

19:20:07.094226: Evaluating Language: japanese
19:20:07.094274: ----------
19:20:11.658618: OBI: 
 [[3896   44  215]
 [   2   16    1]
 [  15    3   96]]
19:20:11.663225: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97      4155
           1       0.25      0.84      0.39        19
           2       0.31      0.84      0.45       114

    accuracy                           0.93      4288
   macro avg       0.52      0.87      0.60      4288
weighted avg       0.97      0.93      0.95      4288
19:20:11.663266: ----------
19:20:11.663903: LR: 
 [[580 261]
 [  4  15]]
19:20:11.666575: LR: 
               precision    recall  f1-score   support

           0       0.99      0.69      0.81       841
           1       0.05      0.79      0.10        19

    accuracy                           0.69       860
   macro avg       0.52      0.74      0.46       860
weighted avg       0.97      0.69      0.80       860
19:20:11.668244: Validation Seq.Label F1: 0.6022463020582918; Log.Reg F1: 0.4578650014867678; train loss: 0.0419505350291729; Language: japanese 

19:20:11.669516: Combined F1 SeqLab: 0.5709144512144052; train loss: 0.0419505350291729
19:20:11.670770: Combined F1 LogReg: 0.37558837006827245; train loss: 0.0419505350291729 

19:20:11.671359: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 14/40
19:22:56.149879: Evaluating Language: english
19:22:56.150413: ----------
19:23:00.910786: OBI: 
 [[2223   25  123]
 [   2    4    2]
 [  20    2   95]]
19:23:00.914444: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      2371
           1       0.13      0.50      0.21         8
           2       0.43      0.81      0.56       117

    accuracy                           0.93      2496
   macro avg       0.52      0.75      0.58      2496
weighted avg       0.96      0.93      0.94      2496
19:23:00.914486: ----------
19:23:00.915167: LR: 
 [[438 522]
 [  1   7]]
19:23:00.917940: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63       960
           1       0.01      0.88      0.03         8

    accuracy                           0.46       968
   macro avg       0.51      0.67      0.33       968
weighted avg       0.99      0.46      0.62       968
19:23:00.921945: Validation Seq.Label F1: 0.5773660006119417; Log.Reg F1: 0.3261161537304512; train loss: 0.03912464156746864; Language: english 

19:23:00.922006: Evaluating Language: finnish
19:23:00.922049: ----------
19:23:08.636642: OBI: 
 [[5262   63  202]
 [   6   16    0]
 [ 199    6  165]]
19:23:08.642297: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.95      0.96      5527
           1       0.19      0.73      0.30        22
           2       0.45      0.45      0.45       370

    accuracy                           0.92      5919
   macro avg       0.53      0.71      0.57      5919
weighted avg       0.93      0.92      0.92      5919
19:23:08.642346: ----------
19:23:08.643214: LR: 
 [[779 818]
 [  6  16]]
19:23:08.646512: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.65      1597
           1       0.02      0.73      0.04        22

    accuracy                           0.49      1619
   macro avg       0.51      0.61      0.35      1619
weighted avg       0.98      0.49      0.65      1619
19:23:08.648188: Validation Seq.Label F1: 0.5680253411196725; Log.Reg F1: 0.3457276928992365; train loss: 0.03912464156746864; Language: finnish 

19:23:08.648238: Evaluating Language: japanese
19:23:08.648279: ----------
19:23:13.333504: OBI: 
 [[6160   59  394]
 [   5   25    4]
 [ 102    7  156]]
19:23:13.340941: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.96      6613
           1       0.27      0.74      0.40        34
           2       0.28      0.59      0.38       265

    accuracy                           0.92      6912
   macro avg       0.51      0.75      0.58      6912
weighted avg       0.95      0.92      0.93      6912
19:23:13.340989: ----------
19:23:13.341758: LR: 
 [[627 199]
 [ 13  21]]
19:23:13.344930: LR: 
               precision    recall  f1-score   support

           0       0.98      0.76      0.86       826
           1       0.10      0.62      0.17        34

    accuracy                           0.75       860
   macro avg       0.54      0.69      0.51       860
weighted avg       0.94      0.75      0.83       860
19:23:13.346902: Validation Seq.Label F1: 0.5791580400276053; Log.Reg F1: 0.5103715719027618; train loss: 0.03912464156746864; Language: japanese 

19:23:13.348405: Combined F1 SeqLab: 0.574870513578309; train loss: 0.03912464156746864
19:23:13.349886: Combined F1 LogReg: 0.4026406689046153; train loss: 0.03912464156746864 

19:23:13.350580: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 15/40
19:25:57.730249: Evaluating Language: english
19:25:57.730370: ----------
19:26:02.300457: OBI: 
 [[3237   35  206]
 [   2    7    4]
 [  34    3   88]]
19:26:02.305140: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      3478
           1       0.16      0.54      0.24        13
           2       0.30      0.70      0.42       125

    accuracy                           0.92      3616
   macro avg       0.48      0.72      0.54      3616
weighted avg       0.96      0.92      0.94      3616
19:26:02.305184: ----------
19:26:02.305857: LR: 
 [[440 515]
 [  1  12]]
19:26:02.308915: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63       955
           1       0.02      0.92      0.04        13

    accuracy                           0.47       968
   macro avg       0.51      0.69      0.34       968
weighted avg       0.98      0.47      0.62       968
19:26:02.310877: Validation Seq.Label F1: 0.538808000695498; Log.Reg F1: 0.33740846864056034; train loss: 0.046409446746110916; Language: english 

19:26:02.310930: Evaluating Language: finnish
19:26:02.310972: ----------
19:26:10.104566: OBI: 
 [[7062  137  548]
 [   7   24    7]
 [ 130   12  263]]
19:26:10.111817: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.91      0.95      7747
           1       0.14      0.63      0.23        38
           2       0.32      0.65      0.43       405

    accuracy                           0.90      8190
   macro avg       0.48      0.73      0.53      8190
weighted avg       0.94      0.90      0.92      8190
19:26:10.111860: ----------
19:26:10.112741: LR: 
 [[829 752]
 [  3  35]]
19:26:10.116054: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.69      1581
           1       0.04      0.92      0.08        38

    accuracy                           0.53      1619
   macro avg       0.52      0.72      0.39      1619
weighted avg       0.97      0.53      0.67      1619
19:26:10.117768: Validation Seq.Label F1: 0.5341933672161591; Log.Reg F1: 0.3859799821673008; train loss: 0.046409446746110916; Language: finnish 

19:26:10.117822: Evaluating Language: japanese
19:26:10.117863: ----------
19:26:14.713502: OBI: 
 [[4536   64  307]
 [   3   17    2]
 [  50    0  157]]
19:26:14.718635: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.96      4907
           1       0.21      0.77      0.33        22
           2       0.34      0.76      0.47       207

    accuracy                           0.92      5136
   macro avg       0.51      0.82      0.58      5136
weighted avg       0.96      0.92      0.93      5136
19:26:14.718678: ----------
19:26:14.719319: LR: 
 [[365 473]
 [  4  18]]
19:26:14.721982: LR: 
               precision    recall  f1-score   support

           0       0.99      0.44      0.60       838
           1       0.04      0.82      0.07        22

    accuracy                           0.45       860
   macro avg       0.51      0.63      0.34       860
weighted avg       0.96      0.45      0.59       860
19:26:14.723647: Validation Seq.Label F1: 0.5840047719994153; Log.Reg F1: 0.3374903704995712; train loss: 0.046409446746110916; Language: japanese 

19:26:14.724922: Combined F1 SeqLab: 0.552792362739485; train loss: 0.046409446746110916
19:26:14.726191: Combined F1 LogReg: 0.3543655229299147; train loss: 0.046409446746110916 

19:26:14.726763: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 16/40
19:29:07.455493: Evaluating Language: english
19:29:07.455642: ----------
19:29:12.079532: OBI: 
 [[2765   28  163]
 [   0   12    2]
 [  11    4   87]]
19:29:12.083477: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.96      2956
           1       0.27      0.86      0.41        14
           2       0.35      0.85      0.49       102

    accuracy                           0.93      3072
   macro avg       0.54      0.88      0.62      3072
weighted avg       0.97      0.93      0.95      3072
19:29:12.083525: ----------
19:29:12.084203: LR: 
 [[454 500]
 [  1  13]]
19:29:12.086962: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.64       954
           1       0.03      0.93      0.05        14

    accuracy                           0.48       968
   macro avg       0.51      0.70      0.35       968
weighted avg       0.98      0.48      0.64       968
19:29:12.090423: Validation Seq.Label F1: 0.6233592578378157; Log.Reg F1: 0.34688226809760514; train loss: 0.030168738216161728; Language: english 

19:29:12.090487: Evaluating Language: finnish
19:29:12.090532: ----------
19:29:19.869526: OBI: 
 [[5575   84  315]
 [   7   21    3]
 [ 218    6  190]]
19:29:19.875487: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.93      0.95      5974
           1       0.19      0.68      0.30        31
           2       0.37      0.46      0.41       414

    accuracy                           0.90      6419
   macro avg       0.51      0.69      0.55      6419
weighted avg       0.92      0.90      0.91      6419
19:29:19.875529: ----------
19:29:19.876402: LR: 
 [[971 617]
 [ 11  20]]
19:29:19.879721: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.76      1588
           1       0.03      0.65      0.06        31

    accuracy                           0.61      1619
   macro avg       0.51      0.63      0.41      1619
weighted avg       0.97      0.61      0.74      1619
19:29:19.881474: Validation Seq.Label F1: 0.5516413406113946; Log.Reg F1: 0.40776113143363074; train loss: 0.030168738216161728; Language: finnish 

19:29:19.881525: Evaluating Language: japanese
19:29:19.881566: ----------
19:29:24.479317: OBI: 
 [[2983   43  296]
 [   2   13    2]
 [  25    1  123]]
19:29:24.483406: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      3322
           1       0.23      0.76      0.35        17
           2       0.29      0.83      0.43       149

    accuracy                           0.89      3488
   macro avg       0.50      0.83      0.58      3488
weighted avg       0.96      0.89      0.92      3488
19:29:24.483452: ----------
19:29:24.484103: LR: 
 [[711 132]
 [  9   8]]
19:29:24.486743: LR: 
               precision    recall  f1-score   support

           0       0.99      0.84      0.91       843
           1       0.06      0.47      0.10        17

    accuracy                           0.84       860
   macro avg       0.52      0.66      0.51       860
weighted avg       0.97      0.84      0.89       860
19:29:24.488451: Validation Seq.Label F1: 0.57504288542291; Log.Reg F1: 0.5058498477939289; train loss: 0.030168738216161728; Language: japanese 

19:29:24.489746: Combined F1 SeqLab: 0.5841116483113924; train loss: 0.030168738216161728
19:29:24.491029: Combined F1 LogReg: 0.42523739124623655; train loss: 0.030168738216161728 

19:29:24.491629: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 17/40
19:32:10.280660: Evaluating Language: english
19:32:10.280763: ----------
19:32:15.025448: OBI: 
 [[2993   34  106]
 [   1    6    1]
 [  16    3   96]]
19:32:15.029396: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97      3133
           1       0.14      0.75      0.24         8
           2       0.47      0.83      0.60       115

    accuracy                           0.95      3256
   macro avg       0.54      0.85      0.60      3256
weighted avg       0.97      0.95      0.96      3256
19:32:15.029439: ----------
19:32:15.030106: LR: 
 [[498 462]
 [  0   8]]
19:32:15.032841: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.68       960
           1       0.02      1.00      0.03         8

    accuracy                           0.52       968
   macro avg       0.51      0.76      0.36       968
weighted avg       0.99      0.52      0.68       968
19:32:15.034822: Validation Seq.Label F1: 0.6045033857931171; Log.Reg F1: 0.3583001876818706; train loss: 0.02982393465936184; Language: english 

19:32:15.034880: Evaluating Language: finnish
19:32:15.034923: ----------
19:32:22.894162: OBI: 
 [[4466   58  184]
 [  10   15    1]
 [ 154    9  136]]
19:32:22.899259: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.95      0.96      4708
           1       0.18      0.58      0.28        26
           2       0.42      0.45      0.44       299

    accuracy                           0.92      5033
   macro avg       0.52      0.66      0.56      5033
weighted avg       0.93      0.92      0.92      5033
19:32:22.899301: ----------
19:32:22.900170: LR: 
 [[1015  578]
 [  11   15]]
19:32:22.903526: LR: 
               precision    recall  f1-score   support

           0       0.99      0.64      0.78      1593
           1       0.03      0.58      0.05        26

    accuracy                           0.64      1619
   macro avg       0.51      0.61      0.41      1619
weighted avg       0.97      0.64      0.76      1619
19:32:22.905210: Validation Seq.Label F1: 0.5576697314425225; Log.Reg F1: 0.4117851342340459; train loss: 0.02982393465936184; Language: finnish 

19:32:22.905261: Evaluating Language: japanese
19:32:22.905303: ----------
19:32:27.551458: OBI: 
 [[4748   32   83]
 [   3    7    1]
 [  48    0   70]]
19:32:27.556441: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.98      0.98      4863
           1       0.18      0.64      0.28        11
           2       0.45      0.59      0.51       118

    accuracy                           0.97      4992
   macro avg       0.54      0.74      0.59      4992
weighted avg       0.97      0.97      0.97      4992
19:32:27.556482: ----------
19:32:27.557118: LR: 
 [[671 178]
 [  5   6]]
19:32:27.559763: LR: 
               precision    recall  f1-score   support

           0       0.99      0.79      0.88       849
           1       0.03      0.55      0.06        11

    accuracy                           0.79       860
   macro avg       0.51      0.67      0.47       860
weighted avg       0.98      0.79      0.87       860
19:32:27.561510: Validation Seq.Label F1: 0.5925083914749919; Log.Reg F1: 0.4707692307692308; train loss: 0.02982393465936184; Language: japanese 

19:32:27.562806: Combined F1 SeqLab: 0.585231027535508; train loss: 0.02982393465936184
19:32:27.564101: Combined F1 LogReg: 0.41616090233949504; train loss: 0.02982393465936184 

19:32:27.564685: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 18/40
19:35:13.180281: Evaluating Language: english
19:35:13.180437: ----------
19:35:17.796495: OBI: 
 [[3907   48  159]
 [   3   11    1]
 [  40    9  110]]
19:35:17.801246: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      4114
           1       0.16      0.73      0.27        15
           2       0.41      0.69      0.51       159

    accuracy                           0.94      4288
   macro avg       0.52      0.79      0.58      4288
weighted avg       0.96      0.94      0.95      4288
19:35:17.801290: ----------
19:35:17.801980: LR: 
 [[417 536]
 [  0  15]]
19:35:17.804729: LR: 
               precision    recall  f1-score   support

           0       1.00      0.44      0.61       953
           1       0.03      1.00      0.05        15

    accuracy                           0.45       968
   macro avg       0.51      0.72      0.33       968
weighted avg       0.98      0.45      0.60       968
19:35:17.807217: Validation Seq.Label F1: 0.5822929232191281; Log.Reg F1: 0.33088132882824794; train loss: 0.035244472324848175; Language: english 

19:35:17.807278: Evaluating Language: finnish
19:35:17.807329: ----------
19:35:25.715807: OBI: 
 [[7309  112  279]
 [   6   29    3]
 [ 140    7  173]]
19:35:25.724354: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96      7700
           1       0.20      0.76      0.31        38
           2       0.38      0.54      0.45       320

    accuracy                           0.93      8058
   macro avg       0.52      0.75      0.57      8058
weighted avg       0.95      0.93      0.94      8058
19:35:25.724411: ----------
19:35:25.725473: LR: 
 [[682 899]
 [  5  33]]
19:35:25.729391: LR: 
               precision    recall  f1-score   support

           0       0.99      0.43      0.60      1581
           1       0.04      0.87      0.07        38

    accuracy                           0.44      1619
   macro avg       0.51      0.65      0.33      1619
weighted avg       0.97      0.44      0.59      1619
19:35:25.731377: Validation Seq.Label F1: 0.5742819065593409; Log.Reg F1: 0.33472608592883507; train loss: 0.035244472324848175; Language: finnish 

19:35:25.731440: Evaluating Language: japanese
19:35:25.731494: ----------
19:35:30.354764: OBI: 
 [[5736   73  299]
 [   6   13    3]
 [  53    2  183]]
19:35:30.360649: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      6108
           1       0.15      0.59      0.24        22
           2       0.38      0.77      0.51       238

    accuracy                           0.93      6368
   macro avg       0.50      0.77      0.57      6368
weighted avg       0.96      0.93      0.94      6368
19:35:30.360691: ----------
19:35:30.361334: LR: 
 [[588 250]
 [ 10  12]]
19:35:30.363979: LR: 
               precision    recall  f1-score   support

           0       0.98      0.70      0.82       838
           1       0.05      0.55      0.08        22

    accuracy                           0.70       860
   macro avg       0.51      0.62      0.45       860
weighted avg       0.96      0.70      0.80       860
19:35:30.365658: Validation Seq.Label F1: 0.5687927812561827; Log.Reg F1: 0.4517242732158971; train loss: 0.035244472324848175; Language: japanese 

19:35:30.366932: Combined F1 SeqLab: 0.5751492515401698; train loss: 0.035244472324848175
19:35:30.368193: Combined F1 LogReg: 0.3766425473313813; train loss: 0.035244472324848175 

19:35:30.368798: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 19/40
19:38:20.120896: Evaluating Language: english
19:38:20.121030: ----------
19:38:24.683245: OBI: 
 [[3839   42  163]
 [   1   16    1]
 [  57    3   62]]
19:38:24.687913: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      4044
           1       0.26      0.89      0.41        18
           2       0.27      0.51      0.36       122

    accuracy                           0.94      4184
   macro avg       0.51      0.78      0.58      4184
weighted avg       0.96      0.94      0.95      4184
19:38:24.687961: ----------
19:38:24.688650: LR: 
 [[498 452]
 [  3  15]]
19:38:24.691364: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.69       950
           1       0.03      0.83      0.06        18

    accuracy                           0.53       968
   macro avg       0.51      0.68      0.37       968
weighted avg       0.98      0.53      0.67       968
19:38:24.696400: Validation Seq.Label F1: 0.5760886252392495; Log.Reg F1: 0.3741394132734623; train loss: 0.028930477797985077; Language: english 

19:38:24.696462: Evaluating Language: finnish
19:38:24.696505: ----------
19:38:32.254480: OBI: 
 [[3897   65  162]
 [   5   13    2]
 [ 157    8   90]]
19:38:32.259199: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.94      0.95      4124
           1       0.15      0.65      0.25        20
           2       0.35      0.35      0.35       255

    accuracy                           0.91      4399
   macro avg       0.49      0.65      0.52      4399
weighted avg       0.92      0.91      0.91      4399
19:38:32.259243: ----------
19:38:32.260131: LR: 
 [[818 781]
 [  3  17]]
19:38:32.263417: LR: 
               precision    recall  f1-score   support

           0       1.00      0.51      0.68      1599
           1       0.02      0.85      0.04        20

    accuracy                           0.52      1619
   macro avg       0.51      0.68      0.36      1619
weighted avg       0.98      0.52      0.67      1619
19:38:32.265075: Validation Seq.Label F1: 0.5171266728552181; Log.Reg F1: 0.3587989250136394; train loss: 0.028930477797985077; Language: finnish 

19:38:32.265126: Evaluating Language: japanese
19:38:32.265168: ----------
19:38:36.831053: OBI: 
 [[5334   63  216]
 [   4   15    1]
 [  72    2  149]]
19:38:36.836598: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      5613
           1       0.19      0.75      0.30        20
           2       0.41      0.67      0.51       223

    accuracy                           0.94      5856
   macro avg       0.53      0.79      0.59      5856
weighted avg       0.96      0.94      0.95      5856
19:38:36.836643: ----------
19:38:36.837293: LR: 
 [[715 125]
 [  9  11]]
19:38:36.839910: LR: 
               precision    recall  f1-score   support

           0       0.99      0.85      0.91       840
           1       0.08      0.55      0.14        20

    accuracy                           0.84       860
   macro avg       0.53      0.70      0.53       860
weighted avg       0.97      0.84      0.90       860
19:38:36.841625: Validation Seq.Label F1: 0.5912456287699316; Log.Reg F1: 0.5276739458325136; train loss: 0.028930477797985077; Language: japanese 

19:38:36.842925: Combined F1 SeqLab: 0.5623965070564562; train loss: 0.028930477797985077
19:38:36.844225: Combined F1 LogReg: 0.42706625647784763; train loss: 0.028930477797985077 

19:38:36.844837: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 20/40
19:41:22.161484: Evaluating Language: english
19:41:22.161580: ----------
19:41:26.952547: OBI: 
 [[1897   43  269]
 [   0    9    3]
 [  16    5   86]]
19:41:26.956291: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      2209
           1       0.16      0.75      0.26        12
           2       0.24      0.80      0.37       107

    accuracy                           0.86      2328
   macro avg       0.46      0.80      0.52      2328
weighted avg       0.95      0.86      0.89      2328
19:41:26.956360: ----------
19:41:26.957090: LR: 
 [[363 593]
 [  1  11]]
19:41:26.959812: LR: 
               precision    recall  f1-score   support

           0       1.00      0.38      0.55       956
           1       0.02      0.92      0.04        12

    accuracy                           0.39       968
   macro avg       0.51      0.65      0.29       968
weighted avg       0.99      0.39      0.54       968
19:41:26.971966: Validation Seq.Label F1: 0.517063005177069; Log.Reg F1: 0.29285714285714287; train loss: 0.04591977968811989; Language: english 

19:41:26.972022: Evaluating Language: finnish
19:41:26.972064: ----------
19:41:34.745176: OBI: 
 [[5216  234 1151]
 [   5   23    3]
 [ 116   11  221]]
19:41:34.751580: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.79      0.87      6601
           1       0.09      0.74      0.15        31
           2       0.16      0.64      0.26       348

    accuracy                           0.78      6980
   macro avg       0.41      0.72      0.43      6980
weighted avg       0.93      0.78      0.84      6980
19:41:34.751624: ----------
19:41:34.752504: LR: 
 [[696 892]
 [  4  27]]
19:41:34.755768: LR: 
               precision    recall  f1-score   support

           0       0.99      0.44      0.61      1588
           1       0.03      0.87      0.06        31

    accuracy                           0.45      1619
   macro avg       0.51      0.65      0.33      1619
weighted avg       0.98      0.45      0.60      1619
19:41:34.757432: Validation Seq.Label F1: 0.4280745596572863; Log.Reg F1: 0.3326168568273832; train loss: 0.04591977968811989; Language: finnish 

19:41:34.757481: Evaluating Language: japanese
19:41:34.757523: ----------
19:41:39.250454: OBI: 
 [[3205  137 1099]
 [   1   25    1]
 [  19    2  163]]
19:41:39.255405: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.72      0.84      4441
           1       0.15      0.93      0.26        27
           2       0.13      0.89      0.23       184

    accuracy                           0.73      4652
   macro avg       0.43      0.84      0.44      4652
weighted avg       0.95      0.73      0.81      4652
19:41:39.255447: ----------
19:41:39.256095: LR: 
 [[358 475]
 [  3  24]]
19:41:39.258762: LR: 
               precision    recall  f1-score   support

           0       0.99      0.43      0.60       833
           1       0.05      0.89      0.09        27

    accuracy                           0.44       860
   macro avg       0.52      0.66      0.35       860
weighted avg       0.96      0.44      0.58       860
19:41:39.260414: Validation Seq.Label F1: 0.44107782729880946; Log.Reg F1: 0.34545987223825086; train loss: 0.04591977968811989; Language: japanese 

19:41:39.261711: Combined F1 SeqLab: 0.4637354237361212; train loss: 0.04591977968811989
19:41:39.262990: Combined F1 LogReg: 0.32441835279725134; train loss: 0.04591977968811989 

19:41:39.263567: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 21/40
19:44:26.878584: Evaluating Language: english
19:44:26.878676: ----------
19:44:31.502510: OBI: 
 [[3214   40  128]
 [   4   14    3]
 [  36    2  119]]
19:44:31.506759: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      3382
           1       0.25      0.67      0.36        21
           2       0.48      0.76      0.58       157

    accuracy                           0.94      3560
   macro avg       0.57      0.79      0.64      3560
weighted avg       0.96      0.94      0.95      3560
19:44:31.506801: ----------
19:44:31.507488: LR: 
 [[509 438]
 [  2  19]]
19:44:31.510211: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70       947
           1       0.04      0.90      0.08        21

    accuracy                           0.55       968
   macro avg       0.52      0.72      0.39       968
weighted avg       0.98      0.55      0.68       968
19:44:31.514567: Validation Seq.Label F1: 0.639019588386677; Log.Reg F1: 0.3888573216017816; train loss: 0.042301930487155914; Language: english 

19:44:31.514625: Evaluating Language: finnish
19:44:31.514668: ----------
19:44:39.236863: OBI: 
 [[5526   60  104]
 [   8   14    1]
 [ 155    8  151]]
19:44:39.242571: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.97      0.97      5690
           1       0.17      0.61      0.27        23
           2       0.59      0.48      0.53       314

    accuracy                           0.94      6027
   macro avg       0.58      0.69      0.59      6027
weighted avg       0.95      0.94      0.95      6027
19:44:39.242616: ----------
19:44:39.243495: LR: 
 [[940 656]
 [  9  14]]
19:44:39.246765: LR: 
               precision    recall  f1-score   support

           0       0.99      0.59      0.74      1596
           1       0.02      0.61      0.04        23

    accuracy                           0.59      1619
   macro avg       0.51      0.60      0.39      1619
weighted avg       0.98      0.59      0.73      1619
19:44:39.248526: Validation Seq.Label F1: 0.589251360231143; Log.Reg F1: 0.3895536901430811; train loss: 0.042301930487155914; Language: finnish 

19:44:39.248585: Evaluating Language: japanese
19:44:39.248629: ----------
19:44:43.897004: OBI: 
 [[3790   32   69]
 [   3   13    0]
 [  45    2   78]]
19:44:43.901417: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.97      0.98      3891
           1       0.28      0.81      0.41        16
           2       0.53      0.62      0.57       125

    accuracy                           0.96      4032
   macro avg       0.60      0.80      0.66      4032
weighted avg       0.97      0.96      0.97      4032
19:44:43.901459: ----------
19:44:43.902119: LR: 
 [[636 208]
 [  9   7]]
19:44:43.904756: LR: 
               precision    recall  f1-score   support

           0       0.99      0.75      0.85       844
           1       0.03      0.44      0.06        16

    accuracy                           0.75       860
   macro avg       0.51      0.60      0.46       860
weighted avg       0.97      0.75      0.84       860
19:44:43.906623: Validation Seq.Label F1: 0.6556499269105724; Log.Reg F1: 0.45743533386246615; train loss: 0.042301930487155914; Language: japanese 

19:44:43.907912: Combined F1 SeqLab: 0.6286069324397585; train loss: 0.042301930487155914
19:44:44.565477: Combined F1 LogReg: 0.4132026051600953; train loss: 0.042301930487155914 

19:44:44.566279: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 22/40
19:47:30.060073: Evaluating Language: english
19:47:30.060176: ----------
19:47:34.725890: OBI: 
 [[3647   26  102]
 [   0    7    0]
 [  49    3   70]]
19:47:34.730533: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.97      0.98      3775
           1       0.19      1.00      0.33         7
           2       0.41      0.57      0.48       122

    accuracy                           0.95      3904
   macro avg       0.53      0.85      0.59      3904
weighted avg       0.97      0.95      0.96      3904
19:47:34.730583: ----------
19:47:34.731382: LR: 
 [[427 534]
 [  0   7]]
19:47:34.734101: LR: 
               precision    recall  f1-score   support

           0       1.00      0.44      0.62       961
           1       0.01      1.00      0.03         7

    accuracy                           0.45       968
   macro avg       0.51      0.72      0.32       968
weighted avg       0.99      0.45      0.61       968
19:47:34.736103: Validation Seq.Label F1: 0.5926934213300411; Log.Reg F1: 0.3204106102358064; train loss: 0.0392257422208786; Language: english 

19:47:34.736157: Evaluating Language: finnish
19:47:34.736199: ----------
19:47:42.705218: OBI: 
 [[3994   78  109]
 [   6   14    1]
 [ 182    9   85]]
19:47:42.710058: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.96      0.96      4181
           1       0.14      0.67      0.23        21
           2       0.44      0.31      0.36       276

    accuracy                           0.91      4478
   macro avg       0.51      0.64      0.52      4478
weighted avg       0.92      0.91      0.92      4478
19:47:42.710106: ----------
19:47:42.711176: LR: 
 [[1058  540]
 [   6   15]]
19:47:42.714551: LR: 
               precision    recall  f1-score   support

           0       0.99      0.66      0.79      1598
           1       0.03      0.71      0.05        21

    accuracy                           0.66      1619
   macro avg       0.51      0.69      0.42      1619
weighted avg       0.98      0.66      0.79      1619
19:47:42.716202: Validation Seq.Label F1: 0.5152006703408846; Log.Reg F1: 0.4234871963436014; train loss: 0.0392257422208786; Language: finnish 

19:47:42.716254: Evaluating Language: japanese
19:47:42.716296: ----------
19:47:47.293799: OBI: 
 [[7049   95  153]
 [  11   26    1]
 [ 190    6  177]]
19:47:47.300676: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.97      0.97      7297
           1       0.20      0.68      0.32        38
           2       0.53      0.47      0.50       373

    accuracy                           0.94      7708
   macro avg       0.57      0.71      0.60      7708
weighted avg       0.95      0.94      0.94      7708
19:47:47.300720: ----------
19:47:47.301354: LR: 
 [[651 171]
 [ 21  17]]
19:47:47.303965: LR: 
               precision    recall  f1-score   support

           0       0.97      0.79      0.87       822
           1       0.09      0.45      0.15        38

    accuracy                           0.78       860
   macro avg       0.53      0.62      0.51       860
weighted avg       0.93      0.78      0.84       860
19:47:47.305751: Validation Seq.Label F1: 0.5957089845662232; Log.Reg F1: 0.5109642108256033; train loss: 0.0392257422208786; Language: japanese 

19:47:47.307042: Combined F1 SeqLab: 0.5690888673135117; train loss: 0.0392257422208786
19:47:47.308331: Combined F1 LogReg: 0.4254757295715301; train loss: 0.0392257422208786 

19:47:47.308899: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 23/40
19:51:46.307154: Evaluating Language: english
19:51:46.307301: ----------
19:51:51.013624: OBI: 
 [[3678   48  187]
 [   1    9    5]
 [  29    5  126]]
19:51:51.020337: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.97      3913
           1       0.15      0.60      0.23        15
           2       0.40      0.79      0.53       160

    accuracy                           0.93      4088
   macro avg       0.51      0.78      0.58      4088
weighted avg       0.97      0.93      0.95      4088
19:51:51.020403: ----------
19:51:51.021424: LR: 
 [[469 484]
 [  0  15]]
19:51:51.025348: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       953
           1       0.03      1.00      0.06        15

    accuracy                           0.50       968
   macro avg       0.52      0.75      0.36       968
weighted avg       0.98      0.50      0.65       968
19:51:51.028560: Validation Seq.Label F1: 0.5753968489659728; Log.Reg F1: 0.3590000383085149; train loss: 0.0352780744433403; Language: english 

19:51:51.028638: Evaluating Language: finnish
19:51:51.028694: ----------
19:51:58.775972: OBI: 
 [[4533   91  258]
 [   7   19    3]
 [ 135    6  130]]
19:51:58.782182: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.93      0.95      4882
           1       0.16      0.66      0.26        29
           2       0.33      0.48      0.39       271

    accuracy                           0.90      5182
   macro avg       0.49      0.69      0.53      5182
weighted avg       0.93      0.90      0.92      5182
19:51:58.782228: ----------
19:51:58.783324: LR: 
 [[910 680]
 [  5  24]]
19:51:58.787183: LR: 
               precision    recall  f1-score   support

           0       0.99      0.57      0.73      1590
           1       0.03      0.83      0.07        29

    accuracy                           0.58      1619
   macro avg       0.51      0.70      0.40      1619
weighted avg       0.98      0.58      0.71      1619
19:51:58.788924: Validation Seq.Label F1: 0.5344807518109006; Log.Reg F1: 0.3960156086190511; train loss: 0.0352780744433403; Language: finnish 

19:51:58.788980: Evaluating Language: japanese
19:51:58.789026: ----------
19:52:03.404751: OBI: 
 [[3991   84  312]
 [   2   25    1]
 [  40    0  113]]
19:52:03.410762: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      4387
           1       0.23      0.89      0.36        28
           2       0.27      0.74      0.39       153

    accuracy                           0.90      4568
   macro avg       0.49      0.85      0.57      4568
weighted avg       0.96      0.90      0.93      4568
19:52:03.410819: ----------
19:52:03.411770: LR: 
 [[658 174]
 [ 12  16]]
19:52:03.414961: LR: 
               precision    recall  f1-score   support

           0       0.98      0.79      0.88       832
           1       0.08      0.57      0.15        28

    accuracy                           0.78       860
   macro avg       0.53      0.68      0.51       860
weighted avg       0.95      0.78      0.85       860
19:52:03.416844: Validation Seq.Label F1: 0.5677575510868405; Log.Reg F1: 0.5114770520040557; train loss: 0.0352780744433403; Language: japanese 

19:52:03.418154: Combined F1 SeqLab: 0.5594937725815013; train loss: 0.0352780744433403
19:52:03.419465: Combined F1 LogReg: 0.42712924059047674; train loss: 0.0352780744433403 

19:52:03.420299: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 24/40
19:54:50.802990: Evaluating Language: english
19:54:50.803106: ----------
19:54:55.355260: OBI: 
 [[2274   25  114]
 [   0    5    2]
 [   9    5   54]]
19:54:55.358872: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97      2413
           1       0.14      0.71      0.24         7
           2       0.32      0.79      0.45        68

    accuracy                           0.94      2488
   macro avg       0.49      0.82      0.55      2488
weighted avg       0.98      0.94      0.95      2488
19:54:55.358914: ----------
19:54:55.359609: LR: 
 [[456 505]
 [  0   7]]
19:54:55.362338: LR: 
               precision    recall  f1-score   support

           0       1.00      0.47      0.64       961
           1       0.01      1.00      0.03         7

    accuracy                           0.48       968
   macro avg       0.51      0.74      0.34       968
weighted avg       0.99      0.48      0.64       968
19:54:55.366307: Validation Seq.Label F1: 0.5534535222379696; Log.Reg F1: 0.33529410964846085; train loss: 0.022872600704431534; Language: english 

19:54:55.366381: Evaluating Language: finnish
19:54:55.366425: ----------
19:55:03.195881: OBI: 
 [[7737  131  605]
 [   6   24    2]
 [ 171   10  296]]
19:55:03.205096: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.91      0.94      8473
           1       0.15      0.75      0.24        32
           2       0.33      0.62      0.43       477

    accuracy                           0.90      8982
   macro avg       0.48      0.76      0.54      8982
weighted avg       0.94      0.90      0.91      8982
19:55:03.205147: ----------
19:55:03.206206: LR: 
 [[1019  568]
 [   6   26]]
19:55:03.210167: LR: 
               precision    recall  f1-score   support

           0       0.99      0.64      0.78      1587
           1       0.04      0.81      0.08        32

    accuracy                           0.65      1619
   macro avg       0.52      0.73      0.43      1619
weighted avg       0.98      0.65      0.77      1619
19:55:03.212152: Validation Seq.Label F1: 0.5389751445424308; Log.Reg F1: 0.4316560578113304; train loss: 0.022872600704431534; Language: finnish 

19:55:03.212214: Evaluating Language: japanese
19:55:03.212264: ----------
19:55:07.765113: OBI: 
 [[3510   43  243]
 [   7   10    2]
 [  61    2   98]]
19:55:07.769523: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.92      0.95      3796
           1       0.18      0.53      0.27        19
           2       0.29      0.61      0.39       161

    accuracy                           0.91      3976
   macro avg       0.48      0.69      0.54      3976
weighted avg       0.95      0.91      0.93      3976
19:55:07.769567: ----------
19:55:07.770199: LR: 
 [[688 153]
 [ 11   8]]
19:55:07.772817: LR: 
               precision    recall  f1-score   support

           0       0.98      0.82      0.89       841
           1       0.05      0.42      0.09        19

    accuracy                           0.81       860
   macro avg       0.52      0.62      0.49       860
weighted avg       0.96      0.81      0.88       860
19:55:07.774490: Validation Seq.Label F1: 0.5370508832673194; Log.Reg F1: 0.49119769119769124; train loss: 0.022872600704431534; Language: japanese 

19:55:07.775754: Combined F1 SeqLab: 0.5432091858975253; train loss: 0.022872600704431534
19:55:07.777016: Combined F1 LogReg: 0.4242736004231684; train loss: 0.022872600704431534 

19:55:07.777619: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 25/40
19:57:51.727182: Evaluating Language: english
19:57:51.727282: ----------
19:57:56.326408: OBI: 
 [[3051   37  174]
 [   3    8    3]
 [  34    2   80]]
19:57:56.330448: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      3262
           1       0.17      0.57      0.26        14
           2       0.31      0.69      0.43       116

    accuracy                           0.93      3392
   macro avg       0.49      0.73      0.55      3392
weighted avg       0.96      0.93      0.94      3392
19:57:56.330491: ----------
19:57:56.331165: LR: 
 [[455 499]
 [  0  14]]
19:57:56.333915: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65       954
           1       0.03      1.00      0.05        14

    accuracy                           0.48       968
   macro avg       0.51      0.74      0.35       968
weighted avg       0.99      0.48      0.64       968
19:57:56.335811: Validation Seq.Label F1: 0.5507314624831567; Log.Reg F1: 0.34948952451238513; train loss: 0.023490382358431816; Language: english 

19:57:56.335866: Evaluating Language: finnish
19:57:56.335909: ----------
19:58:04.166203: OBI: 
 [[3966   99  385]
 [   4   14    1]
 [  81   11  115]]
19:58:04.171120: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.89      0.93      4450
           1       0.11      0.74      0.20        19
           2       0.23      0.56      0.32       207

    accuracy                           0.88      4676
   macro avg       0.44      0.73      0.48      4676
weighted avg       0.94      0.88      0.90      4676
19:58:04.171162: ----------
19:58:04.172045: LR: 
 [[927 673]
 [  6  13]]
19:58:04.175353: LR: 
               precision    recall  f1-score   support

           0       0.99      0.58      0.73      1600
           1       0.02      0.68      0.04        19

    accuracy                           0.58      1619
   macro avg       0.51      0.63      0.38      1619
weighted avg       0.98      0.58      0.72      1619
19:58:04.176978: Validation Seq.Label F1: 0.4845765503006226; Log.Reg F1: 0.3844089227865929; train loss: 0.023490382358431816; Language: finnish 

19:58:04.177029: Evaluating Language: japanese
19:58:04.177070: ----------
19:58:08.661813: OBI: 
 [[6749  101  444]
 [   9   17    2]
 [  94    3  121]]
19:58:08.668562: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      7294
           1       0.14      0.61      0.23        28
           2       0.21      0.56      0.31       218

    accuracy                           0.91      7540
   macro avg       0.45      0.70      0.50      7540
weighted avg       0.96      0.91      0.93      7540
19:58:08.668604: ----------
19:58:08.669233: LR: 
 [[706 126]
 [ 17  11]]
19:58:08.671880: LR: 
               precision    recall  f1-score   support

           0       0.98      0.85      0.91       832
           1       0.08      0.39      0.13        28

    accuracy                           0.83       860
   macro avg       0.53      0.62      0.52       860
weighted avg       0.95      0.83      0.88       860
19:58:08.673626: Validation Seq.Label F1: 0.4968867239926779; Log.Reg F1: 0.5206859592711683; train loss: 0.023490382358431816; Language: japanese 

19:58:08.674899: Combined F1 SeqLab: 0.511538852662651; train loss: 0.023490382358431816
19:58:08.676164: Combined F1 LogReg: 0.4246673269921522; train loss: 0.023490382358431816 

19:58:08.676746: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 26/40
20:02:06.419456: Evaluating Language: english
20:02:06.419585: ----------
20:02:11.150679: OBI: 
 [[3799   51  219]
 [   1    5    6]
 [   9    6  112]]
20:02:11.156254: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96      4069
           1       0.08      0.42      0.14        12
           2       0.33      0.88      0.48       127

    accuracy                           0.93      4208
   macro avg       0.47      0.74      0.53      4208
weighted avg       0.97      0.93      0.95      4208
20:02:11.156302: ----------
20:02:11.157164: LR: 
 [[478 478]
 [  0  12]]
20:02:11.160399: LR: 
               precision    recall  f1-score   support

           0       1.00      0.50      0.67       956
           1       0.02      1.00      0.05        12

    accuracy                           0.51       968
   macro avg       0.51      0.75      0.36       968
weighted avg       0.99      0.51      0.66       968
20:02:11.162802: Validation Seq.Label F1: 0.5274505800282516; Log.Reg F1: 0.3572377158034528; train loss: 0.02634870819747448; Language: english 

20:02:11.162870: Evaluating Language: finnish
20:02:11.162919: ----------
20:02:19.141472: OBI: 
 [[5843  114  614]
 [   8   25    2]
 [ 157   10  231]]
20:02:19.149142: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.89      0.93      6571
           1       0.17      0.71      0.27        35
           2       0.27      0.58      0.37       398

    accuracy                           0.87      7004
   macro avg       0.47      0.73      0.52      7004
weighted avg       0.93      0.87      0.89      7004
20:02:19.149188: ----------
20:02:19.150285: LR: 
 [[770 814]
 [  5  30]]
20:02:19.154165: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.65      1584
           1       0.04      0.86      0.07        35

    accuracy                           0.49      1619
   macro avg       0.51      0.67      0.36      1619
weighted avg       0.97      0.49      0.64      1619
20:02:19.155969: Validation Seq.Label F1: 0.5239440443399634; Log.Reg F1: 0.36053918838172594; train loss: 0.02634870819747448; Language: finnish 

20:02:19.156029: Evaluating Language: japanese
20:02:19.156075: ----------
20:02:23.810601: OBI: 
 [[5143   83  481]
 [   5   20    3]
 [  43    4  234]]
20:02:23.817630: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      5707
           1       0.19      0.71      0.30        28
           2       0.33      0.83      0.47       281

    accuracy                           0.90      6016
   macro avg       0.50      0.82      0.57      6016
weighted avg       0.96      0.90      0.92      6016
20:02:23.817677: ----------
20:02:23.818458: LR: 
 [[627 205]
 [ 12  16]]
20:02:23.821704: LR: 
               precision    recall  f1-score   support

           0       0.98      0.75      0.85       832
           1       0.07      0.57      0.13        28

    accuracy                           0.75       860
   macro avg       0.53      0.66      0.49       860
weighted avg       0.95      0.75      0.83       860
20:02:23.823525: Validation Seq.Label F1: 0.5695358905733898; Log.Reg F1: 0.49049768072971694; train loss: 0.02634870819747448; Language: japanese 

20:02:23.824904: Combined F1 SeqLab: 0.5407071316411134; train loss: 0.02634870819747448
20:02:23.826233: Combined F1 LogReg: 0.40751084515329306; train loss: 0.02634870819747448 

20:02:23.827059: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 27/40
20:06:23.702101: Evaluating Language: english
20:06:23.702242: ----------
20:06:28.339358: OBI: 
 [[3858   49  174]
 [   0   14    5]
 [  79    3   98]]
20:06:28.344980: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96      4081
           1       0.21      0.74      0.33        19
           2       0.35      0.54      0.43       180

    accuracy                           0.93      4280
   macro avg       0.52      0.74      0.57      4280
weighted avg       0.95      0.93      0.94      4280
20:06:28.345026: ----------
20:06:28.345875: LR: 
 [[466 483]
 [  1  18]]
20:06:28.349111: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       949
           1       0.04      0.95      0.07        19

    accuracy                           0.50       968
   macro avg       0.52      0.72      0.36       968
weighted avg       0.98      0.50      0.65       968
20:06:28.353381: Validation Seq.Label F1: 0.5735435125945813; Log.Reg F1: 0.3637114298131247; train loss: 0.03237694874405861; Language: english 

20:06:28.353448: Evaluating Language: finnish
20:06:28.353497: ----------
20:06:36.150166: OBI: 
 [[5336   89  409]
 [  11   20    1]
 [ 185    8  198]]
20:06:36.158700: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.91      0.94      5834
           1       0.17      0.62      0.27        32
           2       0.33      0.51      0.40       391

    accuracy                           0.89      6257
   macro avg       0.49      0.68      0.53      6257
weighted avg       0.92      0.89      0.90      6257
20:06:36.158754: ----------
20:06:36.160058: LR: 
 [[834 753]
 [  6  26]]
20:06:36.164647: LR: 
               precision    recall  f1-score   support

           0       0.99      0.53      0.69      1587
           1       0.03      0.81      0.06        32

    accuracy                           0.53      1619
   macro avg       0.51      0.67      0.38      1619
weighted avg       0.97      0.53      0.67      1619
20:06:36.166725: Validation Seq.Label F1: 0.5345978241898844; Log.Reg F1: 0.3756933023827197; train loss: 0.03237694874405861; Language: finnish 

20:06:36.166796: Evaluating Language: japanese
20:06:36.166850: ----------
20:06:40.893221: OBI: 
 [[3381   37  228]
 [   6   18    1]
 [  55    1   89]]
20:06:40.898353: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      3646
           1       0.32      0.72      0.44        25
           2       0.28      0.61      0.38       145

    accuracy                           0.91      3816
   macro avg       0.53      0.75      0.59      3816
weighted avg       0.95      0.91      0.93      3816
20:06:40.898399: ----------
20:06:40.899172: LR: 
 [[689 146]
 [ 11  14]]
20:06:40.902266: LR: 
               precision    recall  f1-score   support

           0       0.98      0.83      0.90       835
           1       0.09      0.56      0.15        25

    accuracy                           0.82       860
   macro avg       0.54      0.69      0.52       860
weighted avg       0.96      0.82      0.88       860
20:06:40.903979: Validation Seq.Label F1: 0.5943001535046497; Log.Reg F1: 0.5245356105290959; train loss: 0.03237694874405861; Language: japanese 

20:06:40.905263: Combined F1 SeqLab: 0.5680198549709154; train loss: 0.03237694874405861
20:06:40.906561: Combined F1 LogReg: 0.42761706714655834; train loss: 0.03237694874405861 

20:06:40.907392: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 28/40
20:09:32.354522: Evaluating Language: english
20:09:32.354682: ----------
20:09:37.080378: OBI: 
 [[3492   33   87]
 [   4   12    5]
 [  58    8   85]]
20:09:37.084853: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.97      0.97      3612
           1       0.23      0.57      0.32        21
           2       0.48      0.56      0.52       151

    accuracy                           0.95      3784
   macro avg       0.56      0.70      0.61      3784
weighted avg       0.96      0.95      0.95      3784
20:09:37.084896: ----------
20:09:37.085584: LR: 
 [[549 398]
 [  5  16]]
20:09:37.088330: LR: 
               precision    recall  f1-score   support

           0       0.99      0.58      0.73       947
           1       0.04      0.76      0.07        21

    accuracy                           0.58       968
   macro avg       0.51      0.67      0.40       968
weighted avg       0.97      0.58      0.72       968
20:09:37.093094: Validation Seq.Label F1: 0.6057397652787128; Log.Reg F1: 0.4025377717536967; train loss: 0.02527293935418129; Language: english 

20:09:37.093155: Evaluating Language: finnish
20:09:37.093197: ----------
20:09:44.901733: OBI: 
 [[4135   52  132]
 [   4   13    2]
 [ 142    6   95]]
20:09:44.906498: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.96      4319
           1       0.18      0.68      0.29        19
           2       0.41      0.39      0.40       243

    accuracy                           0.93      4581
   macro avg       0.52      0.68      0.55      4581
weighted avg       0.93      0.93      0.93      4581
20:09:44.906540: ----------
20:09:44.907417: LR: 
 [[1055  545]
 [   7   12]]
20:09:44.910660: LR: 
               precision    recall  f1-score   support

           0       0.99      0.66      0.79      1600
           1       0.02      0.63      0.04        19

    accuracy                           0.66      1619
   macro avg       0.51      0.65      0.42      1619
weighted avg       0.98      0.66      0.78      1619
20:09:44.912343: Validation Seq.Label F1: 0.551019722915663; Log.Reg F1: 0.4171518908089156; train loss: 0.02527293935418129; Language: finnish 

20:09:44.912397: Evaluating Language: japanese
20:09:44.912444: ----------
20:09:49.540823: OBI: 
 [[5287   49  193]
 [   6   16    0]
 [  78    2   85]]
20:09:49.546265: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      5529
           1       0.24      0.73      0.36        22
           2       0.31      0.52      0.38       165

    accuracy                           0.94      5716
   macro avg       0.51      0.73      0.57      5716
weighted avg       0.96      0.94      0.95      5716
20:09:49.546314: ----------
20:09:49.546944: LR: 
 [[661 177]
 [  9  13]]
20:09:49.549586: LR: 
               precision    recall  f1-score   support

           0       0.99      0.79      0.88       838
           1       0.07      0.59      0.12        22

    accuracy                           0.78       860
   macro avg       0.53      0.69      0.50       860
weighted avg       0.96      0.78      0.86       860
20:09:49.551328: Validation Seq.Label F1: 0.5711298277488633; Log.Reg F1: 0.4996496671838246; train loss: 0.02527293935418129; Language: japanese 

20:09:49.552602: Combined F1 SeqLab: 0.5764063030034775; train loss: 0.02527293935418129
20:09:49.553885: Combined F1 LogReg: 0.44185297238289245; train loss: 0.02527293935418129 

20:09:49.554504: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 29/40
20:12:34.780009: Evaluating Language: english
20:12:34.780105: ----------
20:12:39.389029: OBI: 
 [[3607   50  278]
 [   8   14    3]
 [  38    6  140]]
20:12:39.394006: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95      3935
           1       0.20      0.56      0.29        25
           2       0.33      0.76      0.46       184

    accuracy                           0.91      4144
   macro avg       0.51      0.75      0.57      4144
weighted avg       0.95      0.91      0.93      4144
20:12:39.394052: ----------
20:12:39.394748: LR: 
 [[485 458]
 [  2  23]]
20:12:39.397512: LR: 
               precision    recall  f1-score   support

           0       1.00      0.51      0.68       943
           1       0.05      0.92      0.09        25

    accuracy                           0.52       968
   macro avg       0.52      0.72      0.38       968
weighted avg       0.97      0.52      0.66       968
20:12:39.399428: Validation Seq.Label F1: 0.5694194698114259; Log.Reg F1: 0.3846153846153846; train loss: 0.02239128388464451; Language: english 

20:12:39.399483: Evaluating Language: finnish
20:12:39.399525: ----------
20:12:47.192104: OBI: 
 [[4047   97  393]
 [  10   11    1]
 [  95    8  151]]
20:12:47.197080: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.89      0.93      4537
           1       0.09      0.50      0.16        22
           2       0.28      0.59      0.38       254

    accuracy                           0.87      4813
   macro avg       0.45      0.66      0.49      4813
weighted avg       0.93      0.87      0.90      4813
20:12:47.197122: ----------
20:12:47.197996: LR: 
 [[821 776]
 [  5  17]]
20:12:47.201258: LR: 
               precision    recall  f1-score   support

           0       0.99      0.51      0.68      1597
           1       0.02      0.77      0.04        22

    accuracy                           0.52      1619
   macro avg       0.51      0.64      0.36      1619
weighted avg       0.98      0.52      0.67      1619
20:12:47.202905: Validation Seq.Label F1: 0.4896384567457907; Log.Reg F1: 0.35969504923420487; train loss: 0.02239128388464451; Language: finnish 

20:12:47.202955: Evaluating Language: japanese
20:12:47.202997: ----------
20:12:51.790231: OBI: 
 [[4029   84  551]
 [   3   17    1]
 [  28    3  196]]
20:12:51.795250: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      4664
           1       0.16      0.81      0.27        21
           2       0.26      0.86      0.40       227

    accuracy                           0.86      4912
   macro avg       0.47      0.85      0.53      4912
weighted avg       0.96      0.86      0.90      4912
20:12:51.795293: ----------
20:12:51.795934: LR: 
 [[551 288]
 [  6  15]]
20:12:51.798527: LR: 
               precision    recall  f1-score   support

           0       0.99      0.66      0.79       839
           1       0.05      0.71      0.09        21

    accuracy                           0.66       860
   macro avg       0.52      0.69      0.44       860
weighted avg       0.97      0.66      0.77       860
20:12:51.800202: Validation Seq.Label F1: 0.5325700513761037; Log.Reg F1: 0.44099543669744246; train loss: 0.02239128388464451; Language: japanese 

20:12:51.801498: Combined F1 SeqLab: 0.5315434163977798; train loss: 0.02239128388464451
20:12:51.802773: Combined F1 LogReg: 0.3965629406598677; train loss: 0.02239128388464451 

20:12:51.804043: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 30/40
20:15:38.950167: Evaluating Language: english
20:15:38.950285: ----------
20:15:43.598769: OBI: 
 [[3036   21  235]
 [   2   11    2]
 [  49    5   95]]
20:15:43.603120: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.92      0.95      3292
           1       0.30      0.73      0.42        15
           2       0.29      0.64      0.40       149

    accuracy                           0.91      3456
   macro avg       0.52      0.76      0.59      3456
weighted avg       0.95      0.91      0.93      3456
20:15:43.603164: ----------
20:15:43.603859: LR: 
 [[535 418]
 [  2  13]]
20:15:43.606607: LR: 
               precision    recall  f1-score   support

           0       1.00      0.56      0.72       953
           1       0.03      0.87      0.06        15

    accuracy                           0.57       968
   macro avg       0.51      0.71      0.39       968
weighted avg       0.98      0.57      0.71       968
20:15:43.610854: Validation Seq.Label F1: 0.589986884155249; Log.Reg F1: 0.388208384747344; train loss: 0.040032994002103806; Language: english 

20:15:43.610913: Evaluating Language: finnish
20:15:43.610961: ----------
20:15:51.549723: OBI: 
 [[4327   71  615]
 [   7   17    7]
 [  95    1  143]]
20:15:51.555018: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.86      0.92      5013
           1       0.19      0.55      0.28        31
           2       0.19      0.60      0.28       239

    accuracy                           0.85      5283
   macro avg       0.45      0.67      0.49      5283
weighted avg       0.94      0.85      0.88      5283
20:15:51.555061: ----------
20:15:51.555949: LR: 
 [[839 749]
 [  4  27]]
20:15:51.559253: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.69      1588
           1       0.03      0.87      0.07        31

    accuracy                           0.53      1619
   macro avg       0.52      0.70      0.38      1619
weighted avg       0.98      0.53      0.68      1619
20:15:51.560986: Validation Seq.Label F1: 0.49491233212552127; Log.Reg F1: 0.3785827118431536; train loss: 0.040032994002103806; Language: finnish 

20:15:51.561037: Evaluating Language: japanese
20:15:51.561078: ----------
20:15:56.183379: OBI: 
 [[5528   81 1189]
 [  11   26    3]
 [  39    2  225]]
20:15:56.189793: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.81      0.89      6798
           1       0.24      0.65      0.35        40
           2       0.16      0.85      0.27       266

    accuracy                           0.81      7104
   macro avg       0.46      0.77      0.50      7104
weighted avg       0.96      0.81      0.87      7104
20:15:56.189836: ----------
20:15:56.190478: LR: 
 [[476 344]
 [ 11  29]]
20:15:56.193117: LR: 
               precision    recall  f1-score   support

           0       0.98      0.58      0.73       820
           1       0.08      0.72      0.14        40

    accuracy                           0.59       860
   macro avg       0.53      0.65      0.43       860
weighted avg       0.94      0.59      0.70       860
20:15:56.194879: Validation Seq.Label F1: 0.5032383066334901; Log.Reg F1: 0.43441072563269856; train loss: 0.040032994002103806; Language: japanese 

20:15:56.196181: Combined F1 SeqLab: 0.5311219361654735; train loss: 0.040032994002103806
20:15:56.197497: Combined F1 LogReg: 0.40114141240522894; train loss: 0.040032994002103806 

20:15:56.198102: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 31/40
20:18:41.956600: Evaluating Language: english
20:18:41.956706: ----------
20:18:46.666631: OBI: 
 [[4065   49  245]
 [   2   11    3]
 [  29    4  128]]
20:18:46.671824: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      4359
           1       0.17      0.69      0.28        16
           2       0.34      0.80      0.48       161

    accuracy                           0.93      4536
   macro avg       0.50      0.81      0.57      4536
weighted avg       0.97      0.93      0.94      4536
20:18:46.671876: ----------
20:18:46.672676: LR: 
 [[378 574]
 [  0  16]]
20:18:46.675666: LR: 
               precision    recall  f1-score   support

           0       1.00      0.40      0.57       952
           1       0.03      1.00      0.05        16

    accuracy                           0.41       968
   macro avg       0.51      0.70      0.31       968
weighted avg       0.98      0.41      0.56       968
20:18:46.677828: Validation Seq.Label F1: 0.5710945796584026; Log.Reg F1: 0.31061316657981586; train loss: 0.031867094337940216; Language: english 

20:18:46.677882: Evaluating Language: finnish
20:18:46.677924: ----------
20:18:54.453559: OBI: 
 [[6028  109  455]
 [   7   17    3]
 [ 144   10  157]]
20:18:54.460204: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.91      0.94      6592
           1       0.12      0.63      0.21        27
           2       0.26      0.50      0.34       311

    accuracy                           0.89      6930
   macro avg       0.45      0.68      0.50      6930
weighted avg       0.94      0.89      0.91      6930
20:18:54.460246: ----------
20:18:54.461122: LR: 
 [[ 574 1018]
 [   2   25]]
20:18:54.464740: LR: 
               precision    recall  f1-score   support

           0       1.00      0.36      0.53      1592
           1       0.02      0.93      0.05        27

    accuracy                           0.37      1619
   macro avg       0.51      0.64      0.29      1619
weighted avg       0.98      0.37      0.52      1619
20:18:54.466415: Validation Seq.Label F1: 0.4972318702828309; Log.Reg F1: 0.28812463358278445; train loss: 0.031867094337940216; Language: finnish 

20:18:54.466471: Evaluating Language: japanese
20:18:54.466523: ----------
20:18:59.108275: OBI: 
 [[4264   92  715]
 [   4   24    3]
 [  24    1  153]]
20:18:59.113605: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.84      0.91      5071
           1       0.21      0.77      0.32        31
           2       0.18      0.86      0.29       178

    accuracy                           0.84      5280
   macro avg       0.46      0.82      0.51      5280
weighted avg       0.96      0.84      0.89      5280
20:18:59.113663: ----------
20:18:59.114433: LR: 
 [[393 436]
 [  5  26]]
20:18:59.117192: LR: 
               precision    recall  f1-score   support

           0       0.99      0.47      0.64       829
           1       0.06      0.84      0.11        31

    accuracy                           0.49       860
   macro avg       0.52      0.66      0.37       860
weighted avg       0.95      0.49      0.62       860
20:18:59.118884: Validation Seq.Label F1: 0.5089499644152479; Log.Reg F1: 0.3730317352470033; train loss: 0.031867094337940216; Language: japanese 

20:18:59.120185: Combined F1 SeqLab: 0.5267569388938481; train loss: 0.031867094337940216
20:18:59.121494: Combined F1 LogReg: 0.3259084836940909; train loss: 0.031867094337940216 

20:18:59.122075: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 32/40
20:21:43.441653: Evaluating Language: english
20:21:43.441775: ----------
20:21:48.186346: OBI: 
 [[3312   32  160]
 [   3   10    0]
 [  14    3  138]]
20:21:48.190701: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      3504
           1       0.22      0.77      0.34        13
           2       0.46      0.89      0.61       155

    accuracy                           0.94      3672
   macro avg       0.56      0.87      0.64      3672
weighted avg       0.97      0.94      0.95      3672
20:21:48.190743: ----------
20:21:48.191431: LR: 
 [[432 523]
 [  1  12]]
20:21:48.194181: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62       955
           1       0.02      0.92      0.04        13

    accuracy                           0.46       968
   macro avg       0.51      0.69      0.33       968
weighted avg       0.98      0.46      0.61       968
20:21:48.197180: Validation Seq.Label F1: 0.6411707504967324; Log.Reg F1: 0.3331370033025516; train loss: 0.055332913994789124; Language: english 

20:21:48.197242: Evaluating Language: finnish
20:21:48.197286: ----------
20:21:56.023863: OBI: 
 [[4249   84  296]
 [   1   17    3]
 [ 111   10  105]]
20:21:56.029316: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.92      0.95      4629
           1       0.15      0.81      0.26        21
           2       0.26      0.46      0.33       226

    accuracy                           0.90      4876
   macro avg       0.46      0.73      0.51      4876
weighted avg       0.94      0.90      0.91      4876
20:21:56.029360: ----------
20:21:56.030229: LR: 
 [[797 801]
 [  7  14]]
20:21:56.033516: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.66      1598
           1       0.02      0.67      0.03        21

    accuracy                           0.50      1619
   macro avg       0.50      0.58      0.35      1619
weighted avg       0.98      0.50      0.66      1619
20:21:56.035227: Validation Seq.Label F1: 0.5120605386456333; Log.Reg F1: 0.34855323912688385; train loss: 0.055332913994789124; Language: finnish 

20:21:56.035282: Evaluating Language: japanese
20:21:56.035332: ----------
20:22:00.650286: OBI: 
 [[2938   89  365]
 [   5   15    0]
 [  29    0   71]]
20:22:00.654431: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.87      0.92      3392
           1       0.14      0.75      0.24        20
           2       0.16      0.71      0.26       100

    accuracy                           0.86      3512
   macro avg       0.43      0.78      0.48      3512
weighted avg       0.96      0.86      0.90      3512
20:22:00.654475: ----------
20:22:00.655104: LR: 
 [[624 216]
 [ 10  10]]
20:22:00.657757: LR: 
               precision    recall  f1-score   support

           0       0.98      0.74      0.85       840
           1       0.04      0.50      0.08        20

    accuracy                           0.74       860
   macro avg       0.51      0.62      0.46       860
weighted avg       0.96      0.74      0.83       860
20:22:00.659463: Validation Seq.Label F1: 0.4767265081700034; Log.Reg F1: 0.4639882626777421; train loss: 0.055332913994789124; Language: japanese 

20:22:00.660754: Combined F1 SeqLab: 0.5478972197175195; train loss: 0.055332913994789124
20:22:00.662043: Combined F1 LogReg: 0.3863309166064573; train loss: 0.055332913994789124 

20:22:00.662647: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 33/40
20:24:46.136675: Evaluating Language: english
20:24:46.136779: ----------
20:24:50.949755: OBI: 
 [[3105   26  117]
 [   4    7    0]
 [  62    2   93]]
20:24:50.953835: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      3248
           1       0.20      0.64      0.30        11
           2       0.44      0.59      0.51       157

    accuracy                           0.94      3416
   macro avg       0.54      0.73      0.59      3416
weighted avg       0.95      0.94      0.94      3416
20:24:50.956850: ----------
20:24:50.957720: LR: 
 [[468 489]
 [  2   9]]
20:24:50.960463: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       957
           1       0.02      0.82      0.04        11

    accuracy                           0.49       968
   macro avg       0.51      0.65      0.35       968
weighted avg       0.98      0.49      0.65       968
20:24:50.962603: Validation Seq.Label F1: 0.5928667421555964; Log.Reg F1: 0.3456424857126729; train loss: 0.031375348567962646; Language: english 

20:24:50.962656: Evaluating Language: finnish
20:24:50.962698: ----------
20:24:58.692091: OBI: 
 [[5182   96  489]
 [   7   26    2]
 [ 163    6  220]]
20:24:58.697988: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.90      0.93      5767
           1       0.20      0.74      0.32        35
           2       0.31      0.57      0.40       389

    accuracy                           0.88      6191
   macro avg       0.49      0.74      0.55      6191
weighted avg       0.92      0.88      0.90      6191
20:24:58.698032: ----------
20:24:58.698919: LR: 
 [[1121  463]
 [   7   28]]
20:24:58.702194: LR: 
               precision    recall  f1-score   support

           0       0.99      0.71      0.83      1584
           1       0.06      0.80      0.11        35

    accuracy                           0.71      1619
   macro avg       0.53      0.75      0.47      1619
weighted avg       0.97      0.71      0.81      1619
20:24:58.704244: Validation Seq.Label F1: 0.5503722050595611; Log.Reg F1: 0.46658002175936836; train loss: 0.031375348567962646; Language: finnish 

20:24:58.704302: Evaluating Language: japanese
20:24:58.704355: ----------
20:25:03.156759: OBI: 
 [[4550   70  461]
 [   4   14    3]
 [  86    2  122]]
20:25:03.162045: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.90      0.94      5081
           1       0.16      0.67      0.26        21
           2       0.21      0.58      0.31       210

    accuracy                           0.88      5312
   macro avg       0.45      0.71      0.50      5312
weighted avg       0.95      0.88      0.91      5312
20:25:03.162088: ----------
20:25:03.162736: LR: 
 [[600 239]
 [  8  13]]
20:25:03.165400: LR: 
               precision    recall  f1-score   support

           0       0.99      0.72      0.83       839
           1       0.05      0.62      0.10        21

    accuracy                           0.71       860
   macro avg       0.52      0.67      0.46       860
weighted avg       0.96      0.71      0.81       860
20:25:03.167351: Validation Seq.Label F1: 0.5014441965577153; Log.Reg F1: 0.4622700496923026; train loss: 0.031375348567962646; Language: japanese 

20:25:03.168645: Combined F1 SeqLab: 0.5494988081023551; train loss: 0.031375348567962646
20:25:03.169914: Combined F1 LogReg: 0.4285087488321687; train loss: 0.031375348567962646 

20:25:03.170691: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 34/40
20:27:49.378697: Evaluating Language: english
20:27:49.378833: ----------
20:27:54.146737: OBI: 
 [[2999   24  141]
 [   4    7    2]
 [  37    4   86]]
20:27:54.150817: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      3164
           1       0.20      0.54      0.29        13
           2       0.38      0.68      0.48       127

    accuracy                           0.94      3304
   macro avg       0.52      0.72      0.58      3304
weighted avg       0.96      0.94      0.95      3304
20:27:54.150860: ----------
20:27:54.151556: LR: 
 [[451 504]
 [  1  12]]
20:27:54.154324: LR: 
               precision    recall  f1-score   support

           0       1.00      0.47      0.64       955
           1       0.02      0.92      0.05        13

    accuracy                           0.48       968
   macro avg       0.51      0.70      0.34       968
weighted avg       0.98      0.48      0.63       968
20:27:54.156366: Validation Seq.Label F1: 0.5805361166047277; Log.Reg F1: 0.34322446637995546; train loss: 0.02347785420715809; Language: english 

20:27:54.156427: Evaluating Language: finnish
20:27:54.156470: ----------
20:28:02.037179: OBI: 
 [[4505   47  266]
 [   4   21    1]
 [ 143    5  152]]
20:28:02.042373: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.94      0.95      4818
           1       0.29      0.81      0.42        26
           2       0.36      0.51      0.42       300

    accuracy                           0.91      5144
   macro avg       0.54      0.75      0.60      5144
weighted avg       0.93      0.91      0.92      5144
20:28:02.042416: ----------
20:28:02.043288: LR: 
 [[868 725]
 [  3  23]]
20:28:02.046581: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70      1593
           1       0.03      0.88      0.06        26

    accuracy                           0.55      1619
   macro avg       0.51      0.71      0.38      1619
weighted avg       0.98      0.55      0.69      1619
20:28:02.048284: Validation Seq.Label F1: 0.5994924787348853; Log.Reg F1: 0.3819884895466291; train loss: 0.02347785420715809; Language: finnish 

20:28:02.048343: Evaluating Language: japanese
20:28:02.048385: ----------
20:28:06.576179: OBI: 
 [[3721   47  244]
 [   2   14    2]
 [  47    1  114]]
20:28:06.580737: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      4012
           1       0.23      0.78      0.35        18
           2       0.32      0.70      0.44       162

    accuracy                           0.92      4192
   macro avg       0.51      0.80      0.58      4192
weighted avg       0.96      0.92      0.93      4192
20:28:06.580779: ----------
20:28:06.581413: LR: 
 [[612 230]
 [  8  10]]
20:28:06.584064: LR: 
               precision    recall  f1-score   support

           0       0.99      0.73      0.84       842
           1       0.04      0.56      0.08        18

    accuracy                           0.72       860
   macro avg       0.51      0.64      0.46       860
weighted avg       0.97      0.72      0.82       860
20:28:06.585784: Validation Seq.Label F1: 0.5810303470726729; Log.Reg F1: 0.4573643410852713; train loss: 0.02347785420715809; Language: japanese 

20:28:06.587067: Combined F1 SeqLab: 0.5870859332220414; train loss: 0.02347785420715809
20:28:06.588345: Combined F1 LogReg: 0.39703080525499307; train loss: 0.02347785420715809 

20:28:06.588937: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 35/40
20:30:53.704132: Evaluating Language: english
20:30:53.704263: ----------
20:30:58.295294: OBI: 
 [[2958   30  156]
 [   1   12    1]
 [  13    2   67]]
20:30:58.299767: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97      3144
           1       0.27      0.86      0.41        14
           2       0.30      0.82      0.44        82

    accuracy                           0.94      3240
   macro avg       0.52      0.87      0.61      3240
weighted avg       0.97      0.94      0.95      3240
20:30:58.299808: ----------
20:30:58.300506: LR: 
 [[478 476]
 [  1  13]]
20:30:58.303216: LR: 
               precision    recall  f1-score   support

           0       1.00      0.50      0.67       954
           1       0.03      0.93      0.05        14

    accuracy                           0.51       968
   macro avg       0.51      0.71      0.36       968
weighted avg       0.98      0.51      0.66       968
20:30:58.307578: Validation Seq.Label F1: 0.6063334961141665; Log.Reg F1: 0.35941087598623195; train loss: 0.017320849001407623; Language: english 

20:30:58.307631: Evaluating Language: finnish
20:30:58.307682: ----------
20:31:06.152955: OBI: 
 [[4713   69  185]
 [   9   16    2]
 [ 174    4  124]]
20:31:06.158224: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.95      0.96      4967
           1       0.18      0.59      0.28        27
           2       0.40      0.41      0.40       302

    accuracy                           0.92      5296
   macro avg       0.51      0.65      0.55      5296
weighted avg       0.93      0.92      0.92      5296
20:31:06.158266: ----------
20:31:06.159135: LR: 
 [[895 697]
 [  8  19]]
20:31:06.162364: LR: 
               precision    recall  f1-score   support

           0       0.99      0.56      0.72      1592
           1       0.03      0.70      0.05        27

    accuracy                           0.56      1619
   macro avg       0.51      0.63      0.38      1619
weighted avg       0.98      0.56      0.71      1619
20:31:06.164191: Validation Seq.Label F1: 0.5453742542734774; Log.Reg F1: 0.38428944025331957; train loss: 0.017320849001407623; Language: finnish 

20:31:06.164260: Evaluating Language: japanese
20:31:06.164303: ----------
20:31:10.928551: OBI: 
 [[5002   68  325]
 [   7   12    1]
 [  79    4   98]]
20:31:10.933973: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      5395
           1       0.14      0.60      0.23        20
           2       0.23      0.54      0.32       181

    accuracy                           0.91      5596
   macro avg       0.45      0.69      0.50      5596
weighted avg       0.96      0.91      0.93      5596
20:31:10.934015: ----------
20:31:10.934652: LR: 
 [[707 133]
 [ 11   9]]
20:31:10.937254: LR: 
               precision    recall  f1-score   support

           0       0.98      0.84      0.91       840
           1       0.06      0.45      0.11        20

    accuracy                           0.83       860
   macro avg       0.52      0.65      0.51       860
weighted avg       0.96      0.83      0.89       860
20:31:10.938943: Validation Seq.Label F1: 0.5030143820375624; Log.Reg F1: 0.5093424618456711; train loss: 0.017320849001407623; Language: japanese 

20:31:10.940216: Combined F1 SeqLab: 0.5532018481142335; train loss: 0.017320849001407623
20:31:10.941502: Combined F1 LogReg: 0.4228018823304083; train loss: 0.017320849001407623 

20:31:10.942108: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 36/40
20:33:55.428591: Evaluating Language: english
20:33:55.428694: ----------
20:34:00.182606: OBI: 
 [[4734   41  148]
 [   3   17    3]
 [  46    3  173]]
20:34:00.187759: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      4923
           1       0.28      0.74      0.40        23
           2       0.53      0.78      0.63       222

    accuracy                           0.95      5168
   macro avg       0.60      0.83      0.67      5168
weighted avg       0.97      0.95      0.96      5168
20:34:00.187801: ----------
20:34:00.188478: LR: 
 [[493 452]
 [  5  18]]
20:34:00.191214: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.68       945
           1       0.04      0.78      0.07        23

    accuracy                           0.53       968
   macro avg       0.51      0.65      0.38       968
weighted avg       0.97      0.53      0.67       968
20:34:00.193222: Validation Seq.Label F1: 0.6713135411878457; Log.Reg F1: 0.3781604978359542; train loss: 0.014047159813344479; Language: english 

20:34:00.193277: Evaluating Language: finnish
20:34:00.193334: ----------
20:34:07.954215: OBI: 
 [[5695   80  228]
 [   8   24    3]
 [ 171    3  206]]
20:34:07.960182: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.95      0.96      6003
           1       0.22      0.69      0.34        35
           2       0.47      0.54      0.50       380

    accuracy                           0.92      6418
   macro avg       0.56      0.73      0.60      6418
weighted avg       0.94      0.92      0.93      6418
20:34:07.960223: ----------
20:34:07.961094: LR: 
 [[1077  507]
 [   9   26]]
20:34:07.964387: LR: 
               precision    recall  f1-score   support

           0       0.99      0.68      0.81      1584
           1       0.05      0.74      0.09        35

    accuracy                           0.68      1619
   macro avg       0.52      0.71      0.45      1619
weighted avg       0.97      0.68      0.79      1619
20:34:07.966346: Validation Seq.Label F1: 0.600436171433162; Log.Reg F1: 0.4491454344041778; train loss: 0.014047159813344479; Language: finnish 

20:34:07.966405: Evaluating Language: japanese
20:34:07.966447: ----------
20:34:12.598567: OBI: 
 [[3868   30  117]
 [   2   12    1]
 [  39    0  147]]
20:34:12.603204: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      4015
           1       0.29      0.80      0.42        15
           2       0.55      0.79      0.65       186

    accuracy                           0.96      4216
   macro avg       0.61      0.85      0.68      4216
weighted avg       0.97      0.96      0.96      4216
20:34:12.603245: ----------
20:34:12.603881: LR: 
 [[691 154]
 [ 11   4]]
20:34:12.606680: LR: 
               precision    recall  f1-score   support

           0       0.98      0.82      0.89       845
           1       0.03      0.27      0.05        15

    accuracy                           0.81       860
   macro avg       0.50      0.54      0.47       860
weighted avg       0.97      0.81      0.88       860
20:34:12.608388: Validation Seq.Label F1: 0.6830706470091928; Log.Reg F1: 0.4697923633659778; train loss: 0.014047159813344479; Language: japanese 

20:34:12.609667: Combined F1 SeqLab: 0.6526282697301826; train loss: 0.014047159813344479
20:34:13.243882: Combined F1 LogReg: 0.4341435431001461; train loss: 0.014047159813344479 

20:34:13.244691: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 37/40
20:36:58.510485: Evaluating Language: english
20:36:58.510591: ----------
20:37:03.311387: OBI: 
 [[3105   27  114]
 [   2    6    1]
 [  48    0   25]]
20:37:03.319018: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      3246
           1       0.18      0.67      0.29         9
           2       0.18      0.34      0.23        73

    accuracy                           0.94      3328
   macro avg       0.45      0.66      0.50      3328
weighted avg       0.96      0.94      0.95      3328
20:37:03.319065: ----------
20:37:03.319783: LR: 
 [[531 428]
 [  3   6]]
20:37:03.322509: LR: 
               precision    recall  f1-score   support

           0       0.99      0.55      0.71       959
           1       0.01      0.67      0.03         9

    accuracy                           0.55       968
   macro avg       0.50      0.61      0.37       968
weighted avg       0.99      0.55      0.70       968
20:37:03.324542: Validation Seq.Label F1: 0.49687232736976283; Log.Reg F1: 0.36920376353759227; train loss: 0.014926208183169365; Language: english 

20:37:03.324599: Evaluating Language: finnish
20:37:03.324643: ----------
20:37:11.143795: OBI: 
 [[5115   51  233]
 [  12   14    3]
 [ 156    5  129]]
20:37:11.149237: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.95      0.96      5399
           1       0.20      0.48      0.28        29
           2       0.35      0.44      0.39       290

    accuracy                           0.92      5718
   macro avg       0.51      0.62      0.54      5718
weighted avg       0.93      0.92      0.93      5718
20:37:11.149279: ----------
20:37:11.150153: LR: 
 [[1045  545]
 [   9   20]]
20:37:11.153418: LR: 
               precision    recall  f1-score   support

           0       0.99      0.66      0.79      1590
           1       0.04      0.69      0.07        29

    accuracy                           0.66      1619
   macro avg       0.51      0.67      0.43      1619
weighted avg       0.97      0.66      0.78      1619
20:37:11.155073: Validation Seq.Label F1: 0.5448024130745011; Log.Reg F1: 0.4289045268621668; train loss: 0.014926208183169365; Language: finnish 

20:37:11.155127: Evaluating Language: japanese
20:37:11.155170: ----------
20:37:15.770501: OBI: 
 [[5895   34  262]
 [   5   21    0]
 [  65    1  121]]
20:37:15.776335: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      6191
           1       0.38      0.81      0.51        26
           2       0.32      0.65      0.42       187

    accuracy                           0.94      6404
   macro avg       0.56      0.80      0.64      6404
weighted avg       0.97      0.94      0.95      6404
20:37:15.776378: ----------
20:37:15.777006: LR: 
 [[665 169]
 [ 13  13]]
20:37:15.779613: LR: 
               precision    recall  f1-score   support

           0       0.98      0.80      0.88       834
           1       0.07      0.50      0.12        26

    accuracy                           0.79       860
   macro avg       0.53      0.65      0.50       860
weighted avg       0.95      0.79      0.86       860
20:37:15.781296: Validation Seq.Label F1: 0.6355493123695201; Log.Reg F1: 0.5023148148148148; train loss: 0.014926208183169365; Language: japanese 

20:37:15.782585: Combined F1 SeqLab: 0.5620245271786081; train loss: 0.014926208183169365
20:37:15.783848: Combined F1 LogReg: 0.4368793446538846; train loss: 0.014926208183169365 

20:37:15.784443: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 38/40
20:40:04.130857: Evaluating Language: english
20:40:04.130962: ----------
20:40:08.708930: OBI: 
 [[4602   30  119]
 [  11   16    2]
 [  59    5  124]]
20:40:08.713982: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.97      0.98      4751
           1       0.31      0.55      0.40        29
           2       0.51      0.66      0.57       188

    accuracy                           0.95      4968
   macro avg       0.60      0.73      0.65      4968
weighted avg       0.96      0.95      0.96      4968
20:40:08.714024: ----------
20:40:08.714707: LR: 
 [[466 473]
 [  3  26]]
20:40:08.717436: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.66       939
           1       0.05      0.90      0.10        29

    accuracy                           0.51       968
   macro avg       0.52      0.70      0.38       968
weighted avg       0.97      0.51      0.65       968
20:40:08.719434: Validation Seq.Label F1: 0.6498357539497848; Log.Reg F1: 0.38020833333333337; train loss: 0.01585988886654377; Language: english 

20:40:08.719489: Evaluating Language: finnish
20:40:08.719533: ----------
20:40:16.387612: OBI: 
 [[4188   41  139]
 [   8   14    2]
 [ 114    2  100]]
20:40:16.392383: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.97      4368
           1       0.25      0.58      0.35        24
           2       0.41      0.46      0.44       216

    accuracy                           0.93      4608
   macro avg       0.54      0.67      0.58      4608
weighted avg       0.94      0.93      0.94      4608
20:40:16.392424: ----------
20:40:16.393282: LR: 
 [[941 654]
 [  9  15]]
20:40:16.396546: LR: 
               precision    recall  f1-score   support

           0       0.99      0.59      0.74      1595
           1       0.02      0.62      0.04        24

    accuracy                           0.59      1619
   macro avg       0.51      0.61      0.39      1619
weighted avg       0.98      0.59      0.73      1619
20:40:16.398379: Validation Seq.Label F1: 0.5828383761745549; Log.Reg F1: 0.3913896188945305; train loss: 0.01585988886654377; Language: finnish 

20:40:16.398429: Evaluating Language: japanese
20:40:16.398471: ----------
20:40:20.888377: OBI: 
 [[2508   23  167]
 [   5   11    1]
 [  47    4   90]]
20:40:20.892037: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      2698
           1       0.29      0.65      0.40        17
           2       0.35      0.64      0.45       141

    accuracy                           0.91      2856
   macro avg       0.54      0.74      0.60      2856
weighted avg       0.94      0.91      0.93      2856
20:40:20.892080: ----------
20:40:20.892715: LR: 
 [[658 185]
 [  7  10]]
20:40:20.895357: LR: 
               precision    recall  f1-score   support

           0       0.99      0.78      0.87       843
           1       0.05      0.59      0.09        17

    accuracy                           0.78       860
   macro avg       0.52      0.68      0.48       860
weighted avg       0.97      0.78      0.86       860
20:40:20.896994: Validation Seq.Label F1: 0.6017009049821206; Log.Reg F1: 0.4835093338671738; train loss: 0.01585988886654377; Language: japanese 

20:40:20.898270: Combined F1 SeqLab: 0.612108666526236; train loss: 0.01585988886654377
20:40:20.899563: Combined F1 LogReg: 0.4209218005169112; train loss: 0.01585988886654377 

20:40:20.900137: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 39/40
20:43:04.885999: Evaluating Language: english
20:43:04.886120: ----------
20:43:09.653998: OBI: 
 [[3331   16   91]
 [   4    6    1]
 [  58    5   80]]
20:43:09.658268: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.97      0.98      3438
           1       0.22      0.55      0.32        11
           2       0.47      0.56      0.51       143

    accuracy                           0.95      3592
   macro avg       0.56      0.69      0.60      3592
weighted avg       0.96      0.95      0.95      3592
20:43:09.658318: ----------
20:43:09.659018: LR: 
 [[464 493]
 [  2   9]]
20:43:09.661740: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65       957
           1       0.02      0.82      0.04        11

    accuracy                           0.49       968
   macro avg       0.51      0.65      0.34       968
weighted avg       0.98      0.49      0.65       968
20:43:09.664292: Validation Seq.Label F1: 0.5996619421485935; Log.Reg F1: 0.34361553919936877; train loss: 0.015625465661287308; Language: english 

20:43:09.664365: Evaluating Language: finnish
20:43:09.664409: ----------
20:43:17.470542: OBI: 
 [[6698   85  407]
 [   8   13    5]
 [ 190    9  225]]
20:43:17.477368: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.93      0.95      7190
           1       0.12      0.50      0.20        26
           2       0.35      0.53      0.42       424

    accuracy                           0.91      7640
   macro avg       0.48      0.65      0.52      7640
weighted avg       0.93      0.91      0.92      7640
20:43:17.477412: ----------
20:43:17.478280: LR: 
 [[967 626]
 [ 10  16]]
20:43:17.481530: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.75      1593
           1       0.02      0.62      0.05        26

    accuracy                           0.61      1619
   macro avg       0.51      0.61      0.40      1619
weighted avg       0.97      0.61      0.74      1619
20:43:17.483247: Validation Seq.Label F1: 0.5235440317184917; Log.Reg F1: 0.40021668724807197; train loss: 0.015625465661287308; Language: finnish 

20:43:17.483298: Evaluating Language: japanese
20:43:17.483349: ----------
20:43:22.038653: OBI: 
 [[2769   49  312]
 [   5   14    0]
 [  31    2   58]]
20:43:22.042553: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      3130
           1       0.22      0.74      0.33        19
           2       0.16      0.64      0.25        91

    accuracy                           0.88      3240
   macro avg       0.45      0.75      0.51      3240
weighted avg       0.96      0.88      0.91      3240
20:43:22.042595: ----------
20:43:22.043228: LR: 
 [[570 271]
 [  8  11]]
20:43:22.045846: LR: 
               precision    recall  f1-score   support

           0       0.99      0.68      0.80       841
           1       0.04      0.58      0.07        19

    accuracy                           0.68       860
   macro avg       0.51      0.63      0.44       860
weighted avg       0.97      0.68      0.79       860
20:43:22.047640: Validation Seq.Label F1: 0.5060229695729607; Log.Reg F1: 0.43823618242222895; train loss: 0.015625465661287308; Language: japanese 

20:43:22.048952: Combined F1 SeqLab: 0.544595275945025; train loss: 0.015625465661287308
20:43:22.050264: Combined F1 LogReg: 0.3959360163440145; train loss: 0.015625465661287308 

20:43:22.050869: Model: lab6_bert-base-multilingual-cased_english.pt; Language: english; Epoch 40/40
20:46:07.443262: Evaluating Language: english
20:46:07.443375: ----------
20:46:12.018088: OBI: 
 [[4298   32  148]
 [   2   12    2]
 [  56    2   64]]
20:46:12.022849: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97      4478
           1       0.26      0.75      0.39        16
           2       0.30      0.52      0.38       122

    accuracy                           0.95      4616
   macro avg       0.52      0.74      0.58      4616
weighted avg       0.97      0.95      0.96      4616
20:46:12.022896: ----------
20:46:12.023567: LR: 
 [[461 491]
 [  2  14]]
20:46:12.026299: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65       952
           1       0.03      0.88      0.05        16

    accuracy                           0.49       968
   macro avg       0.51      0.68      0.35       968
weighted avg       0.98      0.49      0.64       968
20:46:12.028222: Validation Seq.Label F1: 0.580369264076641; Log.Reg F1: 0.35266645415516507; train loss: 0.02968737483024597; Language: english 

20:46:12.028276: Evaluating Language: finnish
20:46:12.028325: ----------
20:46:19.815127: OBI: 
 [[4833   58  115]
 [  12   15    1]
 [ 154    3   89]]
20:46:19.820515: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.97      0.97      5006
           1       0.20      0.54      0.29        28
           2       0.43      0.36      0.39       246

    accuracy                           0.94      5280
   macro avg       0.53      0.62      0.55      5280
weighted avg       0.94      0.94      0.94      5280
20:46:19.820565: ----------
20:46:19.821582: LR: 
 [[969 622]
 [  9  19]]
20:46:19.824841: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.75      1591
           1       0.03      0.68      0.06        28

    accuracy                           0.61      1619
   macro avg       0.51      0.64      0.41      1619
weighted avg       0.97      0.61      0.74      1619
20:46:19.826616: Validation Seq.Label F1: 0.5497523240767473; Log.Reg F1: 0.4055901658325871; train loss: 0.02968737483024597; Language: finnish 

20:46:19.826667: Evaluating Language: japanese
20:46:19.826709: ----------
20:46:24.228107: OBI: 
 [[5973   54  192]
 [  12   23    1]
 [ 120    4  133]]
20:46:24.234061: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      6219
           1       0.28      0.64      0.39        36
           2       0.41      0.52      0.46       257

    accuracy                           0.94      6512
   macro avg       0.56      0.71      0.61      6512
weighted avg       0.95      0.94      0.95      6512
20:46:24.234104: ----------
20:46:24.234741: LR: 
 [[595 229]
 [ 14  22]]
20:46:24.237355: LR: 
               precision    recall  f1-score   support

           0       0.98      0.72      0.83       824
           1       0.09      0.61      0.15        36

    accuracy                           0.72       860
   macro avg       0.53      0.67      0.49       860
weighted avg       0.94      0.72      0.80       860
20:46:24.239423: Validation Seq.Label F1: 0.6062504179294244; Log.Reg F1: 0.49186789246020257; train loss: 0.02968737483024597; Language: japanese 

20:46:24.240727: Combined F1 SeqLab: 0.5792511458058726; train loss: 0.02968737483024597
20:46:24.242014: Combined F1 LogReg: 0.42063881344914905; train loss: 0.02968737483024597 

20:46:24.242065: Learning rates: []
20:46:29.123451: -- Data Parsing FINNISH; Type: TRAIN--
20:47:20.012546: Unanswerable questions: 6799
20:47:20.125427: Balance of labels: dict_keys([-100, 0, 1, 2]):dict_values([154024, 1648382, 6365, 59353])
20:47:20.125500: Entries skipped due to too long sequence length (>512): 107
20:47:20.125545: Failed to map answer and to context: 430
20:47:20.228686: Label counts: O: 1648382, B: 6365, I: 59353
20:47:20.228931: Final length: 13164 

20:47:20.287567: Language: finnish; Class weights: [0.00347526 0.90000811 0.09651663 0.        ]
20:47:20.551604: Training model: lab6_bert-base-multilingual-cased_finnish.pt
20:47:20.551912: Loading model: bert-base-multilingual-cased
20:47:22.647233: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 1/40
20:52:29.370648: Evaluating Language: english
20:52:29.370803: ----------
20:52:34.155469: OBI: 
 [[1709  291 2133]
 [   0   15    2]
 [   5    3  170]]
20:52:34.160364: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.41      0.58      4133
           1       0.05      0.88      0.09        17
           2       0.07      0.96      0.14       178

    accuracy                           0.44      4328
   macro avg       0.37      0.75      0.27      4328
weighted avg       0.96      0.44      0.56      4328
20:52:34.160409: ----------
20:52:34.161085: LR: 
 [[843 108]
 [ 11   6]]
20:52:34.163803: LR: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.93       951
           1       0.05      0.35      0.09        17

    accuracy                           0.88       968
   macro avg       0.52      0.62      0.51       968
weighted avg       0.97      0.88      0.92       968
20:52:34.169103: Validation Seq.Label F1: 0.2711763190061193; Log.Reg F1: 0.5128375377978897; train loss: 0.47548961639404297; Language: english 

20:52:34.169159: Evaluating Language: finnish
20:52:34.169207: ----------
20:52:42.056055: OBI: 
 [[3622  536 2785]
 [   0   32    4]
 [   4   13  379]]
20:52:42.063001: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.69      6943
           1       0.06      0.89      0.10        36
           2       0.12      0.96      0.21       396

    accuracy                           0.55      7375
   macro avg       0.39      0.79      0.33      7375
weighted avg       0.95      0.55      0.66      7375
20:52:42.063045: ----------
20:52:42.063927: LR: 
 [[832 751]
 [  7  29]]
20:52:42.067300: LR: 
               precision    recall  f1-score   support

           0       0.99      0.53      0.69      1583
           1       0.04      0.81      0.07        36

    accuracy                           0.53      1619
   macro avg       0.51      0.67      0.38      1619
weighted avg       0.97      0.53      0.67      1619
20:52:42.070784: Validation Seq.Label F1: 0.3339369314195593; Log.Reg F1: 0.3790569696086527; train loss: 0.47548961639404297; Language: finnish 

20:52:42.070849: Evaluating Language: japanese
20:52:42.070894: ----------
20:52:46.736508: OBI: 
 [[2997  472 2772]
 [   1   24    0]
 [   4    7  135]]
20:52:46.742601: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65      6241
           1       0.05      0.96      0.09        25
           2       0.05      0.92      0.09       146

    accuracy                           0.49      6412
   macro avg       0.36      0.79      0.28      6412
weighted avg       0.97      0.49      0.63      6412
20:52:46.742645: ----------
20:52:46.743280: LR: 
 [[667 168]
 [  7  18]]
20:52:46.745893: LR: 
               precision    recall  f1-score   support

           0       0.99      0.80      0.88       835
           1       0.10      0.72      0.17        25

    accuracy                           0.80       860
   macro avg       0.54      0.76      0.53       860
weighted avg       0.96      0.80      0.86       860
20:52:46.752464: Validation Seq.Label F1: 0.2759458143413332; Log.Reg F1: 0.5273226360635554; train loss: 0.47548961639404297; Language: japanese 

20:52:46.754707: Combined F1 SeqLab: 0.2950686714467903; train loss: 0.47548961639404297
20:52:47.391847: Combined F1 LogReg: 0.47775715200944013; train loss: 0.47548961639404297 

20:52:47.394073: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 2/40
20:57:52.574456: Evaluating Language: english
20:57:52.574652: ----------
20:57:57.236210: OBI: 
 [[1624  217 1412]
 [   0   11    4]
 [   5    1  110]]
20:57:57.240504: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.50      0.67      3253
           1       0.05      0.73      0.09        15
           2       0.07      0.95      0.13       116

    accuracy                           0.52      3384
   macro avg       0.37      0.73      0.30      3384
weighted avg       0.96      0.52      0.64      3384
20:57:57.240549: ----------
20:57:57.241226: LR: 
 [[564 389]
 [  2  13]]
20:57:57.243966: LR: 
               precision    recall  f1-score   support

           0       1.00      0.59      0.74       953
           1       0.03      0.87      0.06        15

    accuracy                           0.60       968
   macro avg       0.51      0.73      0.40       968
weighted avg       0.98      0.60      0.73       968
20:57:57.252906: Validation Seq.Label F1: 0.29648266271837764; Log.Reg F1: 0.4024719658111562; train loss: 0.3057169020175934; Language: english 

20:57:57.252962: Evaluating Language: finnish
20:57:57.253006: ----------
20:58:05.160347: OBI: 
 [[4921  278 1204]
 [   2   24    2]
 [  55   19  309]]
20:58:05.166626: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.77      0.86      6403
           1       0.07      0.86      0.14        28
           2       0.20      0.81      0.33       383

    accuracy                           0.77      6814
   macro avg       0.42      0.81      0.44      6814
weighted avg       0.94      0.77      0.83      6814
20:58:05.166675: ----------
20:58:05.167551: LR: 
 [[687 904]
 [  2  26]]
20:58:05.171113: LR: 
               precision    recall  f1-score   support

           0       1.00      0.43      0.60      1591
           1       0.03      0.93      0.05        28

    accuracy                           0.44      1619
   macro avg       0.51      0.68      0.33      1619
weighted avg       0.98      0.44      0.59      1619
20:58:05.174117: Validation Seq.Label F1: 0.4426387806470782; Log.Reg F1: 0.3284556642127239; train loss: 0.3057169020175934; Language: finnish 

20:58:05.174173: Evaluating Language: japanese
20:58:05.174217: ----------
20:58:09.773431: OBI: 
 [[3202  271 1322]
 [   0   21    2]
 [  25    2  159]]
20:58:09.778628: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.67      0.80      4795
           1       0.07      0.91      0.13        23
           2       0.11      0.85      0.19       186

    accuracy                           0.68      5004
   macro avg       0.39      0.81      0.37      5004
weighted avg       0.96      0.68      0.77      5004
20:58:09.778675: ----------
20:58:09.779318: LR: 
 [[295 542]
 [  3  20]]
20:58:09.781939: LR: 
               precision    recall  f1-score   support

           0       0.99      0.35      0.52       837
           1       0.04      0.87      0.07        23

    accuracy                           0.37       860
   macro avg       0.51      0.61      0.29       860
weighted avg       0.96      0.37      0.51       860
20:58:09.784816: Validation Seq.Label F1: 0.3737766763962844; Log.Reg F1: 0.2940999284611619; train loss: 0.3057169020175934; Language: japanese 

20:58:09.787109: Combined F1 SeqLab: 0.37573929935668793; train loss: 0.3057169020175934
20:58:10.444749: Combined F1 LogReg: 0.3446551776960941; train loss: 0.3057169020175934 

20:58:10.445592: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 3/40
21:03:24.881419: Evaluating Language: english
21:03:24.881543: ----------
21:03:29.528091: OBI: 
 [[2172  333  851]
 [   0   11    0]
 [   8   12  125]]
21:03:29.532481: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.65      0.78      3356
           1       0.03      1.00      0.06        11
           2       0.13      0.86      0.22       145

    accuracy                           0.66      3512
   macro avg       0.39      0.84      0.36      3512
weighted avg       0.96      0.66      0.76      3512
21:03:29.532525: ----------
21:03:29.533386: LR: 
 [[682 275]
 [  5   6]]
21:03:29.536394: LR: 
               precision    recall  f1-score   support

           0       0.99      0.71      0.83       957
           1       0.02      0.55      0.04        11

    accuracy                           0.71       968
   macro avg       0.51      0.63      0.44       968
weighted avg       0.98      0.71      0.82       968
21:03:29.545900: Validation Seq.Label F1: 0.3558809166810904; Log.Reg F1: 0.435389794353898; train loss: 0.232939213514328; Language: english 

21:03:29.545953: Evaluating Language: finnish
21:03:29.545996: ----------
21:03:37.216227: OBI: 
 [[4636  324  532]
 [   1   23    2]
 [  66   17  228]]
21:03:37.221919: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.84      0.91      5492
           1       0.06      0.88      0.12        26
           2       0.30      0.73      0.42       311

    accuracy                           0.84      5829
   macro avg       0.45      0.82      0.48      5829
weighted avg       0.95      0.84      0.88      5829
21:03:37.221961: ----------
21:03:37.222835: LR: 
 [[872 721]
 [  7  19]]
21:03:37.226102: LR: 
               precision    recall  f1-score   support

           0       0.99      0.55      0.71      1593
           1       0.03      0.73      0.05        26

    accuracy                           0.55      1619
   macro avg       0.51      0.64      0.38      1619
weighted avg       0.98      0.55      0.69      1619
21:03:37.228990: Validation Seq.Label F1: 0.4841302810050167; Log.Reg F1: 0.3775549866071806; train loss: 0.232939213514328; Language: finnish 

21:03:37.229047: Evaluating Language: japanese
21:03:37.229089: ----------
21:03:41.799712: OBI: 
 [[1965  198  382]
 [   0   11    1]
 [  23    5   83]]
21:03:41.803336: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.77      0.87      2545
           1       0.05      0.92      0.10        12
           2       0.18      0.75      0.29       111

    accuracy                           0.77      2668
   macro avg       0.41      0.81      0.42      2668
weighted avg       0.95      0.77      0.84      2668
21:03:41.803379: ----------
21:03:41.804014: LR: 
 [[405 443]
 [  1  11]]
21:03:41.806659: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65       848
           1       0.02      0.92      0.05        12

    accuracy                           0.48       860
   macro avg       0.51      0.70      0.35       860
weighted avg       0.98      0.48      0.64       860
21:03:41.809831: Validation Seq.Label F1: 0.4173385398840632; Log.Reg F1: 0.34657165739162576; train loss: 0.232939213514328; Language: japanese 

21:03:41.812135: Combined F1 SeqLab: 0.42237614070728136; train loss: 0.232939213514328
21:03:42.474376: Combined F1 LogReg: 0.38825419278554113; train loss: 0.232939213514328 

21:03:42.476033: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 4/40
21:08:54.910116: Evaluating Language: english
21:08:54.910291: ----------
21:08:59.667336: OBI: 
 [[2839  244 1589]
 [   2   11    6]
 [  13    4  164]]
21:08:59.672528: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.75      4672
           1       0.04      0.58      0.08        19
           2       0.09      0.91      0.17       181

    accuracy                           0.62      4872
   macro avg       0.38      0.70      0.33      4872
weighted avg       0.96      0.62      0.73      4872
21:08:59.672575: ----------
21:08:59.673281: LR: 
 [[464 485]
 [  4  15]]
21:08:59.676007: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.65       949
           1       0.03      0.79      0.06        19

    accuracy                           0.49       968
   macro avg       0.51      0.64      0.36       968
weighted avg       0.97      0.49      0.64       968
21:08:59.685101: Validation Seq.Label F1: 0.3342200304373732; Log.Reg F1: 0.3563540982536581; train loss: 0.17428182065486908; Language: english 

21:08:59.685156: Evaluating Language: finnish
21:08:59.685198: ----------
21:09:07.487962: OBI: 
 [[3539  132  675]
 [   1   21    0]
 [   8    5  261]]
21:09:07.493849: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.81      0.90      4346
           1       0.13      0.95      0.23        22
           2       0.28      0.95      0.43       274

    accuracy                           0.82      4642
   macro avg       0.47      0.91      0.52      4642
weighted avg       0.95      0.82      0.87      4642
21:09:07.493903: ----------
21:09:07.494965: LR: 
 [[760 837]
 [  2  20]]
21:09:07.498862: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.64      1597
           1       0.02      0.91      0.05        22

    accuracy                           0.48      1619
   macro avg       0.51      0.69      0.34      1619
weighted avg       0.98      0.48      0.64      1619
21:09:07.502104: Validation Seq.Label F1: 0.5204562147257406; Log.Reg F1: 0.3449235397463591; train loss: 0.17428182065486908; Language: finnish 

21:09:07.502168: Evaluating Language: japanese
21:09:07.502220: ----------
21:09:12.087725: OBI: 
 [[3868  258 1235]
 [   0   21    3]
 [  33    2  180]]
21:09:12.093238: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.72      0.84      5361
           1       0.07      0.88      0.14        24
           2       0.13      0.84      0.22       215

    accuracy                           0.73      5600
   macro avg       0.40      0.81      0.40      5600
weighted avg       0.95      0.73      0.81      5600
21:09:12.093282: ----------
21:09:12.093945: LR: 
 [[543 293]
 [  6  18]]
21:09:12.096583: LR: 
               precision    recall  f1-score   support

           0       0.99      0.65      0.78       836
           1       0.06      0.75      0.11        24

    accuracy                           0.65       860
   macro avg       0.52      0.70      0.45       860
weighted avg       0.96      0.65      0.77       860
21:09:12.099812: Validation Seq.Label F1: 0.3977996134900266; Log.Reg F1: 0.4457891050164341; train loss: 0.17428182065486908; Language: japanese 

21:09:12.102119: Combined F1 SeqLab: 0.42458694935392577; train loss: 0.17428182065486908
21:09:12.757711: Combined F1 LogReg: 0.38500580851232585; train loss: 0.17428182065486908 

21:09:12.758860: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 5/40
21:14:21.708759: Evaluating Language: english
21:14:21.708921: ----------
21:14:26.460362: OBI: 
 [[2507  188  825]
 [   0   10    4]
 [   8    1   73]]
21:14:26.464906: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.71      0.83      3520
           1       0.05      0.71      0.09        14
           2       0.08      0.89      0.15        82

    accuracy                           0.72      3616
   macro avg       0.38      0.77      0.36      3616
weighted avg       0.97      0.72      0.81      3616
21:14:26.464954: ----------
21:14:26.465671: LR: 
 [[304 650]
 [  1  13]]
21:14:26.468389: LR: 
               precision    recall  f1-score   support

           0       1.00      0.32      0.48       954
           1       0.02      0.93      0.04        14

    accuracy                           0.33       968
   macro avg       0.51      0.62      0.26       968
weighted avg       0.98      0.33      0.48       968
21:14:26.478281: Validation Seq.Label F1: 0.3576969709216562; Log.Reg F1: 0.26066384073078563; train loss: 0.13498647511005402; Language: english 

21:14:26.478345: Evaluating Language: finnish
21:14:26.478391: ----------
21:14:34.322220: OBI: 
 [[6833  214  933]
 [   1   27    7]
 [  14    9  291]]
21:14:34.329571: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92      7980
           1       0.11      0.77      0.19        35
           2       0.24      0.93      0.38       314

    accuracy                           0.86      8329
   macro avg       0.45      0.85      0.50      8329
weighted avg       0.97      0.86      0.90      8329
21:14:34.329618: ----------
21:14:34.330492: LR: 
 [[787 797]
 [  3  32]]
21:14:34.333790: LR: 
               precision    recall  f1-score   support

           0       1.00      0.50      0.66      1584
           1       0.04      0.91      0.07        35

    accuracy                           0.51      1619
   macro avg       0.52      0.71      0.37      1619
weighted avg       0.98      0.51      0.65      1619
21:14:34.336743: Validation Seq.Label F1: 0.49593581947120713; Log.Reg F1: 0.368545040406877; train loss: 0.13498647511005402; Language: finnish 

21:14:34.336797: Evaluating Language: japanese
21:14:34.336843: ----------
21:14:38.961447: OBI: 
 [[3155  188  733]
 [   0   22    1]
 [  34    1  130]]
21:14:38.966103: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.77      0.87      4076
           1       0.10      0.96      0.19        23
           2       0.15      0.79      0.25       165

    accuracy                           0.78      4264
   macro avg       0.41      0.84      0.44      4264
weighted avg       0.95      0.78      0.84      4264
21:14:38.966147: ----------
21:14:38.966792: LR: 
 [[399 438]
 [  5  18]]
21:14:38.969417: LR: 
               precision    recall  f1-score   support

           0       0.99      0.48      0.64       837
           1       0.04      0.78      0.08        23

    accuracy                           0.48       860
   macro avg       0.51      0.63      0.36       860
weighted avg       0.96      0.48      0.63       860
21:14:38.972563: Validation Seq.Label F1: 0.4364181725587402; Log.Reg F1: 0.3590931954330049; train loss: 0.13498647511005402; Language: japanese 

21:14:38.975173: Combined F1 SeqLab: 0.43372813350477823; train loss: 0.13498647511005402
21:14:39.733749: Combined F1 LogReg: 0.3330260288522592; train loss: 0.13498647511005402 

21:14:39.734575: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 6/40
21:19:47.251636: Evaluating Language: english
21:19:47.251843: ----------
21:19:52.027648: OBI: 
 [[1899   74  476]
 [   1    6    5]
 [  12    5   74]]
21:19:52.031321: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.78      0.87      2449
           1       0.07      0.50      0.12        12
           2       0.13      0.81      0.23        91

    accuracy                           0.78      2552
   macro avg       0.40      0.70      0.41      2552
weighted avg       0.96      0.78      0.84      2552
21:19:52.031370: ----------
21:19:52.032055: LR: 
 [[499 457]
 [  3   9]]
21:19:52.034788: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.68       956
           1       0.02      0.75      0.04        12

    accuracy                           0.52       968
   macro avg       0.51      0.64      0.36       968
weighted avg       0.98      0.52      0.68       968
21:19:52.043869: Validation Seq.Label F1: 0.40790489228179827; Log.Reg F1: 0.36107810894731707; train loss: 0.1186569482088089; Language: english 

21:19:52.043925: Evaluating Language: finnish
21:19:52.043970: ----------
21:19:59.756030: OBI: 
 [[5134   94  365]
 [   2   29    2]
 [  81   11  347]]
21:19:59.761854: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.92      0.95      5593
           1       0.22      0.88      0.35        33
           2       0.49      0.79      0.60       439

    accuracy                           0.91      6065
   macro avg       0.56      0.86      0.63      6065
weighted avg       0.94      0.91      0.92      6065
21:19:59.761902: ----------
21:19:59.762795: LR: 
 [[979 607]
 [  7  26]]
21:19:59.766071: LR: 
               precision    recall  f1-score   support

           0       0.99      0.62      0.76      1586
           1       0.04      0.79      0.08        33

    accuracy                           0.62      1619
   macro avg       0.52      0.70      0.42      1619
weighted avg       0.97      0.62      0.75      1619
21:19:59.769164: Validation Seq.Label F1: 0.633024898243177; Log.Reg F1: 0.41967667511990997; train loss: 0.1186569482088089; Language: finnish 

21:19:59.769219: Evaluating Language: japanese
21:19:59.769262: ----------
21:20:04.391442: OBI: 
 [[3174   71  367]
 [   1   15    3]
 [  35    1   97]]
21:20:04.395813: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      3612
           1       0.17      0.79      0.28        19
           2       0.21      0.73      0.32       133

    accuracy                           0.87      3764
   macro avg       0.46      0.80      0.51      3764
weighted avg       0.96      0.87      0.91      3764
21:20:04.395858: ----------
21:20:04.396509: LR: 
 [[493 348]
 [  6  13]]
21:20:04.399151: LR: 
               precision    recall  f1-score   support

           0       0.99      0.59      0.74       841
           1       0.04      0.68      0.07        19

    accuracy                           0.59       860
   macro avg       0.51      0.64      0.40       860
weighted avg       0.97      0.59      0.72       860
21:20:04.402207: Validation Seq.Label F1: 0.5122903702228639; Log.Reg F1: 0.4021209740769835; train loss: 0.1186569482088089; Language: japanese 

21:20:04.404611: Combined F1 SeqLab: 0.5258479965307747; train loss: 0.1186569482088089
21:20:05.084944: Combined F1 LogReg: 0.39505577251543234; train loss: 0.1186569482088089 

21:20:05.086001: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 7/40
21:25:21.224097: Evaluating Language: english
21:25:21.224269: ----------
21:25:25.935840: OBI: 
 [[3283  107  634]
 [   3   12    3]
 [   5    5  108]]
21:25:25.940599: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.82      0.90      4024
           1       0.10      0.67      0.17        18
           2       0.14      0.92      0.25       118

    accuracy                           0.82      4160
   macro avg       0.41      0.80      0.44      4160
weighted avg       0.97      0.82      0.88      4160
21:25:25.940641: ----------
21:25:25.941342: LR: 
 [[413 537]
 [  5  13]]
21:25:25.944076: LR: 
               precision    recall  f1-score   support

           0       0.99      0.43      0.60       950
           1       0.02      0.72      0.05        18

    accuracy                           0.44       968
   macro avg       0.51      0.58      0.32       968
weighted avg       0.97      0.44      0.59       968
21:25:25.953451: Validation Seq.Label F1: 0.43897047571577524; Log.Reg F1: 0.32478790873898356; train loss: 0.09029997140169144; Language: english 

21:25:25.953511: Evaluating Language: finnish
21:25:25.953556: ----------
21:25:33.631069: OBI: 
 [[5164   77  282]
 [   6   23    0]
 [  46    5  304]]
21:25:33.636753: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      5523
           1       0.22      0.79      0.34        29
           2       0.52      0.86      0.65       355

    accuracy                           0.93      5907
   macro avg       0.58      0.86      0.65      5907
weighted avg       0.96      0.93      0.94      5907
21:25:33.636794: ----------
21:25:33.637672: LR: 
 [[864 726]
 [  9  20]]
21:25:33.640947: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70      1590
           1       0.03      0.69      0.05        29

    accuracy                           0.55      1619
   macro avg       0.51      0.62      0.38      1619
weighted avg       0.97      0.55      0.69      1619
21:25:33.643939: Validation Seq.Label F1: 0.650377669968439; Log.Reg F1: 0.37659816903068644; train loss: 0.09029997140169144; Language: finnish 

21:25:33.643992: Evaluating Language: japanese
21:25:33.644036: ----------
21:25:38.278096: OBI: 
 [[4901   91  458]
 [   3   19    1]
 [  36    6  137]]
21:25:38.283600: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      5450
           1       0.16      0.83      0.27        23
           2       0.23      0.77      0.35       179

    accuracy                           0.89      5652
   macro avg       0.46      0.83      0.52      5652
weighted avg       0.96      0.89      0.92      5652
21:25:38.283641: ----------
21:25:38.284279: LR: 
 [[347 490]
 [  4  19]]
21:25:38.286947: LR: 
               precision    recall  f1-score   support

           0       0.99      0.41      0.58       837
           1       0.04      0.83      0.07        23

    accuracy                           0.43       860
   macro avg       0.51      0.62      0.33       860
weighted avg       0.96      0.43      0.57       860
21:25:38.290182: Validation Seq.Label F1: 0.5234456014312397; Log.Reg F1: 0.32780182780182776; train loss: 0.09029997140169144; Language: japanese 

21:25:38.292784: Combined F1 SeqLab: 0.5445736833528352; train loss: 0.09029997140169144
21:25:38.942825: Combined F1 LogReg: 0.34388341284536483; train loss: 0.09029997140169144 

21:25:38.943651: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 8/40
21:30:51.878331: Evaluating Language: english
21:30:51.878697: ----------
21:30:56.661669: OBI: 
 [[2907   76  576]
 [   2    9    2]
 [  29    2   85]]
21:30:56.666892: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.82      0.89      3559
           1       0.10      0.69      0.18        13
           2       0.13      0.73      0.22       116

    accuracy                           0.81      3688
   macro avg       0.41      0.75      0.43      3688
weighted avg       0.96      0.81      0.87      3688
21:30:56.666944: ----------
21:30:56.667760: LR: 
 [[373 582]
 [  1  12]]
21:30:56.671025: LR: 
               precision    recall  f1-score   support

           0       1.00      0.39      0.56       955
           1       0.02      0.92      0.04        13

    accuracy                           0.40       968
   macro avg       0.51      0.66      0.30       968
weighted avg       0.98      0.40      0.55       968
21:30:56.681400: Validation Seq.Label F1: 0.43103435185417527; Log.Reg F1: 0.30043150948986175; train loss: 0.08084520697593689; Language: english 

21:30:56.681468: Evaluating Language: finnish
21:30:56.681520: ----------
21:31:04.611004: OBI: 
 [[3788   60  308]
 [   3   17    2]
 [  18    9  217]]
21:31:04.615727: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      4156
           1       0.20      0.77      0.31        22
           2       0.41      0.89      0.56       244

    accuracy                           0.91      4422
   macro avg       0.53      0.86      0.61      4422
weighted avg       0.96      0.91      0.93      4422
21:31:04.615769: ----------
21:31:04.616645: LR: 
 [[796 801]
 [  4  18]]
21:31:04.619921: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.66      1597
           1       0.02      0.82      0.04        22

    accuracy                           0.50      1619
   macro avg       0.51      0.66      0.35      1619
weighted avg       0.98      0.50      0.66      1619
21:31:04.622879: Validation Seq.Label F1: 0.6096271544687646; Log.Reg F1: 0.3534848604354333; train loss: 0.08084520697593689; Language: finnish 

21:31:04.622934: Evaluating Language: japanese
21:31:04.622977: ----------
21:31:09.217947: OBI: 
 [[4491   69  409]
 [   5   22    2]
 [  46    1  211]]
21:31:09.223154: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      4969
           1       0.24      0.76      0.36        29
           2       0.34      0.82      0.48       258

    accuracy                           0.90      5256
   macro avg       0.52      0.83      0.60      5256
weighted avg       0.95      0.90      0.92      5256
21:31:09.223197: ----------
21:31:09.223842: LR: 
 [[616 215]
 [  9  20]]
21:31:09.226498: LR: 
               precision    recall  f1-score   support

           0       0.99      0.74      0.85       831
           1       0.09      0.69      0.15        29

    accuracy                           0.74       860
   macro avg       0.54      0.72      0.50       860
weighted avg       0.96      0.74      0.82       860
21:31:09.229477: Validation Seq.Label F1: 0.5958540031797313; Log.Reg F1: 0.49883449883449876; train loss: 0.08084520697593689; Language: japanese 

21:31:09.231809: Combined F1 SeqLab: 0.5515063834775149; train loss: 0.08084520697593689
21:31:09.919587: Combined F1 LogReg: 0.3932965359957972; train loss: 0.08084520697593689 

21:31:09.920845: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 9/40
21:36:16.878976: Evaluating Language: english
21:36:16.879118: ----------
21:36:21.384404: OBI: 
 [[3755  104  530]
 [   3   15    3]
 [  58    8  116]]
21:36:21.390345: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.86      0.92      4389
           1       0.12      0.71      0.20        21
           2       0.18      0.64      0.28       182

    accuracy                           0.85      4592
   macro avg       0.43      0.74      0.47      4592
weighted avg       0.95      0.85      0.89      4592
21:36:21.390396: ----------
21:36:21.391222: LR: 
 [[427 520]
 [  1  20]]
21:36:21.394450: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62       947
           1       0.04      0.95      0.07        21

    accuracy                           0.46       968
   macro avg       0.52      0.70      0.35       968
weighted avg       0.98      0.46      0.61       968
21:36:21.403930: Validation Seq.Label F1: 0.4657266543267639; Log.Reg F1: 0.34619607843137257; train loss: 0.06279876828193665; Language: english 

21:36:21.403989: Evaluating Language: finnish
21:36:21.404032: ----------
21:36:29.113753: OBI: 
 [[4488   83  275]
 [   5   18    1]
 [  79    6  221]]
21:36:29.118968: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      4846
           1       0.17      0.75      0.27        24
           2       0.44      0.72      0.55       306

    accuracy                           0.91      5176
   macro avg       0.53      0.80      0.59      5176
weighted avg       0.95      0.91      0.93      5176
21:36:29.119012: ----------
21:36:29.119994: LR: 
 [[871 724]
 [  3  21]]
21:36:29.123536: LR: 
               precision    recall  f1-score   support

           0       1.00      0.55      0.71      1595
           1       0.03      0.88      0.05        24

    accuracy                           0.55      1619
   macro avg       0.51      0.71      0.38      1619
weighted avg       0.98      0.55      0.70      1619
21:36:29.126914: Validation Seq.Label F1: 0.5927712059558213; Log.Reg F1: 0.38008259504987985; train loss: 0.06279876828193665; Language: finnish 

21:36:29.126968: Evaluating Language: japanese
21:36:29.127011: ----------
21:36:33.559926: OBI: 
 [[2277   50  226]
 [   3   10    0]
 [  23    0   87]]
21:36:33.563532: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      2553
           1       0.17      0.77      0.27        13
           2       0.28      0.79      0.41       110

    accuracy                           0.89      2676
   macro avg       0.48      0.82      0.54      2676
weighted avg       0.96      0.89      0.91      2676
21:36:33.563575: ----------
21:36:33.564207: LR: 
 [[481 366]
 [  0  13]]
21:36:33.566873: LR: 
               precision    recall  f1-score   support

           0       1.00      0.57      0.72       847
           1       0.03      1.00      0.07        13

    accuracy                           0.57       860
   macro avg       0.52      0.78      0.40       860
weighted avg       0.99      0.57      0.71       860
21:36:33.569891: Validation Seq.Label F1: 0.5410430055603652; Log.Reg F1: 0.3953620604868454; train loss: 0.06279876828193665; Language: japanese 

21:36:33.572278: Combined F1 SeqLab: 0.5357258481183926; train loss: 0.06279876828193665
21:36:33.574662: Combined F1 LogReg: 0.37444432726086085; train loss: 0.06279876828193665 

21:36:33.575288: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 10/40
21:41:42.527988: Evaluating Language: english
21:41:42.528124: ----------
21:41:47.167529: OBI: 
 [[3011  112  558]
 [   2   13    2]
 [   6    2   86]]
21:41:47.171993: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.82      0.90      3681
           1       0.10      0.76      0.18        17
           2       0.13      0.91      0.23        94

    accuracy                           0.82      3792
   macro avg       0.41      0.83      0.44      3792
weighted avg       0.97      0.82      0.88      3792
21:41:47.172040: ----------
21:41:47.172732: LR: 
 [[370 581]
 [  2  15]]
21:41:47.175485: LR: 
               precision    recall  f1-score   support

           0       0.99      0.39      0.56       951
           1       0.03      0.88      0.05        17

    accuracy                           0.40       968
   macro avg       0.51      0.64      0.30       968
weighted avg       0.98      0.40      0.55       968
21:41:47.183847: Validation Seq.Label F1: 0.43726465271241394; Log.Reg F1: 0.30413724307921464; train loss: 0.07125644385814667; Language: english 

21:41:47.183908: Evaluating Language: finnish
21:41:47.183952: ----------
21:41:54.971303: OBI: 
 [[4328   64  229]
 [   4   14    2]
 [  67    3  232]]
21:41:54.979668: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      4621
           1       0.17      0.70      0.28        20
           2       0.50      0.77      0.61       302

    accuracy                           0.93      4943
   macro avg       0.55      0.80      0.61      4943
weighted avg       0.95      0.93      0.94      4943
21:41:54.979715: ----------
21:41:54.980613: LR: 
 [[833 766]
 [  4  16]]
21:41:54.983896: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.68      1599
           1       0.02      0.80      0.04        20

    accuracy                           0.52      1619
   macro avg       0.51      0.66      0.36      1619
weighted avg       0.98      0.52      0.68      1619
21:41:54.986779: Validation Seq.Label F1: 0.6144696344335533; Log.Reg F1: 0.3619041476767851; train loss: 0.07125644385814667; Language: finnish 

21:41:54.986838: Evaluating Language: japanese
21:41:54.986881: ----------
21:41:59.610396: OBI: 
 [[4664   94  667]
 [   4   19    1]
 [  28    0  123]]
21:41:59.615844: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      5425
           1       0.17      0.79      0.28        24
           2       0.16      0.81      0.26       151

    accuracy                           0.86      5600
   macro avg       0.44      0.82      0.49      5600
weighted avg       0.97      0.86      0.90      5600
21:41:59.615888: ----------
21:41:59.616527: LR: 
 [[433 403]
 [  3  21]]
21:41:59.619165: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.68       836
           1       0.05      0.88      0.09        24

    accuracy                           0.53       860
   macro avg       0.52      0.70      0.39       860
weighted avg       0.97      0.53      0.66       860
21:41:59.622086: Validation Seq.Label F1: 0.48672227269375107; Log.Reg F1: 0.3872838050314466; train loss: 0.07125644385814667; Language: japanese 

21:41:59.624551: Combined F1 SeqLab: 0.5182251373321518; train loss: 0.07125644385814667
21:41:59.627036: Combined F1 LogReg: 0.35282801304749084; train loss: 0.07125644385814667 

21:41:59.627701: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 11/40
21:47:15.278301: Evaluating Language: english
21:47:15.278455: ----------
21:47:19.992536: OBI: 
 [[2389   79  817]
 [   1   10    2]
 [   4    3  127]]
21:47:19.996743: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.73      0.84      3285
           1       0.11      0.77      0.19        13
           2       0.13      0.95      0.24       134

    accuracy                           0.74      3432
   macro avg       0.41      0.81      0.42      3432
weighted avg       0.96      0.74      0.82      3432
21:47:19.996783: ----------
21:47:19.997473: LR: 
 [[376 579]
 [  1  12]]
21:47:20.000187: LR: 
               precision    recall  f1-score   support

           0       1.00      0.39      0.56       955
           1       0.02      0.92      0.04        13

    accuracy                           0.40       968
   macro avg       0.51      0.66      0.30       968
weighted avg       0.98      0.40      0.56       968
21:47:20.008433: Validation Seq.Label F1: 0.4223355609779275; Log.Reg F1: 0.3021498319511564; train loss: 0.06761042773723602; Language: english 

21:47:20.008490: Evaluating Language: finnish
21:47:20.008532: ----------
21:47:27.797177: OBI: 
 [[5688   83  555]
 [   2   24    5]
 [  57    9  312]]
21:47:27.803357: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      6326
           1       0.21      0.77      0.33        31
           2       0.36      0.83      0.50       378

    accuracy                           0.89      6735
   macro avg       0.52      0.83      0.59      6735
weighted avg       0.95      0.89      0.91      6735
21:47:27.803399: ----------
21:47:27.804277: LR: 
 [[823 765]
 [  4  27]]
21:47:27.807573: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.68      1588
           1       0.03      0.87      0.07        31

    accuracy                           0.53      1619
   macro avg       0.51      0.69      0.37      1619
weighted avg       0.98      0.53      0.67      1619
21:47:27.810847: Validation Seq.Label F1: 0.5893328275665439; Log.Reg F1: 0.3735935538566422; train loss: 0.06761042773723602; Language: finnish 

21:47:27.810899: Evaluating Language: japanese
21:47:27.810944: ----------
21:47:32.451079: OBI: 
 [[3711  101 1209]
 [   3   13    0]
 [  40    0  139]]
21:47:32.456301: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.74      0.85      5021
           1       0.11      0.81      0.20        16
           2       0.10      0.78      0.18       179

    accuracy                           0.74      5216
   macro avg       0.40      0.78      0.41      5216
weighted avg       0.96      0.74      0.82      5216
21:47:32.456352: ----------
21:47:32.456982: LR: 
 [[466 378]
 [  6  10]]
21:47:32.459621: LR: 
               precision    recall  f1-score   support

           0       0.99      0.55      0.71       844
           1       0.03      0.62      0.05        16

    accuracy                           0.55       860
   macro avg       0.51      0.59      0.38       860
weighted avg       0.97      0.55      0.70       860
21:47:32.462759: Validation Seq.Label F1: 0.4092894284642811; Log.Reg F1: 0.3788558187125704; train loss: 0.06761042773723602; Language: japanese 

21:47:32.465142: Combined F1 SeqLab: 0.48069336864115236; train loss: 0.06761042773723602
21:47:32.467532: Combined F1 LogReg: 0.35326967782121727; train loss: 0.06761042773723602 

21:47:32.468146: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 12/40
21:52:38.849475: Evaluating Language: english
21:52:38.849618: ----------
21:52:43.592617: OBI: 
 [[4572  149  761]
 [   4   16    6]
 [  33    6  221]]
21:52:43.598338: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.83      0.91      5482
           1       0.09      0.62      0.16        26
           2       0.22      0.85      0.35       260

    accuracy                           0.83      5768
   macro avg       0.44      0.77      0.47      5768
weighted avg       0.95      0.83      0.88      5768
21:52:43.598382: ----------
21:52:43.599066: LR: 
 [[389 553]
 [  1  25]]
21:52:43.601787: LR: 
               precision    recall  f1-score   support

           0       1.00      0.41      0.58       942
           1       0.04      0.96      0.08        26

    accuracy                           0.43       968
   macro avg       0.52      0.69      0.33       968
weighted avg       0.97      0.43      0.57       968
21:52:43.609465: Validation Seq.Label F1: 0.47425240450088074; Log.Reg F1: 0.3334327705188632; train loss: 0.0630202367901802; Language: english 

21:52:43.609527: Evaluating Language: finnish
21:52:43.609572: ----------
21:52:51.392928: OBI: 
 [[5797   68  383]
 [   2   23    2]
 [  66    7  311]]
21:52:51.400052: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      6248
           1       0.23      0.85      0.37        27
           2       0.45      0.81      0.58       384

    accuracy                           0.92      6659
   macro avg       0.56      0.86      0.63      6659
weighted avg       0.95      0.92      0.93      6659
21:52:51.400101: ----------
21:52:51.401151: LR: 
 [[785 807]
 [  5  22]]
21:52:51.405101: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.66      1592
           1       0.03      0.81      0.05        27

    accuracy                           0.50      1619
   macro avg       0.51      0.65      0.36      1619
weighted avg       0.98      0.50      0.65      1619
21:52:51.408471: Validation Seq.Label F1: 0.6336931324676173; Log.Reg F1: 0.3552559303812864; train loss: 0.0630202367901802; Language: finnish 

21:52:51.408533: Evaluating Language: japanese
21:52:51.408583: ----------
21:52:56.045989: OBI: 
 [[4477   90  372]
 [   7   19    1]
 [  65    0  193]]
21:52:56.051192: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.91      0.94      4939
           1       0.17      0.70      0.28        27
           2       0.34      0.75      0.47       258

    accuracy                           0.90      5224
   macro avg       0.50      0.79      0.56      5224
weighted avg       0.95      0.90      0.92      5224
21:52:56.051234: ----------
21:52:56.051889: LR: 
 [[568 265]
 [  5  22]]
21:52:56.054535: LR: 
               precision    recall  f1-score   support

           0       0.99      0.68      0.81       833
           1       0.08      0.81      0.14        27

    accuracy                           0.69       860
   macro avg       0.53      0.75      0.47       860
weighted avg       0.96      0.69      0.79       860
21:52:56.057781: Validation Seq.Label F1: 0.5638589159202049; Log.Reg F1: 0.4740466245662357; train loss: 0.0630202367901802; Language: japanese 

21:52:56.060494: Combined F1 SeqLab: 0.5610761108127241; train loss: 0.0630202367901802
21:52:56.744357: Combined F1 LogReg: 0.39247267029675664; train loss: 0.0630202367901802 

21:52:56.745495: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 13/40
21:58:15.627200: Evaluating Language: english
21:58:15.627342: ----------
21:58:20.253085: OBI: 
 [[2303  146  692]
 [   0    9    5]
 [   5    7  121]]
21:58:20.258051: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.73      0.85      3141
           1       0.06      0.64      0.10        14
           2       0.15      0.91      0.25       133

    accuracy                           0.74      3288
   macro avg       0.40      0.76      0.40      3288
weighted avg       0.96      0.74      0.82      3288
21:58:20.258107: ----------
21:58:20.258851: LR: 
 [[471 483]
 [  3  11]]
21:58:20.261626: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.66       954
           1       0.02      0.79      0.04        14

    accuracy                           0.50       968
   macro avg       0.51      0.64      0.35       968
weighted avg       0.98      0.50      0.65       968
21:58:20.267512: Validation Seq.Label F1: 0.4006781405177517; Log.Reg F1: 0.35148547608019587; train loss: 0.05522211268544197; Language: english 

21:58:20.267570: Evaluating Language: finnish
21:58:20.267613: ----------
21:58:27.834134: OBI: 
 [[5033  113  433]
 [   3   23    4]
 [  31    8  239]]
21:58:27.839775: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.95      5579
           1       0.16      0.77      0.26        30
           2       0.35      0.86      0.50       278

    accuracy                           0.90      5887
   macro avg       0.50      0.84      0.57      5887
weighted avg       0.96      0.90      0.92      5887
21:58:27.839818: ----------
21:58:27.840704: LR: 
 [[875 714]
 [  3  27]]
21:58:27.844108: LR: 
               precision    recall  f1-score   support

           0       1.00      0.55      0.71      1589
           1       0.04      0.90      0.07        30

    accuracy                           0.56      1619
   macro avg       0.52      0.73      0.39      1619
weighted avg       0.98      0.56      0.70      1619
21:58:27.847157: Validation Seq.Label F1: 0.5703118260146347; Log.Reg F1: 0.38970125500970787; train loss: 0.05522211268544197; Language: finnish 

21:58:27.847211: Evaluating Language: japanese
21:58:27.847254: ----------
21:58:32.471250: OBI: 
 [[3029  114  587]
 [   5   14    1]
 [  38    0   88]]
21:58:32.475679: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.81      0.89      3730
           1       0.11      0.70      0.19        20
           2       0.13      0.70      0.22       126

    accuracy                           0.81      3876
   macro avg       0.41      0.74      0.43      3876
weighted avg       0.95      0.81      0.87      3876
21:58:32.475722: ----------
21:58:32.476371: LR: 
 [[509 331]
 [  5  15]]
21:58:32.479014: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.75       840
           1       0.04      0.75      0.08        20

    accuracy                           0.61       860
   macro avg       0.52      0.68      0.42       860
weighted avg       0.97      0.61      0.74       860
21:58:32.482011: Validation Seq.Label F1: 0.4330869888410908; Log.Reg F1: 0.4169067971039058; train loss: 0.05522211268544197; Language: japanese 

21:58:32.484534: Combined F1 SeqLab: 0.47376607838480556; train loss: 0.05522211268544197
21:58:32.487008: Combined F1 LogReg: 0.3869626965324094; train loss: 0.05522211268544197 

21:58:32.487639: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 14/40
22:03:38.515009: Evaluating Language: english
22:03:38.515141: ----------
22:03:43.058536: OBI: 
 [[2330   57  439]
 [   1   10    1]
 [  33    3  110]]
22:03:43.062465: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.82      0.90      2826
           1       0.14      0.83      0.24        12
           2       0.20      0.75      0.32       146

    accuracy                           0.82      2984
   macro avg       0.44      0.80      0.49      2984
weighted avg       0.94      0.82      0.87      2984
22:03:43.062509: ----------
22:03:43.063211: LR: 
 [[314 642]
 [  0  12]]
22:03:43.065953: LR: 
               precision    recall  f1-score   support

           0       1.00      0.33      0.49       956
           1       0.02      1.00      0.04        12

    accuracy                           0.34       968
   macro avg       0.51      0.66      0.27       968
weighted avg       0.99      0.34      0.49       968
22:03:43.071294: Validation Seq.Label F1: 0.4859583108488051; Log.Reg F1: 0.26526211250620696; train loss: 0.05163659155368805; Language: english 

22:03:43.071358: Evaluating Language: finnish
22:03:43.071402: ----------
22:03:50.988730: OBI: 
 [[7187   53  456]
 [   4   21    7]
 [  91    6  243]]
22:03:50.996090: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      7696
           1       0.26      0.66      0.38        32
           2       0.34      0.71      0.46       340

    accuracy                           0.92      8068
   macro avg       0.53      0.77      0.60      8068
weighted avg       0.96      0.92      0.94      8068
22:03:50.996133: ----------
22:03:50.997027: LR: 
 [[738 849]
 [  6  26]]
22:03:51.000505: LR: 
               precision    recall  f1-score   support

           0       0.99      0.47      0.63      1587
           1       0.03      0.81      0.06        32

    accuracy                           0.47      1619
   macro avg       0.51      0.64      0.35      1619
weighted avg       0.97      0.47      0.62      1619
22:03:51.003961: Validation Seq.Label F1: 0.5997671132872934; Log.Reg F1: 0.34526824824509494; train loss: 0.05163659155368805; Language: finnish 

22:03:51.004028: Evaluating Language: japanese
22:03:51.004078: ----------
22:03:55.617405: OBI: 
 [[5660   85  745]
 [   6   26    0]
 [  57    1  236]]
22:03:55.623576: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.87      0.93      6490
           1       0.23      0.81      0.36        32
           2       0.24      0.80      0.37       294

    accuracy                           0.87      6816
   macro avg       0.49      0.83      0.55      6816
weighted avg       0.95      0.87      0.90      6816
22:03:55.623622: ----------
22:03:55.624271: LR: 
 [[461 367]
 [  9  23]]
22:03:55.626929: LR: 
               precision    recall  f1-score   support

           0       0.98      0.56      0.71       828
           1       0.06      0.72      0.11        32

    accuracy                           0.56       860
   macro avg       0.52      0.64      0.41       860
weighted avg       0.95      0.56      0.69       860
22:03:55.630018: Validation Seq.Label F1: 0.5527294605715863; Log.Reg F1: 0.4096641570334237; train loss: 0.05163659155368805; Language: japanese 

22:03:55.632494: Combined F1 SeqLab: 0.5481441193237881; train loss: 0.05163659155368805
22:03:55.634921: Combined F1 LogReg: 0.34515642498988663; train loss: 0.05163659155368805 

22:03:55.635550: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 15/40
22:09:01.653500: Evaluating Language: english
22:09:01.653637: ----------
22:09:06.219606: OBI: 
 [[3421  126  619]
 [   2   12    2]
 [  22    4  120]]
22:09:06.224447: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.82      0.90      4166
           1       0.08      0.75      0.15        16
           2       0.16      0.82      0.27       146

    accuracy                           0.82      4328
   macro avg       0.41      0.80      0.44      4328
weighted avg       0.96      0.82      0.88      4328
22:09:06.224491: ----------
22:09:06.225184: LR: 
 [[469 483]
 [  0  16]]
22:09:06.227927: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       952
           1       0.03      1.00      0.06        16

    accuracy                           0.50       968
   macro avg       0.52      0.75      0.36       968
weighted avg       0.98      0.50      0.65       968
22:09:06.233472: Validation Seq.Label F1: 0.44047857821169206; Log.Reg F1: 0.3611172222487924; train loss: 0.04975196719169617; Language: english 

22:09:06.233532: Evaluating Language: finnish
22:09:06.233575: ----------
22:09:14.138764: OBI: 
 [[5533   91  352]
 [   3   24    0]
 [  94    7  259]]
22:09:14.144720: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      5976
           1       0.20      0.89      0.32        27
           2       0.42      0.72      0.53       360

    accuracy                           0.91      6363
   macro avg       0.53      0.84      0.60      6363
weighted avg       0.95      0.91      0.93      6363
22:09:14.144766: ----------
22:09:14.145654: LR: 
 [[825 767]
 [  2  25]]
22:09:14.148921: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.68      1592
           1       0.03      0.93      0.06        27

    accuracy                           0.53      1619
   macro avg       0.51      0.72      0.37      1619
weighted avg       0.98      0.53      0.67      1619
22:09:14.151813: Validation Seq.Label F1: 0.6030302139048301; Log.Reg F1: 0.3715750511947287; train loss: 0.04975196719169617; Language: finnish 

22:09:14.151867: Evaluating Language: japanese
22:09:14.151913: ----------
22:09:18.810051: OBI: 
 [[3934   95  693]
 [   4   20    1]
 [  46    0  119]]
22:09:18.815075: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.83      0.90      4722
           1       0.17      0.80      0.29        25
           2       0.15      0.72      0.24       165

    accuracy                           0.83      4912
   macro avg       0.44      0.78      0.48      4912
weighted avg       0.96      0.83      0.88      4912
22:09:18.815118: ----------
22:09:18.815761: LR: 
 [[482 353]
 [  5  20]]
22:09:18.818782: LR: 
               precision    recall  f1-score   support

           0       0.99      0.58      0.73       835
           1       0.05      0.80      0.10        25

    accuracy                           0.58       860
   macro avg       0.52      0.69      0.41       860
weighted avg       0.96      0.58      0.71       860
22:09:18.822132: Validation Seq.Label F1: 0.47760420431267275; Log.Reg F1: 0.41485034856582464; train loss: 0.04975196719169617; Language: japanese 

22:09:18.824505: Combined F1 SeqLab: 0.5117853041796075; train loss: 0.04975196719169617
22:09:18.826857: Combined F1 LogReg: 0.38322077126213433; train loss: 0.04975196719169617 

22:09:18.827489: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 16/40
22:14:27.323166: Evaluating Language: english
22:14:27.323324: ----------
22:14:31.966586: OBI: 
 [[3496  136 1140]
 [   2   12    5]
 [  10    3  180]]
22:14:31.971781: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.73      0.84      4772
           1       0.08      0.63      0.14        19
           2       0.14      0.93      0.24       193

    accuracy                           0.74      4984
   macro avg       0.40      0.77      0.41      4984
weighted avg       0.96      0.74      0.82      4984
22:14:31.971825: ----------
22:14:31.972514: LR: 
 [[261 688]
 [  0  19]]
22:14:31.975256: LR: 
               precision    recall  f1-score   support

           0       1.00      0.28      0.43       949
           1       0.03      1.00      0.05        19

    accuracy                           0.29       968
   macro avg       0.51      0.64      0.24       968
weighted avg       0.98      0.29      0.42       968
22:14:31.980494: Validation Seq.Label F1: 0.40759168841010274; Log.Reg F1: 0.24187327823691465; train loss: 0.0484175905585289; Language: english 

22:14:31.980548: Evaluating Language: finnish
22:14:31.980591: ----------
22:14:39.878042: OBI: 
 [[6112   73  888]
 [   3   26    5]
 [  70    7  330]]
22:14:39.884829: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      7073
           1       0.25      0.76      0.37        34
           2       0.27      0.81      0.40       407

    accuracy                           0.86      7514
   macro avg       0.50      0.81      0.57      7514
weighted avg       0.95      0.86      0.89      7514
22:14:39.884873: ----------
22:14:39.885759: LR: 
 [[774 811]
 [  5  29]]
22:14:39.889038: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.65      1585
           1       0.03      0.85      0.07        34

    accuracy                           0.50      1619
   macro avg       0.51      0.67      0.36      1619
weighted avg       0.97      0.50      0.64      1619
22:14:39.892085: Validation Seq.Label F1: 0.5661152999107535; Log.Reg F1: 0.36059194554472696; train loss: 0.0484175905585289; Language: finnish 

22:14:39.892144: Evaluating Language: japanese
22:14:39.892192: ----------
22:14:44.472738: OBI: 
 [[3720   83 1242]
 [   3   18    1]
 [  36    1  200]]
22:14:44.478031: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.74      0.85      5045
           1       0.18      0.82      0.29        22
           2       0.14      0.84      0.24       237

    accuracy                           0.74      5304
   macro avg       0.43      0.80      0.46      5304
weighted avg       0.95      0.74      0.82      5304
22:14:44.478075: ----------
22:14:44.478715: LR: 
 [[421 417]
 [  3  19]]
22:14:44.481374: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.67       838
           1       0.04      0.86      0.08        22

    accuracy                           0.51       860
   macro avg       0.52      0.68      0.38       860
weighted avg       0.97      0.51      0.65       860
22:14:44.484399: Validation Seq.Label F1: 0.457829413758537; Log.Reg F1: 0.375082180499519; train loss: 0.0484175905585289; Language: japanese 

22:14:44.486779: Combined F1 SeqLab: 0.48174173210567445; train loss: 0.0484175905585289
22:14:44.489141: Combined F1 LogReg: 0.33126820757259373; train loss: 0.0484175905585289 

22:14:44.489775: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 17/40
22:19:48.774525: Evaluating Language: english
22:19:48.774666: ----------
22:19:53.401278: OBI: 
 [[2896   72  624]
 [   2   11    3]
 [  25    4  115]]
22:19:53.405682: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.81      0.89      3592
           1       0.13      0.69      0.21        16
           2       0.15      0.80      0.26       144

    accuracy                           0.81      3752
   macro avg       0.42      0.76      0.45      3752
weighted avg       0.96      0.81      0.86      3752
22:19:53.405724: ----------
22:19:53.406412: LR: 
 [[441 511]
 [  3  13]]
22:19:53.409142: LR: 
               precision    recall  f1-score   support

           0       0.99      0.46      0.63       952
           1       0.02      0.81      0.05        16

    accuracy                           0.47       968
   macro avg       0.51      0.64      0.34       968
weighted avg       0.98      0.47      0.62       968
22:19:53.413483: Validation Seq.Label F1: 0.45407041287944133; Log.Reg F1: 0.3399766528706357; train loss: 0.0536867156624794; Language: english 

22:19:53.413536: Evaluating Language: finnish
22:19:53.413578: ----------
22:20:01.280454: OBI: 
 [[4926   41  240]
 [   3   21    3]
 [  72    2  251]]
22:20:01.285851: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      5207
           1       0.33      0.78      0.46        27
           2       0.51      0.77      0.61       325

    accuracy                           0.94      5559
   macro avg       0.61      0.83      0.68      5559
weighted avg       0.95      0.94      0.94      5559
22:20:01.285895: ----------
22:20:01.286781: LR: 
 [[805 787]
 [  5  22]]
22:20:01.290036: LR: 
               precision    recall  f1-score   support

           0       0.99      0.51      0.67      1592
           1       0.03      0.81      0.05        27

    accuracy                           0.51      1619
   macro avg       0.51      0.66      0.36      1619
weighted avg       0.98      0.51      0.66      1619
22:20:01.293269: Validation Seq.Label F1: 0.6798688221102015; Log.Reg F1: 0.3614531749857575; train loss: 0.0536867156624794; Language: finnish 

22:20:01.293340: Evaluating Language: japanese
22:20:01.293387: ----------
22:20:05.826633: OBI: 
 [[2913   58  355]
 [   2   17    2]
 [  25    1   83]]
22:20:05.830957: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      3326
           1       0.22      0.81      0.35        21
           2       0.19      0.76      0.30       109

    accuracy                           0.87      3456
   macro avg       0.47      0.82      0.53      3456
weighted avg       0.96      0.87      0.91      3456
22:20:05.831007: ----------
22:20:05.831723: LR: 
 [[412 427]
 [  1  20]]
22:20:05.834374: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       839
           1       0.04      0.95      0.09        21

    accuracy                           0.50       860
   macro avg       0.52      0.72      0.37       860
weighted avg       0.97      0.50      0.64       860
22:20:05.837813: Validation Seq.Label F1: 0.5275543898114633; Log.Reg F1: 0.37180852516315777; train loss: 0.0536867156624794; Language: japanese 

22:20:05.840226: Combined F1 SeqLab: 0.5617577144817756; train loss: 0.0536867156624794
22:20:06.511907: Combined F1 LogReg: 0.3579916673091744; train loss: 0.0536867156624794 

22:20:06.512728: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 18/40
22:25:13.281984: Evaluating Language: english
22:25:13.282122: ----------
22:25:17.815645: OBI: 
 [[3388   76  570]
 [   1   13    2]
 [  29    4  149]]
22:25:17.820281: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.84      0.91      4034
           1       0.14      0.81      0.24        16
           2       0.21      0.82      0.33       182

    accuracy                           0.84      4232
   macro avg       0.45      0.82      0.49      4232
weighted avg       0.95      0.84      0.88      4232
22:25:17.820330: ----------
22:25:17.821021: LR: 
 [[494 458]
 [  4  12]]
22:25:17.823709: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.68       952
           1       0.03      0.75      0.05        16

    accuracy                           0.52       968
   macro avg       0.51      0.63      0.37       968
weighted avg       0.98      0.52      0.67       968
22:25:17.827921: Validation Seq.Label F1: 0.49260976066025286; Log.Reg F1: 0.3653810131971052; train loss: 0.03489275276660919; Language: english 

22:25:17.827975: Evaluating Language: finnish
22:25:17.828018: ----------
22:25:25.651025: OBI: 
 [[5056   58  340]
 [   7   16    3]
 [  95    2  226]]
22:25:25.656590: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      5454
           1       0.21      0.62      0.31        26
           2       0.40      0.70      0.51       323

    accuracy                           0.91      5803
   macro avg       0.53      0.75      0.59      5803
weighted avg       0.94      0.91      0.93      5803
22:25:25.656633: ----------
22:25:25.657510: LR: 
 [[825 768]
 [  6  20]]
22:25:25.660781: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.68      1593
           1       0.03      0.77      0.05        26

    accuracy                           0.52      1619
   macro avg       0.51      0.64      0.36      1619
weighted avg       0.98      0.52      0.67      1619
22:25:25.663769: Validation Seq.Label F1: 0.591111825225533; Log.Reg F1: 0.3649165592234899; train loss: 0.03489275276660919; Language: finnish 

22:25:25.663825: Evaluating Language: japanese
22:25:25.663872: ----------
22:25:30.229932: OBI: 
 [[3846   49  377]
 [   2   22    1]
 [  34    0  117]]
22:25:30.234649: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      4272
           1       0.31      0.88      0.46        25
           2       0.24      0.77      0.36       151

    accuracy                           0.90      4448
   macro avg       0.51      0.85      0.59      4448
weighted avg       0.96      0.90      0.92      4448
22:25:30.234691: ----------
22:25:30.235334: LR: 
 [[460 375]
 [  5  20]]
22:25:30.237960: LR: 
               precision    recall  f1-score   support

           0       0.99      0.55      0.71       835
           1       0.05      0.80      0.10        25

    accuracy                           0.56       860
   macro avg       0.52      0.68      0.40       860
weighted avg       0.96      0.56      0.69       860
22:25:30.241256: Validation Seq.Label F1: 0.5879677090618596; Log.Reg F1: 0.4014652014652015; train loss: 0.03489275276660919; Language: japanese 

22:25:30.244040: Combined F1 SeqLab: 0.5591015391139205; train loss: 0.03489275276660919
22:25:30.246385: Combined F1 LogReg: 0.3776425505633375; train loss: 0.03489275276660919 

22:25:30.247078: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 19/40
22:30:35.776901: Evaluating Language: english
22:30:35.777012: ----------
22:30:40.401646: OBI: 
 [[1958   58  416]
 [   0    5    1]
 [  17    2   71]]
22:30:40.405295: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.81      0.89      2432
           1       0.08      0.83      0.14         6
           2       0.15      0.79      0.25        90

    accuracy                           0.80      2528
   macro avg       0.40      0.81      0.43      2528
weighted avg       0.96      0.80      0.86      2528
22:30:40.405351: ----------
22:30:40.406042: LR: 
 [[430 532]
 [  0   6]]
22:30:40.408762: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62       962
           1       0.01      1.00      0.02         6

    accuracy                           0.45       968
   macro avg       0.51      0.72      0.32       968
weighted avg       0.99      0.45      0.61       968
22:30:40.412186: Validation Seq.Label F1: 0.42503538360691256; Log.Reg F1: 0.3199374577417174; train loss: 0.03342073783278465; Language: english 

22:30:40.412239: Evaluating Language: finnish
22:30:40.412281: ----------
22:30:48.195183: OBI: 
 [[7195   56  515]
 [   4   27    5]
 [  82    2  340]]
22:30:48.202420: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      7766
           1       0.32      0.75      0.45        36
           2       0.40      0.80      0.53       424

    accuracy                           0.92      8226
   macro avg       0.57      0.83      0.64      8226
weighted avg       0.95      0.92      0.93      8226
22:30:48.202463: ----------
22:30:48.203333: LR: 
 [[801 782]
 [  7  29]]
22:30:48.206575: LR: 
               precision    recall  f1-score   support

           0       0.99      0.51      0.67      1583
           1       0.04      0.81      0.07        36

    accuracy                           0.51      1619
   macro avg       0.51      0.66      0.37      1619
weighted avg       0.97      0.51      0.66      1619
22:30:48.209609: Validation Seq.Label F1: 0.6440709395454592; Log.Reg F1: 0.3692447623096648; train loss: 0.03342073783278465; Language: finnish 

22:30:48.209660: Evaluating Language: japanese
22:30:48.209703: ----------
22:30:52.876655: OBI: 
 [[4372   78  696]
 [   5   18    2]
 [  49    1  155]]
22:30:52.882074: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.85      0.91      5146
           1       0.19      0.72      0.30        25
           2       0.18      0.76      0.29       205

    accuracy                           0.85      5376
   macro avg       0.45      0.78      0.50      5376
weighted avg       0.95      0.85      0.89      5376
22:30:52.882125: ----------
22:30:52.882895: LR: 
 [[376 459]
 [  2  23]]
22:30:52.885738: LR: 
               precision    recall  f1-score   support

           0       0.99      0.45      0.62       835
           1       0.05      0.92      0.09        25

    accuracy                           0.46       860
   macro avg       0.52      0.69      0.36       860
weighted avg       0.97      0.46      0.60       860
22:30:52.888944: Validation Seq.Label F1: 0.5005284466401244; Log.Reg F1: 0.3553401594494879; train loss: 0.03342073783278465; Language: japanese 

22:30:52.891562: Combined F1 SeqLab: 0.5310402302339632; train loss: 0.03342073783278465
22:30:52.893873: Combined F1 LogReg: 0.348792345231821; train loss: 0.03342073783278465 

22:30:52.894487: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 20/40
22:35:57.851926: Evaluating Language: english
22:35:57.852041: ----------
22:36:02.598108: OBI: 
 [[3084   59  217]
 [   2    9    2]
 [  33    0   82]]
22:36:02.602307: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95      3360
           1       0.13      0.69      0.22        13
           2       0.27      0.71      0.39       115

    accuracy                           0.91      3488
   macro avg       0.46      0.77      0.52      3488
weighted avg       0.96      0.91      0.93      3488
22:36:02.602357: ----------
22:36:02.603042: LR: 
 [[447 508]
 [  2  11]]
22:36:02.605776: LR: 
               precision    recall  f1-score   support

           0       1.00      0.47      0.64       955
           1       0.02      0.85      0.04        13

    accuracy                           0.47       968
   macro avg       0.51      0.66      0.34       968
weighted avg       0.98      0.47      0.63       968
22:36:02.609903: Validation Seq.Label F1: 0.5228172522315137; Log.Reg F1: 0.33905276010539165; train loss: 0.026208238676190376; Language: english 

22:36:02.609957: Evaluating Language: finnish
22:36:02.610002: ----------
22:36:10.300038: OBI: 
 [[3286   47  151]
 [   1   14    1]
 [  80    4  190]]
22:36:10.304336: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      3484
           1       0.22      0.88      0.35        16
           2       0.56      0.69      0.62       274

    accuracy                           0.92      3774
   macro avg       0.58      0.84      0.64      3774
weighted avg       0.94      0.92      0.93      3774
22:36:10.304378: ----------
22:36:10.305244: LR: 
 [[792 811]
 [  1  15]]
22:36:10.308515: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66      1603
           1       0.02      0.94      0.04        16

    accuracy                           0.50      1619
   macro avg       0.51      0.72      0.35      1619
weighted avg       0.99      0.50      0.65      1619
22:36:10.311471: Validation Seq.Label F1: 0.6406127157761144; Log.Reg F1: 0.3483656450378501; train loss: 0.026208238676190376; Language: finnish 

22:36:10.311523: Evaluating Language: japanese
22:36:10.311568: ----------
22:36:14.973044: OBI: 
 [[4802   54  356]
 [   5   24    0]
 [  69    1  129]]
22:36:14.978709: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.92      0.95      5212
           1       0.30      0.83      0.44        29
           2       0.27      0.65      0.38       199

    accuracy                           0.91      5440
   macro avg       0.52      0.80      0.59      5440
weighted avg       0.95      0.91      0.93      5440
22:36:14.978755: ----------
22:36:14.979408: LR: 
 [[510 321]
 [  5  24]]
22:36:14.982041: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.76       831
           1       0.07      0.83      0.13        29

    accuracy                           0.62       860
   macro avg       0.53      0.72      0.44       860
weighted avg       0.96      0.62      0.74       860
22:36:14.986762: Validation Seq.Label F1: 0.591219877166703; Log.Reg F1: 0.44307156875988274; train loss: 0.026208238676190376; Language: japanese 

22:36:14.989572: Combined F1 SeqLab: 0.5868740563363292; train loss: 0.026208238676190376
22:36:15.679343: Combined F1 LogReg: 0.3797489573481693; train loss: 0.026208238676190376 

22:36:15.680723: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 21/40
22:41:20.881112: Evaluating Language: english
22:41:20.881259: ----------
22:41:26.529097: OBI: 
 [[3141   75  445]
 [   1    8    7]
 [  16    5   70]]
22:41:26.533568: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      3661
           1       0.09      0.50      0.15        16
           2       0.13      0.77      0.23        91

    accuracy                           0.85      3768
   macro avg       0.41      0.71      0.43      3768
weighted avg       0.97      0.85      0.90      3768
22:41:26.533611: ----------
22:41:26.534294: LR: 
 [[428 524]
 [  2  14]]
22:41:26.537030: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62       952
           1       0.03      0.88      0.05        16

    accuracy                           0.46       968
   macro avg       0.51      0.66      0.33       968
weighted avg       0.98      0.46      0.61       968
22:41:26.540715: Validation Seq.Label F1: 0.43449353191851303; Log.Reg F1: 0.3349668507421359; train loss: 0.0315573550760746; Language: english 

22:41:26.540767: Evaluating Language: finnish
22:41:26.540810: ----------
22:41:34.286766: OBI: 
 [[6631   74  462]
 [   5   23    5]
 [ 136    2  308]]
22:41:34.293636: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      7167
           1       0.23      0.70      0.35        33
           2       0.40      0.69      0.50       446

    accuracy                           0.91      7646
   macro avg       0.54      0.77      0.60      7646
weighted avg       0.94      0.91      0.92      7646
22:41:34.293679: ----------
22:41:34.294564: LR: 
 [[736 850]
 [  3  30]]
22:41:34.297865: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63      1586
           1       0.03      0.91      0.07        33

    accuracy                           0.47      1619
   macro avg       0.52      0.69      0.35      1619
weighted avg       0.98      0.47      0.62      1619
22:41:34.301382: Validation Seq.Label F1: 0.6014735296965011; Log.Reg F1: 0.34941784734244896; train loss: 0.0315573550760746; Language: finnish 

22:41:34.301435: Evaluating Language: japanese
22:41:34.301479: ----------
22:41:38.915810: OBI: 
 [[4254   54  346]
 [   4   11    2]
 [  28    0   85]]
22:41:38.921037: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      4654
           1       0.17      0.65      0.27        17
           2       0.20      0.75      0.31       113

    accuracy                           0.91      4784
   macro avg       0.45      0.77      0.51      4784
weighted avg       0.97      0.91      0.93      4784
22:41:38.921079: ----------
22:41:38.921740: LR: 
 [[354 489]
 [  2  15]]
22:41:38.924416: LR: 
               precision    recall  f1-score   support

           0       0.99      0.42      0.59       843
           1       0.03      0.88      0.06        17

    accuracy                           0.43       860
   macro avg       0.51      0.65      0.32       860
weighted avg       0.98      0.43      0.58       860
22:41:38.928497: Validation Seq.Label F1: 0.5104419488770446; Log.Reg F1: 0.324036825313481; train loss: 0.0315573550760746; Language: japanese 

22:41:38.930774: Combined F1 SeqLab: 0.5199698771332775; train loss: 0.0315573550760746
22:41:38.933026: Combined F1 LogReg: 0.33630119798417546; train loss: 0.0315573550760746 

22:41:38.933883: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 22/40
22:46:46.375935: Evaluating Language: english
22:46:46.376098: ----------
22:46:51.034143: OBI: 
 [[2429   69  459]
 [   1    8    1]
 [  12    3   58]]
22:46:51.037996: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.82      0.90      2957
           1       0.10      0.80      0.18        10
           2       0.11      0.79      0.20        73

    accuracy                           0.82      3040
   macro avg       0.40      0.81      0.42      3040
weighted avg       0.97      0.82      0.88      3040
22:46:51.038041: ----------
22:46:51.038731: LR: 
 [[433 525]
 [  0  10]]
22:46:51.041472: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62       958
           1       0.02      1.00      0.04        10

    accuracy                           0.46       968
   macro avg       0.51      0.73      0.33       968
weighted avg       0.99      0.46      0.62       968
22:46:51.046349: Validation Seq.Label F1: 0.42461717737135357; Log.Reg F1: 0.3296354678503354; train loss: 0.04544426500797272; Language: english 

22:46:51.046403: Evaluating Language: finnish
22:46:51.046637: ----------
22:46:58.861209: OBI: 
 [[4571   45  237]
 [   2   13    1]
 [  51    2  163]]
22:46:58.866326: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      4853
           1       0.22      0.81      0.34        16
           2       0.41      0.75      0.53       216

    accuracy                           0.93      5085
   macro avg       0.54      0.84      0.61      5085
weighted avg       0.96      0.93      0.94      5085
22:46:58.866369: ----------
22:46:58.867235: LR: 
 [[818 785]
 [  3  13]]
22:46:58.870718: LR: 
               precision    recall  f1-score   support

           0       1.00      0.51      0.67      1603
           1       0.02      0.81      0.03        16

    accuracy                           0.51      1619
   macro avg       0.51      0.66      0.35      1619
weighted avg       0.99      0.51      0.67      1619
22:46:58.875471: Validation Seq.Label F1: 0.6117065237023576; Log.Reg F1: 0.3534292618451034; train loss: 0.04544426500797272; Language: finnish 

22:46:58.875523: Evaluating Language: japanese
22:46:58.875566: ----------
22:47:03.489272: OBI: 
 [[3824   64  401]
 [   3   17    2]
 [  22    5  162]]
22:47:03.494052: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      4289
           1       0.20      0.77      0.31        22
           2       0.29      0.86      0.43       189

    accuracy                           0.89      4500
   macro avg       0.49      0.84      0.56      4500
weighted avg       0.96      0.89      0.92      4500
22:47:03.494094: ----------
22:47:03.494740: LR: 
 [[464 374]
 [  2  20]]
22:47:03.497395: LR: 
               precision    recall  f1-score   support

           0       1.00      0.55      0.71       838
           1       0.05      0.91      0.10        22

    accuracy                           0.56       860
   macro avg       0.52      0.73      0.40       860
weighted avg       0.97      0.56      0.70       860
22:47:03.501278: Validation Seq.Label F1: 0.561437227828473; Log.Reg F1: 0.4039051439358187; train loss: 0.04544426500797272; Language: japanese 

22:47:03.503506: Combined F1 SeqLab: 0.5384225042506301; train loss: 0.04544426500797272
22:47:03.505718: Combined F1 LogReg: 0.3636441255270958; train loss: 0.04544426500797272 

22:47:03.506550: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 23/40
22:52:16.127827: Evaluating Language: english
22:52:16.127968: ----------
22:52:20.829902: OBI: 
 [[3949  100  673]
 [   3   15    4]
 [  47    3  110]]
22:52:20.835119: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.84      0.91      4722
           1       0.13      0.68      0.21        22
           2       0.14      0.69      0.23       160

    accuracy                           0.83      4904
   macro avg       0.42      0.74      0.45      4904
weighted avg       0.96      0.83      0.88      4904
22:52:20.835162: ----------
22:52:20.835863: LR: 
 [[389 557]
 [  0  22]]
22:52:20.838637: LR: 
               precision    recall  f1-score   support

           0       1.00      0.41      0.58       946
           1       0.04      1.00      0.07        22

    accuracy                           0.42       968
   macro avg       0.52      0.71      0.33       968
weighted avg       0.98      0.42      0.57       968
22:52:20.845839: Validation Seq.Label F1: 0.45074278952540975; Log.Reg F1: 0.327991425028199; train loss: 0.03500137850642204; Language: english 

22:52:20.845892: Evaluating Language: finnish
22:52:20.845936: ----------
22:52:28.511891: OBI: 
 [[5585   49  315]
 [   8   20    2]
 [ 140    1  228]]
22:52:28.517828: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.94      0.96      5949
           1       0.29      0.67      0.40        30
           2       0.42      0.62      0.50       369

    accuracy                           0.92      6348
   macro avg       0.56      0.74      0.62      6348
weighted avg       0.94      0.92      0.93      6348
22:52:28.517870: ----------
22:52:28.518755: LR: 
 [[787 802]
 [  5  25]]
22:52:28.522015: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.66      1589
           1       0.03      0.83      0.06        30

    accuracy                           0.50      1619
   macro avg       0.51      0.66      0.36      1619
weighted avg       0.98      0.50      0.65      1619
22:52:28.526459: Validation Seq.Label F1: 0.6183592654905194; Log.Reg F1: 0.3597049179203114; train loss: 0.03500137850642204; Language: finnish 

22:52:28.526514: Evaluating Language: japanese
22:52:28.526557: ----------
22:52:33.147542: OBI: 
 [[5139   79  528]
 [   4   19    4]
 [  46    0  197]]
22:52:33.153231: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      5746
           1       0.19      0.70      0.30        27
           2       0.27      0.81      0.41       243

    accuracy                           0.89      6016
   macro avg       0.48      0.80      0.55      6016
weighted avg       0.96      0.89      0.92      6016
22:52:33.153272: ----------
22:52:33.153924: LR: 
 [[431 402]
 [  4  23]]
22:52:33.156589: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.68       833
           1       0.05      0.85      0.10        27

    accuracy                           0.53       860
   macro avg       0.52      0.68      0.39       860
weighted avg       0.96      0.53      0.66       860
22:52:33.162614: Validation Seq.Label F1: 0.5497558299039781; Log.Reg F1: 0.39079031852823765; train loss: 0.03500137850642204; Language: japanese 

22:52:33.164799: Combined F1 SeqLab: 0.5439879643400622; train loss: 0.03500137850642204
22:52:33.166969: Combined F1 LogReg: 0.3604085995660518; train loss: 0.03500137850642204 

22:52:33.167776: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 24/40
22:57:44.416142: Evaluating Language: english
22:57:44.416301: ----------
22:57:49.074536: OBI: 
 [[3766   65  309]
 [   4   12    0]
 [  46    4  114]]
22:57:49.079364: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      4140
           1       0.15      0.75      0.25        16
           2       0.27      0.70      0.39       164

    accuracy                           0.90      4320
   macro avg       0.47      0.78      0.53      4320
weighted avg       0.96      0.90      0.92      4320
22:57:49.079414: ----------
22:57:49.080106: LR: 
 [[470 482]
 [  2  14]]
22:57:49.082836: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       952
           1       0.03      0.88      0.05        16

    accuracy                           0.50       968
   macro avg       0.51      0.68      0.36       968
weighted avg       0.98      0.50      0.65       968
22:57:49.091689: Validation Seq.Label F1: 0.527515080402949; Log.Reg F1: 0.3573999297752809; train loss: 0.03133731335401535; Language: english 

22:57:49.091749: Evaluating Language: finnish
22:57:49.091794: ----------
22:57:56.915782: OBI: 
 [[5563   28  205]
 [   4   16    2]
 [ 129    3  249]]
22:57:56.921593: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      5796
           1       0.34      0.73      0.46        22
           2       0.55      0.65      0.59       381

    accuracy                           0.94      6199
   macro avg       0.62      0.78      0.68      6199
weighted avg       0.95      0.94      0.94      6199
22:57:56.921635: ----------
22:57:56.922513: LR: 
 [[855 742]
 [  8  14]]
22:57:56.925801: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70      1597
           1       0.02      0.64      0.04        22

    accuracy                           0.54      1619
   macro avg       0.50      0.59      0.37      1619
weighted avg       0.98      0.54      0.69      1619
22:57:56.929162: Validation Seq.Label F1: 0.6756339841798645; Log.Reg F1: 0.3655558342215813; train loss: 0.03133731335401535; Language: finnish 

22:57:56.929217: Evaluating Language: japanese
22:57:56.929260: ----------
22:58:01.575304: OBI: 
 [[4219   39  284]
 [   6   17    1]
 [  59    0  187]]
22:58:01.580223: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.96      4542
           1       0.30      0.71      0.42        24
           2       0.40      0.76      0.52       246

    accuracy                           0.92      4812
   macro avg       0.56      0.80      0.63      4812
weighted avg       0.95      0.92      0.93      4812
22:58:01.580267: ----------
22:58:01.580906: LR: 
 [[597 239]
 [  7  17]]
22:58:01.583539: LR: 
               precision    recall  f1-score   support

           0       0.99      0.71      0.83       836
           1       0.07      0.71      0.12        24

    accuracy                           0.71       860
   macro avg       0.53      0.71      0.48       860
weighted avg       0.96      0.71      0.81       860
22:58:01.586640: Validation Seq.Label F1: 0.6339767802186542; Log.Reg F1: 0.475297619047619; train loss: 0.03133731335401535; Language: japanese 

22:58:01.588926: Combined F1 SeqLab: 0.6155431202029903; train loss: 0.03133731335401535
22:58:02.267906: Combined F1 LogReg: 0.4030192734883149; train loss: 0.03133731335401535 

22:58:02.269085: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 25/40
23:03:16.429701: Evaluating Language: english
23:03:16.429823: ----------
23:03:21.088325: OBI: 
 [[3917  213  413]
 [   2   12    1]
 [  71   10  145]]
23:03:21.093382: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.86      0.92      4543
           1       0.05      0.80      0.10        15
           2       0.26      0.64      0.37       226

    accuracy                           0.85      4784
   macro avg       0.43      0.77      0.46      4784
weighted avg       0.94      0.85      0.89      4784
23:03:21.093425: ----------
23:03:21.094111: LR: 
 [[371 582]
 [  0  15]]
23:03:21.096851: LR: 
               precision    recall  f1-score   support

           0       1.00      0.39      0.56       953
           1       0.03      1.00      0.05        15

    accuracy                           0.40       968
   macro avg       0.51      0.69      0.30       968
weighted avg       0.98      0.40      0.55       968
23:03:21.102569: Validation Seq.Label F1: 0.46116982973309817; Log.Reg F1: 0.30472128428410644; train loss: 0.037188515067100525; Language: english 

23:03:21.102623: Evaluating Language: finnish
23:03:21.102668: ----------
23:03:28.967810: OBI: 
 [[4810   76  214]
 [   5   24    3]
 [  87   15  230]]
23:03:28.973237: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      5100
           1       0.21      0.75      0.33        32
           2       0.51      0.69      0.59       332

    accuracy                           0.93      5464
   macro avg       0.57      0.80      0.63      5464
weighted avg       0.95      0.93      0.94      5464
23:03:28.973280: ----------
23:03:28.974164: LR: 
 [[784 803]
 [  6  26]]
23:03:28.977452: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.66      1587
           1       0.03      0.81      0.06        32

    accuracy                           0.50      1619
   macro avg       0.51      0.65      0.36      1619
weighted avg       0.97      0.50      0.65      1619
23:03:28.981926: Validation Seq.Label F1: 0.6262796308552424; Log.Reg F1: 0.36002495850428784; train loss: 0.037188515067100525; Language: finnish 

23:03:28.981980: Evaluating Language: japanese
23:03:28.982024: ----------
23:03:33.526710: OBI: 
 [[4957  109  266]
 [   4   27    2]
 [  71    2  186]]
23:03:33.532565: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      5332
           1       0.20      0.82      0.32        33
           2       0.41      0.72      0.52       259

    accuracy                           0.92      5624
   macro avg       0.53      0.82      0.60      5624
weighted avg       0.95      0.92      0.93      5624
23:03:33.532608: ----------
23:03:33.533248: LR: 
 [[317 510]
 [  3  30]]
23:03:33.535909: LR: 
               precision    recall  f1-score   support

           0       0.99      0.38      0.55       827
           1       0.06      0.91      0.10        33

    accuracy                           0.40       860
   macro avg       0.52      0.65      0.33       860
weighted avg       0.95      0.40      0.54       860
23:03:33.539659: Validation Seq.Label F1: 0.598036358326555; Log.Reg F1: 0.3287291682832976; train loss: 0.037188515067100525; Language: japanese 

23:03:33.542472: Combined F1 SeqLab: 0.5664366024427686; train loss: 0.037188515067100525
23:03:33.544682: Combined F1 LogReg: 0.3319316686317622; train loss: 0.037188515067100525 

23:03:33.545500: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 26/40
23:08:43.600032: Evaluating Language: english
23:08:43.600188: ----------
23:08:48.221096: OBI: 
 [[2276   43  493]
 [   0    6    4]
 [   7    3   64]]
23:08:48.225333: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.81      0.89      2812
           1       0.12      0.60      0.19        10
           2       0.11      0.86      0.20        74

    accuracy                           0.81      2896
   macro avg       0.41      0.76      0.43      2896
weighted avg       0.97      0.81      0.87      2896
23:08:48.225379: ----------
23:08:48.226064: LR: 
 [[475 483]
 [  0  10]]
23:08:48.228818: LR: 
               precision    recall  f1-score   support

           0       1.00      0.50      0.66       958
           1       0.02      1.00      0.04        10

    accuracy                           0.50       968
   macro avg       0.51      0.75      0.35       968
weighted avg       0.99      0.50      0.66       968
23:08:48.236266: Validation Seq.Label F1: 0.42951603888160345; Log.Reg F1: 0.35135315115587; train loss: 0.030330412089824677; Language: english 

23:08:48.236326: Evaluating Language: finnish
23:08:48.236381: ----------
23:08:55.863508: OBI: 
 [[6854   36  451]
 [   4   21    7]
 [  51    6  371]]
23:08:55.870485: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      7341
           1       0.33      0.66      0.44        32
           2       0.45      0.87      0.59       428

    accuracy                           0.93      7801
   macro avg       0.59      0.82      0.66      7801
weighted avg       0.96      0.93      0.94      7801
23:08:55.870530: ----------
23:08:55.871403: LR: 
 [[778 809]
 [  7  25]]
23:08:55.874695: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.66      1587
           1       0.03      0.78      0.06        32

    accuracy                           0.50      1619
   macro avg       0.51      0.64      0.36      1619
weighted avg       0.97      0.50      0.64      1619
23:08:55.885026: Validation Seq.Label F1: 0.6647881756898212; Log.Reg F1: 0.356861614914573; train loss: 0.030330412089824677; Language: finnish 

23:08:55.885081: Evaluating Language: japanese
23:08:55.885124: ----------
23:09:00.543672: OBI: 
 [[4994   45  642]
 [   3   16    1]
 [  37    1  169]]
23:09:00.549278: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      5681
           1       0.26      0.80      0.39        20
           2       0.21      0.82      0.33       207

    accuracy                           0.88      5908
   macro avg       0.49      0.83      0.55      5908
weighted avg       0.96      0.88      0.91      5908
23:09:00.549332: ----------
23:09:00.550001: LR: 
 [[398 442]
 [  4  16]]
23:09:00.552631: LR: 
               precision    recall  f1-score   support

           0       0.99      0.47      0.64       840
           1       0.03      0.80      0.07        20

    accuracy                           0.48       860
   macro avg       0.51      0.64      0.35       860
weighted avg       0.97      0.48      0.63       860
23:09:00.568432: Validation Seq.Label F1: 0.5513642784149594; Log.Reg F1: 0.3539236890155573; train loss: 0.030330412089824677; Language: japanese 

23:09:00.570927: Combined F1 SeqLab: 0.5569051127153807; train loss: 0.030330412089824677
23:09:00.573177: Combined F1 LogReg: 0.35405330421325804; train loss: 0.030330412089824677 

23:09:00.573935: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 27/40
23:14:14.794008: Evaluating Language: english
23:14:14.794159: ----------
23:14:19.510302: OBI: 
 [[4360  130  338]
 [   3   18    0]
 [  31    6  122]]
23:14:19.515491: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.95      4828
           1       0.12      0.86      0.21        21
           2       0.27      0.77      0.39       159

    accuracy                           0.90      5008
   macro avg       0.46      0.84      0.52      5008
weighted avg       0.97      0.90      0.92      5008
23:14:19.515546: ----------
23:14:19.516225: LR: 
 [[477 470]
 [  4  17]]
23:14:19.518964: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.67       947
           1       0.03      0.81      0.07        21

    accuracy                           0.51       968
   macro avg       0.51      0.66      0.37       968
weighted avg       0.97      0.51      0.66       968
23:14:19.529202: Validation Seq.Label F1: 0.5151544690331934; Log.Reg F1: 0.367498180374512; train loss: 0.019231701269745827; Language: english 

23:14:19.529258: Evaluating Language: finnish
23:14:19.529303: ----------
23:14:27.275721: OBI: 
 [[7434   92  249]
 [   9   38    1]
 [ 248    3  230]]
23:14:27.284750: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.96      7775
           1       0.29      0.79      0.42        48
           2       0.48      0.48      0.48       481

    accuracy                           0.93      8304
   macro avg       0.58      0.74      0.62      8304
weighted avg       0.93      0.93      0.93      8304
23:14:27.284800: ----------
23:14:27.285868: LR: 
 [[782 789]
 [ 10  38]]
23:14:27.289789: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.66      1571
           1       0.05      0.79      0.09        48

    accuracy                           0.51      1619
   macro avg       0.52      0.64      0.37      1619
weighted avg       0.96      0.51      0.64      1619
23:14:27.293348: Validation Seq.Label F1: 0.6199640323848805; Log.Reg F1: 0.3743638232271326; train loss: 0.019231701269745827; Language: finnish 

23:14:27.293432: Evaluating Language: japanese
23:14:27.293484: ----------
23:14:31.892461: OBI: 
 [[3557   75  285]
 [   4   21    1]
 [  44    1  136]]
23:14:31.896999: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      3917
           1       0.22      0.81      0.34        26
           2       0.32      0.75      0.45       181

    accuracy                           0.90      4124
   macro avg       0.51      0.82      0.58      4124
weighted avg       0.95      0.90      0.92      4124
23:14:31.897040: ----------
23:14:31.897683: LR: 
 [[557 277]
 [  8  18]]
23:14:31.900325: LR: 
               precision    recall  f1-score   support

           0       0.99      0.67      0.80       834
           1       0.06      0.69      0.11        26

    accuracy                           0.67       860
   macro avg       0.52      0.68      0.45       860
weighted avg       0.96      0.67      0.78       860
23:14:31.903546: Validation Seq.Label F1: 0.5794334882899943; Log.Reg F1: 0.4542162960191859; train loss: 0.019231701269745827; Language: japanese 

23:14:31.905798: Combined F1 SeqLab: 0.5731441632980029; train loss: 0.019231701269745827
23:14:31.908023: Combined F1 LogReg: 0.40063101406373164; train loss: 0.019231701269745827 

23:14:31.908643: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 28/40
23:19:37.116834: Evaluating Language: english
23:19:37.116973: ----------
23:19:41.720906: OBI: 
 [[5789   73  373]
 [   5   18    2]
 [  87    3  170]]
23:19:41.727529: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.96      6235
           1       0.19      0.72      0.30        25
           2       0.31      0.65      0.42       260

    accuracy                           0.92      6520
   macro avg       0.50      0.77      0.56      6520
weighted avg       0.95      0.92      0.93      6520
23:19:41.727575: ----------
23:19:41.728264: LR: 
 [[478 465]
 [  5  20]]
23:19:41.731006: LR: 
               precision    recall  f1-score   support

           0       0.99      0.51      0.67       943
           1       0.04      0.80      0.08        25

    accuracy                           0.51       968
   macro avg       0.52      0.65      0.37       968
weighted avg       0.97      0.51      0.66       968
23:19:41.738442: Validation Seq.Label F1: 0.5601590543634165; Log.Reg F1: 0.37441905233341577; train loss: 0.031428951770067215; Language: english 

23:19:41.738498: Evaluating Language: finnish
23:19:41.738541: ----------
23:19:49.489037: OBI: 
 [[6583   43  216]
 [   9   20    3]
 [ 189    3  219]]
23:19:49.495648: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.97      6842
           1       0.30      0.62      0.41        32
           2       0.50      0.53      0.52       411

    accuracy                           0.94      7285
   macro avg       0.59      0.71      0.63      7285
weighted avg       0.94      0.94      0.94      7285
23:19:49.495691: ----------
23:19:49.496575: LR: 
 [[833 754]
 [  5  27]]
23:19:49.499874: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.69      1587
           1       0.03      0.84      0.07        32

    accuracy                           0.53      1619
   macro avg       0.51      0.68      0.38      1619
weighted avg       0.98      0.53      0.67      1619
23:19:49.503838: Validation Seq.Label F1: 0.6301727055863383; Log.Reg F1: 0.3767154867424963; train loss: 0.031428951770067215; Language: finnish 

23:19:49.503891: Evaluating Language: japanese
23:19:49.503934: ----------
23:19:54.193118: OBI: 
 [[3451   26  209]
 [   3   11    1]
 [  57    0   82]]
23:19:54.197469: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      3686
           1       0.30      0.73      0.42        15
           2       0.28      0.59      0.38       139

    accuracy                           0.92      3840
   macro avg       0.52      0.75      0.59      3840
weighted avg       0.95      0.92      0.94      3840
23:19:54.197515: ----------
23:19:54.198153: LR: 
 [[521 324]
 [  2  13]]
23:19:54.200796: LR: 
               precision    recall  f1-score   support

           0       1.00      0.62      0.76       845
           1       0.04      0.87      0.07        15

    accuracy                           0.62       860
   macro avg       0.52      0.74      0.42       860
weighted avg       0.98      0.62      0.75       860
23:19:54.204512: Validation Seq.Label F1: 0.5875326876048368; Log.Reg F1: 0.41777977139819245; train loss: 0.031428951770067215; Language: japanese 

23:19:54.206779: Combined F1 SeqLab: 0.5933212912791533; train loss: 0.031428951770067215
23:19:54.209044: Combined F1 LogReg: 0.3901470330065384; train loss: 0.031428951770067215 

23:19:54.209862: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 29/40
23:25:08.300074: Evaluating Language: english
23:25:08.300230: ----------
23:25:13.026229: OBI: 
 [[2858   49  251]
 [   0   16    3]
 [  36    3  120]]
23:25:13.030406: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.94      3158
           1       0.24      0.84      0.37        19
           2       0.32      0.75      0.45       159

    accuracy                           0.90      3336
   macro avg       0.51      0.83      0.59      3336
weighted avg       0.95      0.90      0.92      3336
23:25:13.030448: ----------
23:25:13.031134: LR: 
 [[524 425]
 [  4  15]]
23:25:13.033889: LR: 
               precision    recall  f1-score   support

           0       0.99      0.55      0.71       949
           1       0.03      0.79      0.07        19

    accuracy                           0.56       968
   macro avg       0.51      0.67      0.39       968
weighted avg       0.97      0.56      0.70       968
23:25:13.044353: Validation Seq.Label F1: 0.5875262270323408; Log.Reg F1: 0.3874529274585031; train loss: 0.021504605188965797; Language: english 

23:25:13.044408: Evaluating Language: finnish
23:25:13.044450: ----------
23:25:20.762587: OBI: 
 [[4981   32  133]
 [  10   23    1]
 [ 132    5  158]]
23:25:20.767971: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.97      0.97      5146
           1       0.38      0.68      0.49        34
           2       0.54      0.54      0.54       295

    accuracy                           0.94      5475
   macro avg       0.63      0.73      0.67      5475
weighted avg       0.95      0.94      0.94      5475
23:25:20.768013: ----------
23:25:20.768897: LR: 
 [[869 716]
 [  8  26]]
23:25:20.772212: LR: 
               precision    recall  f1-score   support

           0       0.99      0.55      0.71      1585
           1       0.04      0.76      0.07        34

    accuracy                           0.55      1619
   macro avg       0.51      0.66      0.39      1619
weighted avg       0.97      0.55      0.69      1619
23:25:20.775082: Validation Seq.Label F1: 0.6659321310877334; Log.Reg F1: 0.38647022368872846; train loss: 0.021504605188965797; Language: finnish 

23:25:20.775134: Evaluating Language: japanese
23:25:20.775175: ----------
23:25:25.350840: OBI: 
 [[4947   50  222]
 [   7   17    0]
 [  59    1  137]]
23:25:25.357202: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      5219
           1       0.25      0.71      0.37        24
           2       0.38      0.70      0.49       197

    accuracy                           0.94      5440
   macro avg       0.54      0.78      0.61      5440
weighted avg       0.96      0.94      0.95      5440
23:25:25.357256: ----------
23:25:25.358026: LR: 
 [[587 249]
 [  7  17]]
23:25:25.361205: LR: 
               precision    recall  f1-score   support

           0       0.99      0.70      0.82       836
           1       0.06      0.71      0.12        24

    accuracy                           0.70       860
   macro avg       0.53      0.71      0.47       860
weighted avg       0.96      0.70      0.80       860
23:25:25.364574: Validation Seq.Label F1: 0.6097791175904502; Log.Reg F1: 0.46911020014468285; train loss: 0.021504605188965797; Language: japanese 

23:25:25.367145: Combined F1 SeqLab: 0.6219547794160215; train loss: 0.021504605188965797
23:25:26.018978: Combined F1 LogReg: 0.41615036732490673; train loss: 0.021504605188965797 

23:25:26.019989: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 30/40
23:30:33.515984: Evaluating Language: english
23:30:33.516136: ----------
23:30:38.300665: OBI: 
 [[2834  130  588]
 [   2   10    5]
 [  15    5  107]]
23:30:38.305106: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.80      0.89      3552
           1       0.07      0.59      0.12        17
           2       0.15      0.84      0.26       127

    accuracy                           0.80      3696
   macro avg       0.41      0.74      0.42      3696
weighted avg       0.96      0.80      0.86      3696
23:30:38.305148: ----------
23:30:38.305852: LR: 
 [[475 476]
 [  1  16]]
23:30:38.308601: LR: 
               precision    recall  f1-score   support

           0       1.00      0.50      0.67       951
           1       0.03      0.94      0.06        17

    accuracy                           0.51       968
   macro avg       0.52      0.72      0.36       968
weighted avg       0.98      0.51      0.66       968
23:30:38.319797: Validation Seq.Label F1: 0.4224778247564029; Log.Reg F1: 0.36430033744387985; train loss: 0.027048278599977493; Language: english 

23:30:38.319852: Evaluating Language: finnish
23:30:38.319897: ----------
23:30:46.297907: OBI: 
 [[6477   89  517]
 [   3   30    5]
 [  44    3  289]]
23:30:46.304617: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      7083
           1       0.25      0.79      0.38        38
           2       0.36      0.86      0.50       336

    accuracy                           0.91      7457
   macro avg       0.53      0.85      0.61      7457
weighted avg       0.96      0.91      0.93      7457
23:30:46.304660: ----------
23:30:46.305544: LR: 
 [[776 805]
 [  6  32]]
23:30:46.308837: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.66      1581
           1       0.04      0.84      0.07        38

    accuracy                           0.50      1619
   macro avg       0.52      0.67      0.36      1619
weighted avg       0.97      0.50      0.64      1619
23:30:46.311738: Validation Seq.Label F1: 0.6103110909908052; Log.Reg F1: 0.36496753521552505; train loss: 0.027048278599977493; Language: finnish 

23:30:46.311792: Evaluating Language: japanese
23:30:46.311835: ----------
23:30:50.996059: OBI: 
 [[4216  130 1396]
 [   5   19    1]
 [  28    3  206]]
23:30:51.002903: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.73      0.84      5742
           1       0.12      0.76      0.21        25
           2       0.13      0.87      0.22       237

    accuracy                           0.74      6004
   macro avg       0.42      0.79      0.43      6004
weighted avg       0.95      0.74      0.82      6004
23:30:51.002952: ----------
23:30:51.003725: LR: 
 [[422 413]
 [  2  23]]
23:30:51.006910: LR: 
               precision    recall  f1-score   support

           0       1.00      0.51      0.67       835
           1       0.05      0.92      0.10        25

    accuracy                           0.52       860
   macro avg       0.52      0.71      0.39       860
weighted avg       0.97      0.52      0.65       860
23:30:51.010307: Validation Seq.Label F1: 0.4275206242074101; Log.Reg F1: 0.3850781962064028; train loss: 0.027048278599977493; Language: japanese 

23:30:51.012954: Combined F1 SeqLab: 0.4945506459807672; train loss: 0.027048278599977493
23:30:51.015619: Combined F1 LogReg: 0.3715737947418597; train loss: 0.027048278599977493 

23:30:51.016340: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 31/40
23:36:02.985679: Evaluating Language: english
23:36:02.985847: ----------
23:36:07.733347: OBI: 
 [[3445   94  804]
 [   0   15    0]
 [  37    2  139]]
23:36:07.738289: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.79      0.88      4343
           1       0.14      1.00      0.24        15
           2       0.15      0.78      0.25       178

    accuracy                           0.79      4536
   macro avg       0.42      0.86      0.46      4536
weighted avg       0.95      0.79      0.85      4536
23:36:07.738348: ----------
23:36:07.739030: LR: 
 [[426 527]
 [  2  13]]
23:36:07.741761: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62       953
           1       0.02      0.87      0.05        15

    accuracy                           0.45       968
   macro avg       0.51      0.66      0.33       968
weighted avg       0.98      0.45      0.61       968
23:36:07.753223: Validation Seq.Label F1: 0.4555330945728611; Log.Reg F1: 0.33189554507440094; train loss: 0.03463242948055267; Language: english 

23:36:07.753277: Evaluating Language: finnish
23:36:07.753332: ----------
23:36:15.610793: OBI: 
 [[4208   52  353]
 [   2   15    5]
 [  47    4  235]]
23:36:15.615816: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      4613
           1       0.21      0.68      0.32        22
           2       0.40      0.82      0.53       286

    accuracy                           0.91      4921
   macro avg       0.53      0.81      0.60      4921
weighted avg       0.95      0.91      0.92      4921
23:36:15.615859: ----------
23:36:15.616737: LR: 
 [[754 843]
 [  0  22]]
23:36:15.620004: LR: 
               precision    recall  f1-score   support

           0       1.00      0.47      0.64      1597
           1       0.03      1.00      0.05        22

    accuracy                           0.48      1619
   macro avg       0.51      0.74      0.35      1619
weighted avg       0.99      0.48      0.63      1619
23:36:15.622922: Validation Seq.Label F1: 0.6020318002354144; Log.Reg F1: 0.34551729528608566; train loss: 0.03463242948055267; Language: finnish 

23:36:15.622977: Evaluating Language: japanese
23:36:15.623021: ----------
23:36:20.222059: OBI: 
 [[4106   58  618]
 [   8   12    1]
 [  52    1   88]]
23:36:20.226997: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      4782
           1       0.17      0.57      0.26        21
           2       0.12      0.62      0.21       141

    accuracy                           0.85      4944
   macro avg       0.43      0.68      0.46      4944
weighted avg       0.96      0.85      0.89      4944
23:36:20.227039: ----------
23:36:20.227676: LR: 
 [[575 264]
 [  8  13]]
23:36:20.230299: LR: 
               precision    recall  f1-score   support

           0       0.99      0.69      0.81       839
           1       0.05      0.62      0.09        21

    accuracy                           0.68       860
   macro avg       0.52      0.65      0.45       860
weighted avg       0.96      0.68      0.79       860
23:36:20.233301: Validation Seq.Label F1: 0.46205457253154947; Log.Reg F1: 0.44798421733261595; train loss: 0.03463242948055267; Language: japanese 

23:36:20.235568: Combined F1 SeqLab: 0.5110274346005095; train loss: 0.03463242948055267
23:36:20.237802: Combined F1 LogReg: 0.3786936814723136; train loss: 0.03463242948055267 

23:36:20.238435: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 32/40
23:41:25.147789: Evaluating Language: english
23:41:25.147951: ----------
23:41:29.916443: OBI: 
 [[2335   54  300]
 [   3    8    2]
 [  26    0   72]]
23:41:29.920260: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.87      0.92      2689
           1       0.13      0.62      0.21        13
           2       0.19      0.73      0.31        98

    accuracy                           0.86      2800
   macro avg       0.44      0.74      0.48      2800
weighted avg       0.96      0.86      0.90      2800
23:41:29.920303: ----------
23:41:29.920997: LR: 
 [[470 485]
 [  4   9]]
23:41:29.923707: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.66       955
           1       0.02      0.69      0.04        13

    accuracy                           0.49       968
   macro avg       0.50      0.59      0.35       968
weighted avg       0.98      0.49      0.65       968
23:41:29.934764: Validation Seq.Label F1: 0.4808738408649855; Log.Reg F1: 0.3466528088910605; train loss: 0.021356914192438126; Language: english 

23:41:29.934819: Evaluating Language: finnish
23:41:29.934862: ----------
23:41:37.729800: OBI: 
 [[6019   37  191]
 [   8   23    5]
 [ 105    3  370]]
23:41:37.735948: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      6247
           1       0.37      0.64      0.46        36
           2       0.65      0.77      0.71       478

    accuracy                           0.95      6761
   macro avg       0.67      0.79      0.72      6761
weighted avg       0.96      0.95      0.95      6761
23:41:37.735990: ----------
23:41:37.736864: LR: 
 [[842 741]
 [  7  29]]
23:41:37.740151: LR: 
               precision    recall  f1-score   support

           0       0.99      0.53      0.69      1583
           1       0.04      0.81      0.07        36

    accuracy                           0.54      1619
   macro avg       0.51      0.67      0.38      1619
weighted avg       0.97      0.54      0.68      1619
23:41:37.743130: Validation Seq.Label F1: 0.7153040245318324; Log.Reg F1: 0.3821972541465326; train loss: 0.021356914192438126; Language: finnish 

23:41:37.743183: Evaluating Language: japanese
23:41:37.743226: ----------
23:41:42.190596: OBI: 
 [[4575   36  452]
 [   6   16    1]
 [  51    1  110]]
23:41:42.195780: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      5063
           1       0.30      0.70      0.42        23
           2       0.20      0.68      0.30       162

    accuracy                           0.90      5248
   macro avg       0.49      0.76      0.56      5248
weighted avg       0.96      0.90      0.92      5248
23:41:42.195821: ----------
23:41:42.196465: LR: 
 [[518 319]
 [  2  21]]
23:41:42.199089: LR: 
               precision    recall  f1-score   support

           0       1.00      0.62      0.76       837
           1       0.06      0.91      0.12        23

    accuracy                           0.63       860
   macro avg       0.53      0.77      0.44       860
weighted avg       0.97      0.63      0.75       860
23:41:42.202068: Validation Seq.Label F1: 0.5560954546206173; Log.Reg F1: 0.4395756317106889; train loss: 0.021356914192438126; Language: japanese 

23:41:42.204346: Combined F1 SeqLab: 0.592211013347267; train loss: 0.021356914192438126
23:41:42.206634: Combined F1 LogReg: 0.39135220581255725; train loss: 0.021356914192438126 

23:41:42.207242: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 33/40
23:46:45.369028: Evaluating Language: english
23:46:45.369163: ----------
23:46:49.991846: OBI: 
 [[3798   85  579]
 [   4   15    6]
 [  94    4  111]]
23:46:49.996879: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.85      0.91      4462
           1       0.14      0.60      0.23        25
           2       0.16      0.53      0.25       209

    accuracy                           0.84      4696
   macro avg       0.43      0.66      0.46      4696
weighted avg       0.93      0.84      0.88      4696
23:46:49.996923: ----------
23:46:49.997618: LR: 
 [[458 485]
 [  3  22]]
23:46:50.000586: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.65       943
           1       0.04      0.88      0.08        25

    accuracy                           0.50       968
   macro avg       0.52      0.68      0.37       968
weighted avg       0.97      0.50      0.64       968
23:46:50.011358: Validation Seq.Label F1: 0.4622306235139772; Log.Reg F1: 0.36756420966947284; train loss: 0.023232055827975273; Language: english 

23:46:50.011415: Evaluating Language: finnish
23:46:50.011458: ----------
23:46:57.815406: OBI: 
 [[5839   59  371]
 [   5   22    2]
 [  75    0  256]]
23:46:57.821919: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      6269
           1       0.27      0.76      0.40        29
           2       0.41      0.77      0.53       331

    accuracy                           0.92      6629
   macro avg       0.56      0.82      0.63      6629
weighted avg       0.95      0.92      0.93      6629
23:46:57.821970: ----------
23:46:57.823032: LR: 
 [[823 767]
 [  3  26]]
23:46:57.826333: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.68      1590
           1       0.03      0.90      0.06        29

    accuracy                           0.52      1619
   macro avg       0.51      0.71      0.37      1619
weighted avg       0.98      0.52      0.67      1619
23:46:57.829471: Validation Seq.Label F1: 0.6304962987273456; Log.Reg F1: 0.3722758656805401; train loss: 0.023232055827975273; Language: finnish 

23:46:57.829532: Evaluating Language: japanese
23:46:57.829584: ----------
23:47:02.416454: OBI: 
 [[3683   58  538]
 [   2   22    2]
 [  52    0  123]]
23:47:02.421174: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      4279
           1       0.28      0.85      0.42        26
           2       0.19      0.70      0.29       175

    accuracy                           0.85      4480
   macro avg       0.48      0.80      0.54      4480
weighted avg       0.95      0.85      0.89      4480
23:47:02.421215: ----------
23:47:02.421870: LR: 
 [[505 329]
 [  5  21]]
23:47:02.424502: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.75       834
           1       0.06      0.81      0.11        26

    accuracy                           0.61       860
   macro avg       0.53      0.71      0.43       860
weighted avg       0.96      0.61      0.73       860
23:47:02.427546: Validation Seq.Label F1: 0.5425208670633995; Log.Reg F1: 0.43159511144883483; train loss: 0.023232055827975273; Language: japanese 

23:47:02.429796: Combined F1 SeqLab: 0.5493971311726533; train loss: 0.023232055827975273
23:47:02.432045: Combined F1 LogReg: 0.39156400439973704; train loss: 0.023232055827975273 

23:47:02.432663: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 34/40
23:52:11.046226: Evaluating Language: english
23:52:11.046391: ----------
23:52:15.745879: OBI: 
 [[2756   41  338]
 [   7   10    1]
 [  49    3  115]]
23:52:15.750019: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.88      0.93      3135
           1       0.19      0.56      0.28        18
           2       0.25      0.69      0.37       167

    accuracy                           0.87      3320
   macro avg       0.47      0.71      0.53      3320
weighted avg       0.94      0.87      0.90      3320
23:52:15.750063: ----------
23:52:15.750751: LR: 
 [[525 425]
 [  4  14]]
23:52:15.753517: LR: 
               precision    recall  f1-score   support

           0       0.99      0.55      0.71       950
           1       0.03      0.78      0.06        18

    accuracy                           0.56       968
   macro avg       0.51      0.67      0.39       968
weighted avg       0.97      0.56      0.70       968
23:52:15.762341: Validation Seq.Label F1: 0.5250006746839885; Log.Reg F1: 0.38560414734066867; train loss: 0.021264130249619484; Language: english 

23:52:15.762396: Evaluating Language: finnish
23:52:15.762439: ----------
23:52:23.544834: OBI: 
 [[6428   32  104]
 [   4   24    3]
 [  85    3  275]]
23:52:23.551093: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.98      0.98      6564
           1       0.41      0.77      0.53        31
           2       0.72      0.76      0.74       363

    accuracy                           0.97      6958
   macro avg       0.70      0.84      0.75      6958
weighted avg       0.97      0.97      0.97      6958
23:52:23.551136: ----------
23:52:23.552025: LR: 
 [[865 723]
 [  4  27]]
23:52:23.555344: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70      1588
           1       0.04      0.87      0.07        31

    accuracy                           0.55      1619
   macro avg       0.52      0.71      0.39      1619
weighted avg       0.98      0.55      0.69      1619
23:52:23.558324: Validation Seq.Label F1: 0.7514626156841492; Log.Reg F1: 0.3866264147954289; train loss: 0.021264130249619484; Language: finnish 

23:52:23.558378: Evaluating Language: japanese
23:52:23.558422: ----------
23:52:28.058512: OBI: 
 [[4339   30  281]
 [   8   20    1]
 [  56    0  161]]
23:52:28.063482: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      4650
           1       0.40      0.69      0.51        29
           2       0.36      0.74      0.49       217

    accuracy                           0.92      4896
   macro avg       0.58      0.79      0.65      4896
weighted avg       0.95      0.92      0.94      4896
23:52:28.063525: ----------
23:52:28.064162: LR: 
 [[508 323]
 [  6  23]]
23:52:28.066812: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.76       831
           1       0.07      0.79      0.12        29

    accuracy                           0.62       860
   macro avg       0.53      0.70      0.44       860
weighted avg       0.96      0.62      0.73       860
23:52:28.069818: Validation Seq.Label F1: 0.6509283896690268; Log.Reg F1: 0.43902850061957865; train loss: 0.021264130249619484; Language: japanese 

23:52:28.072131: Combined F1 SeqLab: 0.6491095284224943; train loss: 0.021264130249619484
23:52:28.766297: Combined F1 LogReg: 0.40452299787122387; train loss: 0.021264130249619484 

23:52:28.767131: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 35/40
23:57:36.309767: Evaluating Language: english
23:57:36.309905: ----------
23:57:40.908486: OBI: 
 [[2355   62  307]
 [   3   15    1]
 [  61    8  100]]
23:57:40.912376: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.86      0.92      2724
           1       0.18      0.79      0.29        19
           2       0.25      0.59      0.35       169

    accuracy                           0.85      2912
   macro avg       0.47      0.75      0.52      2912
weighted avg       0.93      0.85      0.88      2912
23:57:40.912420: ----------
23:57:40.913099: LR: 
 [[515 434]
 [  4  15]]
23:57:40.915840: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70       949
           1       0.03      0.79      0.06        19

    accuracy                           0.55       968
   macro avg       0.51      0.67      0.38       968
weighted avg       0.97      0.55      0.69       968
23:57:40.925560: Validation Seq.Label F1: 0.5169632944310949; Log.Reg F1: 0.38286872074338013; train loss: 0.032924834638834; Language: english 

23:57:40.925615: Evaluating Language: finnish
23:57:40.925659: ----------
23:57:48.469182: OBI: 
 [[6374   76  406]
 [   7   25    2]
 [ 136    2  312]]
23:57:48.475834: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      6856
           1       0.24      0.74      0.36        34
           2       0.43      0.69      0.53       450

    accuracy                           0.91      7340
   macro avg       0.55      0.79      0.62      7340
weighted avg       0.94      0.91      0.92      7340
23:57:48.475876: ----------
23:57:48.476756: LR: 
 [[859 726]
 [  4  30]]
23:57:48.480065: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70      1585
           1       0.04      0.88      0.08        34

    accuracy                           0.55      1619
   macro avg       0.52      0.71      0.39      1619
weighted avg       0.98      0.55      0.69      1619
23:57:48.483128: Validation Seq.Label F1: 0.6171869588218359; Log.Reg F1: 0.3888733763547613; train loss: 0.032924834638834; Language: finnish 

23:57:48.483181: Evaluating Language: japanese
23:57:48.483225: ----------
23:57:53.089015: OBI: 
 [[3203   71  559]
 [   3   20    1]
 [  42    1  160]]
23:57:53.093503: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.84      0.90      3833
           1       0.22      0.83      0.34        24
           2       0.22      0.79      0.35       203

    accuracy                           0.83      4060
   macro avg       0.48      0.82      0.53      4060
weighted avg       0.94      0.83      0.87      4060
23:57:53.093546: ----------
23:57:53.094182: LR: 
 [[467 369]
 [  3  21]]
23:57:53.096830: LR: 
               precision    recall  f1-score   support

           0       0.99      0.56      0.72       836
           1       0.05      0.88      0.10        24

    accuracy                           0.57       860
   macro avg       0.52      0.72      0.41       860
weighted avg       0.97      0.57      0.70       860
23:57:53.100176: Validation Seq.Label F1: 0.5320658750585227; Log.Reg F1: 0.4083050358434871; train loss: 0.032924834638834; Language: japanese 

23:57:53.102542: Combined F1 SeqLab: 0.557154941146114; train loss: 0.032924834638834
23:57:53.104826: Combined F1 LogReg: 0.39349881933595665; train loss: 0.032924834638834 

23:57:53.105444: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 36/40
00:02:57.679304: Evaluating Language: english
00:02:57.679434: ----------
00:03:02.206488: OBI: 
 [[3634   78  463]
 [   4   13    1]
 [  53    2  120]]
00:03:02.211204: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.87      0.92      4175
           1       0.14      0.72      0.23        18
           2       0.21      0.69      0.32       175

    accuracy                           0.86      4368
   macro avg       0.44      0.76      0.49      4368
weighted avg       0.95      0.86      0.90      4368
00:03:02.211246: ----------
00:03:02.211929: LR: 
 [[536 414]
 [  4  14]]
00:03:02.214640: LR: 
               precision    recall  f1-score   support

           0       0.99      0.56      0.72       950
           1       0.03      0.78      0.06        18

    accuracy                           0.57       968
   macro avg       0.51      0.67      0.39       968
weighted avg       0.97      0.57      0.71       968
00:03:02.218402: Validation Seq.Label F1: 0.49147212533940215; Log.Reg F1: 0.391121678153309; train loss: 0.028836701065301895; Language: english 

00:03:02.218456: Evaluating Language: finnish
00:03:02.218500: ----------
00:03:10.017692: OBI: 
 [[5312   38  184]
 [   5   24    3]
 [ 145    5  255]]
00:03:10.023355: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.97      5534
           1       0.36      0.75      0.48        32
           2       0.58      0.63      0.60       405

    accuracy                           0.94      5971
   macro avg       0.64      0.78      0.68      5971
weighted avg       0.94      0.94      0.94      5971
00:03:10.023398: ----------
00:03:10.024274: LR: 
 [[843 744]
 [  4  28]]
00:03:10.027565: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.69      1587
           1       0.04      0.88      0.07        32

    accuracy                           0.54      1619
   macro avg       0.52      0.70      0.38      1619
weighted avg       0.98      0.54      0.68      1619
00:03:10.030426: Validation Seq.Label F1: 0.6843810495386276; Log.Reg F1: 0.381169338189905; train loss: 0.028836701065301895; Language: finnish 

00:03:10.030481: Evaluating Language: japanese
00:03:10.030525: ----------
00:03:14.701183: OBI: 
 [[5316   59  471]
 [   7    8    2]
 [  50    1  134]]
00:03:14.706828: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      5846
           1       0.12      0.47      0.19        17
           2       0.22      0.72      0.34       185

    accuracy                           0.90      6048
   macro avg       0.44      0.70      0.49      6048
weighted avg       0.96      0.90      0.93      6048
00:03:14.706869: ----------
00:03:14.707510: LR: 
 [[517 326]
 [  4  13]]
00:03:14.710137: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.76       843
           1       0.04      0.76      0.07        17

    accuracy                           0.62       860
   macro avg       0.52      0.69      0.42       860
weighted avg       0.97      0.62      0.74       860
00:03:14.713094: Validation Seq.Label F1: 0.4914323928910529; Log.Reg F1: 0.41554911199710043; train loss: 0.028836701065301895; Language: japanese 

00:03:14.715394: Combined F1 SeqLab: 0.563154232200454; train loss: 0.028836701065301895
00:03:14.717675: Combined F1 LogReg: 0.39621008567811156; train loss: 0.028836701065301895 

00:03:14.718269: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 37/40
00:08:19.788172: Evaluating Language: english
00:08:19.788336: ----------
00:08:24.500597: OBI: 
 [[3818   46  502]
 [   3   17    3]
 [  38    4  121]]
00:08:24.505512: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.87      0.93      4366
           1       0.25      0.74      0.38        23
           2       0.19      0.74      0.31       163

    accuracy                           0.87      4552
   macro avg       0.48      0.79      0.54      4552
weighted avg       0.96      0.87      0.90      4552
00:08:24.505558: ----------
00:08:24.506246: LR: 
 [[511 434]
 [  6  17]]
00:08:24.508996: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70       945
           1       0.04      0.74      0.07        23

    accuracy                           0.55       968
   macro avg       0.51      0.64      0.39       968
weighted avg       0.97      0.55      0.68       968
00:08:24.515320: Validation Seq.Label F1: 0.5376280664267074; Log.Reg F1: 0.3853861827333229; train loss: 0.014914666302502155; Language: english 

00:08:24.515374: Evaluating Language: finnish
00:08:24.515419: ----------
00:08:32.372881: OBI: 
 [[5602   32  235]
 [   7   16    4]
 [ 180    5  188]]
00:08:32.378731: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.95      0.96      5869
           1       0.30      0.59      0.40        27
           2       0.44      0.50      0.47       373

    accuracy                           0.93      6269
   macro avg       0.57      0.68      0.61      6269
weighted avg       0.93      0.93      0.93      6269
00:08:32.378775: ----------
00:08:32.379664: LR: 
 [[863 729]
 [  5  22]]
00:08:32.382950: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70      1592
           1       0.03      0.81      0.06        27

    accuracy                           0.55      1619
   macro avg       0.51      0.68      0.38      1619
weighted avg       0.98      0.55      0.69      1619
00:08:32.385823: Validation Seq.Label F1: 0.6103522616801051; Log.Reg F1: 0.3790906430915209; train loss: 0.014914666302502155; Language: finnish 

00:08:32.385876: Evaluating Language: japanese
00:08:32.385920: ----------
00:08:37.029911: OBI: 
 [[3768   31  405]
 [   5    9    2]
 [  34    0  122]]
00:08:37.034546: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      4204
           1       0.23      0.56      0.32        16
           2       0.23      0.78      0.36       156

    accuracy                           0.89      4376
   macro avg       0.48      0.75      0.54      4376
weighted avg       0.96      0.89      0.92      4376
00:08:37.034591: ----------
00:08:37.035220: LR: 
 [[589 255]
 [  5  11]]
00:08:37.037858: LR: 
               precision    recall  f1-score   support

           0       0.99      0.70      0.82       844
           1       0.04      0.69      0.08        16

    accuracy                           0.70       860
   macro avg       0.52      0.69      0.45       860
weighted avg       0.97      0.70      0.81       860
00:08:37.040951: Validation Seq.Label F1: 0.5394464931712986; Log.Reg F1: 0.4486037542291796; train loss: 0.014914666302502155; Language: japanese 

00:08:37.043209: Combined F1 SeqLab: 0.5634939633342879; train loss: 0.014914666302502155
00:08:37.045475: Combined F1 LogReg: 0.40557677194739966; train loss: 0.014914666302502155 

00:08:37.046104: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 38/40
00:13:46.824127: Evaluating Language: english
00:13:46.824236: ----------
00:13:51.488475: OBI: 
 [[3035  106  464]
 [   2   16    3]
 [  39    5   82]]
00:13:51.493343: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.84      0.91      3605
           1       0.13      0.76      0.22        21
           2       0.15      0.65      0.24       126

    accuracy                           0.84      3752
   macro avg       0.42      0.75      0.46      3752
weighted avg       0.95      0.84      0.88      3752
00:13:51.493389: ----------
00:13:51.494057: LR: 
 [[533 414]
 [  4  17]]
00:13:51.496767: LR: 
               precision    recall  f1-score   support

           0       0.99      0.56      0.72       947
           1       0.04      0.81      0.08        21

    accuracy                           0.57       968
   macro avg       0.52      0.69      0.40       968
weighted avg       0.97      0.57      0.70       968
00:13:51.516763: Validation Seq.Label F1: 0.45590860131198413; Log.Reg F1: 0.39677503995420177; train loss: 0.01668637990951538; Language: english 

00:13:51.516866: Evaluating Language: finnish
00:13:51.516912: ----------
00:13:59.362031: OBI: 
 [[4561   68  151]
 [   3   17    3]
 [ 112    5  242]]
00:13:59.367211: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96      4780
           1       0.19      0.74      0.30        23
           2       0.61      0.67      0.64       359

    accuracy                           0.93      5162
   macro avg       0.59      0.79      0.64      5162
weighted avg       0.95      0.93      0.94      5162
00:13:59.367252: ----------
00:13:59.368128: LR: 
 [[828 768]
 [  3  20]]
00:13:59.371393: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.68      1596
           1       0.03      0.87      0.05        23

    accuracy                           0.52      1619
   macro avg       0.51      0.69      0.37      1619
weighted avg       0.98      0.52      0.67      1619
00:13:59.374339: Validation Seq.Label F1: 0.6355410231331756; Log.Reg F1: 0.3658228407603121; train loss: 0.01668637990951538; Language: finnish 

00:13:59.374395: Evaluating Language: japanese
00:13:59.374445: ----------
00:14:03.989995: OBI: 
 [[2765   47  287]
 [   3   15    1]
 [  12    0   98]]
00:14:03.993913: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      3099
           1       0.24      0.79      0.37        19
           2       0.25      0.89      0.40       110

    accuracy                           0.89      3228
   macro avg       0.50      0.86      0.57      3228
weighted avg       0.96      0.89      0.92      3228
00:14:03.993957: ----------
00:14:03.994597: LR: 
 [[600 241]
 [  7  12]]
00:14:03.997218: LR: 
               precision    recall  f1-score   support

           0       0.99      0.71      0.83       841
           1       0.05      0.63      0.09        19

    accuracy                           0.71       860
   macro avg       0.52      0.67      0.46       860
weighted avg       0.97      0.71      0.81       860
00:14:04.000074: Validation Seq.Label F1: 0.5687226077685468; Log.Reg F1: 0.45848228794280144; train loss: 0.01668637990951538; Language: japanese 

00:14:04.002285: Combined F1 SeqLab: 0.5583339650013749; train loss: 0.01668637990951538
00:14:04.004493: Combined F1 LogReg: 0.40884503645834197; train loss: 0.01668637990951538 

00:14:04.005098: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 39/40
00:19:07.153246: Evaluating Language: english
00:19:07.153410: ----------
00:19:11.801698: OBI: 
 [[2888   59  341]
 [   4   10    0]
 [  30    4   72]]
00:19:11.805905: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      3288
           1       0.14      0.71      0.23        14
           2       0.17      0.68      0.28       106

    accuracy                           0.87      3408
   macro avg       0.43      0.76      0.48      3408
weighted avg       0.96      0.87      0.91      3408
00:19:11.805949: ----------
00:19:11.806641: LR: 
 [[518 436]
 [  5   9]]
00:19:11.809403: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70       954
           1       0.02      0.64      0.04        14

    accuracy                           0.54       968
   macro avg       0.51      0.59      0.37       968
weighted avg       0.98      0.54      0.69       968
00:19:11.827940: Validation Seq.Label F1: 0.4791514754290591; Log.Reg F1: 0.37031874361118855; train loss: 0.01927327737212181; Language: english 

00:19:11.828049: Evaluating Language: finnish
00:19:11.828103: ----------
00:19:19.513681: OBI: 
 [[6010   51  345]
 [   4   23    4]
 [  68    3  253]]
00:19:19.521045: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      6406
           1       0.30      0.74      0.43        31
           2       0.42      0.78      0.55       324

    accuracy                           0.93      6761
   macro avg       0.57      0.82      0.64      6761
weighted avg       0.96      0.93      0.94      6761
00:19:19.521100: ----------
00:19:19.522150: LR: 
 [[845 743]
 [  4  27]]
00:19:19.526114: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.69      1588
           1       0.04      0.87      0.07        31

    accuracy                           0.54      1619
   macro avg       0.52      0.70      0.38      1619
weighted avg       0.98      0.54      0.68      1619
00:19:19.529716: Validation Seq.Label F1: 0.6449620780284192; Log.Reg F1: 0.3804456575362044; train loss: 0.01927327737212181; Language: finnish 

00:19:19.529792: Evaluating Language: japanese
00:19:19.529843: ----------
00:19:24.199586: OBI: 
 [[5212   68  528]
 [   5   18    2]
 [  74    1  128]]
00:19:24.205258: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      5808
           1       0.21      0.72      0.32        25
           2       0.19      0.63      0.30       203

    accuracy                           0.89      6036
   macro avg       0.46      0.75      0.52      6036
weighted avg       0.96      0.89      0.92      6036
00:19:24.205302: ----------
00:19:24.205941: LR: 
 [[591 244]
 [  8  17]]
00:19:24.208598: LR: 
               precision    recall  f1-score   support

           0       0.99      0.71      0.82       835
           1       0.07      0.68      0.12        25

    accuracy                           0.71       860
   macro avg       0.53      0.69      0.47       860
weighted avg       0.96      0.71      0.80       860
00:19:24.211577: Validation Seq.Label F1: 0.5193136564151092; Log.Reg F1: 0.4715744506539486; train loss: 0.01927327737212181; Language: japanese 

00:19:24.213832: Combined F1 SeqLab: 0.5523431579008986; train loss: 0.01927327737212181
00:19:24.216075: Combined F1 LogReg: 0.4099826552093383; train loss: 0.01927327737212181 

00:19:24.216698: Model: lab6_bert-base-multilingual-cased_finnish.pt; Language: finnish; Epoch 40/40
00:24:28.031971: Evaluating Language: english
00:24:28.032107: ----------
00:24:32.700330: OBI: 
 [[2390   34  374]
 [   0    8    3]
 [  15    1   87]]
00:24:32.704168: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.85      0.92      2798
           1       0.19      0.73      0.30        11
           2       0.19      0.84      0.31       103

    accuracy                           0.85      2912
   macro avg       0.46      0.81      0.51      2912
weighted avg       0.96      0.85      0.89      2912
00:24:32.704211: ----------
00:24:32.704895: LR: 
 [[499 458]
 [  1  10]]
00:24:32.707612: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.68       957
           1       0.02      0.91      0.04        11

    accuracy                           0.53       968
   macro avg       0.51      0.72      0.36       968
weighted avg       0.99      0.53      0.68       968
00:24:32.711751: Validation Seq.Label F1: 0.5072917842473867; Log.Reg F1: 0.3633613840318784; train loss: 0.01836719736456871; Language: english 

00:24:32.711804: Evaluating Language: finnish
00:24:32.711847: ----------
00:24:40.699933: OBI: 
 [[5060   30  153]
 [   3   21    1]
 [  91    2  207]]
00:24:40.705336: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.97      0.97      5243
           1       0.40      0.84      0.54        25
           2       0.57      0.69      0.63       300

    accuracy                           0.95      5568
   macro avg       0.65      0.83      0.71      5568
weighted avg       0.96      0.95      0.95      5568
00:24:40.705381: ----------
00:24:40.706264: LR: 
 [[855 739]
 [  5  20]]
00:24:40.709549: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70      1594
           1       0.03      0.80      0.05        25

    accuracy                           0.54      1619
   macro avg       0.51      0.67      0.37      1619
weighted avg       0.98      0.54      0.69      1619
00:24:40.712306: Validation Seq.Label F1: 0.7127143298963198; Log.Reg F1: 0.373920962027843; train loss: 0.01836719736456871; Language: finnish 

00:24:40.712371: Evaluating Language: japanese
00:24:40.712415: ----------
00:24:45.243486: OBI: 
 [[3812   42  449]
 [   5   15    2]
 [  20    1  134]]
00:24:45.248152: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      4303
           1       0.26      0.68      0.38        22
           2       0.23      0.86      0.36       155

    accuracy                           0.88      4480
   macro avg       0.49      0.81      0.56      4480
weighted avg       0.96      0.88      0.91      4480
00:24:45.248194: ----------
00:24:45.248834: LR: 
 [[453 385]
 [  6  16]]
00:24:45.251459: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70       838
           1       0.04      0.73      0.08        22

    accuracy                           0.55       860
   macro avg       0.51      0.63      0.39       860
weighted avg       0.96      0.55      0.68       860
00:24:45.254218: Validation Seq.Label F1: 0.5579238329238329; Log.Reg F1: 0.38709259957968106; train loss: 0.01836719736456871; Language: japanese 

00:24:45.256436: Combined F1 SeqLab: 0.5990508252641223; train loss: 0.01836719736456871
00:24:45.258645: Combined F1 LogReg: 0.37491735173623936; train loss: 0.01836719736456871 

00:24:45.258698: Learning rates: []
00:24:55.427522: -- Data Parsing JAPANESE; Type: TRAIN--
00:25:17.264651: Unanswerable questions: 4250
00:25:17.337777: Balance of labels: dict_keys([-100, 0, 1, 2]):dict_values([110591, 1074396, 2953, 20486])
00:25:17.337835: Entries skipped due to too long sequence length (>512): 375
00:25:17.337882: Failed to map answer and to context: 1200
00:25:17.401265: Label counts: O: 1074396, B: 2953, I: 20486
00:25:17.401461: Final length: 7203 

00:25:17.423482: Language: japanese; Class weights: [0.00239649 0.87191883 0.12568468 0.        ]
00:25:17.682599: Training model: lab6_bert-base-multilingual-cased_japanese.pt
00:25:17.682767: Loading model: bert-base-multilingual-cased
00:25:19.373156: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 1/40
00:28:29.191325: Evaluating Language: english
00:28:29.191450: ----------
00:28:33.803250: OBI: 
 [[2470  354 1266]
 [   2   14    6]
 [  26    9  157]]
00:28:33.808068: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.60      0.75      4090
           1       0.04      0.64      0.07        22
           2       0.11      0.82      0.19       192

    accuracy                           0.61      4304
   macro avg       0.38      0.69      0.34      4304
weighted avg       0.94      0.61      0.72      4304
00:28:33.808117: ----------
00:28:33.808809: LR: 
 [[625 321]
 [  7  15]]
00:28:33.811556: LR: 
               precision    recall  f1-score   support

           0       0.99      0.66      0.79       946
           1       0.04      0.68      0.08        22

    accuracy                           0.66       968
   macro avg       0.52      0.67      0.44       968
weighted avg       0.97      0.66      0.78       968
00:28:33.813623: Validation Seq.Label F1: 0.3379104117899306; Log.Reg F1: 0.43797041725966673; train loss: 0.5185008645057678; Language: english 

00:28:33.813685: Evaluating Language: finnish
00:28:33.813730: ----------
00:28:41.456610: OBI: 
 [[2780  456 1528]
 [   0   14    2]
 [  42   29  221]]
00:28:41.461910: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.58      0.73      4764
           1       0.03      0.88      0.05        16
           2       0.13      0.76      0.22       292

    accuracy                           0.59      5072
   macro avg       0.38      0.74      0.33      5072
weighted avg       0.93      0.59      0.70      5072
00:28:41.461955: ----------
00:28:41.462821: LR: 
 [[1383  220]
 [  13    3]]
00:28:41.466015: LR: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      1603
           1       0.01      0.19      0.03        16

    accuracy                           0.86      1619
   macro avg       0.50      0.53      0.47      1619
weighted avg       0.98      0.86      0.91      1619
00:28:41.467822: Validation Seq.Label F1: 0.3345488396734125; Log.Reg F1: 0.47370601916119875; train loss: 0.5185008645057678; Language: finnish 

00:28:41.467881: Evaluating Language: japanese
00:28:41.467926: ----------
00:28:46.036121: OBI: 
 [[5026  648 2341]
 [   0   33    3]
 [   2    8  259]]
00:28:46.043623: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.63      0.77      8015
           1       0.05      0.92      0.09        36
           2       0.10      0.96      0.18       269

    accuracy                           0.64      8320
   macro avg       0.38      0.84      0.35      8320
weighted avg       0.97      0.64      0.75      8320
00:28:46.043673: ----------
00:28:46.044330: LR: 
 [[397 427]
 [  3  33]]
00:28:46.047000: LR: 
               precision    recall  f1-score   support

           0       0.99      0.48      0.65       824
           1       0.07      0.92      0.13        36

    accuracy                           0.50       860
   macro avg       0.53      0.70      0.39       860
weighted avg       0.95      0.50      0.63       860
00:28:46.048801: Validation Seq.Label F1: 0.34735939713620834; Log.Reg F1: 0.3908786632932743; train loss: 0.5185008645057678; Language: japanese 

00:28:46.050126: Combined F1 SeqLab: 0.33998280510524703; train loss: 0.5185008645057678
00:28:47.152265: Combined F1 LogReg: 0.43550798247643846; train loss: 0.5185008645057678 

00:28:47.154538: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 2/40
00:31:50.348778: Evaluating Language: english
00:31:50.348985: ----------
00:31:55.120054: OBI: 
 [[1251  113  704]
 [   0    4    2]
 [   5    3   62]]
00:31:55.123865: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.60      0.75      2068
           1       0.03      0.67      0.06         6
           2       0.08      0.89      0.15        70

    accuracy                           0.61      2144
   macro avg       0.37      0.72      0.32      2144
weighted avg       0.96      0.61      0.73      2144
00:31:55.123920: ----------
00:31:55.124744: LR: 
 [[577 385]
 [  2   4]]
00:31:55.128024: LR: 
               precision    recall  f1-score   support

           0       1.00      0.60      0.75       962
           1       0.01      0.67      0.02         6

    accuracy                           0.60       968
   macro avg       0.50      0.63      0.38       968
weighted avg       0.99      0.60      0.74       968
00:31:55.132647: Validation Seq.Label F1: 0.3213903350337873; Log.Reg F1: 0.38455876917010984; train loss: 0.32378989458084106; Language: english 

00:31:55.132715: Evaluating Language: finnish
00:31:55.132762: ----------
00:32:03.013994: OBI: 
 [[4810  428 2392]
 [   1   26    9]
 [  41   25  271]]
00:32:03.021323: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.63      0.77      7630
           1       0.05      0.72      0.10        36
           2       0.10      0.80      0.18       337

    accuracy                           0.64      8003
   macro avg       0.38      0.72      0.35      8003
weighted avg       0.95      0.64      0.74      8003
00:32:03.021370: ----------
00:32:03.022235: LR: 
 [[1301  282]
 [  25   11]]
00:32:03.025478: LR: 
               precision    recall  f1-score   support

           0       0.98      0.82      0.89      1583
           1       0.04      0.31      0.07        36

    accuracy                           0.81      1619
   macro avg       0.51      0.56      0.48      1619
weighted avg       0.96      0.81      0.88      1619
00:32:03.027189: Validation Seq.Label F1: 0.350602327911184; Log.Reg F1: 0.48066737647861524; train loss: 0.32378989458084106; Language: finnish 

00:32:03.027246: Evaluating Language: japanese
00:32:03.027291: ----------
00:32:07.650825: OBI: 
 [[3049  143 1098]
 [   0   29    0]
 [   3    0  190]]
00:32:07.655701: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.71      0.83      4290
           1       0.17      1.00      0.29        29
           2       0.15      0.98      0.26       193

    accuracy                           0.72      4512
   macro avg       0.44      0.90      0.46      4512
weighted avg       0.96      0.72      0.80      4512
00:32:07.655747: ----------
00:32:07.656398: LR: 
 [[515 316]
 [  9  20]]
00:32:07.659054: LR: 
               precision    recall  f1-score   support

           0       0.98      0.62      0.76       831
           1       0.06      0.69      0.11        29

    accuracy                           0.62       860
   macro avg       0.52      0.65      0.43       860
weighted avg       0.95      0.62      0.74       860
00:32:07.660749: Validation Seq.Label F1: 0.45856816086133273; Log.Reg F1: 0.43486832128595254; train loss: 0.32378989458084106; Language: japanese 

00:32:07.662030: Combined F1 SeqLab: 0.38144396615388415; train loss: 0.32378989458084106
00:32:08.802596: Combined F1 LogReg: 0.4351386869395883; train loss: 0.32378989458084106 

00:32:08.804099: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 3/40
00:35:10.631065: Evaluating Language: english
00:35:10.631182: ----------
00:35:15.334493: OBI: 
 [[4152  282 1442]
 [   1   13   10]
 [  11    9  136]]
00:35:15.340386: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.71      0.83      5876
           1       0.04      0.54      0.08        24
           2       0.09      0.87      0.16       156

    accuracy                           0.71      6056
   macro avg       0.38      0.71      0.35      6056
weighted avg       0.97      0.71      0.81      6056
00:35:15.340431: ----------
00:35:15.341105: LR: 
 [[727 217]
 [ 16   8]]
00:35:15.343825: LR: 
               precision    recall  f1-score   support

           0       0.98      0.77      0.86       944
           1       0.04      0.33      0.06        24

    accuracy                           0.76       968
   macro avg       0.51      0.55      0.46       968
weighted avg       0.96      0.76      0.84       968
00:35:15.345796: Validation Seq.Label F1: 0.3541077429671186; Log.Reg F1: 0.4630710155381455; train loss: 0.2018037587404251; Language: english 

00:35:15.345855: Evaluating Language: finnish
00:35:15.345902: ----------
00:35:23.246354: OBI: 
 [[4496  337 1291]
 [   1   27    1]
 [  66   13  239]]
00:35:23.252482: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.73      0.84      6124
           1       0.07      0.93      0.13        29
           2       0.16      0.75      0.26       318

    accuracy                           0.74      6471
   macro avg       0.40      0.81      0.41      6471
weighted avg       0.94      0.74      0.81      6471
00:35:23.252527: ----------
00:35:23.253404: LR: 
 [[1519   71]
 [  27    2]]
00:35:23.256592: LR: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      1590
           1       0.03      0.07      0.04        29

    accuracy                           0.94      1619
   macro avg       0.50      0.51      0.50      1619
weighted avg       0.97      0.94      0.95      1619
00:35:23.258394: Validation Seq.Label F1: 0.41097304423861575; Log.Reg F1: 0.5039828431372548; train loss: 0.2018037587404251; Language: finnish 

00:35:23.258449: Evaluating Language: japanese
00:35:23.258494: ----------
00:35:27.901025: OBI: 
 [[3866  132  638]
 [   0   14    3]
 [   5    2  152]]
00:35:27.906010: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.91      4636
           1       0.09      0.82      0.17        17
           2       0.19      0.96      0.32       159

    accuracy                           0.84      4812
   macro avg       0.43      0.87      0.47      4812
weighted avg       0.97      0.84      0.89      4812
00:35:27.906056: ----------
00:35:27.906708: LR: 
 [[552 291]
 [  1  16]]
00:35:27.909350: LR: 
               precision    recall  f1-score   support

           0       1.00      0.65      0.79       843
           1       0.05      0.94      0.10        17

    accuracy                           0.66       860
   macro avg       0.53      0.80      0.44       860
weighted avg       0.98      0.66      0.78       860
00:35:27.911109: Validation Seq.Label F1: 0.46597441830709935; Log.Reg F1: 0.4447981888287524; train loss: 0.2018037587404251; Language: japanese 

00:35:27.912415: Combined F1 SeqLab: 0.4128854947143989; train loss: 0.2018037587404251
00:35:28.654081: Combined F1 LogReg: 0.4712674047691603; train loss: 0.2018037587404251 

00:35:28.657426: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 4/40
00:38:32.859879: Evaluating Language: english
00:38:32.860045: ----------
00:38:37.625797: OBI: 
 [[3749  185  909]
 [   1   11    4]
 [  17    7  133]]
00:38:37.631145: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.77      0.87      4843
           1       0.05      0.69      0.10        16
           2       0.13      0.85      0.22       157

    accuracy                           0.78      5016
   macro avg       0.39      0.77      0.40      5016
weighted avg       0.97      0.78      0.85      5016
00:38:37.631196: ----------
00:38:37.631894: LR: 
 [[736 216]
 [ 11   5]]
00:38:37.634647: LR: 
               precision    recall  f1-score   support

           0       0.99      0.77      0.87       952
           1       0.02      0.31      0.04        16

    accuracy                           0.77       968
   macro avg       0.50      0.54      0.45       968
weighted avg       0.97      0.77      0.85       968
00:38:37.637016: Validation Seq.Label F1: 0.3974727847673282; Log.Reg F1: 0.45429304405917603; train loss: 0.14994743466377258; Language: english 

00:38:37.637074: Evaluating Language: finnish
00:38:37.637126: ----------
00:38:45.394303: OBI: 
 [[3913  213  880]
 [   1   19    3]
 [  80    6  149]]
00:38:45.399652: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.78      0.87      5006
           1       0.08      0.83      0.15        23
           2       0.14      0.63      0.24       235

    accuracy                           0.78      5264
   macro avg       0.40      0.75      0.42      5264
weighted avg       0.94      0.78      0.84      5264
00:38:45.399700: ----------
00:38:45.400585: LR: 
 [[1405  191]
 [  15    8]]
00:38:45.403790: LR: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      1596
           1       0.04      0.35      0.07        23

    accuracy                           0.87      1619
   macro avg       0.51      0.61      0.50      1619
weighted avg       0.98      0.87      0.92      1619
00:38:45.405632: Validation Seq.Label F1: 0.4167835627043095; Log.Reg F1: 0.5018848424020839; train loss: 0.14994743466377258; Language: finnish 

00:38:45.405688: Evaluating Language: japanese
00:38:45.405733: ----------
00:38:50.112022: OBI: 
 [[4689  114  585]
 [   3   24    3]
 [   7    1  230]]
00:38:50.117574: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93      5388
           1       0.17      0.80      0.28        30
           2       0.28      0.97      0.44       238

    accuracy                           0.87      5656
   macro avg       0.48      0.88      0.55      5656
weighted avg       0.96      0.87      0.91      5656
00:38:50.117621: ----------
00:38:50.118268: LR: 
 [[472 358]
 [  6  24]]
00:38:50.120936: LR: 
               precision    recall  f1-score   support

           0       0.99      0.57      0.72       830
           1       0.06      0.80      0.12        30

    accuracy                           0.58       860
   macro avg       0.53      0.68      0.42       860
weighted avg       0.96      0.58      0.70       860
00:38:50.122775: Validation Seq.Label F1: 0.5497804130364319; Log.Reg F1: 0.41910869629761593; train loss: 0.14994743466377258; Language: japanese 

00:38:50.124097: Combined F1 SeqLab: 0.4596925259814802; train loss: 0.14994743466377258
00:38:51.549116: Combined F1 LogReg: 0.45968201481234255; train loss: 0.14994743466377258 

00:38:51.550184: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 5/40
00:41:54.353300: Evaluating Language: english
00:41:54.353506: ----------
00:41:59.096955: OBI: 
 [[1556   72  301]
 [   1    8    4]
 [   8    5   85]]
00:41:59.101188: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.81      0.89      1929
           1       0.09      0.62      0.16        13
           2       0.22      0.87      0.35        98

    accuracy                           0.81      2040
   macro avg       0.44      0.76      0.47      2040
weighted avg       0.95      0.81      0.86      2040
00:41:59.101247: ----------
00:41:59.102072: LR: 
 [[408 547]
 [  3  10]]
00:41:59.105366: LR: 
               precision    recall  f1-score   support

           0       0.99      0.43      0.60       955
           1       0.02      0.77      0.04        13

    accuracy                           0.43       968
   macro avg       0.51      0.60      0.32       968
weighted avg       0.98      0.43      0.59       968
00:41:59.110764: Validation Seq.Label F1: 0.46743189379310984; Log.Reg F1: 0.3162261436901184; train loss: 0.11653109639883041; Language: english 

00:41:59.110841: Evaluating Language: finnish
00:41:59.110900: ----------
00:42:06.917911: OBI: 
 [[5077  228  766]
 [   1   24    2]
 [  75   11  156]]
00:42:06.923956: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.84      0.90      6071
           1       0.09      0.89      0.17        27
           2       0.17      0.64      0.27       242

    accuracy                           0.83      6340
   macro avg       0.42      0.79      0.45      6340
weighted avg       0.95      0.83      0.88      6340
00:42:06.924001: ----------
00:42:06.924865: LR: 
 [[1525   67]
 [  23    4]]
00:42:06.928029: LR: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97      1592
           1       0.06      0.15      0.08        27

    accuracy                           0.94      1619
   macro avg       0.52      0.55      0.53      1619
weighted avg       0.97      0.94      0.96      1619
00:42:06.929829: Validation Seq.Label F1: 0.44592242795454057; Log.Reg F1: 0.5264851163395294; train loss: 0.11653109639883041; Language: finnish 

00:42:06.929884: Evaluating Language: japanese
00:42:06.929929: ----------
00:42:11.519846: OBI: 
 [[3858  105  412]
 [   1   23    1]
 [   3    0  141]]
00:42:11.524653: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.94      4375
           1       0.18      0.92      0.30        25
           2       0.25      0.98      0.40       144

    accuracy                           0.89      4544
   macro avg       0.48      0.93      0.55      4544
weighted avg       0.97      0.89      0.92      4544
00:42:11.524700: ----------
00:42:11.525348: LR: 
 [[423 412]
 [  6  19]]
00:42:11.528005: LR: 
               precision    recall  f1-score   support

           0       0.99      0.51      0.67       835
           1       0.04      0.76      0.08        25

    accuracy                           0.51       860
   macro avg       0.52      0.63      0.38       860
weighted avg       0.96      0.51      0.65       860
00:42:11.529718: Validation Seq.Label F1: 0.5471379574686379; Log.Reg F1: 0.37631856540084385; train loss: 0.11653109639883041; Language: japanese 

00:42:11.531027: Combined F1 SeqLab: 0.4887737484736125; train loss: 0.11653109639883041
00:42:12.628271: Combined F1 LogReg: 0.41585302465555485; train loss: 0.11653109639883041 

00:42:12.629132: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 6/40
00:45:16.216396: Evaluating Language: english
00:45:16.216567: ----------
00:45:20.947480: OBI: 
 [[2544   95  501]
 [   1   10    5]
 [  22    7  103]]
00:45:20.951503: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.81      0.89      3140
           1       0.09      0.62      0.16        16
           2       0.17      0.78      0.28       132

    accuracy                           0.81      3288
   macro avg       0.42      0.74      0.44      3288
weighted avg       0.95      0.81      0.86      3288
00:45:20.951547: ----------
00:45:20.952218: LR: 
 [[533 419]
 [  6  10]]
00:45:20.954991: LR: 
               precision    recall  f1-score   support

           0       0.99      0.56      0.71       952
           1       0.02      0.62      0.04        16

    accuracy                           0.56       968
   macro avg       0.51      0.59      0.38       968
weighted avg       0.97      0.56      0.70       968
00:45:20.957006: Validation Seq.Label F1: 0.4419298027865646; Log.Reg F1: 0.37995011266098466; train loss: 0.09521323442459106; Language: english 

00:45:20.957064: Evaluating Language: finnish
00:45:20.957108: ----------
00:45:28.743429: OBI: 
 [[6312  200 1331]
 [   5   22    4]
 [ 149   13  284]]
00:45:28.750802: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.80      0.88      7843
           1       0.09      0.71      0.17        31
           2       0.18      0.64      0.28       446

    accuracy                           0.80      8320
   macro avg       0.42      0.72      0.44      8320
weighted avg       0.93      0.80      0.85      8320
00:45:28.750846: ----------
00:45:28.751722: LR: 
 [[1059  529]
 [  19   12]]
00:45:28.754991: LR: 
               precision    recall  f1-score   support

           0       0.98      0.67      0.79      1588
           1       0.02      0.39      0.04        31

    accuracy                           0.66      1619
   macro avg       0.50      0.53      0.42      1619
weighted avg       0.96      0.66      0.78      1619
00:45:28.756829: Validation Seq.Label F1: 0.4409053373836211; Log.Reg F1: 0.41820332705554014; train loss: 0.09521323442459106; Language: finnish 

00:45:28.756885: Evaluating Language: japanese
00:45:28.756929: ----------
00:45:33.275131: OBI: 
 [[4865   67  435]
 [   1   22    2]
 [  11    0  173]]
00:45:33.280542: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.91      0.95      5367
           1       0.25      0.88      0.39        25
           2       0.28      0.94      0.44       184

    accuracy                           0.91      5576
   macro avg       0.51      0.91      0.59      5576
weighted avg       0.97      0.91      0.93      5576
00:45:33.280591: ----------
00:45:33.281228: LR: 
 [[481 354]
 [  3  22]]
00:45:33.283893: LR: 
               precision    recall  f1-score   support

           0       0.99      0.58      0.73       835
           1       0.06      0.88      0.11        25

    accuracy                           0.58       860
   macro avg       0.53      0.73      0.42       860
weighted avg       0.97      0.58      0.71       860
00:45:33.285698: Validation Seq.Label F1: 0.5905191538777256; Log.Reg F1: 0.4195330475932988; train loss: 0.09521323442459106; Language: japanese 

00:45:33.287002: Combined F1 SeqLab: 0.49612241037227944; train loss: 0.09521323442459106
00:45:33.970336: Combined F1 LogReg: 0.4063102627690401; train loss: 0.09521323442459106 

00:45:33.971115: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 7/40
00:48:38.781704: Evaluating Language: english
00:48:38.782018: ----------
00:48:43.446213: OBI: 
 [[3100  164  465]
 [   3   13    4]
 [  63    8  156]]
00:48:43.450811: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.83      0.90      3729
           1       0.07      0.65      0.13        20
           2       0.25      0.69      0.37       227

    accuracy                           0.82      3976
   macro avg       0.43      0.72      0.46      3976
weighted avg       0.93      0.82      0.86      3976
00:48:43.450857: ----------
00:48:43.451540: LR: 
 [[773 175]
 [ 14   6]]
00:48:43.454271: LR: 
               precision    recall  f1-score   support

           0       0.98      0.82      0.89       948
           1       0.03      0.30      0.06        20

    accuracy                           0.80       968
   macro avg       0.51      0.56      0.48       968
weighted avg       0.96      0.80      0.87       968
00:48:43.456247: Validation Seq.Label F1: 0.46407625730446395; Log.Reg F1: 0.4753838874790314; train loss: 0.06762214004993439; Language: english 

00:48:43.456305: Evaluating Language: finnish
00:48:43.456357: ----------
00:48:51.308805: OBI: 
 [[5357  260  695]
 [   3   19    8]
 [ 111   16  299]]
00:48:51.315488: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.85      0.91      6312
           1       0.06      0.63      0.12        30
           2       0.30      0.70      0.42       426

    accuracy                           0.84      6768
   macro avg       0.45      0.73      0.48      6768
weighted avg       0.93      0.84      0.87      6768
00:48:51.315532: ----------
00:48:51.316391: LR: 
 [[1442  147]
 [  24    6]]
00:48:51.319583: LR: 
               precision    recall  f1-score   support

           0       0.98      0.91      0.94      1589
           1       0.04      0.20      0.07        30

    accuracy                           0.89      1619
   macro avg       0.51      0.55      0.50      1619
weighted avg       0.97      0.89      0.93      1619
00:48:51.321319: Validation Seq.Label F1: 0.48165555320938697; Log.Reg F1: 0.5047999785355907; train loss: 0.06762214004993439; Language: finnish 

00:48:51.321378: Evaluating Language: japanese
00:48:51.321424: ----------
00:48:55.896237: OBI: 
 [[3778   45  354]
 [   1   17    2]
 [   3    0  120]]
00:48:55.900879: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.95      4177
           1       0.27      0.85      0.41        20
           2       0.25      0.98      0.40       123

    accuracy                           0.91      4320
   macro avg       0.51      0.91      0.59      4320
weighted avg       0.97      0.91      0.93      4320
00:48:55.900923: ----------
00:48:55.901566: LR: 
 [[504 336]
 [  3  17]]
00:48:55.904202: LR: 
               precision    recall  f1-score   support

           0       0.99      0.60      0.75       840
           1       0.05      0.85      0.09        20

    accuracy                           0.61       860
   macro avg       0.52      0.72      0.42       860
weighted avg       0.97      0.61      0.73       860
00:48:55.905954: Validation Seq.Label F1: 0.5882224747174493; Log.Reg F1: 0.4197412181971256; train loss: 0.06762214004993439; Language: japanese 

00:48:55.907277: Combined F1 SeqLab: 0.51425172963374; train loss: 0.06762214004993439
00:48:57.135477: Combined F1 LogReg: 0.4679727730889965; train loss: 0.06762214004993439 

00:48:57.136349: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 8/40
00:52:02.404799: Evaluating Language: english
00:52:02.405028: ----------
00:52:07.087987: OBI: 
 [[2929   82  184]
 [   4   11    1]
 [  70   17  110]]
00:52:07.092270: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.92      0.95      3195
           1       0.10      0.69      0.17        16
           2       0.37      0.56      0.45       197

    accuracy                           0.89      3408
   macro avg       0.48      0.72      0.52      3408
weighted avg       0.94      0.89      0.91      3408
00:52:07.092324: ----------
00:52:07.093008: LR: 
 [[313 639]
 [  3  13]]
00:52:07.095745: LR: 
               precision    recall  f1-score   support

           0       0.99      0.33      0.49       952
           1       0.02      0.81      0.04        16

    accuracy                           0.34       968
   macro avg       0.51      0.57      0.27       968
weighted avg       0.97      0.34      0.49       968
00:52:07.100455: Validation Seq.Label F1: 0.5223004136186201; Log.Reg F1: 0.26630650371181924; train loss: 0.05800747126340866; Language: english 

00:52:07.100521: Evaluating Language: finnish
00:52:07.100566: ----------
00:52:14.785456: OBI: 
 [[7223  166  292]
 [  10   36    5]
 [ 288   34  273]]
00:52:14.792821: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.94      0.95      7681
           1       0.15      0.71      0.25        51
           2       0.48      0.46      0.47       595

    accuracy                           0.90      8327
   macro avg       0.53      0.70      0.56      8327
weighted avg       0.92      0.90      0.91      8327
00:52:14.792866: ----------
00:52:14.798523: LR: 
 [[1192  376]
 [  31   20]]
00:52:14.801778: LR: 
               precision    recall  f1-score   support

           0       0.97      0.76      0.85      1568
           1       0.05      0.39      0.09        51

    accuracy                           0.75      1619
   macro avg       0.51      0.58      0.47      1619
weighted avg       0.95      0.75      0.83      1619
00:52:14.803583: Validation Seq.Label F1: 0.5566034364638178; Log.Reg F1: 0.47182979487438453; train loss: 0.05800747126340866; Language: finnish 

00:52:14.803638: Evaluating Language: japanese
00:52:14.803686: ----------
00:52:19.416204: OBI: 
 [[4856   63  218]
 [   5   17    1]
 [  30    2  120]]
00:52:19.421438: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      5137
           1       0.21      0.74      0.32        23
           2       0.35      0.79      0.49       152

    accuracy                           0.94      5312
   macro avg       0.52      0.82      0.59      5312
weighted avg       0.97      0.94      0.95      5312
00:52:19.421482: ----------
00:52:19.422116: LR: 
 [[494 343]
 [  5  18]]
00:52:19.424777: LR: 
               precision    recall  f1-score   support

           0       0.99      0.59      0.74       837
           1       0.05      0.78      0.09        23

    accuracy                           0.60       860
   macro avg       0.52      0.69      0.42       860
weighted avg       0.96      0.60      0.72       860
00:52:19.426526: Validation Seq.Label F1: 0.5936987091431226; Log.Reg F1: 0.41663547904191617; train loss: 0.05800747126340866; Language: japanese 

00:52:19.427835: Combined F1 SeqLab: 0.5582959981908411; train loss: 0.05800747126340866
00:52:20.452740: Combined F1 LogReg: 0.39460006405089193; train loss: 0.05800747126340866 

00:52:20.453559: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 9/40
00:55:22.752049: Evaluating Language: english
00:55:22.752157: ----------
00:55:27.490307: OBI: 
 [[3820   57  178]
 [   4    6    0]
 [  65    9   85]]
00:55:27.494919: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      4055
           1       0.08      0.60      0.15        10
           2       0.32      0.53      0.40       159

    accuracy                           0.93      4224
   macro avg       0.46      0.69      0.50      4224
weighted avg       0.96      0.93      0.94      4224
00:55:27.494964: ----------
00:55:27.495643: LR: 
 [[513 445]
 [  3   7]]
00:55:27.498358: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70       958
           1       0.02      0.70      0.03        10

    accuracy                           0.54       968
   macro avg       0.50      0.62      0.36       968
weighted avg       0.98      0.54      0.69       968
00:55:27.500447: Validation Seq.Label F1: 0.5036390633948292; Log.Reg F1: 0.36318407960199; train loss: 0.060285333544015884; Language: english 

00:55:27.500503: Evaluating Language: finnish
00:55:27.500547: ----------
00:55:35.194424: OBI: 
 [[6568   96  201]
 [  11   29    5]
 [ 238   19  194]]
00:55:35.201042: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.96      0.96      6865
           1       0.20      0.64      0.31        45
           2       0.48      0.43      0.46       451

    accuracy                           0.92      7361
   macro avg       0.55      0.68      0.57      7361
weighted avg       0.93      0.92      0.93      7361
00:55:35.201086: ----------
00:55:35.201965: LR: 
 [[981 593]
 [ 15  30]]
00:55:35.205248: LR: 
               precision    recall  f1-score   support

           0       0.98      0.62      0.76      1574
           1       0.05      0.67      0.09        45

    accuracy                           0.62      1619
   macro avg       0.52      0.64      0.43      1619
weighted avg       0.96      0.62      0.74      1619
00:55:35.207058: Validation Seq.Label F1: 0.5743020185056585; Log.Reg F1: 0.42662224189752795; train loss: 0.060285333544015884; Language: finnish 

00:55:35.207113: Evaluating Language: japanese
00:55:35.207157: ----------
00:55:39.802329: OBI: 
 [[2957   24  147]
 [   0   17    1]
 [  26    0  120]]
00:55:39.806280: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      3128
           1       0.41      0.94      0.58        18
           2       0.45      0.82      0.58       146

    accuracy                           0.94      3292
   macro avg       0.62      0.90      0.71      3292
weighted avg       0.96      0.94      0.95      3292
00:55:39.806329: ----------
00:55:39.806962: LR: 
 [[482 360]
 [  4  14]]
00:55:39.809601: LR: 
               precision    recall  f1-score   support

           0       0.99      0.57      0.73       842
           1       0.04      0.78      0.07        18

    accuracy                           0.58       860
   macro avg       0.51      0.68      0.40       860
weighted avg       0.97      0.58      0.71       860
00:55:39.811361: Validation Seq.Label F1: 0.707914793868497; Log.Reg F1: 0.3986660929432014; train loss: 0.060285333544015884; Language: japanese 

00:55:39.812682: Combined F1 SeqLab: 0.6012815397173971; train loss: 0.060285333544015884
00:55:40.644855: Combined F1 LogReg: 0.39700708080193176; train loss: 0.060285333544015884 

00:55:40.645844: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 10/40
00:58:44.407659: Evaluating Language: english
00:58:44.407789: ----------
00:58:49.174419: OBI: 
 [[2697  100  355]
 [   1   13    3]
 [  26    7  134]]
00:58:49.178595: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      3152
           1       0.11      0.76      0.19        17
           2       0.27      0.80      0.41       167

    accuracy                           0.85      3336
   macro avg       0.46      0.81      0.50      3336
weighted avg       0.95      0.85      0.89      3336
00:58:49.178640: ----------
00:58:49.179321: LR: 
 [[674 277]
 [ 13   4]]
00:58:49.182040: LR: 
               precision    recall  f1-score   support

           0       0.98      0.71      0.82       951
           1       0.01      0.24      0.03        17

    accuracy                           0.70       968
   macro avg       0.50      0.47      0.42       968
weighted avg       0.96      0.70      0.81       968
00:58:49.184320: Validation Seq.Label F1: 0.5048097380080714; Log.Reg F1: 0.42490023026935775; train loss: 0.05217383801937103; Language: english 

00:58:49.184376: Evaluating Language: finnish
00:58:49.184419: ----------
00:58:56.999541: OBI: 
 [[6753  187  589]
 [   4   29    4]
 [ 127   21  240]]
00:58:57.006662: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.90      0.94      7529
           1       0.12      0.78      0.21        37
           2       0.29      0.62      0.39       388

    accuracy                           0.88      7954
   macro avg       0.46      0.77      0.51      7954
weighted avg       0.94      0.88      0.91      7954
00:58:57.006706: ----------
00:58:57.007573: LR: 
 [[1477  105]
 [  29    8]]
00:58:57.010800: LR: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.96      1582
           1       0.07      0.22      0.11        37

    accuracy                           0.92      1619
   macro avg       0.53      0.57      0.53      1619
weighted avg       0.96      0.92      0.94      1619
00:58:57.012701: Validation Seq.Label F1: 0.5139566417665417; Log.Reg F1: 0.5316364421416234; train loss: 0.05217383801937103; Language: finnish 

00:58:57.012768: Evaluating Language: japanese
00:58:57.012814: ----------
00:59:01.668611: OBI: 
 [[5150   49  273]
 [   2   18    1]
 [  20    0  131]]
00:59:01.675039: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97      5472
           1       0.27      0.86      0.41        21
           2       0.32      0.87      0.47       151

    accuracy                           0.94      5644
   macro avg       0.53      0.89      0.62      5644
weighted avg       0.98      0.94      0.95      5644
00:59:01.675089: ----------
00:59:01.675855: LR: 
 [[469 370]
 [  4  17]]
00:59:01.679011: LR: 
               precision    recall  f1-score   support

           0       0.99      0.56      0.71       839
           1       0.04      0.81      0.08        21

    accuracy                           0.57       860
   macro avg       0.52      0.68      0.40       860
weighted avg       0.97      0.57      0.70       860
00:59:01.681126: Validation Seq.Label F1: 0.6159984178282054; Log.Reg F1: 0.39913617886178865; train loss: 0.05217383801937103; Language: japanese 

00:59:01.682721: Combined F1 SeqLab: 0.5472471568284819; train loss: 0.05217383801937103
00:59:01.684360: Combined F1 LogReg: 0.45551699623334463; train loss: 0.05217383801937103 

00:59:01.685044: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 11/40
01:02:03.935156: Evaluating Language: english
01:02:03.935266: ----------
01:02:08.718861: OBI: 
 [[5090   69  430]
 [   5   13    4]
 [  76    5  132]]
01:02:08.724866: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.91      0.95      5589
           1       0.15      0.59      0.24        22
           2       0.23      0.62      0.34       213

    accuracy                           0.90      5824
   macro avg       0.46      0.71      0.51      5824
weighted avg       0.95      0.90      0.92      5824
01:02:08.724912: ----------
01:02:08.725581: LR: 
 [[827 119]
 [ 21   1]]
01:02:08.728275: LR: 
               precision    recall  f1-score   support

           0       0.98      0.87      0.92       946
           1       0.01      0.05      0.01        22

    accuracy                           0.86       968
   macro avg       0.49      0.46      0.47       968
weighted avg       0.95      0.86      0.90       968
01:02:08.730440: Validation Seq.Label F1: 0.5078415949686629; Log.Reg F1: 0.4680233014586964; train loss: 0.04051754251122475; Language: english 

01:02:08.730505: Evaluating Language: finnish
01:02:08.730557: ----------
01:02:16.439705: OBI: 
 [[5147   80  410]
 [   7   15    6]
 [ 178    6  217]]
01:02:16.445453: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.91      0.94      5637
           1       0.15      0.54      0.23        28
           2       0.34      0.54      0.42       401

    accuracy                           0.89      6066
   macro avg       0.49      0.66      0.53      6066
weighted avg       0.92      0.89      0.90      6066
01:02:16.445502: ----------
01:02:16.446388: LR: 
 [[1273  318]
 [  16   12]]
01:02:16.449613: LR: 
               precision    recall  f1-score   support

           0       0.99      0.80      0.88      1591
           1       0.04      0.43      0.07        28

    accuracy                           0.79      1619
   macro avg       0.51      0.61      0.48      1619
weighted avg       0.97      0.79      0.87      1619
01:02:16.451488: Validation Seq.Label F1: 0.5302500958379075; Log.Reg F1: 0.47553344196151454; train loss: 0.04051754251122475; Language: finnish 

01:02:16.451545: Evaluating Language: japanese
01:02:16.451593: ----------
01:02:20.903706: OBI: 
 [[6152   40  322]
 [   2   28    0]
 [  20    1  299]]
01:02:20.909998: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97      6514
           1       0.41      0.93      0.57        30
           2       0.48      0.93      0.64       320

    accuracy                           0.94      6864
   macro avg       0.63      0.94      0.72      6864
weighted avg       0.97      0.94      0.95      6864
01:02:20.910043: ----------
01:02:20.910704: LR: 
 [[505 325]
 [  5  25]]
01:02:20.913397: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.75       830
           1       0.07      0.83      0.13        30

    accuracy                           0.62       860
   macro avg       0.53      0.72      0.44       860
weighted avg       0.96      0.62      0.73       860
01:02:20.915341: Validation Seq.Label F1: 0.7236286345535313; Log.Reg F1: 0.4426551453260016; train loss: 0.04051754251122475; Language: japanese 

01:02:20.916722: Combined F1 SeqLab: 0.5951769066034719; train loss: 0.04051754251122475
01:02:20.918103: Combined F1 LogReg: 0.46228470405715943; train loss: 0.04051754251122475 

01:02:20.918696: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 12/40
01:05:24.092748: Evaluating Language: english
01:05:24.092862: ----------
01:05:28.799070: OBI: 
 [[3402   81  347]
 [   4   11    2]
 [  38    4  143]]
01:05:28.803623: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      3830
           1       0.11      0.65      0.19        17
           2       0.29      0.77      0.42       185

    accuracy                           0.88      4032
   macro avg       0.46      0.77      0.52      4032
weighted avg       0.95      0.88      0.91      4032
01:05:28.803667: ----------
01:05:28.804343: LR: 
 [[620 331]
 [ 12   5]]
01:05:28.807063: LR: 
               precision    recall  f1-score   support

           0       0.98      0.65      0.78       951
           1       0.01      0.29      0.03        17

    accuracy                           0.65       968
   macro avg       0.50      0.47      0.41       968
weighted avg       0.96      0.65      0.77       968
01:05:28.809074: Validation Seq.Label F1: 0.5175095223248373; Log.Reg F1: 0.4058257083495138; train loss: 0.04703814536333084; Language: english 

01:05:28.809131: Evaluating Language: finnish
01:05:28.809174: ----------
01:05:36.749120: OBI: 
 [[5643  114  355]
 [  12   21    1]
 [ 245   12  181]]
01:05:36.755201: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.92      0.94      6112
           1       0.14      0.62      0.23        34
           2       0.34      0.41      0.37       438

    accuracy                           0.89      6584
   macro avg       0.48      0.65      0.51      6584
weighted avg       0.91      0.89      0.90      6584
01:05:36.755245: ----------
01:05:36.756119: LR: 
 [[1094  491]
 [  15   19]]
01:05:36.759375: LR: 
               precision    recall  f1-score   support

           0       0.99      0.69      0.81      1585
           1       0.04      0.56      0.07        34

    accuracy                           0.69      1619
   macro avg       0.51      0.62      0.44      1619
weighted avg       0.97      0.69      0.80      1619
01:05:36.761127: Validation Seq.Label F1: 0.5142955632458395; Log.Reg F1: 0.4410140726669286; train loss: 0.04703814536333084; Language: finnish 

01:05:36.761180: Evaluating Language: japanese
01:05:36.761224: ----------
01:05:41.357621: OBI: 
 [[3007   21  109]
 [   2   14    1]
 [  13    0   97]]
01:05:41.361549: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98      3137
           1       0.40      0.82      0.54        17
           2       0.47      0.88      0.61       110

    accuracy                           0.96      3264
   macro avg       0.62      0.89      0.71      3264
weighted avg       0.97      0.96      0.96      3264
01:05:41.361593: ----------
01:05:41.362232: LR: 
 [[479 364]
 [  4  13]]
01:05:41.364880: LR: 
               precision    recall  f1-score   support

           0       0.99      0.57      0.72       843
           1       0.03      0.76      0.07        17

    accuracy                           0.57       860
   macro avg       0.51      0.67      0.39       860
weighted avg       0.97      0.57      0.71       860
01:05:41.366687: Validation Seq.Label F1: 0.7089687124152345; Log.Reg F1: 0.394231726271141; train loss: 0.04703814536333084; Language: japanese 

01:05:41.368048: Combined F1 SeqLab: 0.5873535753005317; train loss: 0.04703814536333084
01:05:41.369393: Combined F1 LogReg: 0.41416847290540254; train loss: 0.04703814536333084 

01:05:41.369977: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 13/40
01:08:44.301835: Evaluating Language: english
01:08:44.301939: ----------
01:08:49.032106: OBI: 
 [[3471  138  399]
 [   1    3    2]
 [  21    7   94]]
01:08:49.036706: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.87      0.93      4008
           1       0.02      0.50      0.04         6
           2       0.19      0.77      0.30       122

    accuracy                           0.86      4136
   macro avg       0.40      0.71      0.42      4136
weighted avg       0.97      0.86      0.91      4136
01:08:49.036750: ----------
01:08:49.037427: LR: 
 [[615 347]
 [  4   2]]
01:08:49.040141: LR: 
               precision    recall  f1-score   support

           0       0.99      0.64      0.78       962
           1       0.01      0.33      0.01         6

    accuracy                           0.64       968
   macro avg       0.50      0.49      0.39       968
weighted avg       0.99      0.64      0.77       968
01:08:49.042165: Validation Seq.Label F1: 0.4230459347183924; Log.Reg F1: 0.39462811021728084; train loss: 0.07315755635499954; Language: english 

01:08:49.042222: Evaluating Language: finnish
01:08:49.042267: ----------
01:08:57.043239: OBI: 
 [[5014  135  366]
 [   6   20    2]
 [ 135   23  186]]
01:08:57.048911: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.91      0.94      5515
           1       0.11      0.71      0.19        28
           2       0.34      0.54      0.41       344

    accuracy                           0.89      5887
   macro avg       0.47      0.72      0.52      5887
weighted avg       0.93      0.89      0.91      5887
01:08:57.048955: ----------
01:08:57.049840: LR: 
 [[1151  440]
 [   9   19]]
01:08:57.053098: LR: 
               precision    recall  f1-score   support

           0       0.99      0.72      0.84      1591
           1       0.04      0.68      0.08        28

    accuracy                           0.72      1619
   macro avg       0.52      0.70      0.46      1619
weighted avg       0.98      0.72      0.82      1619
01:08:57.054789: Validation Seq.Label F1: 0.5160866525165219; Log.Reg F1: 0.457407685239715; train loss: 0.07315755635499954; Language: finnish 

01:08:57.054845: Evaluating Language: japanese
01:08:57.054892: ----------
01:09:01.664621: OBI: 
 [[4673   77  295]
 [   1   19    0]
 [  18    3  226]]
01:09:01.669886: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96      5045
           1       0.19      0.95      0.32        20
           2       0.43      0.91      0.59       247

    accuracy                           0.93      5312
   macro avg       0.54      0.93      0.62      5312
weighted avg       0.97      0.93      0.94      5312
01:09:01.669930: ----------
01:09:01.670576: LR: 
 [[445 395]
 [  2  18]]
01:09:01.673401: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.69       840
           1       0.04      0.90      0.08        20

    accuracy                           0.54       860
   macro avg       0.52      0.71      0.39       860
weighted avg       0.97      0.54      0.68       860
01:09:01.675244: Validation Seq.Label F1: 0.6225710973941457; Log.Reg F1: 0.38733578456442197; train loss: 0.07315755635499954; Language: japanese 

01:09:01.676599: Combined F1 SeqLab: 0.5269117785417271; train loss: 0.07315755635499954
01:09:01.677924: Combined F1 LogReg: 0.4143195811183089; train loss: 0.07315755635499954 

01:09:01.678525: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 14/40
01:12:10.784502: Evaluating Language: english
01:12:10.784840: ----------
01:12:15.501364: OBI: 
 [[2920  203  685]
 [   1    9    1]
 [  13    7  105]]
01:12:15.505923: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.77      0.87      3808
           1       0.04      0.82      0.08        11
           2       0.13      0.84      0.23       125

    accuracy                           0.77      3944
   macro avg       0.39      0.81      0.39      3944
weighted avg       0.97      0.77      0.84      3944
01:12:15.505969: ----------
01:12:15.506655: LR: 
 [[375 582]
 [  3   8]]
01:12:15.509406: LR: 
               precision    recall  f1-score   support

           0       0.99      0.39      0.56       957
           1       0.01      0.73      0.03        11

    accuracy                           0.40       968
   macro avg       0.50      0.56      0.29       968
weighted avg       0.98      0.40      0.56       968
01:12:15.513494: Validation Seq.Label F1: 0.3912434393573993; Log.Reg F1: 0.29421002449101685; train loss: 0.06176958233118057; Language: english 

01:12:15.513550: Evaluating Language: finnish
01:12:15.513594: ----------
01:12:23.260170: OBI: 
 [[5557  372 1362]
 [   7   32    2]
 [ 129   32  247]]
01:12:23.267318: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.76      0.86      7291
           1       0.07      0.78      0.13        41
           2       0.15      0.61      0.24       408

    accuracy                           0.75      7740
   macro avg       0.40      0.72      0.41      7740
weighted avg       0.93      0.75      0.82      7740
01:12:23.267376: ----------
01:12:23.268277: LR: 
 [[593 985]
 [  4  37]]
01:12:23.271908: LR: 
               precision    recall  f1-score   support

           0       0.99      0.38      0.55      1578
           1       0.04      0.90      0.07        41

    accuracy                           0.39      1619
   macro avg       0.51      0.64      0.31      1619
weighted avg       0.97      0.39      0.53      1619
01:12:23.274565: Validation Seq.Label F1: 0.4116080254320568; Log.Reg F1: 0.30745082773758936; train loss: 0.06176958233118057; Language: finnish 

01:12:23.274625: Evaluating Language: japanese
01:12:23.274669: ----------
01:12:27.948885: OBI: 
 [[4821  120  547]
 [   1   29    2]
 [   7    3  206]]
01:12:27.955567: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.93      5488
           1       0.19      0.91      0.32        32
           2       0.27      0.95      0.42       216

    accuracy                           0.88      5736
   macro avg       0.49      0.91      0.56      5736
weighted avg       0.97      0.88      0.91      5736
01:12:27.955614: ----------
01:12:27.956254: LR: 
 [[369 459]
 [  2  30]]
01:12:27.959257: LR: 
               precision    recall  f1-score   support

           0       0.99      0.45      0.62       828
           1       0.06      0.94      0.12        32

    accuracy                           0.46       860
   macro avg       0.53      0.69      0.37       860
weighted avg       0.96      0.46      0.60       860
01:12:27.961425: Validation Seq.Label F1: 0.5580320785820169; Log.Reg F1: 0.3653380376161196; train loss: 0.06176958233118057; Language: japanese 

01:12:27.963006: Combined F1 SeqLab: 0.4596710404071046; train loss: 0.06176958233118057
01:12:27.964688: Combined F1 LogReg: 0.3238093223471342; train loss: 0.06176958233118057 

01:12:27.965677: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 15/40
01:15:33.816553: Evaluating Language: english
01:15:33.816663: ----------
01:15:38.406062: OBI: 
 [[3210  110  558]
 [   0   11    1]
 [  15    1  126]]
01:15:38.410591: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.90      3878
           1       0.09      0.92      0.16        12
           2       0.18      0.89      0.30       142

    accuracy                           0.83      4032
   macro avg       0.42      0.88      0.46      4032
weighted avg       0.96      0.83      0.88      4032
01:15:38.410639: ----------
01:15:38.411306: LR: 
 [[338 618]
 [  0  12]]
01:15:38.414010: LR: 
               precision    recall  f1-score   support

           0       1.00      0.35      0.52       956
           1       0.02      1.00      0.04        12

    accuracy                           0.36       968
   macro avg       0.51      0.68      0.28       968
weighted avg       0.99      0.36      0.52       968
01:15:38.416153: Validation Seq.Label F1: 0.4575794637652127; Log.Reg F1: 0.2798971529272415; train loss: 0.05175435170531273; Language: english 

01:15:38.416214: Evaluating Language: finnish
01:15:38.416260: ----------
01:15:46.397274: OBI: 
 [[6048  169  738]
 [  10   23    3]
 [ 109   18  225]]
01:15:46.403979: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.87      0.92      6955
           1       0.11      0.64      0.19        36
           2       0.23      0.64      0.34       352

    accuracy                           0.86      7343
   macro avg       0.44      0.72      0.48      7343
weighted avg       0.94      0.86      0.89      7343
01:15:46.404024: ----------
01:15:46.404894: LR: 
 [[ 484 1099]
 [   1   35]]
01:15:46.408124: LR: 
               precision    recall  f1-score   support

           0       1.00      0.31      0.47      1583
           1       0.03      0.97      0.06        36

    accuracy                           0.32      1619
   macro avg       0.51      0.64      0.26      1619
weighted avg       0.98      0.32      0.46      1619
01:15:46.409939: Validation Seq.Label F1: 0.48340965771635275; Log.Reg F1: 0.26395708310601923; train loss: 0.05175435170531273; Language: finnish 

01:15:46.409992: Evaluating Language: japanese
01:15:46.410036: ----------
01:15:50.978158: OBI: 
 [[4377   65  281]
 [   1   24    2]
 [  13    1  128]]
01:15:50.983149: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96      4723
           1       0.27      0.89      0.41        27
           2       0.31      0.90      0.46       142

    accuracy                           0.93      4892
   macro avg       0.52      0.91      0.61      4892
weighted avg       0.97      0.93      0.94      4892
01:15:50.983193: ----------
01:15:50.983841: LR: 
 [[452 381]
 [  3  24]]
01:15:50.986492: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70       833
           1       0.06      0.89      0.11        27

    accuracy                           0.55       860
   macro avg       0.53      0.72      0.41       860
weighted avg       0.96      0.55      0.68       860
01:15:50.988365: Validation Seq.Label F1: 0.6112287383360124; Log.Reg F1: 0.4064872325741892; train loss: 0.05175435170531273; Language: japanese 

01:15:50.989756: Combined F1 SeqLab: 0.5217484813588934; train loss: 0.05175435170531273
01:15:50.991134: Combined F1 LogReg: 0.32313445508252264; train loss: 0.05175435170531273 

01:15:50.991726: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 16/40
01:18:58.049734: Evaluating Language: english
01:18:58.049842: ----------
01:19:02.729333: OBI: 
 [[2893   84  328]
 [   1    9    5]
 [  35    7   86]]
01:19:02.733478: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      3305
           1       0.09      0.60      0.16        15
           2       0.21      0.67      0.31       128

    accuracy                           0.87      3448
   macro avg       0.43      0.72      0.47      3448
weighted avg       0.95      0.87      0.90      3448
01:19:02.733524: ----------
01:19:02.734193: LR: 
 [[519 434]
 [  6   9]]
01:19:02.736948: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70       953
           1       0.02      0.60      0.04        15

    accuracy                           0.55       968
   macro avg       0.50      0.57      0.37       968
weighted avg       0.97      0.55      0.69       968
01:19:02.739071: Validation Seq.Label F1: 0.4663667268418051; Log.Reg F1: 0.37080085799883; train loss: 0.049324601888656616; Language: english 

01:19:02.739131: Evaluating Language: finnish
01:19:02.739176: ----------
01:19:10.431824: OBI: 
 [[3382   70  239]
 [  11   14    1]
 [ 117   14  112]]
01:19:10.436665: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.92      0.94      3691
           1       0.14      0.54      0.23        26
           2       0.32      0.46      0.38       243

    accuracy                           0.89      3960
   macro avg       0.47      0.64      0.51      3960
weighted avg       0.92      0.89      0.90      3960
01:19:10.436712: ----------
01:19:10.437586: LR: 
 [[952 641]
 [ 10  16]]
01:19:10.441147: LR: 
               precision    recall  f1-score   support

           0       0.99      0.60      0.75      1593
           1       0.02      0.62      0.05        26

    accuracy                           0.60      1619
   macro avg       0.51      0.61      0.40      1619
weighted avg       0.97      0.60      0.73      1619
01:19:10.443015: Validation Seq.Label F1: 0.5138636746723543; Log.Reg F1: 0.39602880121943884; train loss: 0.049324601888656616; Language: finnish 

01:19:10.443069: Evaluating Language: japanese
01:19:10.443112: ----------
01:19:14.908913: OBI: 
 [[5641   48  357]
 [   3   21    0]
 [  22    3  185]]
01:19:14.914743: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96      6046
           1       0.29      0.88      0.44        24
           2       0.34      0.88      0.49       210

    accuracy                           0.93      6280
   macro avg       0.54      0.90      0.63      6280
weighted avg       0.97      0.93      0.95      6280
01:19:14.914787: ----------
01:19:14.915437: LR: 
 [[482 354]
 [  4  20]]
01:19:14.918080: LR: 
               precision    recall  f1-score   support

           0       0.99      0.58      0.73       836
           1       0.05      0.83      0.10        24

    accuracy                           0.58       860
   macro avg       0.52      0.70      0.41       860
weighted avg       0.97      0.58      0.71       860
01:19:14.920003: Validation Seq.Label F1: 0.6309355985738092; Log.Reg F1: 0.4148503485658246; train loss: 0.049324601888656616; Language: japanese 

01:19:14.921349: Combined F1 SeqLab: 0.5414897750960169; train loss: 0.049324601888656616
01:19:14.922691: Combined F1 LogReg: 0.3943065217962461; train loss: 0.049324601888656616 

01:19:14.923275: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 17/40
01:22:17.658204: Evaluating Language: english
01:22:17.658298: ----------
01:22:22.421776: OBI: 
 [[2972   49  250]
 [   3    9    2]
 [  54    5  120]]
01:22:22.426328: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.91      0.94      3271
           1       0.14      0.64      0.23        14
           2       0.32      0.67      0.44       179

    accuracy                           0.90      3464
   macro avg       0.48      0.74      0.54      3464
weighted avg       0.94      0.90      0.91      3464
01:22:22.426373: ----------
01:22:22.427162: LR: 
 [[463 491]
 [  4  10]]
01:22:22.430442: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.65       954
           1       0.02      0.71      0.04        14

    accuracy                           0.49       968
   macro avg       0.51      0.60      0.35       968
weighted avg       0.98      0.49      0.64       968
01:22:22.432644: Validation Seq.Label F1: 0.5376099950328626; Log.Reg F1: 0.34524435820528415; train loss: 0.03298856317996979; Language: english 

01:22:22.432699: Evaluating Language: finnish
01:22:22.432745: ----------
01:22:30.096880: OBI: 
 [[7597   94  317]
 [  11   20    4]
 [ 181   13  182]]
01:22:30.104268: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96      8008
           1       0.16      0.57      0.25        35
           2       0.36      0.48      0.41       376

    accuracy                           0.93      8419
   macro avg       0.50      0.67      0.54      8419
weighted avg       0.94      0.93      0.93      8419
01:22:30.104315: ----------
01:22:30.105178: LR: 
 [[1360  224]
 [  24   11]]
01:22:30.108390: LR: 
               precision    recall  f1-score   support

           0       0.98      0.86      0.92      1584
           1       0.05      0.31      0.08        35

    accuracy                           0.85      1619
   macro avg       0.51      0.59      0.50      1619
weighted avg       0.96      0.85      0.90      1619
01:22:30.110305: Validation Seq.Label F1: 0.5409495717260216; Log.Reg F1: 0.4989617649995008; train loss: 0.03298856317996979; Language: finnish 

01:22:30.110365: Evaluating Language: japanese
01:22:30.110409: ----------
01:22:34.756474: OBI: 
 [[5566   36  203]
 [   2   23    2]
 [  36    1  147]]
01:22:34.762661: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      5805
           1       0.38      0.85      0.53        27
           2       0.42      0.80      0.55       184

    accuracy                           0.95      6016
   macro avg       0.60      0.87      0.68      6016
weighted avg       0.97      0.95      0.96      6016
01:22:34.762711: ----------
01:22:34.763485: LR: 
 [[473 360]
 [  2  25]]
01:22:34.766132: LR: 
               precision    recall  f1-score   support

           0       1.00      0.57      0.72       833
           1       0.06      0.93      0.12        27

    accuracy                           0.58       860
   macro avg       0.53      0.75      0.42       860
weighted avg       0.97      0.58      0.70       860
01:22:34.768052: Validation Seq.Label F1: 0.6843213389831785; Log.Reg F1: 0.422300406757519; train loss: 0.03298856317996979; Language: japanese 

01:22:34.769404: Combined F1 SeqLab: 0.591592945894819; train loss: 0.03298856317996979
01:22:34.770739: Combined F1 LogReg: 0.42680758480903375; train loss: 0.03298856317996979 

01:22:34.771333: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 18/40
01:25:36.930959: Evaluating Language: english
01:25:36.931075: ----------
01:25:41.569874: OBI: 
 [[3006   41  111]
 [   1    6    0]
 [  21    3   67]]
01:25:41.573853: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      3158
           1       0.12      0.86      0.21         7
           2       0.38      0.74      0.50        91

    accuracy                           0.95      3256
   macro avg       0.50      0.85      0.56      3256
weighted avg       0.97      0.95      0.96      3256
01:25:41.573925: ----------
01:25:41.574617: LR: 
 [[701 260]
 [  2   5]]
01:25:41.577345: LR: 
               precision    recall  f1-score   support

           0       1.00      0.73      0.84       961
           1       0.02      0.71      0.04         7

    accuracy                           0.73       968
   macro avg       0.51      0.72      0.44       968
weighted avg       0.99      0.73      0.84       968
01:25:41.579458: Validation Seq.Label F1: 0.5601798495640556; Log.Reg F1: 0.43965639140271495; train loss: 0.023049630224704742; Language: english 

01:25:41.579514: Evaluating Language: finnish
01:25:41.579560: ----------
01:25:49.318253: OBI: 
 [[4164   54  131]
 [  10   15    2]
 [ 199   13  158]]
01:25:49.323116: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.96      0.95      4349
           1       0.18      0.56      0.28        27
           2       0.54      0.43      0.48       370

    accuracy                           0.91      4746
   macro avg       0.56      0.65      0.57      4746
weighted avg       0.92      0.91      0.91      4746
01:25:49.323157: ----------
01:25:49.324034: LR: 
 [[1057  535]
 [   9   18]]
01:25:49.327277: LR: 
               precision    recall  f1-score   support

           0       0.99      0.66      0.80      1592
           1       0.03      0.67      0.06        27

    accuracy                           0.66      1619
   macro avg       0.51      0.67      0.43      1619
weighted avg       0.98      0.66      0.78      1619
01:25:49.329030: Validation Seq.Label F1: 0.5693732574863298; Log.Reg F1: 0.4287019018707351; train loss: 0.023049630224704742; Language: finnish 

01:25:49.329085: Evaluating Language: japanese
01:25:49.329128: ----------
01:25:53.843184: OBI: 
 [[5516   24  146]
 [   0   25    2]
 [  32    2  185]]
01:25:53.848747: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.97      0.98      5686
           1       0.49      0.93      0.64        27
           2       0.56      0.84      0.67       219

    accuracy                           0.97      5932
   macro avg       0.68      0.91      0.76      5932
weighted avg       0.98      0.97      0.97      5932
01:25:53.848792: ----------
01:25:53.849435: LR: 
 [[458 375]
 [  1  26]]
01:25:53.852085: LR: 
               precision    recall  f1-score   support

           0       1.00      0.55      0.71       833
           1       0.06      0.96      0.12        27

    accuracy                           0.56       860
   macro avg       0.53      0.76      0.42       860
weighted avg       0.97      0.56      0.69       860
01:25:53.854024: Validation Seq.Label F1: 0.7644447891272361; Log.Reg F1: 0.41523682763808917; train loss: 0.023049630224704742; Language: japanese 

01:25:53.855403: Combined F1 SeqLab: 0.6383215505845485; train loss: 0.023049630224704742
01:25:55.128441: Combined F1 LogReg: 0.4279815752248325; train loss: 0.023049630224704742 

01:25:55.129325: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 19/40
01:28:58.591498: Evaluating Language: english
01:28:58.591645: ----------
01:29:03.180277: OBI: 
 [[4069   66  307]
 [   3    9    3]
 [  43    4   96]]
01:29:03.185188: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95      4442
           1       0.11      0.60      0.19        15
           2       0.24      0.67      0.35       143

    accuracy                           0.91      4600
   macro avg       0.45      0.73      0.50      4600
weighted avg       0.96      0.91      0.93      4600
01:29:03.185232: ----------
01:29:03.185920: LR: 
 [[682 271]
 [  8   7]]
01:29:03.188645: LR: 
               precision    recall  f1-score   support

           0       0.99      0.72      0.83       953
           1       0.03      0.47      0.05        15

    accuracy                           0.71       968
   macro avg       0.51      0.59      0.44       968
weighted avg       0.97      0.71      0.82       968
01:29:03.191053: Validation Seq.Label F1: 0.49741679287690505; Log.Reg F1: 0.4389851246055766; train loss: 0.022154349833726883; Language: english 

01:29:03.191114: Evaluating Language: finnish
01:29:03.191159: ----------
01:29:11.139147: OBI: 
 [[4323   69  241]
 [   7   17    2]
 [ 158   12  163]]
01:29:11.144244: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.93      0.95      4633
           1       0.17      0.65      0.27        26
           2       0.40      0.49      0.44       333

    accuracy                           0.90      4992
   macro avg       0.51      0.69      0.55      4992
weighted avg       0.92      0.90      0.91      4992
01:29:11.144287: ----------
01:29:11.145171: LR: 
 [[838 755]
 [  6  20]]
01:29:11.148479: LR: 
               precision    recall  f1-score   support

           0       0.99      0.53      0.69      1593
           1       0.03      0.77      0.05        26

    accuracy                           0.53      1619
   macro avg       0.51      0.65      0.37      1619
weighted avg       0.98      0.53      0.68      1619
01:29:11.150287: Validation Seq.Label F1: 0.5544175321655724; Log.Reg F1: 0.36883419730261263; train loss: 0.022154349833726883; Language: finnish 

01:29:11.150346: Evaluating Language: japanese
01:29:11.150389: ----------
01:29:15.717563: OBI: 
 [[2779   20  111]
 [   3   15    1]
 [   6    0  109]]
01:29:15.721365: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.95      0.98      2910
           1       0.43      0.79      0.56        19
           2       0.49      0.95      0.65       115

    accuracy                           0.95      3044
   macro avg       0.64      0.90      0.73      3044
weighted avg       0.97      0.95      0.96      3044
01:29:15.721410: ----------
01:29:15.722038: LR: 
 [[456 385]
 [  1  18]]
01:29:15.724693: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70       841
           1       0.04      0.95      0.09        19

    accuracy                           0.55       860
   macro avg       0.52      0.74      0.39       860
weighted avg       0.98      0.55      0.69       860
01:29:15.726571: Validation Seq.Label F1: 0.7265983515983517; Log.Reg F1: 0.39396373567792964; train loss: 0.022154349833726883; Language: japanese 

01:29:15.727962: Combined F1 SeqLab: 0.6007626903511767; train loss: 0.022154349833726883
01:29:15.729370: Combined F1 LogReg: 0.4016441334291447; train loss: 0.022154349833726883 

01:29:15.729958: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 20/40
01:32:22.565961: Evaluating Language: english
01:32:22.566101: ----------
01:32:27.196931: OBI: 
 [[3901   90  274]
 [   4   13    3]
 [  31    6  102]]
01:32:27.201822: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      4265
           1       0.12      0.65      0.20        20
           2       0.27      0.73      0.39       139

    accuracy                           0.91      4424
   macro avg       0.46      0.77      0.52      4424
weighted avg       0.96      0.91      0.93      4424
01:32:27.201867: ----------
01:32:27.202540: LR: 
 [[676 272]
 [ 12   8]]
01:32:27.205243: LR: 
               precision    recall  f1-score   support

           0       0.98      0.71      0.83       948
           1       0.03      0.40      0.05        20

    accuracy                           0.71       968
   macro avg       0.51      0.56      0.44       968
weighted avg       0.96      0.71      0.81       968
01:32:27.208611: Validation Seq.Label F1: 0.5155733926927457; Log.Reg F1: 0.43986960065199676; train loss: 0.020824730396270752; Language: english 

01:32:27.208683: Evaluating Language: finnish
01:32:27.208734: ----------
01:32:35.166371: OBI: 
 [[8225  128  426]
 [  20   22    2]
 [ 252   20  194]]
01:32:35.175865: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.94      0.95      8779
           1       0.13      0.50      0.21        44
           2       0.31      0.42      0.36       466

    accuracy                           0.91      9289
   macro avg       0.47      0.62      0.50      9289
weighted avg       0.93      0.91      0.92      9289
01:32:35.175916: ----------
01:32:35.176967: LR: 
 [[1031  544]
 [  23   21]]
01:32:35.180867: LR: 
               precision    recall  f1-score   support

           0       0.98      0.65      0.78      1575
           1       0.04      0.48      0.07        44

    accuracy                           0.65      1619
   macro avg       0.51      0.57      0.43      1619
weighted avg       0.95      0.65      0.76      1619
01:32:35.183218: Validation Seq.Label F1: 0.5048043767257733; Log.Reg F1: 0.4266470796553036; train loss: 0.020824730396270752; Language: finnish 

01:32:35.183293: Evaluating Language: japanese
01:32:35.183359: ----------
01:32:39.833167: OBI: 
 [[2822   12   72]
 [   0   17    1]
 [  23    1   92]]
01:32:39.836975: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.97      0.98      2906
           1       0.57      0.94      0.71        18
           2       0.56      0.79      0.65       116

    accuracy                           0.96      3040
   macro avg       0.71      0.90      0.78      3040
weighted avg       0.97      0.96      0.97      3040
01:32:39.837018: ----------
01:32:39.837659: LR: 
 [[488 354]
 [  0  18]]
01:32:39.840295: LR: 
               precision    recall  f1-score   support

           0       1.00      0.58      0.73       842
           1       0.05      1.00      0.09        18

    accuracy                           0.59       860
   macro avg       0.52      0.79      0.41       860
weighted avg       0.98      0.59      0.72       860
01:32:39.842423: Validation Seq.Label F1: 0.7815107146253176; Log.Reg F1: 0.41307113938692885; train loss: 0.020824730396270752; Language: japanese 

01:32:39.843809: Combined F1 SeqLab: 0.6141124704504812; train loss: 0.020824730396270752
01:32:39.845242: Combined F1 LogReg: 0.4266695686166528; train loss: 0.020824730396270752 

01:32:39.845881: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 21/40
01:35:44.442038: Evaluating Language: english
01:35:44.442170: ----------
01:35:49.229380: OBI: 
 [[2520   73  204]
 [   4    8    4]
 [  74   12   85]]
01:35:49.233227: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.90      0.93      2797
           1       0.09      0.50      0.15        16
           2       0.29      0.50      0.37       171

    accuracy                           0.88      2984
   macro avg       0.45      0.63      0.48      2984
weighted avg       0.93      0.88      0.90      2984
01:35:49.233270: ----------
01:35:49.233963: LR: 
 [[620 332]
 [ 12   4]]
01:35:49.236686: LR: 
               precision    recall  f1-score   support

           0       0.98      0.65      0.78       952
           1       0.01      0.25      0.02        16

    accuracy                           0.64       968
   macro avg       0.50      0.45      0.40       968
weighted avg       0.96      0.64      0.77       968
01:35:49.238831: Validation Seq.Label F1: 0.48245554431973625; Log.Reg F1: 0.4027777777777778; train loss: 0.022139810025691986; Language: english 

01:35:49.238887: Evaluating Language: finnish
01:35:49.238930: ----------
01:35:56.812164: OBI: 
 [[8274  161  329]
 [  12   23    0]
 [ 218   16  147]]
01:35:56.820127: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.94      0.96      8764
           1       0.12      0.66      0.20        35
           2       0.31      0.39      0.34       381

    accuracy                           0.92      9180
   macro avg       0.47      0.66      0.50      9180
weighted avg       0.94      0.92      0.93      9180
01:35:56.820170: ----------
01:35:56.821054: LR: 
 [[986 598]
 [ 10  25]]
01:35:56.824302: LR: 
               precision    recall  f1-score   support

           0       0.99      0.62      0.76      1584
           1       0.04      0.71      0.08        35

    accuracy                           0.62      1619
   macro avg       0.52      0.67      0.42      1619
weighted avg       0.97      0.62      0.75      1619
01:35:56.826165: Validation Seq.Label F1: 0.49903541169580073; Log.Reg F1: 0.4201644636083033; train loss: 0.022139810025691986; Language: finnish 

01:35:56.826219: Evaluating Language: japanese
01:35:56.826263: ----------
01:36:01.414043: OBI: 
 [[4356   33  168]
 [   1   18    2]
 [  13    1  116]]
01:36:01.419754: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98      4557
           1       0.35      0.86      0.49        21
           2       0.41      0.89      0.56       130

    accuracy                           0.95      4708
   macro avg       0.58      0.90      0.68      4708
weighted avg       0.98      0.95      0.96      4708
01:36:01.419804: ----------
01:36:01.420565: LR: 
 [[514 325]
 [  2  19]]
01:36:01.423450: LR: 
               precision    recall  f1-score   support

           0       1.00      0.61      0.76       839
           1       0.06      0.90      0.10        21

    accuracy                           0.62       860
   macro avg       0.53      0.76      0.43       860
weighted avg       0.97      0.62      0.74       860
01:36:01.425700: Validation Seq.Label F1: 0.6755862512659271; Log.Reg F1: 0.43139058787848156; train loss: 0.022139810025691986; Language: japanese 

01:36:01.427355: Combined F1 SeqLab: 0.5592305658285613; train loss: 0.022139810025691986
01:36:01.428881: Combined F1 LogReg: 0.41827660467725586; train loss: 0.022139810025691986 

01:36:01.429570: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 22/40
01:39:05.361928: Evaluating Language: english
01:39:05.362042: ----------
01:39:10.211243: OBI: 
 [[3889   60  264]
 [   6    8    2]
 [  51    7   89]]
01:39:10.215926: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95      4213
           1       0.11      0.50      0.18        16
           2       0.25      0.61      0.35       147

    accuracy                           0.91      4376
   macro avg       0.45      0.68      0.49      4376
weighted avg       0.96      0.91      0.93      4376
01:39:10.215968: ----------
01:39:10.216645: LR: 
 [[584 368]
 [  6  10]]
01:39:10.219376: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.76       952
           1       0.03      0.62      0.05        16

    accuracy                           0.61       968
   macro avg       0.51      0.62      0.40       968
weighted avg       0.97      0.61      0.75       968
01:39:10.221574: Validation Seq.Label F1: 0.49456965000038444; Log.Reg F1: 0.40410963413590373; train loss: 0.024044260382652283; Language: english 

01:39:10.221632: Evaluating Language: finnish
01:39:10.221676: ----------
01:39:17.919676: OBI: 
 [[4430   61  274]
 [   9   16    2]
 [ 114    9  170]]
01:39:17.924842: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.93      0.95      4765
           1       0.19      0.59      0.28        27
           2       0.38      0.58      0.46       293

    accuracy                           0.91      5085
   macro avg       0.51      0.70      0.56      5085
weighted avg       0.93      0.91      0.92      5085
01:39:17.924885: ----------
01:39:17.925763: LR: 
 [[ 543 1049]
 [   3   24]]
01:39:17.929043: LR: 
               precision    recall  f1-score   support

           0       0.99      0.34      0.51      1592
           1       0.02      0.89      0.04        27

    accuracy                           0.35      1619
   macro avg       0.51      0.61      0.28      1619
weighted avg       0.98      0.35      0.50      1619
01:39:17.931134: Validation Seq.Label F1: 0.5647049509757489; Log.Reg F1: 0.2757938600221107; train loss: 0.024044260382652283; Language: finnish 

01:39:17.931188: Evaluating Language: japanese
01:39:17.931232: ----------
01:39:22.459723: OBI: 
 [[3582   18  141]
 [   4   11    1]
 [  18    0   65]]
01:39:22.463989: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      3741
           1       0.38      0.69      0.49        16
           2       0.31      0.78      0.45        83

    accuracy                           0.95      3840
   macro avg       0.56      0.81      0.64      3840
weighted avg       0.98      0.95      0.96      3840
01:39:22.464031: ----------
01:39:22.464667: LR: 
 [[497 347]
 [  1  15]]
01:39:22.467279: LR: 
               precision    recall  f1-score   support

           0       1.00      0.59      0.74       844
           1       0.04      0.94      0.08        16

    accuracy                           0.60       860
   macro avg       0.52      0.76      0.41       860
weighted avg       0.98      0.60      0.73       860
01:39:22.469166: Validation Seq.Label F1: 0.6375073789782365; Log.Reg F1: 0.410025311664656; train loss: 0.024044260382652283; Language: japanese 

01:39:22.470545: Combined F1 SeqLab: 0.5685966580420391; train loss: 0.024044260382652283
01:39:22.471900: Combined F1 LogReg: 0.3685501349129441; train loss: 0.024044260382652283 

01:39:22.472499: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 23/40
01:42:25.995035: Evaluating Language: english
01:42:25.995138: ----------
01:42:30.576262: OBI: 
 [[4125   37  215]
 [   3    6    3]
 [  50    2   71]]
01:42:30.581828: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      4377
           1       0.13      0.50      0.21        12
           2       0.25      0.58      0.34       123

    accuracy                           0.93      4512
   macro avg       0.46      0.67      0.51      4512
weighted avg       0.96      0.93      0.95      4512
01:42:30.581877: ----------
01:42:30.582609: LR: 
 [[665 291]
 [  7   5]]
01:42:30.585339: LR: 
               precision    recall  f1-score   support

           0       0.99      0.70      0.82       956
           1       0.02      0.42      0.03        12

    accuracy                           0.69       968
   macro avg       0.50      0.56      0.42       968
weighted avg       0.98      0.69      0.81       968
01:42:30.588206: Validation Seq.Label F1: 0.5065116147572178; Log.Reg F1: 0.4247104247104247; train loss: 0.018164148554205894; Language: english 

01:42:30.588264: Evaluating Language: finnish
01:42:30.588312: ----------
01:42:38.246570: OBI: 
 [[5142   58  204]
 [   9   21    1]
 [ 143    4  116]]
01:42:38.252137: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.95      0.96      5404
           1       0.25      0.68      0.37        31
           2       0.36      0.44      0.40       263

    accuracy                           0.93      5698
   macro avg       0.53      0.69      0.58      5698
weighted avg       0.94      0.93      0.93      5698
01:42:38.252186: ----------
01:42:38.253118: LR: 
 [[644 944]
 [  3  28]]
01:42:38.256434: LR: 
               precision    recall  f1-score   support

           0       1.00      0.41      0.58      1588
           1       0.03      0.90      0.06        31

    accuracy                           0.42      1619
   macro avg       0.51      0.65      0.32      1619
weighted avg       0.98      0.42      0.57      1619
01:42:38.259781: Validation Seq.Label F1: 0.575660834798141; Log.Reg F1: 0.316059427980042; train loss: 0.018164148554205894; Language: finnish 

01:42:38.259840: Evaluating Language: japanese
01:42:38.259886: ----------
01:42:42.819458: OBI: 
 [[4681   15  209]
 [   2   26    2]
 [  29    0  216]]
01:42:42.824648: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      4905
           1       0.63      0.87      0.73        30
           2       0.51      0.88      0.64       245

    accuracy                           0.95      5180
   macro avg       0.71      0.90      0.78      5180
weighted avg       0.97      0.95      0.96      5180
01:42:42.824695: ----------
01:42:42.825375: LR: 
 [[494 336]
 [  3  27]]
01:42:42.828008: LR: 
               precision    recall  f1-score   support

           0       0.99      0.60      0.74       830
           1       0.07      0.90      0.14        30

    accuracy                           0.61       860
   macro avg       0.53      0.75      0.44       860
weighted avg       0.96      0.61      0.72       860
01:42:42.830715: Validation Seq.Label F1: 0.7829119878886504; Log.Reg F1: 0.44097056437927484; train loss: 0.018164148554205894; Language: japanese 

01:42:42.832577: Combined F1 SeqLab: 0.6326901804686121; train loss: 0.018164148554205894
01:42:42.834367: Combined F1 LogReg: 0.3977970778850933; train loss: 0.018164148554205894 

01:42:42.835385: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 24/40
01:45:45.603900: Evaluating Language: english
01:45:45.604033: ----------
01:45:50.239448: OBI: 
 [[2689   42  195]
 [   5    6    3]
 [  53    8   79]]
01:45:50.243445: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.92      0.95      2926
           1       0.11      0.43      0.17        14
           2       0.29      0.56      0.38       140

    accuracy                           0.90      3080
   macro avg       0.46      0.64      0.50      3080
weighted avg       0.94      0.90      0.92      3080
01:45:50.246754: ----------
01:45:50.247458: LR: 
 [[756 198]
 [ 14   0]]
01:45:50.250179: LR: 
               precision    recall  f1-score   support

           0       0.98      0.79      0.88       954
           1       0.00      0.00      0.00        14

    accuracy                           0.78       968
   macro avg       0.49      0.40      0.44       968
weighted avg       0.97      0.78      0.86       968
01:45:50.252447: Validation Seq.Label F1: 0.4994415829427566; Log.Reg F1: 0.43851508120649657; train loss: 0.022755490615963936; Language: english 

01:45:50.252503: Evaluating Language: finnish
01:45:50.252549: ----------
01:45:57.945425: OBI: 
 [[3755   46  183]
 [   5   15    1]
 [ 156   16  109]]
01:45:57.950059: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.94      0.95      3984
           1       0.19      0.71      0.31        21
           2       0.37      0.39      0.38       281

    accuracy                           0.91      4286
   macro avg       0.51      0.68      0.55      4286
weighted avg       0.92      0.91      0.91      4286
01:45:57.950101: ----------
01:45:57.951097: LR: 
 [[842 756]
 [  4  17]]
01:45:57.954704: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.69      1598
           1       0.02      0.81      0.04        21

    accuracy                           0.53      1619
   macro avg       0.51      0.67      0.37      1619
weighted avg       0.98      0.53      0.68      1619
01:45:57.956716: Validation Seq.Label F1: 0.545515433712849; Log.Reg F1: 0.36592776428780505; train loss: 0.022755490615963936; Language: finnish 

01:45:57.956769: Evaluating Language: japanese
01:45:57.956813: ----------
01:46:02.634012: OBI: 
 [[6188   34  213]
 [   1   30    1]
 [  12    2  251]]
01:46:02.640031: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98      6435
           1       0.45      0.94      0.61        32
           2       0.54      0.95      0.69       265

    accuracy                           0.96      6732
   macro avg       0.66      0.95      0.76      6732
weighted avg       0.98      0.96      0.97      6732
01:46:02.640074: ----------
01:46:02.640718: LR: 
 [[472 356]
 [  1  31]]
01:46:02.643356: LR: 
               precision    recall  f1-score   support

           0       1.00      0.57      0.73       828
           1       0.08      0.97      0.15        32

    accuracy                           0.58       860
   macro avg       0.54      0.77      0.44       860
weighted avg       0.96      0.58      0.70       860
01:46:02.645398: Validation Seq.Label F1: 0.7597799997162177; Log.Reg F1: 0.4367835280003081; train loss: 0.022755490615963936; Language: japanese 

01:46:02.646800: Combined F1 SeqLab: 0.6121804285121776; train loss: 0.022755490615963936
01:46:02.648188: Combined F1 LogReg: 0.415121851771504; train loss: 0.022755490615963936 

01:46:02.648794: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 25/40
01:49:06.078688: Evaluating Language: english
01:49:06.078800: ----------
01:49:10.745479: OBI: 
 [[4306   50  545]
 [   3    5    7]
 [  53    5  146]]
01:49:10.750662: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      4901
           1       0.08      0.33      0.13        15
           2       0.21      0.72      0.32       204

    accuracy                           0.87      5120
   macro avg       0.43      0.64      0.46      5120
weighted avg       0.95      0.87      0.90      5120
01:49:10.750706: ----------
01:49:10.751381: LR: 
 [[820 133]
 [ 12   3]]
01:49:10.754102: LR: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92       953
           1       0.02      0.20      0.04        15

    accuracy                           0.85       968
   macro avg       0.50      0.53      0.48       968
weighted avg       0.97      0.85      0.91       968
01:49:10.756316: Validation Seq.Label F1: 0.46225959390898314; Log.Reg F1: 0.4792513031702747; train loss: 0.028122205287218094; Language: english 

01:49:10.756386: Evaluating Language: finnish
01:49:10.756430: ----------
01:49:18.592765: OBI: 
 [[5273   94  673]
 [   6   15    7]
 [  70    7  206]]
01:49:18.598732: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.87      0.93      6040
           1       0.13      0.54      0.21        28
           2       0.23      0.73      0.35       283

    accuracy                           0.87      6351
   macro avg       0.45      0.71      0.50      6351
weighted avg       0.95      0.87      0.90      6351
01:49:18.598775: ----------
01:49:18.599651: LR: 
 [[941 650]
 [ 11  17]]
01:49:18.602926: LR: 
               precision    recall  f1-score   support

           0       0.99      0.59      0.74      1591
           1       0.03      0.61      0.05        28

    accuracy                           0.59      1619
   macro avg       0.51      0.60      0.39      1619
weighted avg       0.97      0.59      0.73      1619
01:49:18.604853: Validation Seq.Label F1: 0.4955841748177483; Log.Reg F1: 0.3944958229248296; train loss: 0.028122205287218094; Language: finnish 

01:49:18.604903: Evaluating Language: japanese
01:49:18.604948: ----------
01:49:23.139913: OBI: 
 [[4282   15  206]
 [   1   18    0]
 [  26    1  123]]
01:49:23.144742: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      4503
           1       0.53      0.95      0.68        19
           2       0.37      0.82      0.51       150

    accuracy                           0.95      4672
   macro avg       0.63      0.91      0.72      4672
weighted avg       0.97      0.95      0.96      4672
01:49:23.144784: ----------
01:49:23.145432: LR: 
 [[526 315]
 [  1  18]]
01:49:23.148092: LR: 
               precision    recall  f1-score   support

           0       1.00      0.63      0.77       841
           1       0.05      0.95      0.10        19

    accuracy                           0.63       860
   macro avg       0.53      0.79      0.44       860
weighted avg       0.98      0.63      0.75       860
01:49:23.150113: Validation Seq.Label F1: 0.7215572598752638; Log.Reg F1: 0.43563928761297177; train loss: 0.028122205287218094; Language: japanese 

01:49:23.151543: Combined F1 SeqLab: 0.5715279187608673; train loss: 0.028122205287218094
01:49:23.152964: Combined F1 LogReg: 0.4378319140216112; train loss: 0.028122205287218094 

01:49:23.153567: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 26/40
01:52:28.587350: Evaluating Language: english
01:52:28.587471: ----------
01:52:33.191887: OBI: 
 [[2914   58  466]
 [   3    9    4]
 [  25    5  100]]
01:52:33.196094: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.85      0.91      3438
           1       0.12      0.56      0.20        16
           2       0.18      0.77      0.29       130

    accuracy                           0.84      3584
   macro avg       0.43      0.73      0.47      3584
weighted avg       0.96      0.84      0.89      3584
01:52:33.196138: ----------
01:52:33.196816: LR: 
 [[469 483]
 [  3  13]]
01:52:33.199548: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.66       952
           1       0.03      0.81      0.05        16

    accuracy                           0.50       968
   macro avg       0.51      0.65      0.35       968
weighted avg       0.98      0.50      0.65       968
01:52:33.201703: Validation Seq.Label F1: 0.4679131213613972; Log.Reg F1: 0.35474455758426965; train loss: 0.03054375946521759; Language: english 

01:52:33.201763: Evaluating Language: finnish
01:52:33.201813: ----------
01:52:41.051947: OBI: 
 [[4585  108  461]
 [  10   10    1]
 [  99   14  149]]
01:52:41.057370: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.89      0.93      5154
           1       0.08      0.48      0.13        21
           2       0.24      0.57      0.34       262

    accuracy                           0.87      5437
   macro avg       0.43      0.64      0.47      5437
weighted avg       0.94      0.87      0.90      5437
01:52:41.057414: ----------
01:52:41.058284: LR: 
 [[776 822]
 [  6  15]]
01:52:41.061553: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.65      1598
           1       0.02      0.71      0.03        21

    accuracy                           0.49      1619
   macro avg       0.51      0.60      0.34      1619
weighted avg       0.98      0.49      0.64      1619
01:52:41.063376: Validation Seq.Label F1: 0.4677413829666948; Log.Reg F1: 0.34353293765058474; train loss: 0.03054375946521759; Language: finnish 

01:52:41.063430: Evaluating Language: japanese
01:52:41.063474: ----------
01:52:46.040255: OBI: 
 [[2779   31  151]
 [   0   13    1]
 [  17    0  112]]
01:52:46.044515: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.97      2961
           1       0.30      0.93      0.45        14
           2       0.42      0.87      0.57       129

    accuracy                           0.94      3104
   macro avg       0.57      0.91      0.66      3104
weighted avg       0.97      0.94      0.95      3104
01:52:46.044561: ----------
01:52:46.045213: LR: 
 [[509 337]
 [  2  12]]
01:52:46.047862: LR: 
               precision    recall  f1-score   support

           0       1.00      0.60      0.75       846
           1       0.03      0.86      0.07        14

    accuracy                           0.61       860
   macro avg       0.52      0.73      0.41       860
weighted avg       0.98      0.61      0.74       860
01:52:46.051070: Validation Seq.Label F1: 0.6612279340733841; Log.Reg F1: 0.40814996619913885; train loss: 0.03054375946521759; Language: japanese 

01:52:46.052726: Combined F1 SeqLab: 0.5400453904629121; train loss: 0.03054375946521759
01:52:46.054274: Combined F1 LogReg: 0.3698851061680541; train loss: 0.03054375946521759 

01:52:46.055313: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 27/40
01:55:49.471106: Evaluating Language: english
01:55:49.471254: ----------
01:55:54.196625: OBI: 
 [[2644   65  216]
 [   1    3    0]
 [  38    3   78]]
01:55:54.200548: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      2925
           1       0.04      0.75      0.08         4
           2       0.27      0.66      0.38       119

    accuracy                           0.89      3048
   macro avg       0.43      0.77      0.47      3048
weighted avg       0.96      0.89      0.92      3048
01:55:54.200591: ----------
01:55:54.201278: LR: 
 [[513 451]
 [  1   3]]
01:55:54.203990: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.69       964
           1       0.01      0.75      0.01         4

    accuracy                           0.53       968
   macro avg       0.50      0.64      0.35       968
weighted avg       0.99      0.53      0.69       968
01:55:54.206248: Validation Seq.Label F1: 0.466887543334266; Log.Reg F1: 0.3536408813987981; train loss: 0.026842404156923294; Language: english 

01:55:54.206325: Evaluating Language: finnish
01:55:54.206372: ----------
01:56:01.835931: OBI: 
 [[5843   98  322]
 [  11   18    3]
 [ 154   19  151]]
01:56:01.842003: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.93      0.95      6263
           1       0.13      0.56      0.22        32
           2       0.32      0.47      0.38       324

    accuracy                           0.91      6619
   macro avg       0.47      0.65      0.52      6619
weighted avg       0.94      0.91      0.92      6619
01:56:01.842047: ----------
01:56:01.842923: LR: 
 [[730 857]
 [  6  26]]
01:56:01.846179: LR: 
               precision    recall  f1-score   support

           0       0.99      0.46      0.63      1587
           1       0.03      0.81      0.06        32

    accuracy                           0.47      1619
   macro avg       0.51      0.64      0.34      1619
weighted avg       0.97      0.47      0.62      1619
01:56:01.848146: Validation Seq.Label F1: 0.515131828674165; Log.Reg F1: 0.34266411673241454; train loss: 0.026842404156923294; Language: finnish 

01:56:01.848199: Evaluating Language: japanese
01:56:01.848244: ----------
01:56:06.475171: OBI: 
 [[3251   25   94]
 [   1   20    1]
 [  20    0  116]]
01:56:06.479283: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      3370
           1       0.44      0.91      0.60        22
           2       0.55      0.85      0.67       136

    accuracy                           0.96      3528
   macro avg       0.66      0.91      0.75      3528
weighted avg       0.97      0.96      0.96      3528
01:56:06.479335: ----------
01:56:06.479973: LR: 
 [[547 291]
 [  3  19]]
01:56:06.482616: LR: 
               precision    recall  f1-score   support

           0       0.99      0.65      0.79       838
           1       0.06      0.86      0.11        22

    accuracy                           0.66       860
   macro avg       0.53      0.76      0.45       860
weighted avg       0.97      0.66      0.77       860
01:56:06.484428: Validation Seq.Label F1: 0.7481749443563578; Log.Reg F1: 0.4513211346828235; train loss: 0.026842404156923294; Language: japanese 

01:56:06.485826: Combined F1 SeqLab: 0.589663894772984; train loss: 0.026842404156923294
01:56:06.487658: Combined F1 LogReg: 0.38564722070130186; train loss: 0.026842404156923294 

01:56:06.488241: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 28/40
01:59:08.946570: Evaluating Language: english
01:59:08.946676: ----------
01:59:13.606806: OBI: 
 [[3890   66  213]
 [   5    9    1]
 [  84    6   78]]
01:59:13.611490: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      4169
           1       0.11      0.60      0.19        15
           2       0.27      0.46      0.34       168

    accuracy                           0.91      4352
   macro avg       0.45      0.67      0.49      4352
weighted avg       0.95      0.91      0.93      4352
01:59:13.611532: ----------
01:59:13.612205: LR: 
 [[428 525]
 [  5  10]]
01:59:13.614959: LR: 
               precision    recall  f1-score   support

           0       0.99      0.45      0.62       953
           1       0.02      0.67      0.04        15

    accuracy                           0.45       968
   macro avg       0.50      0.56      0.33       968
weighted avg       0.97      0.45      0.61       968
01:59:13.617194: Validation Seq.Label F1: 0.49382199241567243; Log.Reg F1: 0.326984126984127; train loss: 0.03671650588512421; Language: english 

01:59:13.617249: Evaluating Language: finnish
01:59:13.617292: ----------
01:59:21.421677: OBI: 
 [[4622   54  183]
 [   8   16    1]
 [  95   10   99]]
01:59:21.426888: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96      4859
           1       0.20      0.64      0.30        25
           2       0.35      0.49      0.41       204

    accuracy                           0.93      5088
   macro avg       0.51      0.69      0.56      5088
weighted avg       0.95      0.93      0.94      5088
01:59:21.426932: ----------
01:59:21.427817: LR: 
 [[ 467 1127]
 [   1   24]]
01:59:21.431068: LR: 
               precision    recall  f1-score   support

           0       1.00      0.29      0.45      1594
           1       0.02      0.96      0.04        25

    accuracy                           0.30      1619
   macro avg       0.51      0.63      0.25      1619
weighted avg       0.98      0.30      0.45      1619
01:59:21.432866: Validation Seq.Label F1: 0.558618984554236; Log.Reg F1: 0.24688730972505393; train loss: 0.03671650588512421; Language: finnish 

01:59:21.432938: Evaluating Language: japanese
01:59:21.432983: ----------
01:59:26.085328: OBI: 
 [[6406   38  116]
 [   7   24    3]
 [  80    0  174]]
01:59:26.091444: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.98      0.98      6560
           1       0.39      0.71      0.50        34
           2       0.59      0.69      0.64       254

    accuracy                           0.96      6848
   macro avg       0.66      0.79      0.71      6848
weighted avg       0.97      0.96      0.97      6848
01:59:26.091488: ----------
01:59:26.092121: LR: 
 [[447 379]
 [  4  30]]
01:59:26.094783: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70       826
           1       0.07      0.88      0.14        34

    accuracy                           0.55       860
   macro avg       0.53      0.71      0.42       860
weighted avg       0.95      0.55      0.68       860
01:59:26.096628: Validation Seq.Label F1: 0.7059114173486587; Log.Reg F1: 0.41775924456126895; train loss: 0.03671650588512421; Language: japanese 

01:59:26.097977: Combined F1 SeqLab: 0.5927973963170954; train loss: 0.03671650588512421
01:59:26.099329: Combined F1 LogReg: 0.3378336619399398; train loss: 0.03671650588512421 

01:59:26.099926: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 29/40
02:02:33.311906: Evaluating Language: english
02:02:33.312016: ----------
02:02:37.843085: OBI: 
 [[2782   74  340]
 [   2   10    2]
 [  46    5  107]]
02:02:37.847120: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.87      0.92      3196
           1       0.11      0.71      0.19        14
           2       0.24      0.68      0.35       158

    accuracy                           0.86      3368
   macro avg       0.44      0.75      0.49      3368
weighted avg       0.94      0.86      0.89      3368
02:02:37.847164: ----------
02:02:37.847842: LR: 
 [[477 477]
 [  3  11]]
02:02:37.850567: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.67       954
           1       0.02      0.79      0.04        14

    accuracy                           0.50       968
   macro avg       0.51      0.64      0.35       968
weighted avg       0.98      0.50      0.66       968
02:02:37.852838: Validation Seq.Label F1: 0.4900201754359003; Log.Reg F1: 0.3545483338612079; train loss: 0.023347310721874237; Language: english 

02:02:37.852895: Evaluating Language: finnish
02:02:37.852940: ----------
02:02:45.682935: OBI: 
 [[4276   67  339]
 [   6   16    1]
 [  94   13  125]]
02:02:45.688008: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.91      0.94      4682
           1       0.17      0.70      0.27        23
           2       0.27      0.54      0.36       232

    accuracy                           0.89      4937
   macro avg       0.47      0.72      0.52      4937
weighted avg       0.94      0.89      0.91      4937
02:02:45.688059: ----------
02:02:45.688933: LR: 
 [[686 910]
 [  4  19]]
02:02:45.692178: LR: 
               precision    recall  f1-score   support

           0       0.99      0.43      0.60      1596
           1       0.02      0.83      0.04        23

    accuracy                           0.44      1619
   macro avg       0.51      0.63      0.32      1619
weighted avg       0.98      0.44      0.59      1619
02:02:45.694116: Validation Seq.Label F1: 0.5239084663910424; Log.Reg F1: 0.3200454722571443; train loss: 0.023347310721874237; Language: finnish 

02:02:45.694167: Evaluating Language: japanese
02:02:45.694211: ----------
02:02:50.365871: OBI: 
 [[4816   21  177]
 [   3   20    4]
 [  18    0  125]]
02:02:50.371019: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98      5014
           1       0.49      0.74      0.59        27
           2       0.41      0.87      0.56       143

    accuracy                           0.96      5184
   macro avg       0.63      0.86      0.71      5184
weighted avg       0.98      0.96      0.96      5184
02:02:50.371062: ----------
02:02:50.371717: LR: 
 [[513 320]
 [  6  21]]
02:02:50.374378: LR: 
               precision    recall  f1-score   support

           0       0.99      0.62      0.76       833
           1       0.06      0.78      0.11        27

    accuracy                           0.62       860
   macro avg       0.53      0.70      0.44       860
weighted avg       0.96      0.62      0.74       860
02:02:50.376256: Validation Seq.Label F1: 0.7075989738700151; Log.Reg F1: 0.43650308721378955; train loss: 0.023347310721874237; Language: japanese 

02:02:50.377659: Combined F1 SeqLab: 0.5817491330210823; train loss: 0.023347310721874237
02:02:50.379048: Combined F1 LogReg: 0.37357220208112657; train loss: 0.023347310721874237 

02:02:50.379644: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 30/40
02:05:52.289011: Evaluating Language: english
02:05:52.289159: ----------
02:05:56.964980: OBI: 
 [[3897   67  386]
 [   4   14    1]
 [  58    7  126]]
02:05:56.969933: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.90      0.94      4350
           1       0.16      0.74      0.26        19
           2       0.25      0.66      0.36       191

    accuracy                           0.89      4560
   macro avg       0.46      0.76      0.52      4560
weighted avg       0.95      0.89      0.91      4560
02:05:56.969981: ----------
02:05:56.970676: LR: 
 [[574 375]
 [  7  12]]
02:05:56.973399: LR: 
               precision    recall  f1-score   support

           0       0.99      0.60      0.75       949
           1       0.03      0.63      0.06        19

    accuracy                           0.61       968
   macro avg       0.51      0.62      0.40       968
weighted avg       0.97      0.61      0.74       968
02:05:56.975758: Validation Seq.Label F1: 0.5192186013235112; Log.Reg F1: 0.4047200489391159; train loss: 0.019854413345456123; Language: english 

02:05:56.975815: Evaluating Language: finnish
02:05:56.975859: ----------
02:06:04.751365: OBI: 
 [[4887   59  292]
 [  11    9    1]
 [ 231   11  131]]
02:06:04.756805: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.93      0.94      5238
           1       0.11      0.43      0.18        21
           2       0.31      0.35      0.33       373

    accuracy                           0.89      5632
   macro avg       0.46      0.57      0.48      5632
weighted avg       0.91      0.89      0.90      5632
02:06:04.756850: ----------
02:06:04.757718: LR: 
 [[1001  597]
 [   7   14]]
02:06:04.760956: LR: 
               precision    recall  f1-score   support

           0       0.99      0.63      0.77      1598
           1       0.02      0.67      0.04        21

    accuracy                           0.63      1619
   macro avg       0.51      0.65      0.41      1619
weighted avg       0.98      0.63      0.76      1619
02:06:04.763046: Validation Seq.Label F1: 0.48384400490295576; Log.Reg F1: 0.4062654827710153; train loss: 0.019854413345456123; Language: finnish 

02:06:04.763099: Evaluating Language: japanese
02:06:04.763143: ----------
02:06:09.376195: OBI: 
 [[4702   22  168]
 [   3   16    3]
 [  28    0   74]]
02:06:09.381686: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      4892
           1       0.42      0.73      0.53        22
           2       0.30      0.73      0.43       102

    accuracy                           0.96      5016
   macro avg       0.57      0.80      0.65      5016
weighted avg       0.98      0.96      0.96      5016
02:06:09.381731: ----------
02:06:09.382373: LR: 
 [[499 339]
 [  2  20]]
02:06:09.385080: LR: 
               precision    recall  f1-score   support

           0       1.00      0.60      0.75       838
           1       0.06      0.91      0.10        22

    accuracy                           0.60       860
   macro avg       0.53      0.75      0.43       860
weighted avg       0.97      0.60      0.73       860
02:06:09.387247: Validation Seq.Label F1: 0.6456284208906687; Log.Reg F1: 0.4251596071028836; train loss: 0.019854413345456123; Language: japanese 

02:06:09.388674: Combined F1 SeqLab: 0.5539341221067878; train loss: 0.019854413345456123
02:06:09.390089: Combined F1 LogReg: 0.41215314791807056; train loss: 0.019854413345456123 

02:06:09.390678: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 31/40
02:09:19.184926: Evaluating Language: english
02:09:19.185382: ----------
02:09:23.775517: OBI: 
 [[3173   99  250]
 [   3   10    1]
 [  51   13   80]]
02:09:23.780581: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.90      0.94      3522
           1       0.08      0.71      0.15        14
           2       0.24      0.56      0.34       144

    accuracy                           0.89      3680
   macro avg       0.44      0.72      0.47      3680
weighted avg       0.95      0.89      0.91      3680
02:09:23.780624: ----------
02:09:23.781298: LR: 
 [[483 471]
 [  2  12]]
02:09:23.784023: LR: 
               precision    recall  f1-score   support

           0       1.00      0.51      0.67       954
           1       0.02      0.86      0.05        14

    accuracy                           0.51       968
   macro avg       0.51      0.68      0.36       968
weighted avg       0.98      0.51      0.66       968
02:09:23.789861: Validation Seq.Label F1: 0.4747294595950538; Log.Reg F1: 0.35979462599083034; train loss: 0.01544239092618227; Language: english 

02:09:23.789934: Evaluating Language: finnish
02:09:23.789995: ----------
02:09:31.672605: OBI: 
 [[4420  100  249]
 [  10   15    1]
 [ 122   18  130]]
02:09:31.677935: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.93      0.95      4769
           1       0.11      0.58      0.19        26
           2       0.34      0.48      0.40       270

    accuracy                           0.90      5065
   macro avg       0.48      0.66      0.51      5065
weighted avg       0.93      0.90      0.92      5065
02:09:31.677979: ----------
02:09:31.678858: LR: 
 [[605 988]
 [  4  22]]
02:09:31.682127: LR: 
               precision    recall  f1-score   support

           0       0.99      0.38      0.55      1593
           1       0.02      0.85      0.04        26

    accuracy                           0.39      1619
   macro avg       0.51      0.61      0.30      1619
weighted avg       0.98      0.39      0.54      1619
02:09:31.683908: Validation Seq.Label F1: 0.5123584467075428; Log.Reg F1: 0.2959857483018246; train loss: 0.01544239092618227; Language: finnish 

02:09:31.683962: Evaluating Language: japanese
02:09:31.684006: ----------
02:09:36.368793: OBI: 
 [[3069   20   95]
 [   2   14    1]
 [  27    2  154]]
02:09:36.372785: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      3184
           1       0.39      0.82      0.53        17
           2       0.62      0.84      0.71       183

    accuracy                           0.96      3384
   macro avg       0.67      0.88      0.74      3384
weighted avg       0.97      0.96      0.96      3384
02:09:36.372831: ----------
02:09:36.373480: LR: 
 [[395 448]
 [  2  15]]
02:09:36.376119: LR: 
               precision    recall  f1-score   support

           0       0.99      0.47      0.64       843
           1       0.03      0.88      0.06        17

    accuracy                           0.48       860
   macro avg       0.51      0.68      0.35       860
weighted avg       0.98      0.48      0.63       860
02:09:36.377963: Validation Seq.Label F1: 0.7388985493059795; Log.Reg F1: 0.3497983870967742; train loss: 0.01544239092618227; Language: japanese 

02:09:36.379343: Combined F1 SeqLab: 0.5870406868030128; train loss: 0.01544239092618227
02:09:36.380721: Combined F1 LogReg: 0.3363622292039626; train loss: 0.01544239092618227 

02:09:36.381330: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 32/40
02:12:38.938489: Evaluating Language: english
02:12:38.938597: ----------
02:12:43.630658: OBI: 
 [[4425   91  412]
 [   4   11    5]
 [  70    2  100]]
02:12:43.635840: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.90      0.94      4928
           1       0.11      0.55      0.18        20
           2       0.19      0.58      0.29       172

    accuracy                           0.89      5120
   macro avg       0.43      0.68      0.47      5120
weighted avg       0.95      0.89      0.91      5120
02:12:43.635883: ----------
02:12:43.636554: LR: 
 [[755 193]
 [ 13   7]]
02:12:43.639267: LR: 
               precision    recall  f1-score   support

           0       0.98      0.80      0.88       948
           1       0.04      0.35      0.06        20

    accuracy                           0.79       968
   macro avg       0.51      0.57      0.47       968
weighted avg       0.96      0.79      0.86       968
02:12:43.641592: Validation Seq.Label F1: 0.46882931530682215; Log.Reg F1: 0.4717948717948718; train loss: 0.016968155279755592; Language: english 

02:12:43.641646: Evaluating Language: finnish
02:12:43.641689: ----------
02:12:51.325338: OBI: 
 [[4107   66  284]
 [  11   16    3]
 [ 171    9   94]]
02:12:51.330290: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.92      0.94      4457
           1       0.18      0.53      0.26        30
           2       0.25      0.34      0.29       274

    accuracy                           0.89      4761
   macro avg       0.46      0.60      0.50      4761
weighted avg       0.91      0.89      0.90      4761
02:12:51.330339: ----------
02:12:51.331226: LR: 
 [[984 605]
 [ 12  18]]
02:12:51.334526: LR: 
               precision    recall  f1-score   support

           0       0.99      0.62      0.76      1589
           1       0.03      0.60      0.06        30

    accuracy                           0.62      1619
   macro avg       0.51      0.61      0.41      1619
weighted avg       0.97      0.62      0.75      1619
02:12:51.336361: Validation Seq.Label F1: 0.4968859678944099; Log.Reg F1: 0.4082227244587545; train loss: 0.016968155279755592; Language: finnish 

02:12:51.336414: Evaluating Language: japanese
02:12:51.336457: ----------
02:12:55.953119: OBI: 
 [[4266   31  206]
 [   5   20    2]
 [  37    0  153]]
02:12:55.958023: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      4503
           1       0.39      0.74      0.51        27
           2       0.42      0.81      0.56       190

    accuracy                           0.94      4720
   macro avg       0.60      0.83      0.68      4720
weighted avg       0.96      0.94      0.95      4720
02:12:55.958067: ----------
02:12:55.958708: LR: 
 [[485 348]
 [  3  24]]
02:12:55.961335: LR: 
               precision    recall  f1-score   support

           0       0.99      0.58      0.73       833
           1       0.06      0.89      0.12        27

    accuracy                           0.59       860
   macro avg       0.53      0.74      0.43       860
weighted avg       0.96      0.59      0.72       860
02:12:55.963163: Validation Seq.Label F1: 0.6788364835225497; Log.Reg F1: 0.4272964773781539; train loss: 0.016968155279755592; Language: japanese 

02:12:55.964527: Combined F1 SeqLab: 0.5560322422733802; train loss: 0.016968155279755592
02:12:55.965875: Combined F1 LogReg: 0.4365846513549794; train loss: 0.016968155279755592 

02:12:55.966499: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 33/40
02:15:59.332702: Evaluating Language: english
02:15:59.332802: ----------
02:16:03.823526: OBI: 
 [[3008   64  331]
 [   3    6    3]
 [  36    4  105]]
02:16:03.828017: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      3403
           1       0.08      0.50      0.14        12
           2       0.24      0.72      0.36       145

    accuracy                           0.88      3560
   macro avg       0.44      0.70      0.48      3560
weighted avg       0.95      0.88      0.91      3560
02:16:03.828068: ----------
02:16:03.828840: LR: 
 [[758 198]
 [ 11   1]]
02:16:03.831943: LR: 
               precision    recall  f1-score   support

           0       0.99      0.79      0.88       956
           1       0.01      0.08      0.01        12

    accuracy                           0.78       968
   macro avg       0.50      0.44      0.44       968
weighted avg       0.97      0.78      0.87       968
02:16:03.834259: Validation Seq.Label F1: 0.47727903437046476; Log.Reg F1: 0.4441596263479635; train loss: 0.018132081255316734; Language: english 

02:16:03.834322: Evaluating Language: finnish
02:16:03.834371: ----------
02:16:11.584855: OBI: 
 [[3779   71  266]
 [   5   10    3]
 [  85    7  108]]
02:16:11.589498: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.92      0.95      4116
           1       0.11      0.56      0.19        18
           2       0.29      0.54      0.37       200

    accuracy                           0.90      4334
   macro avg       0.46      0.67      0.50      4334
weighted avg       0.94      0.90      0.92      4334
02:16:11.589541: ----------
02:16:11.590415: LR: 
 [[1071  530]
 [   9    9]]
02:16:11.593655: LR: 
               precision    recall  f1-score   support

           0       0.99      0.67      0.80      1601
           1       0.02      0.50      0.03        18

    accuracy                           0.67      1619
   macro avg       0.50      0.58      0.42      1619
weighted avg       0.98      0.67      0.79      1619
02:16:11.595452: Validation Seq.Label F1: 0.5031846886047163; Log.Reg F1: 0.415635796016519; train loss: 0.018132081255316734; Language: finnish 

02:16:11.595508: Evaluating Language: japanese
02:16:11.595555: ----------
02:16:16.215729: OBI: 
 [[6261   31  237]
 [   3   24    2]
 [  20    0  170]]
02:16:16.221803: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98      6529
           1       0.44      0.83      0.57        29
           2       0.42      0.89      0.57       190

    accuracy                           0.96      6748
   macro avg       0.62      0.89      0.71      6748
weighted avg       0.98      0.96      0.96      6748
02:16:16.221847: ----------
02:16:16.222491: LR: 
 [[474 357]
 [  1  28]]
02:16:16.225129: LR: 
               precision    recall  f1-score   support

           0       1.00      0.57      0.73       831
           1       0.07      0.97      0.14        29

    accuracy                           0.58       860
   macro avg       0.54      0.77      0.43       860
weighted avg       0.97      0.58      0.71       860
02:16:16.227079: Validation Seq.Label F1: 0.7054433168048734; Log.Reg F1: 0.4305731258923882; train loss: 0.018132081255316734; Language: japanese 

02:16:16.228451: Combined F1 SeqLab: 0.5711509960073283; train loss: 0.018132081255316734
02:16:16.229825: Combined F1 LogReg: 0.4302805694538508; train loss: 0.018132081255316734 

02:16:16.230416: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 34/40
02:19:24.838892: Evaluating Language: english
02:19:24.839024: ----------
02:19:29.548449: OBI: 
 [[1939   63  190]
 [   2    6    1]
 [  53    2   48]]
02:19:29.552035: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.88      0.93      2192
           1       0.08      0.67      0.15         9
           2       0.20      0.47      0.28       103

    accuracy                           0.87      2304
   macro avg       0.42      0.67      0.45      2304
weighted avg       0.93      0.87      0.89      2304
02:19:29.552078: ----------
02:19:29.552756: LR: 
 [[669 290]
 [  5   4]]
02:19:29.555464: LR: 
               precision    recall  f1-score   support

           0       0.99      0.70      0.82       959
           1       0.01      0.44      0.03         9

    accuracy                           0.70       968
   macro avg       0.50      0.57      0.42       968
weighted avg       0.98      0.70      0.81       968
02:19:29.561287: Validation Seq.Label F1: 0.4523743863560797; Log.Reg F1: 0.42287676410017; train loss: 0.03132135048508644; Language: english 

02:19:29.561356: Evaluating Language: finnish
02:19:29.561400: ----------
02:19:37.181156: OBI: 
 [[6112  213  651]
 [   9   14    6]
 [ 196   14  124]]
02:19:37.187760: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.88      0.92      6976
           1       0.06      0.48      0.10        29
           2       0.16      0.37      0.22       334

    accuracy                           0.85      7339
   macro avg       0.39      0.58      0.42      7339
weighted avg       0.93      0.85      0.88      7339
02:19:37.187803: ----------
02:19:37.188676: LR: 
 [[1077  513]
 [  13   16]]
02:19:37.191914: LR: 
               precision    recall  f1-score   support

           0       0.99      0.68      0.80      1590
           1       0.03      0.55      0.06        29

    accuracy                           0.68      1619
   macro avg       0.51      0.61      0.43      1619
weighted avg       0.97      0.68      0.79      1619
02:19:37.193819: Validation Seq.Label F1: 0.41523565437166415; Log.Reg F1: 0.430539506767239; train loss: 0.03132135048508644; Language: finnish 

02:19:37.193900: Evaluating Language: japanese
02:19:37.193947: ----------
02:19:41.797359: OBI: 
 [[3435   27  116]
 [   2   13    2]
 [  28    1  144]]
02:19:41.802451: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      3578
           1       0.32      0.76      0.45        17
           2       0.55      0.83      0.66       173

    accuracy                           0.95      3768
   macro avg       0.62      0.85      0.70      3768
weighted avg       0.97      0.95      0.96      3768
02:19:41.802502: ----------
02:19:41.803262: LR: 
 [[440 403]
 [  1  16]]
02:19:41.806410: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.69       843
           1       0.04      0.94      0.07        17

    accuracy                           0.53       860
   macro avg       0.52      0.73      0.38       860
weighted avg       0.98      0.53      0.67       860
02:19:41.808587: Validation Seq.Label F1: 0.6952604771020708; Log.Reg F1: 0.37937637543227876; train loss: 0.03132135048508644; Language: japanese 

02:19:41.810243: Combined F1 SeqLab: 0.5355527876604704; train loss: 0.03132135048508644
02:19:41.811891: Combined F1 LogReg: 0.4115480768753276; train loss: 0.03132135048508644 

02:19:41.812592: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 35/40
02:22:45.539598: Evaluating Language: english
02:22:45.539704: ----------
02:22:50.227018: OBI: 
 [[2711   71  382]
 [   3    9    2]
 [  48    4  122]]
02:22:50.231056: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.86      0.91      3164
           1       0.11      0.64      0.18        14
           2       0.24      0.70      0.36       174

    accuracy                           0.85      3352
   macro avg       0.44      0.73      0.49      3352
weighted avg       0.94      0.85      0.88      3352
02:22:50.231098: ----------
02:22:50.231772: LR: 
 [[570 384]
 [  5   9]]
02:22:50.234495: LR: 
               precision    recall  f1-score   support

           0       0.99      0.60      0.75       954
           1       0.02      0.64      0.04        14

    accuracy                           0.60       968
   macro avg       0.51      0.62      0.39       968
weighted avg       0.98      0.60      0.74       968
02:22:50.236697: Validation Seq.Label F1: 0.48581602063707696; Log.Reg F1: 0.39490569706397044; train loss: 0.023141199722886086; Language: english 

02:22:50.236752: Evaluating Language: finnish
02:22:50.236795: ----------
02:22:57.776536: OBI: 
 [[3834   63  289]
 [   8   13    2]
 [ 167   14  122]]
02:22:57.781281: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.92      0.94      4186
           1       0.14      0.57      0.23        23
           2       0.30      0.40      0.34       303

    accuracy                           0.88      4512
   macro avg       0.47      0.63      0.50      4512
weighted avg       0.91      0.88      0.89      4512
02:22:57.781328: ----------
02:22:57.782195: LR: 
 [[846 750]
 [  6  17]]
02:22:57.785457: LR: 
               precision    recall  f1-score   support

           0       0.99      0.53      0.69      1596
           1       0.02      0.74      0.04        23

    accuracy                           0.53      1619
   macro avg       0.51      0.63      0.37      1619
weighted avg       0.98      0.53      0.68      1619
02:22:57.787228: Validation Seq.Label F1: 0.5021877046347627; Log.Reg F1: 0.36710722263588985; train loss: 0.023141199722886086; Language: finnish 

02:22:57.787279: Evaluating Language: japanese
02:22:57.787328: ----------
02:23:02.288003: OBI: 
 [[3210   20  111]
 [   1   23    0]
 [  22    0  133]]
02:23:02.292110: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      3341
           1       0.53      0.96      0.69        24
           2       0.55      0.86      0.67       155

    accuracy                           0.96      3520
   macro avg       0.69      0.93      0.78      3520
weighted avg       0.97      0.96      0.96      3520
02:23:02.292154: ----------
02:23:02.292796: LR: 
 [[501 335]
 [  2  22]]
02:23:02.295439: LR: 
               precision    recall  f1-score   support

           0       1.00      0.60      0.75       836
           1       0.06      0.92      0.12        24

    accuracy                           0.61       860
   macro avg       0.53      0.76      0.43       860
weighted avg       0.97      0.61      0.73       860
02:23:02.297299: Validation Seq.Label F1: 0.7766027382608306; Log.Reg F1: 0.4319026029139935; train loss: 0.023141199722886086; Language: japanese 

02:23:02.298703: Combined F1 SeqLab: 0.6031366649077682; train loss: 0.023141199722886086
02:23:02.300085: Combined F1 LogReg: 0.3988558974905181; train loss: 0.023141199722886086 

02:23:02.300672: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 36/40
02:26:07.916057: Evaluating Language: english
02:26:07.916155: ----------
02:26:12.448657: OBI: 
 [[3298   36  254]
 [   9    6    2]
 [  44    2   85]]
02:26:12.452968: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.92      0.95      3588
           1       0.14      0.35      0.20        17
           2       0.25      0.65      0.36       131

    accuracy                           0.91      3736
   macro avg       0.46      0.64      0.50      3736
weighted avg       0.95      0.91      0.93      3736
02:26:12.453010: ----------
02:26:12.453692: LR: 
 [[650 301]
 [ 10   7]]
02:26:12.456415: LR: 
               precision    recall  f1-score   support

           0       0.98      0.68      0.81       951
           1       0.02      0.41      0.04        17

    accuracy                           0.68       968
   macro avg       0.50      0.55      0.43       968
weighted avg       0.97      0.68      0.79       968
02:26:12.458598: Validation Seq.Label F1: 0.5024866830966414; Log.Reg F1: 0.4250145633385857; train loss: 0.01896579936146736; Language: english 

02:26:12.458656: Evaluating Language: finnish
02:26:12.458700: ----------
02:26:20.361533: OBI: 
 [[4316   44  222]
 [  12    8    3]
 [ 172    5  111]]
02:26:20.366532: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.94      0.95      4582
           1       0.14      0.35      0.20        23
           2       0.33      0.39      0.36       288

    accuracy                           0.91      4893
   macro avg       0.48      0.56      0.50      4893
weighted avg       0.92      0.91      0.91      4893
02:26:20.366575: ----------
02:26:20.367443: LR: 
 [[1022  574]
 [   6   17]]
02:26:20.370675: LR: 
               precision    recall  f1-score   support

           0       0.99      0.64      0.78      1596
           1       0.03      0.74      0.06        23

    accuracy                           0.64      1619
   macro avg       0.51      0.69      0.42      1619
weighted avg       0.98      0.64      0.77      1619
02:26:20.372469: Validation Seq.Label F1: 0.5020735577275987; Log.Reg F1: 0.4171690037340113; train loss: 0.01896579936146736; Language: finnish 

02:26:20.372522: Evaluating Language: japanese
02:26:20.372566: ----------
02:26:24.917599: OBI: 
 [[4303   17  218]
 [   2   16    1]
 [  29    0   78]]
02:26:24.922372: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      4538
           1       0.48      0.84      0.62        19
           2       0.26      0.73      0.39       107

    accuracy                           0.94      4664
   macro avg       0.58      0.84      0.66      4664
weighted avg       0.97      0.94      0.96      4664
02:26:24.922416: ----------
02:26:24.923046: LR: 
 [[474 367]
 [  2  17]]
02:26:24.925667: LR: 
               precision    recall  f1-score   support

           0       1.00      0.56      0.72       841
           1       0.04      0.89      0.08        19

    accuracy                           0.57       860
   macro avg       0.52      0.73      0.40       860
weighted avg       0.97      0.57      0.71       860
02:26:24.927500: Validation Seq.Label F1: 0.6571804211703683; Log.Reg F1: 0.40209250665566343; train loss: 0.01896579936146736; Language: japanese 

02:26:24.928867: Combined F1 SeqLab: 0.5587058946137271; train loss: 0.01896579936146736
02:26:24.930245: Combined F1 LogReg: 0.4148677462497139; train loss: 0.01896579936146736 

02:26:24.930830: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 37/40
02:29:33.259781: Evaluating Language: english
02:29:33.259945: ----------
02:29:37.950357: OBI: 
 [[2640   40  205]
 [   5    7    2]
 [  73    3   81]]
02:29:37.954373: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.92      0.94      2885
           1       0.14      0.50      0.22        14
           2       0.28      0.52      0.36       157

    accuracy                           0.89      3056
   macro avg       0.46      0.64      0.51      3056
weighted avg       0.93      0.89      0.91      3056
02:29:37.954416: ----------
02:29:37.955096: LR: 
 [[469 485]
 [  3  11]]
02:29:37.957816: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.66       954
           1       0.02      0.79      0.04        14

    accuracy                           0.50       968
   macro avg       0.51      0.64      0.35       968
weighted avg       0.98      0.50      0.65       968
02:29:37.963744: Validation Seq.Label F1: 0.508382418360683; Log.Reg F1: 0.35046063306107855; train loss: 0.014806011691689491; Language: english 

02:29:37.963808: Evaluating Language: finnish
02:29:37.963854: ----------
02:29:45.796460: OBI: 
 [[5913   78  306]
 [  15   20    6]
 [ 222   11  197]]
02:29:45.802648: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.94      0.95      6297
           1       0.18      0.49      0.27        41
           2       0.39      0.46      0.42       430

    accuracy                           0.91      6768
   macro avg       0.51      0.63      0.55      6768
weighted avg       0.92      0.91      0.91      6768
02:29:45.802691: ----------
02:29:45.803567: LR: 
 [[989 589]
 [ 16  25]]
02:29:45.806819: LR: 
               precision    recall  f1-score   support

           0       0.98      0.63      0.77      1578
           1       0.04      0.61      0.08        41

    accuracy                           0.63      1619
   macro avg       0.51      0.62      0.42      1619
weighted avg       0.96      0.63      0.75      1619
02:29:45.808684: Validation Seq.Label F1: 0.5454568135668397; Log.Reg F1: 0.42105605352672937; train loss: 0.014806011691689491; Language: finnish 

02:29:45.808744: Evaluating Language: japanese
02:29:45.808787: ----------
02:29:50.481186: OBI: 
 [[3827   20  150]
 [   2   23    1]
 [  17    0  212]]
02:29:50.485767: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98      3997
           1       0.53      0.88      0.67        26
           2       0.58      0.93      0.72       229

    accuracy                           0.96      4252
   macro avg       0.70      0.92      0.79      4252
weighted avg       0.97      0.96      0.96      4252
02:29:50.485811: ----------
02:29:50.486451: LR: 
 [[454 380]
 [  3  23]]
02:29:50.489090: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70       834
           1       0.06      0.88      0.11        26

    accuracy                           0.55       860
   macro avg       0.53      0.71      0.41       860
weighted avg       0.97      0.55      0.69       860
02:29:50.491072: Validation Seq.Label F1: 0.7862616537230842; Log.Reg F1: 0.4052784292908228; train loss: 0.014806011691689491; Language: japanese 

02:29:50.492488: Combined F1 SeqLab: 0.625615219039122; train loss: 0.014806011691689491
02:29:50.493907: Combined F1 LogReg: 0.39342998563298504; train loss: 0.014806011691689491 

02:29:50.494515: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 38/40
02:32:54.680497: Evaluating Language: english
02:32:54.680597: ----------
02:32:59.389502: OBI: 
 [[2346   26  139]
 [   2    7    1]
 [  25    1   69]]
02:32:59.393322: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      2511
           1       0.21      0.70      0.32        10
           2       0.33      0.73      0.45        95

    accuracy                           0.93      2616
   macro avg       0.51      0.79      0.58      2616
weighted avg       0.96      0.93      0.94      2616
02:32:59.393368: ----------
02:32:59.394113: LR: 
 [[649 309]
 [  4   6]]
02:32:59.396938: LR: 
               precision    recall  f1-score   support

           0       0.99      0.68      0.81       958
           1       0.02      0.60      0.04        10

    accuracy                           0.68       968
   macro avg       0.51      0.64      0.42       968
weighted avg       0.98      0.68      0.80       968
02:32:59.399157: Validation Seq.Label F1: 0.5776057157636105; Log.Reg F1: 0.42131690779735476; train loss: 0.010598951019346714; Language: english 

02:32:59.399212: Evaluating Language: finnish
02:32:59.399255: ----------
02:33:07.025576: OBI: 
 [[4648   32  191]
 [   9   10    2]
 [ 145    7   80]]
02:33:07.030691: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.95      0.96      4871
           1       0.20      0.48      0.29        21
           2       0.29      0.34      0.32       232

    accuracy                           0.92      5124
   macro avg       0.49      0.59      0.52      5124
weighted avg       0.93      0.92      0.93      5124
02:33:07.030735: ----------
02:33:07.031601: LR: 
 [[1294  304]
 [  12    9]]
02:33:07.034818: LR: 
               precision    recall  f1-score   support

           0       0.99      0.81      0.89      1598
           1       0.03      0.43      0.05        21

    accuracy                           0.80      1619
   macro avg       0.51      0.62      0.47      1619
weighted avg       0.98      0.80      0.88      1619
02:33:07.036601: Validation Seq.Label F1: 0.5211905012923056; Log.Reg F1: 0.4725383942858085; train loss: 0.010598951019346714; Language: finnish 

02:33:07.036656: Evaluating Language: japanese
02:33:07.036704: ----------
02:33:11.579949: OBI: 
 [[4148   16  173]
 [   4   13    2]
 [  45    1   98]]
02:33:11.584630: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97      4337
           1       0.43      0.68      0.53        19
           2       0.36      0.68      0.47       144

    accuracy                           0.95      4500
   macro avg       0.59      0.77      0.66      4500
weighted avg       0.97      0.95      0.95      4500
02:33:11.584672: ----------
02:33:11.585303: LR: 
 [[488 353]
 [  4  15]]
02:33:11.587949: LR: 
               precision    recall  f1-score   support

           0       0.99      0.58      0.73       841
           1       0.04      0.79      0.08        19

    accuracy                           0.58       860
   macro avg       0.52      0.68      0.40       860
weighted avg       0.97      0.58      0.72       860
02:33:11.589813: Validation Seq.Label F1: 0.6575825931660558; Log.Reg F1: 0.40485121280320074; train loss: 0.010598951019346714; Language: japanese 

02:33:11.591187: Combined F1 SeqLab: 0.5881277549294632; train loss: 0.010598951019346714
02:33:11.592550: Combined F1 LogReg: 0.4338605672249851; train loss: 0.010598951019346714 

02:33:11.593144: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 39/40
02:36:15.090886: Evaluating Language: english
02:36:15.090993: ----------
02:36:19.856594: OBI: 
 [[4367   42  233]
 [   8    8    3]
 [  49    4  118]]
02:36:19.861550: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      4642
           1       0.15      0.42      0.22        19
           2       0.33      0.69      0.45       171

    accuracy                           0.93      4832
   macro avg       0.49      0.68      0.54      4832
weighted avg       0.96      0.93      0.94      4832
02:36:19.861594: ----------
02:36:19.862262: LR: 
 [[732 217]
 [  9  10]]
02:36:19.864976: LR: 
               precision    recall  f1-score   support

           0       0.99      0.77      0.87       949
           1       0.04      0.53      0.08        19

    accuracy                           0.77       968
   macro avg       0.52      0.65      0.47       968
weighted avg       0.97      0.77      0.85       968
02:36:19.867203: Validation Seq.Label F1: 0.5440271839949092; Log.Reg F1: 0.47378650117862126; train loss: 0.012754066847264767; Language: english 

02:36:19.867257: Evaluating Language: finnish
02:36:19.867301: ----------
02:36:27.713774: OBI: 
 [[6538   39  255]
 [  13   10    2]
 [ 172    5  123]]
02:36:27.720242: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.96      6832
           1       0.19      0.40      0.25        25
           2       0.32      0.41      0.36       300

    accuracy                           0.93      7157
   macro avg       0.49      0.59      0.53      7157
weighted avg       0.94      0.93      0.94      7157
02:36:27.720284: ----------
02:36:27.721159: LR: 
 [[975 619]
 [  9  16]]
02:36:27.724415: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.76      1594
           1       0.03      0.64      0.05        25

    accuracy                           0.61      1619
   macro avg       0.51      0.63      0.40      1619
weighted avg       0.98      0.61      0.75      1619
02:36:27.726224: Validation Seq.Label F1: 0.5265305830039481; Log.Reg F1: 0.4024425794014622; train loss: 0.012754066847264767; Language: finnish 

02:36:27.726277: Evaluating Language: japanese
02:36:27.726326: ----------
02:36:32.240593: OBI: 
 [[2966   15   96]
 [   1   10    1]
 [  22    0   57]]
02:36:32.244441: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      3077
           1       0.40      0.83      0.54        12
           2       0.37      0.72      0.49        79

    accuracy                           0.96      3168
   macro avg       0.59      0.84      0.67      3168
weighted avg       0.97      0.96      0.96      3168
02:36:32.244484: ----------
02:36:32.245117: LR: 
 [[483 365]
 [  1  11]]
02:36:32.247749: LR: 
               precision    recall  f1-score   support

           0       1.00      0.57      0.73       848
           1       0.03      0.92      0.06        12

    accuracy                           0.57       860
   macro avg       0.51      0.74      0.39       860
weighted avg       0.98      0.57      0.72       860
02:36:32.249625: Validation Seq.Label F1: 0.6692401957362923; Log.Reg F1: 0.39096312807653016; train loss: 0.012754066847264767; Language: japanese 

02:36:32.251299: Combined F1 SeqLab: 0.5834045112821403; train loss: 0.012754066847264767
02:36:32.252810: Combined F1 LogReg: 0.4239834296800475; train loss: 0.012754066847264767 

02:36:32.253420: Model: lab6_bert-base-multilingual-cased_japanese.pt; Language: japanese; Epoch 40/40
02:39:39.956711: Evaluating Language: english
02:39:39.956823: ----------
02:39:44.712094: OBI: 
 [[2774   13  108]
 [   3    6    0]
 [  52    1   59]]
02:39:44.715959: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      2895
           1       0.30      0.67      0.41         9
           2       0.35      0.53      0.42       112

    accuracy                           0.94      3016
   macro avg       0.54      0.72      0.60      3016
weighted avg       0.96      0.94      0.95      3016
02:39:44.716001: ----------
02:39:44.716685: LR: 
 [[604 355]
 [  5   4]]
02:39:44.719445: LR: 
               precision    recall  f1-score   support

           0       0.99      0.63      0.77       959
           1       0.01      0.44      0.02         9

    accuracy                           0.63       968
   macro avg       0.50      0.54      0.40       968
weighted avg       0.98      0.63      0.76       968
02:39:44.725359: Validation Seq.Label F1: 0.6019948142292325; Log.Reg F1: 0.39607364685004437; train loss: 0.009522072039544582; Language: english 

02:39:44.725431: Evaluating Language: finnish
02:39:44.725479: ----------
02:39:52.515893: OBI: 
 [[8192   26  265]
 [  23   14    2]
 [ 282    4  158]]
02:39:52.523722: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.97      0.96      8483
           1       0.32      0.36      0.34        39
           2       0.37      0.36      0.36       444

    accuracy                           0.93      8966
   macro avg       0.55      0.56      0.56      8966
weighted avg       0.93      0.93      0.93      8966
02:39:52.523765: ----------
02:39:52.524650: LR: 
 [[965 615]
 [  9  30]]
02:39:52.527917: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.76      1580
           1       0.05      0.77      0.09        39

    accuracy                           0.61      1619
   macro avg       0.52      0.69      0.42      1619
weighted avg       0.97      0.61      0.74      1619
02:39:52.529918: Validation Seq.Label F1: 0.555295214480365; Log.Reg F1: 0.42169833353940844; train loss: 0.009522072039544582; Language: finnish 

02:39:52.529988: Evaluating Language: japanese
02:39:52.530033: ----------
02:39:57.161554: OBI: 
 [[3722   14   52]
 [   1   15    2]
 [  31    1   90]]
02:39:57.165899: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.98      0.99      3788
           1       0.50      0.83      0.62        18
           2       0.62      0.74      0.68       122

    accuracy                           0.97      3928
   macro avg       0.71      0.85      0.76      3928
weighted avg       0.98      0.97      0.98      3928
02:39:57.165941: ----------
02:39:57.166581: LR: 
 [[493 349]
 [  1  17]]
02:39:57.169196: LR: 
               precision    recall  f1-score   support

           0       1.00      0.59      0.74       842
           1       0.05      0.94      0.09        18

    accuracy                           0.59       860
   macro avg       0.52      0.76      0.41       860
weighted avg       0.98      0.59      0.72       860
02:39:57.171027: Validation Seq.Label F1: 0.7628992761670818; Log.Reg F1: 0.41328280938123746; train loss: 0.009522072039544582; Language: japanese 

02:39:57.172371: Combined F1 SeqLab: 0.6462109658514368; train loss: 0.009522072039544582
02:39:58.584101: Combined F1 LogReg: 0.41049015366553193; train loss: 0.009522072039544582 

02:39:58.584178: Learning rates: []
02:40:03.311196: Loading tokenizer: xlm-roberta-base
02:40:06.012315: -- Data Parsing ENGLISH; Type: VALIDATION--
02:40:08.102186: Unanswerable questions: 491
02:40:08.110794: Balance of labels: dict_keys([-100, 0, 1, 2]):dict_values([10377, 130838, 454, 2949])
02:40:08.110852: Entries skipped due to too long sequence length (>512): 6
02:40:08.110900: Failed to map answer and to context: 39
02:40:08.118443: Final length: 945 

02:40:08.119822: -- Data Parsing FINNISH; Type: VALIDATION--
02:40:11.071054: Unanswerable questions: 841
02:40:11.083878: Balance of labels: dict_keys([-100, 0, 1, 2]):dict_values([17536, 186524, 755, 6393])
02:40:11.083933: Entries skipped due to too long sequence length (>512): 10
02:40:11.083981: Failed to map answer and to context: 80
02:40:11.094824: Final length: 1596 

02:40:11.097033: -- Data Parsing JAPANESE; Type: VALIDATION--
02:40:12.315893: Unanswerable questions: 511
02:40:12.321017: Balance of labels: dict_keys([-100, 1, 2, 0]):dict_values([7783, 79, 436, 75522])
02:40:12.321071: Entries skipped due to too long sequence length (>512): 27
02:40:12.321119: Failed to map answer and to context: 419
02:40:12.325569: Final length: 590 

02:40:12.537555: -- Data Parsing ENGLISH; Type: TRAIN--
02:40:13.003235: Failed Answer extraction: ['▁July', '▁1960']; Prompt: ['<s>', '▁When', '▁did', '▁DC', '▁comic', 's', '▁first', '▁introduce', '▁the', '▁Guardian', 's', '▁of', '▁the', '▁Universe', '?', '▁The', '▁Guardian', 's', '▁of', '▁the', '▁Universe', '▁are', '▁a', '▁fiction', 'al', '▁race', '▁of', '▁extra', 'ter', 're', 'stri', 'als', '▁appear', 'ing', '▁in', '▁American', '▁comic', '▁books', '▁published', '▁by', '▁DC', '▁Comic', 's', ',', '▁common', 'ly', '▁in', '▁association', '▁with', '▁Green', '▁Lan', 'tern', '.', '▁They', '▁first', '▁appeared', '▁in', '▁Green', '▁Lan', 'tern', '▁Vol', '.', '▁2', ',', '▁Issue', '▁1', '▁(', 'Jul', 'y', '▁1960', '),', '▁and', '▁were', '▁created', '▁by', '▁John', '▁Bro', 'ome', '▁and', '▁Gil', '▁Kan', 'e', '.[1]', '▁The', '▁Guardian', 's', '▁of', '▁the', '▁Universe', '▁have', '▁been', '▁adapt', 'ed', '▁to', '▁a', '▁number', '▁of', '▁films', ',', '▁television', '▁programs', ',', '▁and', '▁video', '▁games', '.', '</s>']
02:40:13.005930: Failed Answer extraction: ['▁2007']; Prompt: ['<s>', '▁When', '▁was', '▁the', '▁first', '▁Assassin', "'", 's', '▁Creed', '▁released', '?', '▁The', '▁video', '▁game', '▁series', '▁took', '▁inspiration', '▁from', '▁the', '▁novel', '▁Alam', 'ut', '▁by', '▁the', '▁Slovenia', 'n', '▁', 'writer', '▁Vladimir', '▁Bart', 'ol', ',', '[1]', '▁while', '▁building', '▁upon', '▁concept', 's', '▁from', '▁the', '▁Prince', '▁of', '▁Persi', 'a', '▁series', '.[2]', '▁It', '▁begin', 's', '▁with', '▁the', '▁self', '-', 'title', 'd', '▁game', '▁in', '▁2007,', '▁and', '▁has', '▁feature', 'd', '▁eleven', '▁main', '▁games', '.', '▁The', '▁most', '▁recent', '▁released', '▁game', '▁is', '▁2018', "'", 's', '▁Assassin', "'", 's', '▁Creed', '▁O', 'dys', 'sey', '.', '</s>']
02:40:13.010631: Failed Answer extraction: ['▁6', '▁August', '▁1967']; Prompt: ['<s>', '▁When', '▁was', '▁the', '▁Battle', '▁of', '▁Suo', 'i', '▁Chau', '▁Pha', '▁fo', 'ught', '?', '▁The', '▁Battle', '▁of', '▁Suo', 'i', '▁Chau', '▁Pha', '▁(6', '▁August', '▁1967', ')', '▁was', '▁fo', 'ught', '▁during', '▁the', '▁Vietnam', '▁War', '▁between', '▁Australian', '▁tro', 'ops', '▁and', '▁the', '▁Viet', '▁Con', 'g', '.', '▁The', '▁battle', '▁took', '▁place', '▁during', '▁Operation', '▁Ball', 'arat', ',', '▁an', '▁Australian', '▁search', '▁and', '▁destroy', '▁operation', '▁in', '▁the', '▁ea', 'stern', '▁Hat', '▁Dich', '▁area', ',', '▁north', '-', 'west', '▁of', '▁Nu', 'i', '▁Dat', '▁in', '▁Ph', 'u', 'oc', '▁Tuy', '▁province', '.', '▁Follow', 'ing', '▁a', '▁cover', 't', '▁', 'insertion', '▁the', '▁day', '▁before', '▁which', '▁had', '▁caught', '▁a', '▁number', '▁of', '▁Viet', '▁Con', 'g', '▁sent', 'ries', '▁by', '▁surprise', ',', '▁A', '▁Company', ',', '▁7', 'th', '▁Batt', 'ali', 'on', ',', '▁Royal', '▁Australian', '▁Regi', 'ment', '▁(7', '▁', 'RAR', ')', '▁had', '▁patrol', 'led', '▁forward', '▁una', 'ware', '▁of', '▁the', '▁presence', '▁of', '▁a', '▁large', '▁Viet', '▁Con', 'g', '▁main', '▁force', '▁unit', '▁near', 'by', '.', '▁Cla', 'shing', '▁with', '▁a', '▁rein', 'force', 'd', '▁company', '▁from', '▁the', '▁Viet', '▁Con', 'g', '▁3', 'rd', '▁Batt', 'ali', 'on', ',', '▁27', '4', 'th', '▁Regi', 'ment', ',', '▁a', '▁classic', '▁encounter', '▁battle', '▁en', 'su', 'ed', '▁between', '▁two', '▁forces', '▁of', '▁rough', 'ly', '▁equal', '▁size', '.', '▁Fo', 'ught', '▁at', '▁close', '▁quarter', 's', '▁in', '▁den', 'se', '▁jung', 'le', '▁am', 'id', '▁a', '▁heavy', '▁mon', 'soon', '▁rain', ',', '▁both', '▁side', 's', '▁suffer', 'ed', '▁heavy', '▁casual', 'ties', '▁as', '▁nei', 'ther', '▁was', '▁able', '▁to', '▁gain', '▁an', '▁advantage', '.', '▁Finally', ',', '▁after', '▁a', '▁battle', '▁', 'lasting', '▁several', '▁hours', ',', '▁the', '▁Australian', '▁art', 'iller', 'y', '▁proved', '▁decisiv', 'e', '▁and', '▁the', '▁Viet', '▁Con', 'g', '▁were', '▁forced', '▁to', '▁withdraw', ',', '▁drag', 'ging', '▁many', '▁of', '▁their', '▁dead', '▁from', '▁the', '▁battle', 'field', '▁after', '▁having', '▁suffer', 'ed', '▁cri', 'pp', 'ling', '▁los', 'ses', '.', '</s>']
02:40:13.024501: Failed Answer extraction: ['▁is', '▁the', '▁di', 'minu', 'tive', '▁form', '▁of', '▁"', 'guer', 'ra', '"', '▁("', 'war', '")']; Prompt: ['<s>', '▁Why', '▁is', '▁it', '▁called', '▁', 'guer', 'rilla', '?', '▁The', '▁Spanish', '▁word', '▁"', 'guer', 'rilla', '"', '▁is', '▁the', '▁di', 'minu', 'tive', '▁form', '▁of', '▁"', 'guer', 'ra', '"', '▁("', 'war', '").', '▁The', '▁term', '▁became', '▁popular', '▁during', '▁the', '▁early', '-19', 'th', '▁century', '▁Pen', 'insu', 'lar', '▁War', ',', '▁when', '▁the', '▁Spanish', '▁and', '▁Portu', 'gues', 'e', '▁people', '▁rose', '▁against', '▁the', '▁Napoleon', 'ic', '▁tro', 'ops', '▁and', '▁fo', 'ught', '▁against', '▁a', '▁highly', '▁superior', '▁ar', 'my', '▁using', '▁the', '▁', 'guer', 'rilla', '▁strategy', '.', '▁In', '▁correct', '▁Spanish', '▁usage', ',', '▁a', '▁person', '▁who', '▁is', '▁a', '▁member', '▁of', '▁a', '▁"', 'guer', 'rilla', '"', '▁unit', '▁is', '▁a', '▁"', 'guer', 'r', 'iller', 'o', '"', '▁(', '[', 'ɣ', 'eri', 'ˈ', 'ʎ', 'e', 'ɾ', 'o', ']', ')', '▁if', '▁male', ',', '▁or', '▁a', '▁"', 'guer', 'ril', 'lera', '"', '▁(', '[', 'ɣ', 'eri', 'ˈ', 'ʎ', 'e', 'ɾ', 'a', ']', ')', '▁if', '▁female', '.', '</s>']
02:40:13.064926: Failed Answer extraction: ['▁7', '▁June', '▁2016']; Prompt: ['<s>', '▁When', '▁did', '▁Justin', '▁Morgan', '▁first', '▁appear', '▁as', '▁a', '▁character', '▁on', '▁Home', '▁and', '▁A', 'way', '?', '▁Justin', '▁Morgan', '▁is', '▁a', '▁fiction', 'al', '▁character', '▁from', '▁the', '▁Australian', '▁television', '▁so', 'ap', '▁opera', '▁Home', '▁and', '▁A', 'way', ',', '▁played', '▁by', '▁James', '▁Stewart', '.', '▁The', '▁actor', '▁was', '▁contact', 'ed', '▁by', '▁his', '▁agent', '▁and', '▁the', '▁head', '▁of', '▁drama', '▁at', '▁Seven', '▁Network', '▁about', '▁the', '▁role', '.', '▁After', '▁hearing', '▁their', '▁pitch', ',', '▁Stewart', '▁audi', 'tion', 'ed', '▁and', '▁won', '▁the', '▁part', '.', '▁He', '▁began', '▁film', 'ing', '▁in', '▁December', '▁2015,', '▁and', '▁made', '▁his', '▁first', '▁appearance', '▁during', '▁the', '▁episode', '▁broadcast', '▁on', '▁7', '▁June', '▁2016.', '▁Justin', '▁was', '▁introduce', 'd', '▁to', '▁the', '▁show', '▁along', '▁with', '▁his', '▁three', '▁si', 'bling', 's', ';', '▁Tor', 'i', '▁Morgan', '▁(', 'Pen', 'ny', '▁Mc', 'Name', 'e', '),', '▁Brod', 'y', '▁Morgan', '▁(', 'Jack', 'son', '▁Hey', 'wood', ')', '▁and', '▁Mas', 'on', '▁Morgan', '▁(', 'Or', 'phe', 'us', '▁Ple', 'd', 'ger', ').', '▁The', '▁family', '▁received', '▁immediate', '▁comparison', 's', '▁to', '▁the', '▁show', "'", 's', '▁popular', '▁Bra', 'x', 'ton', '▁brother', 's', '.', '</s>']
02:40:13.079258: Failed Answer extraction: ['▁14']; Prompt: ['<s>', '▁What', "'", 's', '▁the', '▁minimum', '▁age', '▁for', '▁driving', '?', '▁The', '▁minimum', '▁driving', '▁age', '▁is', '▁the', '▁minimum', '▁age', '▁at', '▁which', '▁a', '▁person', '▁may', '▁obtain', '▁a', '▁driver', "'", 's', '▁licence', '▁to', '▁law', 'fully', '▁drive', '▁a', '▁motor', '▁vehicle', '▁on', '▁public', '▁road', 's', '.', '▁That', '▁age', '▁is', '▁determine', 'd', '▁by', '▁and', '▁for', '▁each', '▁juris', 'di', 'ction', '▁and', '▁is', '▁most', '▁common', 'ly', '▁set', '▁at', '▁18', '▁years', '▁of', '▁age', ',', '▁but', '▁learn', 'er', '▁driver', 's', '▁may', '▁be', '▁permit', 'ted', '▁on', '▁the', '▁road', '▁at', '▁an', '▁earlier', '▁age', '▁under', '▁super', 'vision', '.', '▁Before', '▁reach', 'ing', '▁the', '▁minimum', '▁age', '▁for', '▁a', '▁driver', "'", 's', '▁licence', '▁or', '▁any', 'time', '▁after', 'ward', 's', ',', '▁the', '▁person', '▁want', 'ing', '▁the', '▁licence', '▁would', '▁normal', 'ly', '▁be', '▁test', 'ed', '▁for', '▁driving', '▁ability', '▁and', '▁knowledge', '▁of', '▁road', '▁rules', '▁before', '▁being', '▁issue', 'd', '▁with', '▁a', '▁licence', ',', '▁provided', '▁he', '▁or', '▁she', '▁is', '▁above', '▁the', '▁minimum', '▁driving', '▁age', '.', '▁', 'Count', 'ries', '▁with', '▁the', '▁lo', 'west', '▁driving', '▁a', 'ges', '▁(17', '▁and', '▁below', ')', '▁are', '▁Canada', ',', '▁El', '▁Salvador', ',', '▁Iceland', ',', '▁Israel', ',', '▁Malaysia', ',', '▁Australia', ',', '▁New', '▁Zealand', ',', '▁the', '▁Philippines', ',', '▁the', '▁United', '▁Kingdom', '▁(', 'Main', 'land', '),', '▁United', '▁States', '▁and', '▁Zimbabwe', '.', '▁In', '▁several', '▁juris', 'dic', 'tions', '▁in', '▁the', '▁United', '▁States', '▁and', '▁Canada', ',', '▁driver', 's', '▁can', '▁be', '▁as', '▁young', '▁as', '▁14.', '</s>']
02:40:13.087846: Failed Answer extraction: ['▁May', '▁26,', '▁2000']; Prompt: ['<s>', '▁When', '▁did', '▁Andy', '▁Richter', '▁leave', '▁La', 'te', '▁Night', '▁with', '▁Con', 'an', '▁O', "'", 'Bri', 'en', '?', '▁After', '▁seven', '▁years', '▁with', '▁the', '▁show', ',', '▁Richter', '▁departe', 'd', '▁from', '▁La', 'te', '▁Night', '▁after', '▁the', '▁show', '▁on', '▁May', '▁26,', '▁2000.', '▁He', '▁later', '▁said', '▁of', '▁the', '▁decision', ',', '▁"', 'A', 'fter', '▁seven', '▁years', '▁of', '▁being', '▁on', '▁the', '▁show', ',', '▁I', '▁got', '▁it', 'chy', '.', '▁I', '▁have', '▁a', '▁', 'philosoph', 'y', '▁that', '▁if', '▁you', '▁enjoy', '▁good', '▁for', 'tune', ',', '▁rather', '▁than', '▁sit', '▁there', '▁and', '▁say', ',', "▁'", 'Oh', ',', '▁that', "'", 's', '▁fine', ',', '▁this', '▁amount', '▁is', '▁good', '▁enough', '▁for', '▁me', ',', "'", '▁you', '▁should', '▁try', '▁and', '▁push', '▁it', '.', '▁You', '▁should', '▁see', '▁how', '▁much', '▁you', '▁can', '▁stretch', '▁your', '▁good', '▁for', 'tune', '.', '▁And', '▁I', '▁was', '▁curious', '."', '[10]', '</s>']
02:40:13.094929: Failed Answer extraction: ['▁April', '▁2008']; Prompt: ['<s>', '▁When', '▁did', '▁The', '▁Pri', 'ze', 'fighter', '▁series', '▁begin', '?', '▁The', '▁Pri', 'ze', 'fighter', '▁series', '▁was', '▁a', '▁professional', '▁box', 'ing', '▁tournament', '▁created', '▁by', '▁box', 'ing', '▁promote', 'r', '▁Barry', '▁He', 'ar', 'n', '▁and', '▁air', 'ed', '▁on', '▁Sky', '▁Sports', '.', '▁The', '▁format', '▁has', '▁an', '▁initial', '▁eight', '▁fight', 'ers', ',', '▁who', '▁compete', '▁in', '▁four', '▁quarter', '-', 'final', 's', '▁of', '▁3', '▁x', '▁3', '▁minute', '▁round', 's', '▁(', 'num', 'ber', '▁and', '▁length', '▁of', '▁the', '▁round', 's', '▁is', '▁same', '▁as', '▁in', '▁amateur', '▁box', 'ing', ')', '▁followed', '▁by', '▁two', '▁semi', '-', 'final', 's', '▁and', '▁one', '▁final', '▁all', '▁on', '▁the', '▁same', '▁night', '.[1]', '▁The', '▁total', '▁pri', 'ze', '▁money', '▁of', '▁the', '▁tournament', '▁is', '▁£', '80,000', '▁with', '▁the', '▁winner', '▁of', '▁the', '▁tournament', '▁taking', '▁home', '▁£', '3', '2,000', ',', '▁a', '▁figure', '▁that', '▁has', '▁increased', '▁from', '▁the', '▁initial', '▁top', '▁pri', 'ze', '▁of', '▁£', '2', '5,000', '▁when', '▁the', '▁tournament', '▁first', '▁air', 'ed', '▁in', '▁April', '▁2008.', '▁There', '▁have', '▁been', '▁34', '▁Pri', 'ze', 'fighter', '▁tournament', 's', '▁so', '▁far', '▁featuring', '▁14', '▁different', '▁weight', '▁division', 's', '.', '▁The', '▁last', '▁tournament', '▁was', '▁held', '▁in', '▁2015.', '</s>']
02:40:13.114546: Failed Answer extraction: ['▁late', '▁2011']; Prompt: ['<s>', '▁When', '▁did', '▁construction', '▁on', '▁I', '-', '69', '▁begin', '?', '▁Inter', 'state', '▁69', '▁(', 'I', '-', '69)', '▁is', '▁an', '▁Inter', 'state', '▁Highway', '▁in', '▁the', '▁United', '▁States', '▁currently', '▁consist', 'ing', '▁of', '▁seven', '▁dis', 'jo', 'in', 'ted', '▁parts', '▁with', '▁an', '▁original', '▁continuo', 'us', '▁segment', '▁from', '▁Indiana', 'polis', ',', '▁Indiana', ',', '▁north', 'e', 'ast', '▁to', '▁the', '▁Canada', '–', 'US', '▁border', '▁in', '▁Port', '▁Hur', 'on', ',', '▁Michigan', ',', '▁at', '▁35', '5.8', '▁miles', '▁(', '57', '2.6', 'km', ').', '▁The', '▁remain', 'ing', '▁separate', 'd', '▁parts', '▁are', '▁various', 'ly', '▁completed', '▁and', '▁posted', '▁or', '▁un', 'post', 'ed', '▁parts', '▁of', '▁an', '▁extension', '▁south', 'west', '▁to', '▁the', '▁Mexican', '▁border', '▁in', '▁Texas', '.', '▁Of', '▁this', '▁extension', '—', 'nick', 'na', 'med', '▁the', '▁NA', 'FTA', '▁Super', 'high', 'way', '▁because', '▁it', '▁would', '▁help', '▁trade', '▁with', '▁Canada', '▁and', '▁Mexico', '▁', 'spur', 'red', '▁by', '▁the', '▁North', '▁American', '▁Free', '▁Trade', '▁Agreement', '—', 'fi', 've', '▁pieces', '▁near', '▁Corpus', '▁Christi', ',', '▁Houston', ',', '▁north', 'we', 'stern', '▁Mississippi', ',', '▁Mem', 'phi', 's', ',', '▁and', '▁Evans', 'ville', '▁have', '▁been', '▁new', 'ly', '▁built', '▁or', '▁upgrade', 'd', '▁and', '▁sign', 'post', 'ed', '▁as', '▁I', '-', '69', '.', '▁A', '▁six', 'th', '▁segment', '▁of', '▁I', '-', '69', '▁through', '▁Kentucky', '▁utili', 'zing', '▁that', '▁state', "'", 's', '▁existing', '▁park', 'way', '▁system', '▁and', '▁a', '▁section', '▁of', '▁I', '-24', '▁was', '▁established', '▁by', '▁federal', '▁legisla', 'tion', '▁in', '▁2008,', '▁but', '▁only', '▁a', '▁portion', '▁is', '▁sign', 'post', 'ed', '.', '▁A', '▁section', '▁of', '▁the', '▁previously', '▁existing', '▁Western', '▁Kentucky', '▁Park', 'way', '▁from', '▁E', 'ddy', 'ville', '▁to', '▁Norton', 'ville', '▁was', '▁approved', '▁and', '▁sign', 'post', 'ed', '▁in', '▁late', '▁2011,', '▁with', '▁the', '▁Pen', 'ny', 'rile', '▁Park', 'way', '▁between', '▁Norton', 'ville', '▁and', '▁Hend', 'er', 'son', '▁being', '▁signed', '▁as', '▁I', '-', '69', '▁in', '▁2015', '.[2]', '▁This', '▁bring', 's', '▁the', '▁total', '▁length', '▁to', '▁about', '▁', '680', '▁miles', '▁(1', ',', '090', 'km', ').', '</s>']
02:40:31.997651: Unanswerable questions: 3663
02:40:32.058726: Balance of labels: dict_keys([-100, 0, 1, 2]):dict_values([75223, 923125, 3299, 18400])
02:40:32.058787: Entries skipped due to too long sequence length (>512): 71
02:40:32.058838: Failed to map answer and to context: 356
02:40:32.116226: Label counts: O: 923125, B: 3299, I: 18400
02:40:32.116450: Final length: 6962 

02:40:32.140802: Language: english; Class weights: [0.00302124 0.84540343 0.15157532 0.        ]
02:40:32.313596: Training model: lab6_xlm-roberta-base_english.pt
02:40:32.315525: Loading model: xlm-roberta-base
02:40:35.349176: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 1/40
02:43:17.695000: Evaluating Language: english
02:43:17.695140: ----------
02:43:22.492129: OBI: 
 [[2700  504 1394]
 [   0   12    1]
 [  15    9  109]]
02:43:22.498136: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.59      0.74      4598
           1       0.02      0.92      0.04        13
           2       0.07      0.82      0.13       133

    accuracy                           0.59      4744
   macro avg       0.36      0.78      0.31      4744
weighted avg       0.97      0.59      0.72      4744
02:43:22.498193: ----------
02:43:22.498994: LR: 
 [[337 595]
 [  1  12]]
02:43:22.502221: LR: 
               precision    recall  f1-score   support

           0       1.00      0.36      0.53       932
           1       0.02      0.92      0.04        13

    accuracy                           0.37       945
   macro avg       0.51      0.64      0.28       945
weighted avg       0.98      0.37      0.52       945
02:43:22.504435: Validation Seq.Label F1: 0.3053970493216347; Log.Reg F1: 0.28470916941833885; train loss: 0.6120309233665466; Language: english 

02:43:22.504510: Evaluating Language: finnish
02:43:22.504574: ----------
02:43:29.708623: OBI: 
 [[2249  517 1270]
 [   1   23    0]
 [  52   23  125]]
02:43:29.714335: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.56      0.71      4036
           1       0.04      0.96      0.08        24
           2       0.09      0.62      0.16       200

    accuracy                           0.56      4260
   macro avg       0.37      0.71      0.31      4260
weighted avg       0.93      0.56      0.68      4260
02:43:29.714394: ----------
02:43:29.715437: LR: 
 [[625 947]
 [  3  21]]
02:43:29.719319: LR: 
               precision    recall  f1-score   support

           0       1.00      0.40      0.57      1572
           1       0.02      0.88      0.04        24

    accuracy                           0.40      1596
   macro avg       0.51      0.64      0.31      1596
weighted avg       0.98      0.40      0.56      1596
02:43:29.721509: Validation Seq.Label F1: 0.31493065870383646; Log.Reg F1: 0.3052602639296188; train loss: 0.6120309233665466; Language: finnish 

02:43:29.721578: Evaluating Language: japanese
02:43:29.721634: ----------
02:43:32.816055: OBI: 
 [[1076  106  394]
 [   1    0    0]
 [   6    1   10]]
02:43:32.818981: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.68      0.81      1576
           1       0.00      0.00      0.00         1
           2       0.02      0.59      0.05        17

    accuracy                           0.68      1594
   macro avg       0.34      0.42      0.29      1594
weighted avg       0.98      0.68      0.80      1594
02:43:32.819028: ----------
02:43:32.819591: LR: 
 [[444 145]
 [  1   0]]
02:43:32.822010: LR: 
               precision    recall  f1-score   support

           0       1.00      0.75      0.86       589
           1       0.00      0.00      0.00         1

    accuracy                           0.75       590
   macro avg       0.50      0.38      0.43       590
weighted avg       1.00      0.75      0.86       590
02:43:32.823592: Validation Seq.Label F1: 0.2856109176114107; Log.Reg F1: 0.42940038684719534; train loss: 0.6120309233665466; Language: japanese 

02:43:32.825020: Combined F1 SeqLab: 0.30222633559680917; train loss: 0.6120309233665466
02:43:33.900594: Combined F1 LogReg: 0.345749346641842; train loss: 0.6120309233665466 

02:43:33.902818: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 2/40
02:46:17.021299: Evaluating Language: english
02:46:17.021451: ----------
02:46:21.955345: OBI: 
 [[2761  197  423]
 [   0   10    1]
 [  14    4   99]]
02:46:21.959654: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.82      0.90      3381
           1       0.05      0.91      0.09        11
           2       0.19      0.85      0.31       117

    accuracy                           0.82      3509
   macro avg       0.41      0.86      0.43      3509
weighted avg       0.97      0.82      0.87      3509
02:46:21.959701: ----------
02:46:21.960402: LR: 
 [[355 579]
 [  1  10]]
02:46:21.963114: LR: 
               precision    recall  f1-score   support

           0       1.00      0.38      0.55       934
           1       0.02      0.91      0.03        11

    accuracy                           0.39       945
   macro avg       0.51      0.64      0.29       945
weighted avg       0.99      0.39      0.54       945
02:46:21.965227: Validation Seq.Label F1: 0.43215871207464773; Log.Reg F1: 0.29186046511627906; train loss: 0.40783989429473877; Language: english 

02:46:21.965293: Evaluating Language: finnish
02:46:21.965348: ----------
02:46:29.123145: OBI: 
 [[3197  314  635]
 [   1   17    2]
 [  83   24  239]]
02:46:29.128104: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.77      0.86      4146
           1       0.05      0.85      0.09        20
           2       0.27      0.69      0.39       346

    accuracy                           0.77      4512
   macro avg       0.43      0.77      0.45      4512
weighted avg       0.92      0.77      0.82      4512
02:46:29.128151: ----------
02:46:29.129022: LR: 
 [[1331  245]
 [  14    6]]
02:46:29.132279: LR: 
               precision    recall  f1-score   support

           0       0.99      0.84      0.91      1576
           1       0.02      0.30      0.04        20

    accuracy                           0.84      1596
   macro avg       0.51      0.57      0.48      1596
weighted avg       0.98      0.84      0.90      1596
02:46:29.134108: Validation Seq.Label F1: 0.4475805271815459; Log.Reg F1: 0.47780608925568885; train loss: 0.40783989429473877; Language: finnish 

02:46:29.134168: Evaluating Language: japanese
02:46:29.134216: ----------
02:46:32.178545: OBI: 
 [[695  22  64]
 [  0   1   0]
 [ 14   0   4]]
02:46:32.181261: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.89      0.93       781
           1       0.04      1.00      0.08         1
           2       0.06      0.22      0.09        18

    accuracy                           0.88       800
   macro avg       0.36      0.70      0.37       800
weighted avg       0.96      0.88      0.91       800
02:46:32.181314: ----------
02:46:32.181886: LR: 
 [[491  98]
 [  0   1]]
02:46:32.184506: LR: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.91       589
           1       0.01      1.00      0.02         1

    accuracy                           0.83       590
   macro avg       0.51      0.92      0.46       590
weighted avg       1.00      0.83      0.91       590
02:46:32.186526: Validation Seq.Label F1: 0.36974749839585175; Log.Reg F1: 0.4646296296296296; train loss: 0.40783989429473877; Language: japanese 

02:46:32.187897: Combined F1 SeqLab: 0.4178527225806238; train loss: 0.40783989429473877
02:46:34.192887: Combined F1 LogReg: 0.4200642342775181; train loss: 0.40783989429473877 

02:46:34.198892: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 3/40
02:49:15.813474: Evaluating Language: english
02:49:15.813594: ----------
02:49:20.636068: OBI: 
 [[4385  201  827]
 [   1   20    1]
 [  25    5  145]]
02:49:20.641631: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.81      0.89      5413
           1       0.09      0.91      0.16        22
           2       0.15      0.83      0.25       175

    accuracy                           0.81      5610
   macro avg       0.41      0.85      0.44      5610
weighted avg       0.96      0.81      0.87      5610
02:49:20.641679: ----------
02:49:20.642361: LR: 
 [[411 512]
 [  0  22]]
02:49:20.645111: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62       923
           1       0.04      1.00      0.08        22

    accuracy                           0.46       945
   macro avg       0.52      0.72      0.35       945
weighted avg       0.98      0.46      0.60       945
02:49:20.646882: Validation Seq.Label F1: 0.4355384297943761; Log.Reg F1: 0.34766429734772897; train loss: 0.3159961402416229; Language: english 

02:49:20.646940: Evaluating Language: finnish
02:49:20.646986: ----------
02:49:27.693843: OBI: 
 [[3839  215  942]
 [   1   21    3]
 [  31   14  278]]
02:49:27.699209: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.77      0.87      4996
           1       0.08      0.84      0.15        25
           2       0.23      0.86      0.36       323

    accuracy                           0.77      5344
   macro avg       0.43      0.82      0.46      5344
weighted avg       0.94      0.77      0.83      5344
02:49:27.699256: ----------
02:49:27.700136: LR: 
 [[ 419 1152]
 [   5   20]]
02:49:27.703365: LR: 
               precision    recall  f1-score   support

           0       0.99      0.27      0.42      1571
           1       0.02      0.80      0.03        25

    accuracy                           0.28      1596
   macro avg       0.50      0.53      0.23      1596
weighted avg       0.97      0.28      0.41      1596
02:49:27.705130: Validation Seq.Label F1: 0.4594241147828056; Log.Reg F1: 0.22673350041771093; train loss: 0.3159961402416229; Language: finnish 

02:49:27.705185: Evaluating Language: japanese
02:49:27.705232: ----------
02:49:30.734269: OBI: 
 [[348   4  52]
 [  0   1   0]
 [  0   1   2]]
02:49:30.736465: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.93       404
           1       0.17      1.00      0.29         1
           2       0.04      0.67      0.07         3

    accuracy                           0.86       408
   macro avg       0.40      0.84      0.43       408
weighted avg       0.99      0.86      0.92       408
02:49:30.736509: ----------
02:49:30.737068: LR: 
 [[226 363]
 [  0   1]]
02:49:30.739501: LR: 
               precision    recall  f1-score   support

           0       1.00      0.38      0.55       589
           1       0.00      1.00      0.01         1

    accuracy                           0.38       590
   macro avg       0.50      0.69      0.28       590
weighted avg       1.00      0.38      0.55       590
02:49:30.741047: Validation Seq.Label F1: 0.42714054640146465; Log.Reg F1: 0.2800403395243298; train loss: 0.3159961402416229; Language: japanese 

02:49:30.742294: Combined F1 SeqLab: 0.44091317643116434; train loss: 0.3159961402416229
02:49:31.668195: Combined F1 LogReg: 0.28907965201241687; train loss: 0.3159961402416229 

02:49:31.669340: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 4/40
02:52:17.430959: Evaluating Language: english
02:52:17.431111: ----------
02:52:22.334418: OBI: 
 [[2842  155  340]
 [   1   14    2]
 [  33    8  137]]
02:52:22.338747: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.85      0.91      3337
           1       0.08      0.82      0.14        17
           2       0.29      0.77      0.42       178

    accuracy                           0.85      3532
   macro avg       0.45      0.81      0.49      3532
weighted avg       0.95      0.85      0.89      3532
02:52:22.338793: ----------
02:52:22.339486: LR: 
 [[410 518]
 [  2  15]]
02:52:22.342186: LR: 
               precision    recall  f1-score   support

           0       1.00      0.44      0.61       928
           1       0.03      0.88      0.05        17

    accuracy                           0.45       945
   macro avg       0.51      0.66      0.33       945
weighted avg       0.98      0.45      0.60       945
02:52:22.344198: Validation Seq.Label F1: 0.4920776760950522; Log.Reg F1: 0.3332428765264587; train loss: 0.23462612926959991; Language: english 

02:52:22.344265: Evaluating Language: finnish
02:52:22.344319: ----------
02:52:29.291979: OBI: 
 [[3687  188  494]
 [   2   20    0]
 [  87   16  154]]
02:52:29.296923: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.84      0.91      4369
           1       0.09      0.91      0.16        22
           2       0.24      0.60      0.34       257

    accuracy                           0.83      4648
   macro avg       0.43      0.78      0.47      4648
weighted avg       0.93      0.83      0.87      4648
02:52:29.296970: ----------
02:52:29.297845: LR: 
 [[1248  326]
 [  12   10]]
02:52:29.301044: LR: 
               precision    recall  f1-score   support

           0       0.99      0.79      0.88      1574
           1       0.03      0.45      0.06        22

    accuracy                           0.79      1596
   macro avg       0.51      0.62      0.47      1596
weighted avg       0.98      0.79      0.87      1596
02:52:29.302705: Validation Seq.Label F1: 0.46942460584826845; Log.Reg F1: 0.4682999333709189; train loss: 0.23462612926959991; Language: finnish 

02:52:29.302762: Evaluating Language: japanese
02:52:29.302808: ----------
02:52:32.412994: OBI: 
 [[652  10  28]
 [  0   0   0]
 [  4   0   0]]
02:52:32.415492: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.97       690
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         4

    accuracy                           0.94       694
   macro avg       0.33      0.31      0.32       694
weighted avg       0.99      0.94      0.96       694
02:52:32.415537: ----------
02:52:32.416093: LR: 
 [[551  39]
 [  0   0]]
02:52:32.418644: LR: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.97       590
           1       0.00      0.00      0.00         0

    accuracy                           0.93       590
   macro avg       0.50      0.47      0.48       590
weighted avg       1.00      0.93      0.97       590
02:52:32.420265: Validation Seq.Label F1: 0.3229321446260525; Log.Reg F1: 0.4829097283085013; train loss: 0.23462612926959991; Language: japanese 

02:52:32.421537: Combined F1 SeqLab: 0.4346588968834033; train loss: 0.23462612926959991
02:52:32.422790: Combined F1 LogReg: 0.43341952272820167; train loss: 0.23462612926959991 

02:52:32.425887: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 5/40
02:55:15.843430: Evaluating Language: english
02:55:15.843575: ----------
02:55:20.674946: OBI: 
 [[3207  106  315]
 [   1    7    1]
 [  11    7  138]]
02:55:20.679322: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.94      3628
           1       0.06      0.78      0.11         9
           2       0.30      0.88      0.45       156

    accuracy                           0.88      3793
   macro avg       0.45      0.85      0.50      3793
weighted avg       0.97      0.88      0.91      3793
02:55:20.679368: ----------
02:55:20.680034: LR: 
 [[427 509]
 [  2   7]]
02:55:20.682724: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63       936
           1       0.01      0.78      0.03         9

    accuracy                           0.46       945
   macro avg       0.50      0.62      0.33       945
weighted avg       0.99      0.46      0.62       945
02:55:20.684747: Validation Seq.Label F1: 0.4992489244225564; Log.Reg F1: 0.3261538461538461; train loss: 0.18634085357189178; Language: english 

02:55:20.684804: Evaluating Language: finnish
02:55:20.684850: ----------
02:55:27.790747: OBI: 
 [[4995  250  602]
 [   4   29    3]
 [ 132    9  232]]
02:55:27.796740: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.85      0.91      5847
           1       0.10      0.81      0.18        36
           2       0.28      0.62      0.38       373

    accuracy                           0.84      6256
   macro avg       0.45      0.76      0.49      6256
weighted avg       0.93      0.84      0.87      6256
02:55:27.796786: ----------
02:55:27.797650: LR: 
 [[1327  233]
 [  26   10]]
02:55:27.800876: LR: 
               precision    recall  f1-score   support

           0       0.98      0.85      0.91      1560
           1       0.04      0.28      0.07        36

    accuracy                           0.84      1596
   macro avg       0.51      0.56      0.49      1596
weighted avg       0.96      0.84      0.89      1596
02:55:27.802606: Validation Seq.Label F1: 0.4908284139615489; Log.Reg F1: 0.4913864065055056; train loss: 0.18634085357189178; Language: finnish 

02:55:27.802661: Evaluating Language: japanese
02:55:27.802706: ----------
02:55:30.837095: OBI: 
 [[1367   16  106]
 [   0    2    0]
 [   0    0    7]]
02:55:30.839899: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96      1489
           1       0.11      1.00      0.20         2
           2       0.06      1.00      0.12         7

    accuracy                           0.92      1498
   macro avg       0.39      0.97      0.42      1498
weighted avg       0.99      0.92      0.95      1498
02:55:30.839943: ----------
02:55:30.840499: LR: 
 [[432 156]
 [  1   1]]
02:55:30.842886: LR: 
               precision    recall  f1-score   support

           0       1.00      0.73      0.85       588
           1       0.01      0.50      0.01         2

    accuracy                           0.73       590
   macro avg       0.50      0.62      0.43       590
weighted avg       0.99      0.73      0.84       590
02:55:30.844462: Validation Seq.Label F1: 0.42464985994397764; Log.Reg F1: 0.42940390171184994; train loss: 0.18634085357189178; Language: japanese 

02:55:30.845718: Combined F1 SeqLab: 0.47275417291989746; train loss: 0.18634085357189178
02:55:32.909951: Combined F1 LogReg: 0.4211985448948832; train loss: 0.18634085357189178 

02:55:32.910745: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 6/40
02:58:18.902153: Evaluating Language: english
02:58:18.902284: ----------
02:58:23.845197: OBI: 
 [[2778   84  327]
 [   1   11    2]
 [  23    2  100]]
02:58:23.849252: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.87      0.93      3189
           1       0.11      0.79      0.20        14
           2       0.23      0.80      0.36       125

    accuracy                           0.87      3328
   macro avg       0.45      0.82      0.50      3328
weighted avg       0.96      0.87      0.90      3328
02:58:23.849297: ----------
02:58:23.849971: LR: 
 [[422 509]
 [  3  11]]
02:58:23.852727: LR: 
               precision    recall  f1-score   support

           0       0.99      0.45      0.62       931
           1       0.02      0.79      0.04        14

    accuracy                           0.46       945
   macro avg       0.51      0.62      0.33       945
weighted avg       0.98      0.46      0.61       945
02:58:23.854646: Validation Seq.Label F1: 0.49553337171768425; Log.Reg F1: 0.3318086904643532; train loss: 0.1690940111875534; Language: english 

02:58:23.854707: Evaluating Language: finnish
02:58:23.854753: ----------
02:58:30.989468: OBI: 
 [[3274  121  453]
 [   2   19    2]
 [  92    4  161]]
02:58:30.994008: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.85      0.91      3848
           1       0.13      0.83      0.23        23
           2       0.26      0.63      0.37       257

    accuracy                           0.84      4128
   macro avg       0.46      0.77      0.50      4128
weighted avg       0.92      0.84      0.87      4128
02:58:30.994053: ----------
02:58:30.994916: LR: 
 [[842 731]
 [  4  19]]
02:58:30.998182: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70      1573
           1       0.03      0.83      0.05        23

    accuracy                           0.54      1596
   macro avg       0.51      0.68      0.37      1596
weighted avg       0.98      0.54      0.69      1596
02:58:30.999925: Validation Seq.Label F1: 0.5012719726564604; Log.Reg F1: 0.37265727822055555; train loss: 0.1690940111875534; Language: finnish 

02:58:30.999981: Evaluating Language: japanese
02:58:31.000026: ----------
02:58:34.173442: OBI: 
 [[2302   31  166]
 [   0    2    0]
 [   0    0    9]]
02:58:34.176878: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96      2499
           1       0.06      1.00      0.11         2
           2       0.05      1.00      0.10         9

    accuracy                           0.92      2510
   macro avg       0.37      0.97      0.39      2510
weighted avg       1.00      0.92      0.96      2510
02:58:34.176922: ----------
02:58:34.177480: LR: 
 [[455 133]
 [  0   2]]
02:58:34.179864: LR: 
               precision    recall  f1-score   support

           0       1.00      0.77      0.87       588
           1       0.01      1.00      0.03         2

    accuracy                           0.77       590
   macro avg       0.51      0.89      0.45       590
weighted avg       1.00      0.77      0.87       590
02:58:34.181470: Validation Seq.Label F1: 0.3903595610472801; Log.Reg F1: 0.45084015088424045; train loss: 0.1690940111875534; Language: japanese 

02:58:34.182753: Combined F1 SeqLab: 0.4651908210465253; train loss: 0.1690940111875534
02:58:34.184034: Combined F1 LogReg: 0.388255627015564; train loss: 0.1690940111875534 

02:58:34.184629: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 7/40
03:01:19.140624: Evaluating Language: english
03:01:19.141010: ----------
03:01:24.103645: OBI: 
 [[4184  129  388]
 [   2   20    4]
 [  19    5  109]]
03:01:24.108798: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94      4701
           1       0.13      0.77      0.22        26
           2       0.22      0.82      0.34       133

    accuracy                           0.89      4860
   macro avg       0.45      0.83      0.50      4860
weighted avg       0.97      0.89      0.92      4860
03:01:24.108843: ----------
03:01:24.109543: LR: 
 [[428 491]
 [  5  21]]
03:01:24.112245: LR: 
               precision    recall  f1-score   support

           0       0.99      0.47      0.63       919
           1       0.04      0.81      0.08        26

    accuracy                           0.48       945
   macro avg       0.51      0.64      0.36       945
weighted avg       0.96      0.48      0.62       945
03:01:24.116089: Validation Seq.Label F1: 0.5018873631456082; Log.Reg F1: 0.35560150458634876; train loss: 0.12337033450603485; Language: english 

03:01:24.116154: Evaluating Language: finnish
03:01:24.116201: ----------
03:01:31.169500: OBI: 
 [[3485  106  359]
 [   1   17    3]
 [  40    6  187]]
03:01:31.174191: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      3950
           1       0.13      0.81      0.23        21
           2       0.34      0.80      0.48       233

    accuracy                           0.88      4204
   macro avg       0.49      0.83      0.55      4204
weighted avg       0.95      0.88      0.90      4204
03:01:31.174236: ----------
03:01:31.175112: LR: 
 [[1163  412]
 [  10   11]]
03:01:31.178337: LR: 
               precision    recall  f1-score   support

           0       0.99      0.74      0.85      1575
           1       0.03      0.52      0.05        21

    accuracy                           0.74      1596
   macro avg       0.51      0.63      0.45      1596
weighted avg       0.98      0.74      0.84      1596
03:01:31.180083: Validation Seq.Label F1: 0.5457480943851242; Log.Reg F1: 0.4479916597820528; train loss: 0.12337033450603485; Language: finnish 

03:01:31.180139: Evaluating Language: japanese
03:01:31.180184: ----------
03:01:34.260890: OBI: 
 [[930  13  51]
 [  0   0   0]
 [  0   0   4]]
03:01:34.263772: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97       994
           1       0.00      0.00      0.00         0
           2       0.07      1.00      0.14         4

    accuracy                           0.94       998
   macro avg       0.36      0.65      0.37       998
weighted avg       1.00      0.94      0.96       998
03:01:34.263816: ----------
03:01:34.264383: LR: 
 [[390 200]
 [  0   0]]
03:01:34.266949: LR: 
               precision    recall  f1-score   support

           0       1.00      0.66      0.80       590
           1       0.00      0.00      0.00         0

    accuracy                           0.66       590
   macro avg       0.50      0.33      0.40       590
weighted avg       1.00      0.66      0.80       590
03:01:34.268546: Validation Seq.Label F1: 0.36744306235831664; Log.Reg F1: 0.3979591836734694; train loss: 0.12337033450603485; Language: japanese 

03:01:34.269923: Combined F1 SeqLab: 0.47775388080946163; train loss: 0.12337033450603485
03:01:36.252933: Combined F1 LogReg: 0.4022936196231171; train loss: 0.12337033450603485 

03:01:36.256637: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 8/40
03:04:18.205422: Evaluating Language: english
03:04:18.205555: ----------
03:04:23.026195: OBI: 
 [[3556  159  641]
 [   2   12    3]
 [   7    2  114]]
03:04:23.031019: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.82      0.90      4356
           1       0.07      0.71      0.13        17
           2       0.15      0.93      0.26       123

    accuracy                           0.82      4496
   macro avg       0.41      0.82      0.43      4496
weighted avg       0.97      0.82      0.88      4496
03:04:23.031065: ----------
03:04:23.031745: LR: 
 [[384 544]
 [  2  15]]
03:04:23.034473: LR: 
               precision    recall  f1-score   support

           0       0.99      0.41      0.58       928
           1       0.03      0.88      0.05        17

    accuracy                           0.42       945
   macro avg       0.51      0.65      0.32       945
weighted avg       0.98      0.42      0.57       945
03:04:23.036476: Validation Seq.Label F1: 0.42765968075776223; Log.Reg F1: 0.31827910958904115; train loss: 0.12031787633895874; Language: english 

03:04:23.036542: Evaluating Language: finnish
03:04:23.036590: ----------
03:04:30.052754: OBI: 
 [[2714  133  519]
 [   0   14    6]
 [  24    2  140]]
03:04:30.056954: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.81      0.89      3366
           1       0.09      0.70      0.17        20
           2       0.21      0.84      0.34       166

    accuracy                           0.81      3552
   macro avg       0.43      0.78      0.46      3552
weighted avg       0.95      0.81      0.86      3552
03:04:30.056999: ----------
03:04:30.057867: LR: 
 [[850 726]
 [  6  14]]
03:04:30.061101: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70      1576
           1       0.02      0.70      0.04        20

    accuracy                           0.54      1596
   macro avg       0.51      0.62      0.37      1596
weighted avg       0.98      0.54      0.69      1596
03:04:30.062798: Validation Seq.Label F1: 0.46395895463177994; Log.Reg F1: 0.3679276315789474; train loss: 0.12031787633895874; Language: finnish 

03:04:30.062853: Evaluating Language: japanese
03:04:30.062899: ----------
03:04:33.149545: OBI: 
 [[380  17  76]
 [  0   0   0]
 [  0   0   1]]
03:04:33.152238: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.80      0.89       473
           1       0.00      0.00      0.00         0
           2       0.01      1.00      0.03         1

    accuracy                           0.80       474
   macro avg       0.34      0.60      0.31       474
weighted avg       1.00      0.80      0.89       474
03:04:33.152290: ----------
03:04:33.152949: LR: 
 [[546  44]
 [  0   0]]
03:04:33.155862: LR: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96       590
           1       0.00      0.00      0.00         0

    accuracy                           0.93       590
   macro avg       0.50      0.46      0.48       590
weighted avg       1.00      0.93      0.96       590
03:04:33.157386: Validation Seq.Label F1: 0.30553802066111563; Log.Reg F1: 0.48063380281690143; train loss: 0.12031787633895874; Language: japanese 

03:04:33.158657: Combined F1 SeqLab: 0.4047650331564217; train loss: 0.12031787633895874
03:04:33.159922: Combined F1 LogReg: 0.3948337988277779; train loss: 0.12031787633895874 

03:04:33.160483: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 9/40
03:07:20.776900: Evaluating Language: english
03:07:20.777082: ----------
03:07:25.666615: OBI: 
 [[3434  120  360]
 [   0   20    5]
 [  22    7  181]]
03:07:25.671351: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      3914
           1       0.14      0.80      0.23        25
           2       0.33      0.86      0.48       210

    accuracy                           0.88      4149
   macro avg       0.49      0.85      0.55      4149
weighted avg       0.95      0.88      0.90      4149
03:07:25.671397: ----------
03:07:25.672091: LR: 
 [[420 500]
 [  4  21]]
03:07:25.674808: LR: 
               precision    recall  f1-score   support

           0       0.99      0.46      0.62       920
           1       0.04      0.84      0.08        25

    accuracy                           0.47       945
   macro avg       0.52      0.65      0.35       945
weighted avg       0.97      0.47      0.61       945
03:07:25.677164: Validation Seq.Label F1: 0.5477600475980668; Log.Reg F1: 0.35096153846153844; train loss: 0.12010757625102997; Language: english 

03:07:25.677230: Evaluating Language: finnish
03:07:25.677276: ----------
03:07:32.746439: OBI: 
 [[3130  125  515]
 [   0   19    1]
 [  35    3  140]]
03:07:32.750882: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.83      0.90      3770
           1       0.13      0.95      0.23        20
           2       0.21      0.79      0.34       178

    accuracy                           0.83      3968
   macro avg       0.44      0.86      0.49      3968
weighted avg       0.95      0.83      0.87      3968
03:07:32.750927: ----------
03:07:32.751794: LR: 
 [[737 839]
 [  2  18]]
03:07:32.755021: LR: 
               precision    recall  f1-score   support

           0       1.00      0.47      0.64      1576
           1       0.02      0.90      0.04        20

    accuracy                           0.47      1596
   macro avg       0.51      0.68      0.34      1596
weighted avg       0.99      0.47      0.63      1596
03:07:32.756854: Validation Seq.Label F1: 0.48864798434059703; Log.Reg F1: 0.3388830467108812; train loss: 0.12010757625102997; Language: finnish 

03:07:32.756911: Evaluating Language: japanese
03:07:32.756956: ----------
03:07:35.925635: OBI: 
 [[368   9  58]
 [  0   1   0]
 [  3   0   1]]
03:07:35.927838: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.85      0.91       435
           1       0.10      1.00      0.18         1
           2       0.02      0.25      0.03         4

    accuracy                           0.84       440
   macro avg       0.37      0.70      0.38       440
weighted avg       0.98      0.84      0.90       440
03:07:35.927883: ----------
03:07:35.928445: LR: 
 [[520  69]
 [  1   0]]
03:07:35.930812: LR: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.94       589
           1       0.00      0.00      0.00         1

    accuracy                           0.88       590
   macro avg       0.50      0.44      0.47       590
weighted avg       1.00      0.88      0.94       590
03:07:35.932438: Validation Seq.Label F1: 0.37557185944282717; Log.Reg F1: 0.4684684684684684; train loss: 0.12010757625102997; Language: japanese 

03:07:35.933733: Combined F1 SeqLab: 0.4760504678953369; train loss: 0.12010757625102997
03:07:35.935016: Combined F1 LogReg: 0.39050327645937943; train loss: 0.12010757625102997 

03:07:35.935607: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 10/40
03:10:21.574652: Evaluating Language: english
03:10:21.574803: ----------
03:10:26.421010: OBI: 
 [[3400   69  353]
 [   1   10    2]
 [  29    3   78]]
03:10:26.426280: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      3822
           1       0.12      0.77      0.21        13
           2       0.18      0.71      0.29       110

    accuracy                           0.88      3945
   macro avg       0.43      0.79      0.48      3945
weighted avg       0.97      0.88      0.92      3945
03:10:26.426342: ----------
03:10:26.427132: LR: 
 [[406 526]
 [  1  12]]
03:10:26.430403: LR: 
               precision    recall  f1-score   support

           0       1.00      0.44      0.61       932
           1       0.02      0.92      0.04        13

    accuracy                           0.44       945
   macro avg       0.51      0.68      0.32       945
weighted avg       0.98      0.44      0.60       945
03:10:26.432645: Validation Seq.Label F1: 0.47849716657094216; Log.Reg F1: 0.32498993614705557; train loss: 0.09189926087856293; Language: english 

03:10:26.432713: Evaluating Language: finnish
03:10:26.432767: ----------
03:10:33.389877: OBI: 
 [[2850   96  497]
 [   0   19    5]
 [  52    3  210]]
03:10:33.394192: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.83      0.90      3443
           1       0.16      0.79      0.27        24
           2       0.29      0.79      0.43       265

    accuracy                           0.83      3732
   macro avg       0.48      0.80      0.53      3732
weighted avg       0.93      0.83      0.86      3732
03:10:33.394234: ----------
03:10:33.395106: LR: 
 [[955 617]
 [  4  20]]
03:10:33.398342: LR: 
               precision    recall  f1-score   support

           0       1.00      0.61      0.75      1572
           1       0.03      0.83      0.06        24

    accuracy                           0.61      1596
   macro avg       0.51      0.72      0.41      1596
weighted avg       0.98      0.61      0.74      1596
03:10:33.400130: Validation Seq.Label F1: 0.5319460659690808; Log.Reg F1: 0.4075784029920065; train loss: 0.09189926087856293; Language: finnish 

03:10:33.400195: Evaluating Language: japanese
03:10:33.400248: ----------
03:10:36.379449: OBI: 
 [[1157   23  169]
 [   0    1    0]
 [   0    0    4]]
03:10:36.382188: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92      1349
           1       0.04      1.00      0.08         1
           2       0.02      1.00      0.05         4

    accuracy                           0.86      1354
   macro avg       0.35      0.95      0.35      1354
weighted avg       1.00      0.86      0.92      1354
03:10:36.382232: ----------
03:10:36.382788: LR: 
 [[506  83]
 [  0   1]]
03:10:36.385166: LR: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92       589
           1       0.01      1.00      0.02         1

    accuracy                           0.86       590
   macro avg       0.51      0.93      0.47       590
weighted avg       1.00      0.86      0.92       590
03:10:36.386754: Validation Seq.Label F1: 0.34952720626804523; Log.Reg F1: 0.47386516250335753; train loss: 0.09189926087856293; Language: japanese 

03:10:36.388014: Combined F1 SeqLab: 0.45974464776219215; train loss: 0.09189926087856293
03:10:36.389264: Combined F1 LogReg: 0.40672956019805717; train loss: 0.09189926087856293 

03:10:36.389846: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 11/40
03:13:21.672433: Evaluating Language: english
03:13:21.672558: ----------
03:13:26.500986: OBI: 
 [[3771   71  205]
 [   2   18    1]
 [  39    1  110]]
03:13:26.505605: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      4047
           1       0.20      0.86      0.32        21
           2       0.35      0.73      0.47       150

    accuracy                           0.92      4218
   macro avg       0.51      0.84      0.59      4218
weighted avg       0.96      0.92      0.94      4218
03:13:26.505650: ----------
03:13:26.506321: LR: 
 [[445 479]
 [  2  19]]
03:13:26.509016: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65       924
           1       0.04      0.90      0.07        21

    accuracy                           0.49       945
   macro avg       0.52      0.69      0.36       945
weighted avg       0.97      0.49      0.64       945
03:13:26.511025: Validation Seq.Label F1: 0.5853638026718614; Log.Reg F1: 0.3611894613020326; train loss: 0.0923345759510994; Language: english 

03:13:26.511081: Evaluating Language: finnish
03:13:26.511126: ----------
03:13:33.667742: OBI: 
 [[1921   36  195]
 [   1    8    2]
 [  42    1   98]]
03:13:33.671076: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.89      0.93      2152
           1       0.18      0.73      0.29        11
           2       0.33      0.70      0.45       141

    accuracy                           0.88      2304
   macro avg       0.50      0.77      0.56      2304
weighted avg       0.93      0.88      0.90      2304
03:13:33.671120: ----------
03:13:33.671979: LR: 
 [[947 638]
 [  4   7]]
03:13:33.675206: LR: 
               precision    recall  f1-score   support

           0       1.00      0.60      0.75      1585
           1       0.01      0.64      0.02        11

    accuracy                           0.60      1596
   macro avg       0.50      0.62      0.38      1596
weighted avg       0.99      0.60      0.74      1596
03:13:33.676884: Validation Seq.Label F1: 0.5562286950603744; Log.Reg F1: 0.38409344464107104; train loss: 0.0923345759510994; Language: finnish 

03:13:33.676940: Evaluating Language: japanese
03:13:33.676987: ----------
03:13:36.757572: OBI: 
 [[866   2  23]
 [  0   0   0]
 [  3   0   0]]
03:13:36.760171: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.97      0.98       891
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         3

    accuracy                           0.97       894
   macro avg       0.33      0.32      0.33       894
weighted avg       0.99      0.97      0.98       894
03:13:36.760214: ----------
03:13:36.760772: LR: 
 [[555  35]
 [  0   0]]
03:13:36.763297: LR: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97       590
           1       0.00      0.00      0.00         0

    accuracy                           0.94       590
   macro avg       0.50      0.47      0.48       590
weighted avg       1.00      0.94      0.97       590
03:13:36.764973: Validation Seq.Label F1: 0.328030303030303; Log.Reg F1: 0.48471615720524014; train loss: 0.0923345759510994; Language: japanese 

03:13:36.766277: Combined F1 SeqLab: 0.5032047371243575; train loss: 0.0923345759510994
03:13:38.842605: Combined F1 LogReg: 0.4134954067571211; train loss: 0.0923345759510994 

03:13:38.847475: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 12/40
03:16:27.314477: Evaluating Language: english
03:16:27.316839: ----------
03:16:32.113465: OBI: 
 [[4650   61  138]
 [   1   20    2]
 [  38    6  181]]
03:16:32.118794: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      4849
           1       0.23      0.87      0.36        23
           2       0.56      0.80      0.66       225

    accuracy                           0.95      5097
   macro avg       0.60      0.88      0.67      5097
weighted avg       0.97      0.95      0.96      5097
03:16:32.118846: ----------
03:16:32.119565: LR: 
 [[454 468]
 [  1  22]]
03:16:32.122288: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       922
           1       0.04      0.96      0.09        23

    accuracy                           0.50       945
   macro avg       0.52      0.72      0.37       945
weighted avg       0.97      0.50      0.65       945
03:16:32.126922: Validation Seq.Label F1: 0.6672290687807566; Log.Reg F1: 0.37258724152429; train loss: 0.08488865941762924; Language: english 

03:16:32.127185: Evaluating Language: finnish
03:16:32.127231: ----------
03:16:39.300254: OBI: 
 [[3742   79  322]
 [   3   16    5]
 [ 134    8  139]]
03:16:39.305022: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.90      0.93      4143
           1       0.16      0.67      0.25        24
           2       0.30      0.49      0.37       281

    accuracy                           0.88      4448
   macro avg       0.47      0.69      0.52      4448
weighted avg       0.92      0.88      0.89      4448
03:16:39.305068: ----------
03:16:39.305945: LR: 
 [[1252  320]
 [   9   15]]
03:16:39.309169: LR: 
               precision    recall  f1-score   support

           0       0.99      0.80      0.88      1572
           1       0.04      0.62      0.08        24

    accuracy                           0.79      1596
   macro avg       0.52      0.71      0.48      1596
weighted avg       0.98      0.79      0.87      1596
03:16:39.310962: Validation Seq.Label F1: 0.5190194073571919; Log.Reg F1: 0.48371707502209826; train loss: 0.08488865941762924; Language: finnish 

03:16:39.311019: Evaluating Language: japanese
03:16:39.311063: ----------
03:16:42.354204: OBI: 
 [[1179    6   28]
 [   0    0    0]
 [  31    0    4]]
03:16:42.357021: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.97      0.97      1213
           1       0.00      0.00      0.00         0
           2       0.12      0.11      0.12        35

    accuracy                           0.95      1248
   macro avg       0.37      0.36      0.36      1248
weighted avg       0.95      0.95      0.95      1248
03:16:42.357064: ----------
03:16:42.357662: LR: 
 [[527  63]
 [  0   0]]
03:16:42.360232: LR: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94       590
           1       0.00      0.00      0.00         0

    accuracy                           0.89       590
   macro avg       0.50      0.45      0.47       590
weighted avg       1.00      0.89      0.94       590
03:16:42.361895: Validation Seq.Label F1: 0.36419224554076496; Log.Reg F1: 0.4717994628469114; train loss: 0.08488865941762924; Language: japanese 

03:16:42.363197: Combined F1 SeqLab: 0.5314169007322064; train loss: 0.08488865941762924
03:16:44.351740: Combined F1 LogReg: 0.4454953027650789; train loss: 0.08488865941762924 

03:16:44.356648: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 13/40
03:19:27.309567: Evaluating Language: english
03:19:27.309732: ----------
03:19:32.199728: OBI: 
 [[4319   84  319]
 [   2   12    6]
 [  37    3  127]]
03:19:32.204772: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      4722
           1       0.12      0.60      0.20        20
           2       0.28      0.76      0.41       167

    accuracy                           0.91      4909
   macro avg       0.46      0.76      0.52      4909
weighted avg       0.96      0.91      0.93      4909
03:19:32.204817: ----------
03:19:32.205484: LR: 
 [[380 545]
 [  0  20]]
03:19:32.208174: LR: 
               precision    recall  f1-score   support

           0       1.00      0.41      0.58       925
           1       0.04      1.00      0.07        20

    accuracy                           0.42       945
   macro avg       0.52      0.71      0.33       945
weighted avg       0.98      0.42      0.57       945
03:19:32.210217: Validation Seq.Label F1: 0.521113838345968; Log.Reg F1: 0.3253757736516357; train loss: 0.07917116582393646; Language: english 

03:19:32.210277: Evaluating Language: finnish
03:19:32.210328: ----------
03:19:39.187160: OBI: 
 [[3516   89  295]
 [   5   29    2]
 [  53    6  165]]
03:19:39.191757: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.90      0.94      3900
           1       0.23      0.81      0.36        36
           2       0.36      0.74      0.48       224

    accuracy                           0.89      4160
   macro avg       0.52      0.81      0.59      4160
weighted avg       0.94      0.89      0.91      4160
03:19:39.191803: ----------
03:19:39.192663: LR: 
 [[1082  478]
 [  13   23]]
03:19:39.195881: LR: 
               precision    recall  f1-score   support

           0       0.99      0.69      0.82      1560
           1       0.05      0.64      0.09        36

    accuracy                           0.69      1596
   macro avg       0.52      0.67      0.45      1596
weighted avg       0.97      0.69      0.80      1596
03:19:39.197684: Validation Seq.Label F1: 0.5948037388050522; Log.Reg F1: 0.450363496722743; train loss: 0.07917116582393646; Language: finnish 

03:19:39.197752: Evaluating Language: japanese
03:19:39.197796: ----------
03:19:42.415393: OBI: 
 [[854   4  21]
 [  0   0   0]
 [ 13   0   0]]
03:19:42.418488: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.97      0.98       879
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00        13

    accuracy                           0.96       892
   macro avg       0.33      0.32      0.33       892
weighted avg       0.97      0.96      0.96       892
03:19:42.418532: ----------
03:19:42.419079: LR: 
 [[495  95]
 [  0   0]]
03:19:42.422067: LR: 
               precision    recall  f1-score   support

           0       1.00      0.84      0.91       590
           1       0.00      0.00      0.00         0

    accuracy                           0.84       590
   macro avg       0.50      0.42      0.46       590
weighted avg       1.00      0.84      0.91       590
03:19:42.423931: Validation Seq.Label F1: 0.3260786559755632; Log.Reg F1: 0.45622119815668205; train loss: 0.07917116582393646; Language: japanese 

03:19:42.425632: Combined F1 SeqLab: 0.4938550428668201; train loss: 0.07917116582393646
03:19:42.427135: Combined F1 LogReg: 0.41506403317530627; train loss: 0.07917116582393646 

03:19:42.427804: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 14/40
03:22:27.787673: Evaluating Language: english
03:22:27.787834: ----------
03:22:32.655504: OBI: 
 [[4279   58  185]
 [   1   10    4]
 [  16    2  123]]
03:22:32.660495: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.95      0.97      4522
           1       0.14      0.67      0.24        15
           2       0.39      0.87      0.54       141

    accuracy                           0.94      4678
   macro avg       0.51      0.83      0.58      4678
weighted avg       0.98      0.94      0.96      4678
03:22:32.660539: ----------
03:22:32.661228: LR: 
 [[383 547]
 [  2  13]]
03:22:32.663963: LR: 
               precision    recall  f1-score   support

           0       0.99      0.41      0.58       930
           1       0.02      0.87      0.05        15

    accuracy                           0.42       945
   macro avg       0.51      0.64      0.31       945
weighted avg       0.98      0.42      0.57       945
03:22:32.666446: Validation Seq.Label F1: 0.5829517770797882; Log.Reg F1: 0.3138634485038849; train loss: 0.05949391797184944; Language: english 

03:22:32.666510: Evaluating Language: finnish
03:22:32.666557: ----------
03:22:39.690396: OBI: 
 [[3182   55  200]
 [   3   12    4]
 [  67    4   89]]
03:22:39.695424: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      3437
           1       0.17      0.63      0.27        19
           2       0.30      0.56      0.39       160

    accuracy                           0.91      3616
   macro avg       0.48      0.70      0.54      3616
weighted avg       0.94      0.91      0.92      3616
03:22:39.695479: ----------
03:22:39.696485: LR: 
 [[848 729]
 [  7  12]]
03:22:39.700184: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70      1577
           1       0.02      0.63      0.03        19

    accuracy                           0.54      1596
   macro avg       0.50      0.58      0.36      1596
weighted avg       0.98      0.54      0.69      1596
03:22:39.702257: Validation Seq.Label F1: 0.5370051387454676; Log.Reg F1: 0.3644736842105263; train loss: 0.05949391797184944; Language: finnish 

03:22:39.702331: Evaluating Language: japanese
03:22:39.702388: ----------
03:22:42.877092: OBI: 
 [[176   1  13]
 [  0   0   0]
 [  2   0   0]]
03:22:42.879332: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96       190
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         2

    accuracy                           0.92       192
   macro avg       0.33      0.31      0.32       192
weighted avg       0.98      0.92      0.95       192
03:22:42.879380: ----------
03:22:42.879942: LR: 
 [[421 169]
 [  0   0]]
03:22:42.882527: LR: 
               precision    recall  f1-score   support

           0       1.00      0.71      0.83       590
           1       0.00      0.00      0.00         0

    accuracy                           0.71       590
   macro avg       0.50      0.36      0.42       590
weighted avg       1.00      0.71      0.83       590
03:22:42.884124: Validation Seq.Label F1: 0.31884057971014496; Log.Reg F1: 0.4164193867457962; train loss: 0.05949391797184944; Language: japanese 

03:22:42.885403: Combined F1 SeqLab: 0.49324321543211086; train loss: 0.05949391797184944
03:22:42.886684: Combined F1 LogReg: 0.3673129621301569; train loss: 0.05949391797184944 

03:22:42.887265: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 15/40
03:25:28.354596: Evaluating Language: english
03:25:28.354731: ----------
03:25:33.135767: OBI: 
 [[3367   42  165]
 [   1   13    3]
 [  49    1   99]]
03:25:33.140093: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      3574
           1       0.23      0.76      0.36        17
           2       0.37      0.66      0.48       149

    accuracy                           0.93      3740
   macro avg       0.53      0.79      0.60      3740
weighted avg       0.96      0.93      0.94      3740
03:25:33.140138: ----------
03:25:33.144644: LR: 
 [[392 536]
 [  1  16]]
03:25:33.147896: LR: 
               precision    recall  f1-score   support

           0       1.00      0.42      0.59       928
           1       0.03      0.94      0.06        17

    accuracy                           0.43       945
   macro avg       0.51      0.68      0.32       945
weighted avg       0.98      0.43      0.58       945
03:25:33.150207: Validation Seq.Label F1: 0.5984547904860568; Log.Reg F1: 0.32486439814328233; train loss: 0.04739001393318176; Language: english 

03:25:33.150278: Evaluating Language: finnish
03:25:33.150343: ----------
03:25:40.140996: OBI: 
 [[3567   74  286]
 [   2   20    3]
 [  63    4  145]]
03:25:40.145570: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.91      0.94      3927
           1       0.20      0.80      0.33        25
           2       0.33      0.68      0.45       212

    accuracy                           0.90      4164
   macro avg       0.51      0.80      0.57      4164
weighted avg       0.94      0.90      0.91      4164
03:25:40.145614: ----------
03:25:40.146485: LR: 
 [[964 607]
 [  7  18]]
03:25:40.149715: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.76      1571
           1       0.03      0.72      0.06        25

    accuracy                           0.62      1596
   macro avg       0.51      0.67      0.41      1596
weighted avg       0.98      0.62      0.75      1596
03:25:40.151493: Validation Seq.Label F1: 0.5726317641328552; Log.Reg F1: 0.4069212612721661; train loss: 0.04739001393318176; Language: finnish 

03:25:40.151548: Evaluating Language: japanese
03:25:40.151593: ----------
03:25:43.329160: OBI: 
 [[1007    9   57]
 [   0    0    0]
 [   0    0    1]]
03:25:43.331875: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97      1073
           1       0.00      0.00      0.00         0
           2       0.02      1.00      0.03         1

    accuracy                           0.94      1074
   macro avg       0.34      0.65      0.33      1074
weighted avg       1.00      0.94      0.97      1074
03:25:43.331918: ----------
03:25:43.332477: LR: 
 [[340 250]
 [  0   0]]
03:25:43.335043: LR: 
               precision    recall  f1-score   support

           0       1.00      0.58      0.73       590
           1       0.00      0.00      0.00         0

    accuracy                           0.58       590
   macro avg       0.50      0.29      0.37       590
weighted avg       1.00      0.58      0.73       590
03:25:43.336751: Validation Seq.Label F1: 0.33405584528465887; Log.Reg F1: 0.3655913978494624; train loss: 0.04739001393318176; Language: japanese 

03:25:43.338054: Combined F1 SeqLab: 0.5156383038909037; train loss: 0.04739001393318176
03:25:43.339377: Combined F1 LogReg: 0.36732313668750904; train loss: 0.04739001393318176 

03:25:43.339954: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 16/40
03:28:26.672539: Evaluating Language: english
03:28:26.672654: ----------
03:28:31.342878: OBI: 
 [[2237   41   89]
 [   2    9    0]
 [  42    1   81]]
03:28:31.347078: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96      2367
           1       0.18      0.82      0.29        11
           2       0.48      0.65      0.55       124

    accuracy                           0.93      2502
   macro avg       0.54      0.81      0.60      2502
weighted avg       0.95      0.93      0.94      2502
03:28:31.347147: ----------
03:28:31.347956: LR: 
 [[470 464]
 [  3   8]]
03:28:31.351202: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.67       934
           1       0.02      0.73      0.03        11

    accuracy                           0.51       945
   macro avg       0.51      0.62      0.35       945
weighted avg       0.98      0.51      0.66       945
03:28:31.353460: Validation Seq.Label F1: 0.6013025108994239; Log.Reg F1: 0.3506072123852786; train loss: 0.051686231046915054; Language: english 

03:28:31.353531: Evaluating Language: finnish
03:28:31.353587: ----------
03:28:38.386457: OBI: 
 [[5237   98  288]
 [   5   19    3]
 [ 156    6  192]]
03:28:38.392157: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.93      0.95      5623
           1       0.15      0.70      0.25        27
           2       0.40      0.54      0.46       354

    accuracy                           0.91      6004
   macro avg       0.51      0.73      0.55      6004
weighted avg       0.93      0.91      0.92      6004
03:28:38.392200: ----------
03:28:38.393067: LR: 
 [[684 885]
 [  2  25]]
03:28:38.396319: LR: 
               precision    recall  f1-score   support

           0       1.00      0.44      0.61      1569
           1       0.03      0.93      0.05        27

    accuracy                           0.44      1596
   macro avg       0.51      0.68      0.33      1596
weighted avg       0.98      0.44      0.60      1596
03:28:38.398024: Validation Seq.Label F1: 0.5541607252018168; Log.Reg F1: 0.3300068388284543; train loss: 0.051686231046915054; Language: finnish 

03:28:38.398079: Evaluating Language: japanese
03:28:38.398123: ----------
03:28:41.662905: OBI: 
 [[1045    8   64]
 [   0    2    0]
 [   2    0   19]]
03:28:41.665536: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97      1117
           1       0.20      1.00      0.33         2
           2       0.23      0.90      0.37        21

    accuracy                           0.94      1140
   macro avg       0.48      0.95      0.55      1140
weighted avg       0.98      0.94      0.95      1140
03:28:41.665580: ----------
03:28:41.666133: LR: 
 [[347 241]
 [  0   2]]
03:28:41.668551: LR: 
               precision    recall  f1-score   support

           0       1.00      0.59      0.74       588
           1       0.01      1.00      0.02         2

    accuracy                           0.59       590
   macro avg       0.50      0.80      0.38       590
weighted avg       1.00      0.59      0.74       590
03:28:41.670189: Validation Seq.Label F1: 0.5548406717537956; Log.Reg F1: 0.3792862599585289; train loss: 0.051686231046915054; Language: japanese 

03:28:41.671501: Combined F1 SeqLab: 0.5705281149959098; train loss: 0.051686231046915054
03:28:43.755145: Combined F1 LogReg: 0.3538775673607347; train loss: 0.051686231046915054 

03:28:43.756301: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 17/40
03:31:32.978602: Evaluating Language: english
03:31:32.978783: ----------
03:31:37.922385: OBI: 
 [[2745   46  124]
 [   0   11    0]
 [  23    1   66]]
03:31:37.926492: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.97      2915
           1       0.19      1.00      0.32        11
           2       0.35      0.73      0.47        90

    accuracy                           0.94      3016
   macro avg       0.51      0.89      0.59      3016
weighted avg       0.97      0.94      0.95      3016
03:31:37.926537: ----------
03:31:37.927219: LR: 
 [[453 481]
 [  1  10]]
03:31:37.929949: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.65       934
           1       0.02      0.91      0.04        11

    accuracy                           0.49       945
   macro avg       0.51      0.70      0.35       945
weighted avg       0.99      0.49      0.65       945
03:31:37.934803: Validation Seq.Label F1: 0.5854360716711434; Log.Reg F1: 0.34628919480579123; train loss: 0.05534733831882477; Language: english 

03:31:37.934867: Evaluating Language: finnish
03:31:37.934913: ----------
03:31:45.092023: OBI: 
 [[4727  113  369]
 [   4   27    3]
 [ 103   11  211]]
03:31:45.097482: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.91      0.94      5209
           1       0.18      0.79      0.29        34
           2       0.36      0.65      0.46       325

    accuracy                           0.89      5568
   macro avg       0.51      0.78      0.57      5568
weighted avg       0.94      0.89      0.91      5568
03:31:45.097530: ----------
03:31:45.098404: LR: 
 [[721 841]
 [  1  33]]
03:31:45.101658: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63      1562
           1       0.04      0.97      0.07        34

    accuracy                           0.47      1596
   macro avg       0.52      0.72      0.35      1596
weighted avg       0.98      0.47      0.62      1596
03:31:45.103514: Validation Seq.Label F1: 0.5660005955816351; Log.Reg F1: 0.3520178680265706; train loss: 0.05534733831882477; Language: finnish 

03:31:45.103567: Evaluating Language: japanese
03:31:45.103611: ----------
03:31:48.285895: OBI: 
 [[595   5  39]
 [  0   1   0]
 [  0   0   0]]
03:31:48.288347: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96       639
           1       0.17      1.00      0.29         1
           2       0.00      0.00      0.00         0

    accuracy                           0.93       640
   macro avg       0.39      0.64      0.42       640
weighted avg       1.00      0.93      0.96       640
03:31:48.288390: ----------
03:31:48.288951: LR: 
 [[488 101]
 [  0   1]]
03:31:48.291346: LR: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.91       589
           1       0.01      1.00      0.02         1

    accuracy                           0.83       590
   macro avg       0.50      0.91      0.46       590
weighted avg       1.00      0.83      0.90       590
03:31:48.293075: Validation Seq.Label F1: 0.4166859612564637; Log.Reg F1: 0.46281922997178426; train loss: 0.05534733831882477; Language: japanese 

03:31:48.294422: Combined F1 SeqLab: 0.5281159148396398; train loss: 0.05534733831882477
03:31:48.295750: Combined F1 LogReg: 0.3907405044616741; train loss: 0.05534733831882477 

03:31:48.296341: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 18/40
03:34:31.908669: Evaluating Language: english
03:34:31.908779: ----------
03:34:36.819149: OBI: 
 [[2926   49  195]
 [   0   12    4]
 [  34    6  101]]
03:34:36.823179: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95      3170
           1       0.18      0.75      0.29        16
           2       0.34      0.72      0.46       141

    accuracy                           0.91      3327
   macro avg       0.50      0.80      0.57      3327
weighted avg       0.96      0.91      0.93      3327
03:34:36.823223: ----------
03:34:36.823904: LR: 
 [[424 505]
 [  1  15]]
03:34:36.826640: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63       929
           1       0.03      0.94      0.06        16

    accuracy                           0.46       945
   macro avg       0.51      0.70      0.34       945
weighted avg       0.98      0.46      0.62       945
03:34:36.828648: Validation Seq.Label F1: 0.5672852596775743; Log.Reg F1: 0.3411313080094358; train loss: 0.057763468474149704; Language: english 

03:34:36.828728: Evaluating Language: finnish
03:34:36.828775: ----------
03:34:43.809162: OBI: 
 [[3526   56  185]
 [   4   13    4]
 [  97    0  115]]
03:34:43.813641: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.94      0.95      3767
           1       0.19      0.62      0.29        21
           2       0.38      0.54      0.45       212

    accuracy                           0.91      4000
   macro avg       0.51      0.70      0.56      4000
weighted avg       0.94      0.91      0.92      4000
03:34:43.813685: ----------
03:34:43.814564: LR: 
 [[876 699]
 [  5  16]]
03:34:43.817830: LR: 
               precision    recall  f1-score   support

           0       0.99      0.56      0.71      1575
           1       0.02      0.76      0.04        21

    accuracy                           0.56      1596
   macro avg       0.51      0.66      0.38      1596
weighted avg       0.98      0.56      0.70      1596
03:34:43.819696: Validation Seq.Label F1: 0.5627905345885355; Log.Reg F1: 0.37841665486475007; train loss: 0.057763468474149704; Language: finnish 

03:34:43.819750: Evaluating Language: japanese
03:34:43.819793: ----------
03:34:46.965201: OBI: 
 [[1559    8   71]
 [   0    2    0]
 [  21    0   13]]
03:34:46.968107: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      1638
           1       0.20      1.00      0.33         2
           2       0.15      0.38      0.22        34

    accuracy                           0.94      1674
   macro avg       0.45      0.78      0.51      1674
weighted avg       0.97      0.94      0.95      1674
03:34:46.968148: ----------
03:34:46.968714: LR: 
 [[357 231]
 [  0   2]]
03:34:46.971131: LR: 
               precision    recall  f1-score   support

           0       1.00      0.61      0.76       588
           1       0.01      1.00      0.02         2

    accuracy                           0.61       590
   macro avg       0.50      0.80      0.39       590
weighted avg       1.00      0.61      0.75       590
03:34:46.972738: Validation Seq.Label F1: 0.5075323714651226; Log.Reg F1: 0.38628841607565007; train loss: 0.057763468474149704; Language: japanese 

03:34:46.974062: Combined F1 SeqLab: 0.5465451673176743; train loss: 0.057763468474149704
03:34:46.975372: Combined F1 LogReg: 0.36913794818806805; train loss: 0.057763468474149704 

03:34:46.975940: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 19/40
03:37:29.548799: Evaluating Language: english
03:37:29.548917: ----------
03:37:34.164889: OBI: 
 [[3767   62  175]
 [   0   15    1]
 [  74    6  116]]
03:37:34.169495: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      4004
           1       0.18      0.94      0.30        16
           2       0.40      0.59      0.48       196

    accuracy                           0.92      4216
   macro avg       0.52      0.82      0.58      4216
weighted avg       0.95      0.92      0.94      4216
03:37:34.169540: ----------
03:37:34.170213: LR: 
 [[425 504]
 [  1  15]]
03:37:34.172922: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63       929
           1       0.03      0.94      0.06        16

    accuracy                           0.47       945
   macro avg       0.51      0.70      0.34       945
weighted avg       0.98      0.47      0.62       945
03:37:34.175023: Validation Seq.Label F1: 0.5795990181095031; Log.Reg F1: 0.34169051970893544; train loss: 0.04139989614486694; Language: english 

03:37:34.175081: Evaluating Language: finnish
03:37:34.175125: ----------
03:37:41.174033: OBI: 
 [[3041   59  232]
 [   2   14    3]
 [  47    5  125]]
03:37:41.178188: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.91      0.95      3332
           1       0.18      0.74      0.29        19
           2       0.35      0.71      0.47       177

    accuracy                           0.90      3528
   macro avg       0.50      0.79      0.57      3528
weighted avg       0.95      0.90      0.92      3528
03:37:41.178234: ----------
03:37:41.179108: LR: 
 [[814 763]
 [  3  16]]
03:37:41.182319: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.68      1577
           1       0.02      0.84      0.04        19

    accuracy                           0.52      1596
   macro avg       0.51      0.68      0.36      1596
weighted avg       0.98      0.52      0.67      1596
03:37:41.184027: Validation Seq.Label F1: 0.56708871121225; Log.Reg F1: 0.36006683375104426; train loss: 0.04139989614486694; Language: finnish 

03:37:41.184081: Evaluating Language: japanese
03:37:41.184125: ----------
03:37:44.381088: OBI: 
 [[1141   10   57]
 [   0    0    0]
 [   4    0    0]]
03:37:44.383879: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97      1208
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         4

    accuracy                           0.94      1212
   macro avg       0.33      0.31      0.32      1212
weighted avg       0.99      0.94      0.97      1212
03:37:44.383924: ----------
03:37:44.384488: LR: 
 [[380 210]
 [  0   0]]
03:37:44.387034: LR: 
               precision    recall  f1-score   support

           0       1.00      0.64      0.78       590
           1       0.00      0.00      0.00         0

    accuracy                           0.64       590
   macro avg       0.50      0.32      0.39       590
weighted avg       1.00      0.64      0.78       590
03:37:44.388774: Validation Seq.Label F1: 0.323275251452047; Log.Reg F1: 0.39175257731958757; train loss: 0.04139989614486694; Language: japanese 

03:37:44.390123: Combined F1 SeqLab: 0.5039945490377368; train loss: 0.04139989614486694
03:37:44.391468: Combined F1 LogReg: 0.365089312298148; train loss: 0.04139989614486694 

03:37:44.392047: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 20/40
03:40:27.928493: Evaluating Language: english
03:40:27.928605: ----------
03:40:32.724343: OBI: 
 [[3073   39  131]
 [   2    9    1]
 [  38    2   73]]
03:40:32.728376: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      3243
           1       0.18      0.75      0.29        12
           2       0.36      0.65      0.46       113

    accuracy                           0.94      3368
   macro avg       0.51      0.78      0.57      3368
weighted avg       0.96      0.94      0.95      3368
03:40:32.728421: ----------
03:40:32.729097: LR: 
 [[434 499]
 [  1  11]]
03:40:32.731804: LR: 
               precision    recall  f1-score   support

           0       1.00      0.47      0.63       933
           1       0.02      0.92      0.04        12

    accuracy                           0.47       945
   macro avg       0.51      0.69      0.34       945
weighted avg       0.99      0.47      0.63       945
03:40:32.733821: Validation Seq.Label F1: 0.5721341433078049; Log.Reg F1: 0.33832425892317; train loss: 0.04246031865477562; Language: english 

03:40:32.733877: Evaluating Language: finnish
03:40:32.733924: ----------
03:40:39.912935: OBI: 
 [[3066   36  165]
 [   3   14    2]
 [  87    3  148]]
03:40:39.917115: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.94      0.95      3267
           1       0.26      0.74      0.39        19
           2       0.47      0.62      0.54       238

    accuracy                           0.92      3524
   macro avg       0.57      0.77      0.63      3524
weighted avg       0.93      0.92      0.92      3524
03:40:39.917164: ----------
03:40:39.918036: LR: 
 [[946 631]
 [  3  16]]
03:40:39.921271: LR: 
               precision    recall  f1-score   support

           0       1.00      0.60      0.75      1577
           1       0.02      0.84      0.05        19

    accuracy                           0.60      1596
   macro avg       0.51      0.72      0.40      1596
weighted avg       0.99      0.60      0.74      1596
03:40:39.923026: Validation Seq.Label F1: 0.6262817210765347; Log.Reg F1: 0.39852917050066694; train loss: 0.04246031865477562; Language: finnish 

03:40:39.923081: Evaluating Language: japanese
03:40:39.923124: ----------
03:40:42.999416: OBI: 
 [[1104   17  111]
 [   0    1    0]
 [   0    0    5]]
03:40:43.002423: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.95      1232
           1       0.06      1.00      0.11         1
           2       0.04      1.00      0.08         5

    accuracy                           0.90      1238
   macro avg       0.37      0.97      0.38      1238
weighted avg       1.00      0.90      0.94      1238
03:40:43.002467: ----------
03:40:43.003020: LR: 
 [[372 217]
 [  0   1]]
03:40:43.005651: LR: 
               precision    recall  f1-score   support

           0       1.00      0.63      0.77       589
           1       0.00      1.00      0.01         1

    accuracy                           0.63       590
   macro avg       0.50      0.82      0.39       590
weighted avg       1.00      0.63      0.77       590
03:40:43.007418: Validation Seq.Label F1: 0.37770442181532177; Log.Reg F1: 0.3916629842392105; train loss: 0.04246031865477562; Language: japanese 

03:40:43.008832: Combined F1 SeqLab: 0.5361053697275031; train loss: 0.04246031865477562
03:40:43.010384: Combined F1 LogReg: 0.37713335269239795; train loss: 0.04246031865477562 

03:40:43.010968: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 21/40
03:43:27.014832: Evaluating Language: english
03:43:27.014975: ----------
03:43:31.745537: OBI: 
 [[3232   58  147]
 [   4   10    4]
 [  22    5  110]]
03:43:31.749759: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.97      3437
           1       0.14      0.56      0.22        18
           2       0.42      0.80      0.55       137

    accuracy                           0.93      3592
   macro avg       0.52      0.77      0.58      3592
weighted avg       0.97      0.93      0.95      3592
03:43:31.749805: ----------
03:43:31.750490: LR: 
 [[400 527]
 [  3  15]]
03:43:31.753191: LR: 
               precision    recall  f1-score   support

           0       0.99      0.43      0.60       927
           1       0.03      0.83      0.05        18

    accuracy                           0.44       945
   macro avg       0.51      0.63      0.33       945
weighted avg       0.97      0.44      0.59       945
03:43:31.755476: Validation Seq.Label F1: 0.5793468927195814; Log.Reg F1: 0.32753759398496246; train loss: 0.044168513268232346; Language: english 

03:43:31.755544: Evaluating Language: finnish
03:43:31.755602: ----------
03:43:38.891178: OBI: 
 [[2452   61  203]
 [   2   15    3]
 [  65    1  114]]
03:43:38.894950: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.90      0.94      2716
           1       0.19      0.75      0.31        20
           2       0.36      0.63      0.46       180

    accuracy                           0.89      2916
   macro avg       0.51      0.76      0.57      2916
weighted avg       0.93      0.89      0.90      2916
03:43:38.894995: ----------
03:43:38.895873: LR: 
 [[746 830]
 [  2  18]]
03:43:38.899097: LR: 
               precision    recall  f1-score   support

           0       1.00      0.47      0.64      1576
           1       0.02      0.90      0.04        20

    accuracy                           0.48      1596
   macro avg       0.51      0.69      0.34      1596
weighted avg       0.99      0.48      0.63      1596
03:43:38.900807: Validation Seq.Label F1: 0.5673500264214233; Log.Reg F1: 0.34173560601854425; train loss: 0.044168513268232346; Language: finnish 

03:43:38.900859: Evaluating Language: japanese
03:43:38.900902: ----------
03:43:41.950706: OBI: 
 [[730  18  35]
 [  0   0   1]
 [  1   0   9]]
03:43:41.953500: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96       783
           1       0.00      0.00      0.00         1
           2       0.20      0.90      0.33        10

    accuracy                           0.93       794
   macro avg       0.40      0.61      0.43       794
weighted avg       0.99      0.93      0.96       794
03:43:41.953551: ----------
03:43:41.954211: LR: 
 [[173 416]
 [  0   1]]
03:43:41.956612: LR: 
               precision    recall  f1-score   support

           0       1.00      0.29      0.45       589
           1       0.00      1.00      0.00         1

    accuracy                           0.29       590
   macro avg       0.50      0.65      0.23       590
weighted avg       1.00      0.29      0.45       590
03:43:41.958200: Validation Seq.Label F1: 0.43053520675713547; Log.Reg F1: 0.2294264652325158; train loss: 0.044168513268232346; Language: japanese 

03:43:41.959514: Combined F1 SeqLab: 0.5300595686152118; train loss: 0.044168513268232346
03:43:41.960823: Combined F1 LogReg: 0.30369974363034213; train loss: 0.044168513268232346 

03:43:41.961406: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 22/40
03:46:26.719140: Evaluating Language: english
03:46:26.719426: ----------
03:46:31.569241: OBI: 
 [[1699   27   48]
 [   2    5    2]
 [  44    2   59]]
03:46:31.572559: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.97      1774
           1       0.15      0.56      0.23         9
           2       0.54      0.56      0.55       105

    accuracy                           0.93      1888
   macro avg       0.55      0.69      0.58      1888
weighted avg       0.95      0.93      0.94      1888
03:46:31.572611: ----------
03:46:31.573321: LR: 
 [[508 428]
 [  2   7]]
03:46:31.576011: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70       936
           1       0.02      0.78      0.03         9

    accuracy                           0.54       945
   macro avg       0.51      0.66      0.37       945
weighted avg       0.99      0.54      0.70       945
03:46:31.581164: Validation Seq.Label F1: 0.5831917467645495; Log.Reg F1: 0.3670797353369967; train loss: 0.034919366240501404; Language: english 

03:46:31.581222: Evaluating Language: finnish
03:46:31.581274: ----------
03:46:38.708757: OBI: 
 [[5163   86  272]
 [   3   24    2]
 [  84    5  185]]
03:46:38.714448: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      5521
           1       0.21      0.83      0.33        29
           2       0.40      0.68      0.50       274

    accuracy                           0.92      5824
   macro avg       0.53      0.81      0.60      5824
weighted avg       0.95      0.92      0.93      5824
03:46:38.714498: ----------
03:46:38.715373: LR: 
 [[802 765]
 [  6  23]]
03:46:38.718659: LR: 
               precision    recall  f1-score   support

           0       0.99      0.51      0.68      1567
           1       0.03      0.79      0.06        29

    accuracy                           0.52      1596
   macro avg       0.51      0.65      0.37      1596
weighted avg       0.98      0.52      0.66      1596
03:46:38.720584: Validation Seq.Label F1: 0.598931196616001; Log.Reg F1: 0.3658359853121175; train loss: 0.034919366240501404; Language: finnish 

03:46:38.720639: Evaluating Language: japanese
03:46:38.720686: ----------
03:46:41.732206: OBI: 
 [[552   5  12]
 [  0   0   0]
 [  0   0   5]]
03:46:41.734657: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.97      0.98       569
           1       0.00      0.00      0.00         0
           2       0.29      1.00      0.45         5

    accuracy                           0.97       574
   macro avg       0.43      0.66      0.48       574
weighted avg       0.99      0.97      0.98       574
03:46:41.734701: ----------
03:46:41.735295: LR: 
 [[245 345]
 [  0   0]]
03:46:41.737854: LR: 
               precision    recall  f1-score   support

           0       1.00      0.42      0.59       590
           1       0.00      0.00      0.00         0

    accuracy                           0.42       590
   macro avg       0.50      0.21      0.29       590
weighted avg       1.00      0.42      0.59       590
03:46:41.739495: Validation Seq.Label F1: 0.4797934744411105; Log.Reg F1: 0.2934131736526946; train loss: 0.034919366240501404; Language: japanese 

03:46:41.740760: Combined F1 SeqLab: 0.556486888102626; train loss: 0.034919366240501404
03:46:41.742035: Combined F1 LogReg: 0.3438385234948297; train loss: 0.034919366240501404 

03:46:41.742627: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 23/40
03:49:24.737949: Evaluating Language: english
03:49:24.738066: ----------
03:49:29.627812: OBI: 
 [[2553   37  140]
 [   0   18    3]
 [  38    1   93]]
03:49:29.631552: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      2730
           1       0.32      0.86      0.47        21
           2       0.39      0.70      0.51       132

    accuracy                           0.92      2883
   macro avg       0.57      0.83      0.64      2883
weighted avg       0.95      0.92      0.94      2883
03:49:29.631595: ----------
03:49:29.632287: LR: 
 [[474 450]
 [  3  18]]
03:49:29.634996: LR: 
               precision    recall  f1-score   support

           0       0.99      0.51      0.68       924
           1       0.04      0.86      0.07        21

    accuracy                           0.52       945
   macro avg       0.52      0.69      0.38       945
weighted avg       0.97      0.52      0.66       945
03:49:29.637043: Validation Seq.Label F1: 0.6441871038026141; Log.Reg F1: 0.3751395804048817; train loss: 0.03917370364069939; Language: english 

03:49:29.637101: Evaluating Language: finnish
03:49:29.637146: ----------
03:49:36.846377: OBI: 
 [[3662   70  252]
 [   1   17    3]
 [  63    5  147]]
03:49:36.850980: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.92      0.95      3984
           1       0.18      0.81      0.30        21
           2       0.37      0.68      0.48       215

    accuracy                           0.91      4220
   macro avg       0.51      0.80      0.58      4220
weighted avg       0.95      0.91      0.92      4220
03:49:36.851022: ----------
03:49:36.851893: LR: 
 [[859 716]
 [  3  18]]
03:49:36.855144: LR: 
               precision    recall  f1-score   support

           0       1.00      0.55      0.70      1575
           1       0.02      0.86      0.05        21

    accuracy                           0.55      1596
   macro avg       0.51      0.70      0.38      1596
weighted avg       0.98      0.55      0.70      1596
03:49:36.856905: Validation Seq.Label F1: 0.5757730981787933; Log.Reg F1: 0.37632362012788495; train loss: 0.03917370364069939; Language: finnish 

03:49:36.856958: Evaluating Language: japanese
03:49:36.857002: ----------
03:49:39.915550: OBI: 
 [[1425   14   88]
 [   0    2    0]
 [   0    0    7]]
03:49:39.918400: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.97      1527
           1       0.12      1.00      0.22         2
           2       0.07      1.00      0.14         7

    accuracy                           0.93      1536
   macro avg       0.40      0.98      0.44      1536
weighted avg       0.99      0.93      0.96      1536
03:49:39.918443: ----------
03:49:39.918989: LR: 
 [[442 146]
 [  0   2]]
03:49:39.921399: LR: 
               precision    recall  f1-score   support

           0       1.00      0.75      0.86       588
           1       0.01      1.00      0.03         2

    accuracy                           0.75       590
   macro avg       0.51      0.88      0.44       590
weighted avg       1.00      0.75      0.86       590
03:49:39.923042: Validation Seq.Label F1: 0.44164142621818375; Log.Reg F1: 0.44245954692556627; train loss: 0.03917370364069939; Language: japanese 

03:49:39.924349: Combined F1 SeqLab: 0.5602198481084718; train loss: 0.03917370364069939
03:49:39.925644: Combined F1 LogReg: 0.3992157405539369; train loss: 0.03917370364069939 

03:49:39.926216: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 24/40
03:52:22.121843: Evaluating Language: english
03:52:22.122036: ----------
03:52:26.996144: OBI: 
 [[3546   34  122]
 [   2    6    2]
 [  29    4   36]]
03:52:27.000443: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97      3702
           1       0.14      0.60      0.22        10
           2       0.23      0.52      0.31        69

    accuracy                           0.95      3781
   macro avg       0.45      0.69      0.50      3781
weighted avg       0.98      0.95      0.96      3781
03:52:27.000487: ----------
03:52:27.001143: LR: 
 [[452 483]
 [  0  10]]
03:52:27.003843: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65       935
           1       0.02      1.00      0.04        10

    accuracy                           0.49       945
   macro avg       0.51      0.74      0.35       945
weighted avg       0.99      0.49      0.65       945
03:52:27.006014: Validation Seq.Label F1: 0.5036474534972037; Log.Reg F1: 0.3457639168593342; train loss: 0.03215287998318672; Language: english 

03:52:27.006071: Evaluating Language: finnish
03:52:27.006117: ----------
03:52:34.060491: OBI: 
 [[3678   41  106]
 [   2   17    0]
 [ 112    4  132]]
03:52:34.064958: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.97      3825
           1       0.27      0.89      0.42        19
           2       0.55      0.53      0.54       248

    accuracy                           0.94      4092
   macro avg       0.60      0.80      0.64      4092
weighted avg       0.94      0.94      0.94      4092
03:52:34.065003: ----------
03:52:34.065868: LR: 
 [[884 693]
 [  3  16]]
03:52:34.069074: LR: 
               precision    recall  f1-score   support

           0       1.00      0.56      0.72      1577
           1       0.02      0.84      0.04        19

    accuracy                           0.56      1596
   macro avg       0.51      0.70      0.38      1596
weighted avg       0.99      0.56      0.71      1596
03:52:34.070776: Validation Seq.Label F1: 0.6428991680402998; Log.Reg F1: 0.38074425574425574; train loss: 0.03215287998318672; Language: finnish 

03:52:34.070829: Evaluating Language: japanese
03:52:34.070875: ----------
03:52:37.016479: OBI: 
 [[492  15]
 [  5   0]]
03:52:37.018820: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.97      0.98       507
           2       0.00      0.00      0.00         5

    accuracy                           0.96       512
   macro avg       0.49      0.49      0.49       512
weighted avg       0.98      0.96      0.97       512
03:52:37.018865: ----------
03:52:37.019426: LR: 
 [[437 153]
 [  0   0]]
03:52:37.021946: LR: 
               precision    recall  f1-score   support

           0       1.00      0.74      0.85       590
           1       0.00      0.00      0.00         0

    accuracy                           0.74       590
   macro avg       0.50      0.37      0.43       590
weighted avg       1.00      0.74      0.85       590
03:52:37.023625: Validation Seq.Label F1: 0.4900398406374502; Log.Reg F1: 0.42551119766309636; train loss: 0.03215287998318672; Language: japanese 

03:52:37.024952: Combined F1 SeqLab: 0.5498845767046951; train loss: 0.03215287998318672
03:52:37.026252: Combined F1 LogReg: 0.3853909935899897; train loss: 0.03215287998318672 

03:52:37.026826: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 25/40
03:55:19.438214: Evaluating Language: english
03:55:19.438379: ----------
03:55:24.321558: OBI: 
 [[4002   55  159]
 [   3    7    4]
 [  57    4   88]]
03:55:24.326200: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      4216
           1       0.11      0.50      0.17        14
           2       0.35      0.59      0.44       149

    accuracy                           0.94      4379
   macro avg       0.48      0.68      0.53      4379
weighted avg       0.96      0.94      0.95      4379
03:55:24.326246: ----------
03:55:24.326923: LR: 
 [[412 519]
 [  0  14]]
03:55:24.329618: LR: 
               precision    recall  f1-score   support

           0       1.00      0.44      0.61       931
           1       0.03      1.00      0.05        14

    accuracy                           0.45       945
   macro avg       0.51      0.72      0.33       945
weighted avg       0.99      0.45      0.61       945
03:55:24.331630: Validation Seq.Label F1: 0.5273000724812756; Log.Reg F1: 0.33237002481551714; train loss: 0.04173586517572403; Language: english 

03:55:24.331686: Evaluating Language: finnish
03:55:24.331732: ----------
03:55:31.391091: OBI: 
 [[2455   31   73]
 [   0   12    0]
 [  57    2   78]]
03:55:31.394693: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      2559
           1       0.27      1.00      0.42        12
           2       0.52      0.57      0.54       137

    accuracy                           0.94      2708
   macro avg       0.59      0.84      0.64      2708
weighted avg       0.95      0.94      0.94      2708
03:55:31.394737: ----------
03:55:31.395614: LR: 
 [[814 770]
 [  2  10]]
03:55:31.398813: LR: 
               precision    recall  f1-score   support

           0       1.00      0.51      0.68      1584
           1       0.01      0.83      0.03        12

    accuracy                           0.52      1596
   macro avg       0.51      0.67      0.35      1596
weighted avg       0.99      0.52      0.67      1596
03:55:31.400614: Validation Seq.Label F1: 0.6436567121148694; Log.Reg F1: 0.3517929292929293; train loss: 0.04173586517572403; Language: finnish 

03:55:31.400691: Evaluating Language: japanese
03:55:31.400745: ----------
03:55:34.392899: OBI: 
 [[1321   14   62]
 [   0    1    0]
 [   4    0    6]]
03:55:34.395659: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.95      0.97      1397
           1       0.07      1.00      0.12         1
           2       0.09      0.60      0.15        10

    accuracy                           0.94      1408
   macro avg       0.38      0.85      0.42      1408
weighted avg       0.99      0.94      0.96      1408
03:55:34.395702: ----------
03:55:34.396254: LR: 
 [[468 121]
 [  0   1]]
03:55:34.401791: LR: 
               precision    recall  f1-score   support

           0       1.00      0.79      0.89       589
           1       0.01      1.00      0.02         1

    accuracy                           0.79       590
   macro avg       0.50      0.90      0.45       590
weighted avg       1.00      0.79      0.88       590
03:55:34.403400: Validation Seq.Label F1: 0.4164853331826146; Log.Reg F1: 0.4508926167785802; train loss: 0.04173586517572403; Language: japanese 

03:55:34.404685: Combined F1 SeqLab: 0.537214842884271; train loss: 0.04173586517572403
03:55:34.405957: Combined F1 LogReg: 0.3818953828654313; train loss: 0.04173586517572403 

03:55:34.406526: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 26/40
03:58:18.185818: Evaluating Language: english
03:58:18.188134: ----------
03:58:22.931503: OBI: 
 [[5454   79  224]
 [   5   15    6]
 [ 131    5  159]]
03:58:22.937572: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96      5757
           1       0.15      0.58      0.24        26
           2       0.41      0.54      0.46       295

    accuracy                           0.93      6078
   macro avg       0.51      0.69      0.56      6078
weighted avg       0.94      0.93      0.93      6078
03:58:22.937628: ----------
03:58:22.938483: LR: 
 [[464 455]
 [  3  23]]
03:58:22.941190: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.67       919
           1       0.05      0.88      0.09        26

    accuracy                           0.52       945
   macro avg       0.52      0.69      0.38       945
weighted avg       0.97      0.52      0.65       945
03:58:22.943933: Validation Seq.Label F1: 0.5554078801775155; Log.Reg F1: 0.3804112554112555; train loss: 0.03491225093603134; Language: english 

03:58:22.943997: Evaluating Language: finnish
03:58:22.944042: ----------
03:58:30.194011: OBI: 
 [[3306   59  188]
 [   2   17    3]
 [  48    3   86]]
03:58:30.198290: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      3553
           1       0.22      0.77      0.34        22
           2       0.31      0.63      0.42       137

    accuracy                           0.92      3712
   macro avg       0.50      0.78      0.57      3712
weighted avg       0.96      0.92      0.93      3712
03:58:30.198342: ----------
03:58:30.199216: LR: 
 [[745 829]
 [  2  20]]
03:58:30.202508: LR: 
               precision    recall  f1-score   support

           0       1.00      0.47      0.64      1574
           1       0.02      0.91      0.05        22

    accuracy                           0.48      1596
   macro avg       0.51      0.69      0.34      1596
weighted avg       0.98      0.48      0.63      1596
03:58:30.204438: Validation Seq.Label F1: 0.5697017309451183; Log.Reg F1: 0.343944447714696; train loss: 0.03491225093603134; Language: finnish 

03:58:30.204491: Evaluating Language: japanese
03:58:30.204536: ----------
03:58:33.219887: OBI: 
 [[633   4  10]
 [  0   0   0]
 [  0   0   1]]
03:58:33.222343: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99       647
           1       0.00      0.00      0.00         0
           2       0.09      1.00      0.17         1

    accuracy                           0.98       648
   macro avg       0.36      0.66      0.39       648
weighted avg       1.00      0.98      0.99       648
03:58:33.222387: ----------
03:58:33.222952: LR: 
 [[435 155]
 [  0   0]]
03:58:33.225519: LR: 
               precision    recall  f1-score   support

           0       1.00      0.74      0.85       590
           1       0.00      0.00      0.00         0

    accuracy                           0.74       590
   macro avg       0.50      0.37      0.42       590
weighted avg       1.00      0.74      0.85       590
03:58:33.227133: Validation Seq.Label F1: 0.38524305555555555; Log.Reg F1: 0.424390243902439; train loss: 0.03491225093603134; Language: japanese 

03:58:33.228477: Combined F1 SeqLab: 0.5103757398423656; train loss: 0.03491225093603134
03:58:33.229802: Combined F1 LogReg: 0.38432520321419916; train loss: 0.03491225093603134 

03:58:33.230393: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 27/40
04:01:15.653813: Evaluating Language: english
04:01:15.653930: ----------
04:01:20.363807: OBI: 
 [[2517   35  115]
 [   0    9    1]
 [  21    2   60]]
04:01:20.367455: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.97      2667
           1       0.20      0.90      0.32        10
           2       0.34      0.72      0.46        83

    accuracy                           0.94      2760
   macro avg       0.51      0.86      0.58      2760
weighted avg       0.97      0.94      0.95      2760
04:01:20.367500: ----------
04:01:20.368174: LR: 
 [[361 574]
 [  0  10]]
04:01:20.370874: LR: 
               precision    recall  f1-score   support

           0       1.00      0.39      0.56       935
           1       0.02      1.00      0.03        10

    accuracy                           0.39       945
   macro avg       0.51      0.69      0.30       945
weighted avg       0.99      0.39      0.55       945
04:01:20.372927: Validation Seq.Label F1: 0.5839653362708117; Log.Reg F1: 0.29538439955106616; train loss: 0.06736810505390167; Language: english 

04:01:20.372984: Evaluating Language: finnish
04:01:20.373028: ----------
04:01:27.512695: OBI: 
 [[2245   41  164]
 [   2    6    1]
 [  44    9  100]]
04:01:27.516525: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.92      0.95      2450
           1       0.11      0.67      0.18         9
           2       0.38      0.65      0.48       153

    accuracy                           0.90      2612
   macro avg       0.49      0.75      0.54      2612
weighted avg       0.94      0.90      0.92      2612
04:01:27.516569: ----------
04:01:27.517476: LR: 
 [[862 725]
 [  2   7]]
04:01:27.520772: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70      1587
           1       0.01      0.78      0.02         9

    accuracy                           0.54      1596
   macro avg       0.50      0.66      0.36      1596
weighted avg       0.99      0.54      0.70      1596
04:01:27.522949: Validation Seq.Label F1: 0.5367139556417857; Log.Reg F1: 0.3611398801117283; train loss: 0.06736810505390167; Language: finnish 

04:01:27.523005: Evaluating Language: japanese
04:01:27.523049: ----------
04:01:30.692255: OBI: 
 [[664   8  20]
 [  0   0   0]
 [  0   0   0]]
04:01:30.694863: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98       692
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.96       692
   macro avg       0.33      0.32      0.33       692
weighted avg       1.00      0.96      0.98       692
04:01:30.694905: ----------
04:01:30.695482: LR: 
 [[481 109]
 [  0   0]]
04:01:30.698057: LR: 
               precision    recall  f1-score   support

           0       1.00      0.82      0.90       590
           1       0.00      0.00      0.00         0

    accuracy                           0.82       590
   macro avg       0.50      0.41      0.45       590
weighted avg       1.00      0.82      0.90       590
04:01:30.700077: Validation Seq.Label F1: 0.3264503441494592; Log.Reg F1: 0.4491129785247432; train loss: 0.06736810505390167; Language: japanese 

04:01:30.701447: Combined F1 SeqLab: 0.49519262627178234; train loss: 0.06736810505390167
04:01:30.702801: Combined F1 LogReg: 0.37388787266800716; train loss: 0.06736810505390167 

04:01:30.703565: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 28/40
04:04:14.315199: Evaluating Language: english
04:04:14.315360: ----------
04:04:18.999867: OBI: 
 [[3186   49  168]
 [   1   11    3]
 [  28    2  108]]
04:04:19.004161: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      3403
           1       0.18      0.73      0.29        15
           2       0.39      0.78      0.52       138

    accuracy                           0.93      3556
   macro avg       0.52      0.82      0.59      3556
weighted avg       0.96      0.93      0.94      3556
04:04:19.004205: ----------
04:04:19.004885: LR: 
 [[418 512]
 [  0  15]]
04:04:19.007643: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62       930
           1       0.03      1.00      0.06        15

    accuracy                           0.46       945
   macro avg       0.51      0.72      0.34       945
weighted avg       0.98      0.46      0.61       945
04:04:19.009991: Validation Seq.Label F1: 0.5888428487879298; Log.Reg F1: 0.3377642975242809; train loss: 0.0300909373909235; Language: english 

04:04:19.010057: Evaluating Language: finnish
04:04:19.010102: ----------
04:04:25.977806: OBI: 
 [[3345   79  164]
 [   4   21    2]
 [ 108    8  109]]
04:04:25.982563: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.93      0.95      3588
           1       0.19      0.78      0.31        27
           2       0.40      0.48      0.44       225

    accuracy                           0.90      3840
   macro avg       0.52      0.73      0.57      3840
weighted avg       0.93      0.90      0.92      3840
04:04:25.982624: ----------
04:04:25.983669: LR: 
 [[842 727]
 [  2  25]]
04:04:25.987319: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70      1569
           1       0.03      0.93      0.06        27

    accuracy                           0.54      1596
   macro avg       0.52      0.73      0.38      1596
weighted avg       0.98      0.54      0.69      1596
04:04:25.989212: Validation Seq.Label F1: 0.5655735877822464; Log.Reg F1: 0.38103565038965764; train loss: 0.0300909373909235; Language: finnish 

04:04:25.989266: Evaluating Language: japanese
04:04:25.989316: ----------
04:04:29.161056: OBI: 
 [[775   4  17]
 [  0   0   0]
 [  0   0   0]]
04:04:29.163580: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.97      0.99       796
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.97       796
   macro avg       0.33      0.32      0.33       796
weighted avg       1.00      0.97      0.99       796
04:04:29.163624: ----------
04:04:29.164179: LR: 
 [[543  47]
 [  0   0]]
04:04:29.166707: LR: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96       590
           1       0.00      0.00      0.00         0

    accuracy                           0.92       590
   macro avg       0.50      0.46      0.48       590
weighted avg       1.00      0.92      0.96       590
04:04:29.168388: Validation Seq.Label F1: 0.3288775726713346; Log.Reg F1: 0.47925860547219773; train loss: 0.0300909373909235; Language: japanese 

04:04:29.169688: Combined F1 SeqLab: 0.5081895452065617; train loss: 0.0300909373909235
04:04:29.170985: Combined F1 LogReg: 0.4037167730266257; train loss: 0.0300909373909235 

04:04:29.171572: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 29/40
04:07:13.836355: Evaluating Language: english
04:07:13.836471: ----------
04:07:18.586029: OBI: 
 [[6705   66  218]
 [   5   24    2]
 [  67    4  174]]
04:07:18.592584: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97      6989
           1       0.26      0.77      0.38        31
           2       0.44      0.71      0.54       245

    accuracy                           0.95      7265
   macro avg       0.56      0.81      0.63      7265
weighted avg       0.97      0.95      0.96      7265
04:07:18.592627: ----------
04:07:18.593291: LR: 
 [[505 409]
 [ 11  20]]
04:07:18.596020: LR: 
               precision    recall  f1-score   support

           0       0.98      0.55      0.71       914
           1       0.05      0.65      0.09        31

    accuracy                           0.56       945
   macro avg       0.51      0.60      0.40       945
weighted avg       0.95      0.56      0.69       945
04:07:18.598222: Validation Seq.Label F1: 0.6342467074875683; Log.Reg F1: 0.39662511401641837; train loss: 0.051841411739587784; Language: english 

04:07:18.598276: Evaluating Language: finnish
04:07:18.598326: ----------
04:07:25.642230: OBI: 
 [[3090   46  140]
 [   2   15    1]
 [ 105    3  102]]
04:07:25.646332: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.94      0.95      3276
           1       0.23      0.83      0.37        18
           2       0.42      0.49      0.45       210

    accuracy                           0.92      3504
   macro avg       0.54      0.75      0.59      3504
weighted avg       0.93      0.92      0.92      3504
04:07:25.646375: ----------
04:07:25.647231: LR: 
 [[1038  540]
 [   5   13]]
04:07:25.650445: LR: 
               precision    recall  f1-score   support

           0       1.00      0.66      0.79      1578
           1       0.02      0.72      0.05        18

    accuracy                           0.66      1596
   macro avg       0.51      0.69      0.42      1596
weighted avg       0.98      0.66      0.78      1596
04:07:25.652330: Validation Seq.Label F1: 0.5903066125542387; Log.Reg F1: 0.41879912414280185; train loss: 0.051841411739587784; Language: finnish 

04:07:25.652384: Evaluating Language: japanese
04:07:25.652428: ----------
04:07:28.683851: OBI: 
 [[650   5  42]
 [  0   0   0]
 [ 10   0   1]]
04:07:28.686328: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.96       697
           1       0.00      0.00      0.00         0
           2       0.02      0.09      0.04        11

    accuracy                           0.92       708
   macro avg       0.34      0.34      0.33       708
weighted avg       0.97      0.92      0.94       708
04:07:28.686372: ----------
04:07:28.686917: LR: 
 [[505  85]
 [  0   0]]
04:07:28.689461: LR: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92       590
           1       0.00      0.00      0.00         0

    accuracy                           0.86       590
   macro avg       0.50      0.43      0.46       590
weighted avg       1.00      0.86      0.92       590
04:07:28.691253: Validation Seq.Label F1: 0.33167753850632753; Log.Reg F1: 0.4611872146118722; train loss: 0.051841411739587784; Language: japanese 

04:07:28.692607: Combined F1 SeqLab: 0.5356431561944007; train loss: 0.051841411739587784
04:07:28.693967: Combined F1 LogReg: 0.4263792655890496; train loss: 0.051841411739587784 

04:07:28.694559: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 30/40
04:10:12.946564: Evaluating Language: english
04:10:12.946668: ----------
04:10:17.923029: OBI: 
 [[3779   52   92]
 [   1   13    2]
 [  40    3   78]]
04:10:17.927536: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      3923
           1       0.19      0.81      0.31        16
           2       0.45      0.64      0.53       121

    accuracy                           0.95      4060
   macro avg       0.54      0.81      0.61      4060
weighted avg       0.97      0.95      0.96      4060
04:10:17.927585: ----------
04:10:17.928247: LR: 
 [[459 470]
 [  1  15]]
04:10:17.930954: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       929
           1       0.03      0.94      0.06        16

    accuracy                           0.50       945
   macro avg       0.51      0.72      0.36       945
weighted avg       0.98      0.50      0.65       945
04:10:17.933157: Validation Seq.Label F1: 0.6060181565356557; Log.Reg F1: 0.3603936834753819; train loss: 0.0399242602288723; Language: english 

04:10:17.933213: Evaluating Language: finnish
04:10:17.933259: ----------
04:10:25.055126: OBI: 
 [[3772   56  115]
 [   5   19    1]
 [ 126    3  127]]
04:10:25.059723: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.96      3943
           1       0.24      0.76      0.37        25
           2       0.52      0.50      0.51       256

    accuracy                           0.93      4224
   macro avg       0.58      0.74      0.61      4224
weighted avg       0.94      0.93      0.93      4224
04:10:25.059766: ----------
04:10:25.060648: LR: 
 [[919 652]
 [  6  19]]
04:10:25.063915: LR: 
               precision    recall  f1-score   support

           0       0.99      0.58      0.74      1571
           1       0.03      0.76      0.05        25

    accuracy                           0.59      1596
   macro avg       0.51      0.67      0.40      1596
weighted avg       0.98      0.59      0.73      1596
04:10:25.065648: Validation Seq.Label F1: 0.6131530413680463; Log.Reg F1: 0.39548795313881524; train loss: 0.0399242602288723; Language: finnish 

04:10:25.065702: Evaluating Language: japanese
04:10:25.065746: ----------
04:10:28.263323: OBI: 
 [[361   4   3]
 [  0   0   0]
 [  0   0   0]]
04:10:28.265613: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99       368
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.98       368
   macro avg       0.33      0.33      0.33       368
weighted avg       1.00      0.98      0.99       368
04:10:28.265655: ----------
04:10:28.266205: LR: 
 [[512  78]
 [  0   0]]
04:10:28.268737: LR: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93       590
           1       0.00      0.00      0.00         0

    accuracy                           0.87       590
   macro avg       0.50      0.43      0.46       590
weighted avg       1.00      0.87      0.93       590
04:10:28.270405: Validation Seq.Label F1: 0.33013260173754; Log.Reg F1: 0.4646098003629764; train loss: 0.0399242602288723; Language: japanese 

04:10:28.271724: Combined F1 SeqLab: 0.5329797347366211; train loss: 0.0399242602288723
04:10:28.273033: Combined F1 LogReg: 0.40912776926864314; train loss: 0.0399242602288723 

04:10:28.273627: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 31/40
04:13:11.620887: Evaluating Language: english
04:13:11.620997: ----------
04:13:16.295264: OBI: 
 [[3188   43  326]
 [   3    9    3]
 [  21    2  154]]
04:13:16.299562: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      3557
           1       0.17      0.60      0.26        15
           2       0.32      0.87      0.47       177

    accuracy                           0.89      3749
   macro avg       0.49      0.79      0.56      3749
weighted avg       0.96      0.89      0.92      3749
04:13:16.299604: ----------
04:13:16.300418: LR: 
 [[404 526]
 [  3  12]]
04:13:16.303356: LR: 
               precision    recall  f1-score   support

           0       0.99      0.43      0.60       930
           1       0.02      0.80      0.04        15

    accuracy                           0.44       945
   macro avg       0.51      0.62      0.32       945
weighted avg       0.98      0.44      0.60       945
04:13:16.305457: Validation Seq.Label F1: 0.5564924781416846; Log.Reg F1: 0.323868854321502; train loss: 0.04388891160488129; Language: english 

04:13:16.305512: Evaluating Language: finnish
04:13:16.305556: ----------
04:13:23.367316: OBI: 
 [[3558   58  572]
 [   3   15    6]
 [  46    4  122]]
04:13:23.371974: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.85      0.91      4188
           1       0.19      0.62      0.30        24
           2       0.17      0.71      0.28       172

    accuracy                           0.84      4384
   macro avg       0.45      0.73      0.50      4384
weighted avg       0.95      0.84      0.88      4384
04:13:23.372019: ----------
04:13:23.372892: LR: 
 [[863 709]
 [  4  20]]
04:13:23.376136: LR: 
               precision    recall  f1-score   support

           0       1.00      0.55      0.71      1572
           1       0.03      0.83      0.05        24

    accuracy                           0.55      1596
   macro avg       0.51      0.69      0.38      1596
weighted avg       0.98      0.55      0.70      1596
04:13:23.377885: Validation Seq.Label F1: 0.4965796989276933; Log.Reg F1: 0.38039396330218284; train loss: 0.04388891160488129; Language: finnish 

04:13:23.377940: Evaluating Language: japanese
04:13:23.377983: ----------
04:13:26.500951: OBI: 
 [[939   7  78]
 [  0   0   0]
 [  0   0   0]]
04:13:26.504002: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96      1024
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.92      1024
   macro avg       0.33      0.31      0.32      1024
weighted avg       1.00      0.92      0.96      1024
04:13:26.504046: ----------
04:13:26.504653: LR: 
 [[487 103]
 [  0   0]]
04:13:26.507633: LR: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.90       590
           1       0.00      0.00      0.00         0

    accuracy                           0.83       590
   macro avg       0.50      0.41      0.45       590
weighted avg       1.00      0.83      0.90       590
04:13:26.509496: Validation Seq.Label F1: 0.3188996434029547; Log.Reg F1: 0.4521819870009285; train loss: 0.04388891160488129; Language: japanese 

04:13:26.511066: Combined F1 SeqLab: 0.46832049502376877; train loss: 0.04388891160488129
04:13:26.512582: Combined F1 LogReg: 0.3890411938275828; train loss: 0.04388891160488129 

04:13:26.513260: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 32/40
04:16:09.875805: Evaluating Language: english
04:16:09.875928: ----------
04:16:14.714665: OBI: 
 [[4825   35  182]
 [   5   17    1]
 [  82    2  122]]
04:16:14.719878: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      5042
           1       0.31      0.74      0.44        23
           2       0.40      0.59      0.48       206

    accuracy                           0.94      5271
   macro avg       0.57      0.76      0.63      5271
weighted avg       0.96      0.94      0.95      5271
04:16:14.719923: ----------
04:16:14.720598: LR: 
 [[447 475]
 [  2  21]]
04:16:14.723301: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65       922
           1       0.04      0.91      0.08        23

    accuracy                           0.50       945
   macro avg       0.52      0.70      0.37       945
weighted avg       0.97      0.50      0.64       945
04:16:14.725468: Validation Seq.Label F1: 0.6295043543179488; Log.Reg F1: 0.36650181505419865; train loss: 0.031931810081005096; Language: english 

04:16:14.725523: Evaluating Language: finnish
04:16:14.725567: ----------
04:16:21.690022: OBI: 
 [[3108   23   80]
 [   2   12    1]
 [  58    1  107]]
04:16:21.694062: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.97      0.97      3211
           1       0.33      0.80      0.47        15
           2       0.57      0.64      0.60       166

    accuracy                           0.95      3392
   macro avg       0.63      0.80      0.68      3392
weighted avg       0.96      0.95      0.95      3392
04:16:21.694109: ----------
04:16:21.694985: LR: 
 [[915 666]
 [  4  11]]
04:16:21.698246: LR: 
               precision    recall  f1-score   support

           0       1.00      0.58      0.73      1581
           1       0.02      0.73      0.03        15

    accuracy                           0.58      1596
   macro avg       0.51      0.66      0.38      1596
weighted avg       0.99      0.58      0.73      1596
04:16:21.700013: Validation Seq.Label F1: 0.6831851382849589; Log.Reg F1: 0.3818959537572254; train loss: 0.031931810081005096; Language: finnish 

04:16:21.700068: Evaluating Language: japanese
04:16:21.700112: ----------
04:16:24.807280: OBI: 
 [[1285    6    5]
 [   1    0    0]
 [  11    0    0]]
04:16:24.809976: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.99      0.99      1296
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00        11

    accuracy                           0.98      1308
   macro avg       0.33      0.33      0.33      1308
weighted avg       0.98      0.98      0.98      1308
04:16:24.810018: ----------
04:16:24.810573: LR: 
 [[497  92]
 [  1   0]]
04:16:24.812961: LR: 
               precision    recall  f1-score   support

           0       1.00      0.84      0.91       589
           1       0.00      0.00      0.00         1

    accuracy                           0.84       590
   macro avg       0.50      0.42      0.46       590
weighted avg       1.00      0.84      0.91       590
04:16:24.814801: Validation Seq.Label F1: 0.33037665509705616; Log.Reg F1: 0.4572217111315548; train loss: 0.031931810081005096; Language: japanese 

04:16:24.816137: Combined F1 SeqLab: 0.5692586991025596; train loss: 0.031931810081005096
04:16:24.817479: Combined F1 LogReg: 0.4038233083351471; train loss: 0.031931810081005096 

04:16:24.818052: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 33/40
04:19:09.011738: Evaluating Language: english
04:19:09.011858: ----------
04:19:13.896373: OBI: 
 [[3186   36   97]
 [   2    6    2]
 [  15    5   80]]
04:19:13.901321: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      3319
           1       0.13      0.60      0.21        10
           2       0.45      0.80      0.57       100

    accuracy                           0.95      3429
   macro avg       0.52      0.79      0.59      3429
weighted avg       0.98      0.95      0.96      3429
04:19:13.901374: ----------
04:19:13.902276: LR: 
 [[463 472]
 [  1   9]]
04:19:13.905513: LR: 
               precision    recall  f1-score   support

           0       1.00      0.50      0.66       935
           1       0.02      0.90      0.04        10

    accuracy                           0.50       945
   macro avg       0.51      0.70      0.35       945
weighted avg       0.99      0.50      0.66       945
04:19:13.908447: Validation Seq.Label F1: 0.5870013127538786; Log.Reg F1: 0.3492806179566726; train loss: 0.03445607051253319; Language: english 

04:19:13.908526: Evaluating Language: finnish
04:19:13.908579: ----------
04:19:20.983035: OBI: 
 [[3508   63  187]
 [   4   23    2]
 [ 126    6   97]]
04:19:20.987510: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.93      0.95      3758
           1       0.25      0.79      0.38        29
           2       0.34      0.42      0.38       229

    accuracy                           0.90      4016
   macro avg       0.52      0.72      0.57      4016
weighted avg       0.92      0.90      0.91      4016
04:19:20.987553: ----------
04:19:20.988425: LR: 
 [[825 742]
 [  1  28]]
04:19:20.991677: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.69      1567
           1       0.04      0.97      0.07        29

    accuracy                           0.53      1596
   macro avg       0.52      0.75      0.38      1596
weighted avg       0.98      0.53      0.68      1596
04:19:20.993414: Validation Seq.Label F1: 0.5684950648438939; Log.Reg F1: 0.37979934173881164; train loss: 0.03445607051253319; Language: finnish 

04:19:20.993469: Evaluating Language: japanese
04:19:20.993511: ----------
04:19:24.182585: OBI: 
 [[298   2   4]
 [  0   0   0]
 [  0   0   4]]
04:19:24.184844: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99       304
           1       0.00      0.00      0.00         0
           2       0.50      1.00      0.67         4

    accuracy                           0.98       308
   macro avg       0.50      0.66      0.55       308
weighted avg       0.99      0.98      0.99       308
04:19:24.184886: ----------
04:19:24.185455: LR: 
 [[352 238]
 [  0   0]]
04:19:24.188019: LR: 
               precision    recall  f1-score   support

           0       1.00      0.60      0.75       590
           1       0.00      0.00      0.00         0

    accuracy                           0.60       590
   macro avg       0.50      0.30      0.37       590
weighted avg       1.00      0.60      0.75       590
04:19:24.189694: Validation Seq.Label F1: 0.5522332964193429; Log.Reg F1: 0.3736730360934183; train loss: 0.03445607051253319; Language: japanese 

04:19:24.191012: Combined F1 SeqLab: 0.5694204052077322; train loss: 0.03445607051253319
04:19:24.192336: Combined F1 LogReg: 0.3678206211224446; train loss: 0.03445607051253319 

04:19:24.192917: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 34/40
04:22:08.848437: Evaluating Language: english
04:22:08.848765: ----------
04:22:13.628982: OBI: 
 [[3096   35   85]
 [   4   12    2]
 [  42    2   57]]
04:22:13.633087: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97      3216
           1       0.24      0.67      0.36        18
           2       0.40      0.56      0.47       101

    accuracy                           0.95      3335
   macro avg       0.54      0.73      0.60      3335
weighted avg       0.96      0.95      0.96      3335
04:22:13.633131: ----------
04:22:13.633824: LR: 
 [[429 498]
 [  0  18]]
04:22:13.636522: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63       927
           1       0.03      1.00      0.07        18

    accuracy                           0.47       945
   macro avg       0.52      0.73      0.35       945
weighted avg       0.98      0.47      0.62       945
04:22:13.639391: Validation Seq.Label F1: 0.5991354128050774; Log.Reg F1: 0.3500795465844685; train loss: 0.02388545498251915; Language: english 

04:22:13.639446: Evaluating Language: finnish
04:22:13.639489: ----------
04:22:20.731877: OBI: 
 [[3258   48  133]
 [   4   18    1]
 [ 106    5  135]]
04:22:20.736219: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.95      0.96      3439
           1       0.25      0.78      0.38        23
           2       0.50      0.55      0.52       246

    accuracy                           0.92      3708
   macro avg       0.57      0.76      0.62      3708
weighted avg       0.93      0.92      0.92      3708
04:22:20.736262: ----------
04:22:20.737132: LR: 
 [[891 682]
 [  5  18]]
04:22:20.740362: LR: 
               precision    recall  f1-score   support

           0       0.99      0.57      0.72      1573
           1       0.03      0.78      0.05        23

    accuracy                           0.57      1596
   macro avg       0.51      0.67      0.39      1596
weighted avg       0.98      0.57      0.71      1596
04:22:20.744189: Validation Seq.Label F1: 0.6215001526279177; Log.Reg F1: 0.38577111367681244; train loss: 0.02388545498251915; Language: finnish 

04:22:20.744247: Evaluating Language: japanese
04:22:20.744292: ----------
04:22:23.846051: OBI: 
 [[299   3  14]
 [  0   0   0]
 [  0   0   0]]
04:22:23.848367: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.95      0.97       316
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.95       316
   macro avg       0.33      0.32      0.32       316
weighted avg       1.00      0.95      0.97       316
04:22:23.848412: ----------
04:22:23.848969: LR: 
 [[527  63]
 [  0   0]]
04:22:23.851524: LR: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94       590
           1       0.00      0.00      0.00         0

    accuracy                           0.89       590
   macro avg       0.50      0.45      0.47       590
weighted avg       1.00      0.89      0.94       590
04:22:23.853826: Validation Seq.Label F1: 0.3241192411924119; Log.Reg F1: 0.4717994628469114; train loss: 0.02388545498251915; Language: japanese 

04:22:23.855606: Combined F1 SeqLab: 0.5323779876193168; train loss: 0.02388545498251915
04:22:23.857318: Combined F1 LogReg: 0.4057789933066477; train loss: 0.02388545498251915 

04:22:23.858101: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 35/40
04:25:10.877837: Evaluating Language: english
04:25:10.877983: ----------
04:25:15.708555: OBI: 
 [[5709   51  214]
 [   4   13    4]
 [ 101    4  176]]
04:25:15.714727: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      5974
           1       0.19      0.62      0.29        21
           2       0.45      0.63      0.52       281

    accuracy                           0.94      6276
   macro avg       0.54      0.73      0.59      6276
weighted avg       0.96      0.94      0.95      6276
04:25:15.714785: ----------
04:25:15.715602: LR: 
 [[429 495]
 [  1  20]]
04:25:15.718410: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63       924
           1       0.04      0.95      0.07        21

    accuracy                           0.48       945
   macro avg       0.52      0.71      0.35       945
weighted avg       0.98      0.48      0.62       945
04:25:15.720800: Validation Seq.Label F1: 0.5940761536297402; Log.Reg F1: 0.35415242840450634; train loss: 0.034619808197021484; Language: english 

04:25:15.720875: Evaluating Language: finnish
04:25:15.720929: ----------
04:25:22.651318: OBI: 
 [[2836   43  175]
 [   3   12    2]
 [ 119    5  101]]
04:25:22.655292: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.93      0.94      3054
           1       0.20      0.71      0.31        17
           2       0.36      0.45      0.40       225

    accuracy                           0.89      3296
   macro avg       0.51      0.69      0.55      3296
weighted avg       0.91      0.89      0.90      3296
04:25:22.655343: ----------
04:25:22.656201: LR: 
 [[784 795]
 [  6  11]]
04:25:22.659467: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.66      1579
           1       0.01      0.65      0.03        17

    accuracy                           0.50      1596
   macro avg       0.50      0.57      0.34      1596
weighted avg       0.98      0.50      0.66      1596
04:25:22.661191: Validation Seq.Label F1: 0.5522417364657338; Log.Reg F1: 0.34430706056920934; train loss: 0.034619808197021484; Language: finnish 

04:25:22.661243: Evaluating Language: japanese
04:25:22.661285: ----------
04:25:25.863260: OBI: 
 [[1071    9   82]
 [   0    1    0]
 [   0    0    3]]
04:25:25.865896: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96      1162
           1       0.10      1.00      0.18         1
           2       0.04      1.00      0.07         3

    accuracy                           0.92      1166
   macro avg       0.38      0.97      0.40      1166
weighted avg       1.00      0.92      0.96      1166
04:25:25.865939: ----------
04:25:25.866505: LR: 
 [[439 150]
 [  0   1]]
04:25:25.868907: LR: 
               precision    recall  f1-score   support

           0       1.00      0.75      0.85       589
           1       0.01      1.00      0.01         1

    accuracy                           0.75       590
   macro avg       0.50      0.87      0.43       590
weighted avg       1.00      0.75      0.85       590
04:25:25.870627: Validation Seq.Label F1: 0.4030825496342738; Log.Reg F1: 0.43362174892484134; train loss: 0.034619808197021484; Language: japanese 

04:25:25.871951: Combined F1 SeqLab: 0.522931784469658; train loss: 0.034619808197021484
04:25:25.873276: Combined F1 LogReg: 0.3794729308058992; train loss: 0.034619808197021484 

04:25:25.873865: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 36/40
04:28:10.127980: Evaluating Language: english
04:28:10.128095: ----------
04:28:15.149691: OBI: 
 [[3191   40  152]
 [   4   12    1]
 [  40    4   87]]
04:28:15.153862: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      3383
           1       0.21      0.71      0.33        17
           2       0.36      0.66      0.47       131

    accuracy                           0.93      3531
   macro avg       0.52      0.77      0.59      3531
weighted avg       0.96      0.93      0.94      3531
04:28:15.153909: ----------
04:28:15.154601: LR: 
 [[456 472]
 [  2  15]]
04:28:15.157299: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       928
           1       0.03      0.88      0.06        17

    accuracy                           0.50       945
   macro avg       0.51      0.69      0.36       945
weighted avg       0.98      0.50      0.65       945
04:28:15.159543: Validation Seq.Label F1: 0.5873698327889967; Log.Reg F1: 0.3587662337662338; train loss: 0.026372676715254784; Language: english 

04:28:15.159599: Evaluating Language: finnish
04:28:15.159644: ----------
04:28:22.242468: OBI: 
 [[1894   19  120]
 [   2    6    0]
 [  70    4   93]]
04:28:22.245763: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.93      0.95      2033
           1       0.21      0.75      0.32         8
           2       0.44      0.56      0.49       167

    accuracy                           0.90      2208
   macro avg       0.54      0.75      0.59      2208
weighted avg       0.92      0.90      0.91      2208
04:28:22.245808: ----------
04:28:22.246676: LR: 
 [[955 633]
 [  3   5]]
04:28:22.249886: LR: 
               precision    recall  f1-score   support

           0       1.00      0.60      0.75      1588
           1       0.01      0.62      0.02         8

    accuracy                           0.60      1596
   macro avg       0.50      0.61      0.38      1596
weighted avg       0.99      0.60      0.75      1596
04:28:22.251607: Validation Seq.Label F1: 0.5870116059123838; Log.Reg F1: 0.38283813132480016; train loss: 0.026372676715254784; Language: finnish 

04:28:22.251663: Evaluating Language: japanese
04:28:22.251706: ----------
04:28:25.452293: OBI: 
 [[1451   16   63]
 [   1    1    0]
 [  20    0   14]]
04:28:25.455179: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      1530
           1       0.06      0.50      0.11         2
           2       0.18      0.41      0.25        34

    accuracy                           0.94      1566
   macro avg       0.41      0.62      0.44      1566
weighted avg       0.97      0.94      0.95      1566
04:28:25.455221: ----------
04:28:25.455775: LR: 
 [[522  66]
 [  1   1]]
04:28:25.458156: LR: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94       588
           1       0.01      0.50      0.03         2

    accuracy                           0.89       590
   macro avg       0.51      0.69      0.48       590
weighted avg       0.99      0.89      0.94       590
04:28:25.459794: Validation Seq.Label F1: 0.44140142807697774; Log.Reg F1: 0.4843397383216583; train loss: 0.026372676715254784; Language: japanese 

04:28:25.461107: Combined F1 SeqLab: 0.5429613757456433; train loss: 0.026372676715254784
04:28:25.462425: Combined F1 LogReg: 0.4122552718096581; train loss: 0.026372676715254784 

04:28:25.463001: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 37/40
04:31:10.770807: Evaluating Language: english
04:31:10.770917: ----------
04:31:15.767061: OBI: 
 [[2470   39  134]
 [   1    7    1]
 [  18    3   83]]
04:31:15.770714: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      2643
           1       0.14      0.78      0.24         9
           2       0.38      0.80      0.52       104

    accuracy                           0.93      2756
   macro avg       0.51      0.84      0.57      2756
weighted avg       0.97      0.93      0.94      2756
04:31:15.770757: ----------
04:31:15.771434: LR: 
 [[459 477]
 [  1   8]]
04:31:15.774157: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       936
           1       0.02      0.89      0.03         9

    accuracy                           0.49       945
   macro avg       0.51      0.69      0.34       945
weighted avg       0.99      0.49      0.65       945
04:31:15.776299: Validation Seq.Label F1: 0.573164981922801; Log.Reg F1: 0.3449908935883902; train loss: 0.02022562175989151; Language: english 

04:31:15.776362: Evaluating Language: finnish
04:31:15.776407: ----------
04:31:22.733861: OBI: 
 [[3617   62  268]
 [   2   18    5]
 [ 107    5  108]]
04:31:22.738448: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.92      0.94      3947
           1       0.21      0.72      0.33        25
           2       0.28      0.49      0.36       220

    accuracy                           0.89      4192
   macro avg       0.49      0.71      0.54      4192
weighted avg       0.93      0.89      0.91      4192
04:31:22.738493: ----------
04:31:22.739370: LR: 
 [[872 699]
 [  3  22]]
04:31:22.742605: LR: 
               precision    recall  f1-score   support

           0       1.00      0.56      0.71      1571
           1       0.03      0.88      0.06        25

    accuracy                           0.56      1596
   macro avg       0.51      0.72      0.39      1596
weighted avg       0.98      0.56      0.70      1596
04:31:22.744409: Validation Seq.Label F1: 0.5431533731524645; Log.Reg F1: 0.38599102545272806; train loss: 0.02022562175989151; Language: finnish 

04:31:22.744463: Evaluating Language: japanese
04:31:22.744506: ----------
04:31:25.988057: OBI: 
 [[89  1 12]
 [ 0  0  0]
 [ 0  0  0]]
04:31:25.990200: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93       102
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.87       102
   macro avg       0.33      0.29      0.31       102
weighted avg       1.00      0.87      0.93       102
04:31:25.990242: ----------
04:31:25.990799: LR: 
 [[437 153]
 [  0   0]]
04:31:25.993354: LR: 
               precision    recall  f1-score   support

           0       1.00      0.74      0.85       590
           1       0.00      0.00      0.00         0

    accuracy                           0.74       590
   macro avg       0.50      0.37      0.43       590
weighted avg       1.00      0.74      0.85       590
04:31:25.994987: Validation Seq.Label F1: 0.3106457242582897; Log.Reg F1: 0.42551119766309636; train loss: 0.02022562175989151; Language: japanese 

04:31:25.996333: Combined F1 SeqLab: 0.48990966829590893; train loss: 0.02022562175989151
04:31:25.997647: Combined F1 LogReg: 0.386896871584512; train loss: 0.02022562175989151 

04:31:25.998219: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 38/40
04:34:10.194708: Evaluating Language: english
04:34:10.194858: ----------
04:34:14.870692: OBI: 
 [[2759   25  108]
 [   0    9    2]
 [  17    2   75]]
04:34:14.874607: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      2892
           1       0.25      0.82      0.38        11
           2       0.41      0.80      0.54        94

    accuracy                           0.95      2997
   macro avg       0.55      0.86      0.63      2997
weighted avg       0.97      0.95      0.96      2997
04:34:14.874657: ----------
04:34:14.875365: LR: 
 [[433 501]
 [  0  11]]
04:34:14.878081: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63       934
           1       0.02      1.00      0.04        11

    accuracy                           0.47       945
   macro avg       0.51      0.73      0.34       945
weighted avg       0.99      0.47      0.63       945
04:34:14.880977: Validation Seq.Label F1: 0.6313829235598863; Log.Reg F1: 0.337784516484577; train loss: 0.01781858317553997; Language: english 

04:34:14.881042: Evaluating Language: finnish
04:34:14.881087: ----------
04:34:21.925926: OBI: 
 [[2523   33  143]
 [   1    7    3]
 [  20    0   58]]
04:34:21.929578: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      2699
           1       0.17      0.64      0.27        11
           2       0.28      0.74      0.41        78

    accuracy                           0.93      2788
   macro avg       0.48      0.77      0.55      2788
weighted avg       0.97      0.93      0.94      2788
04:34:21.929622: ----------
04:34:21.930500: LR: 
 [[898 687]
 [  1  10]]
04:34:21.933741: LR: 
               precision    recall  f1-score   support

           0       1.00      0.57      0.72      1585
           1       0.01      0.91      0.03        11

    accuracy                           0.57      1596
   macro avg       0.51      0.74      0.38      1596
weighted avg       0.99      0.57      0.72      1596
04:34:21.936953: Validation Seq.Label F1: 0.549427804528055; Log.Reg F1: 0.3756379813859549; train loss: 0.01781858317553997; Language: finnish 

04:34:21.937007: Evaluating Language: japanese
04:34:21.937052: ----------
04:34:24.944815: OBI: 
 [[739   3  30]
 [  0   1   1]
 [  5   0   9]]
04:34:24.947204: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97       772
           1       0.25      0.50      0.33         2
           2       0.23      0.64      0.33        14

    accuracy                           0.95       788
   macro avg       0.49      0.70      0.55       788
weighted avg       0.98      0.95      0.96       788
04:34:24.947250: ----------
04:34:24.947836: LR: 
 [[416 172]
 [  1   1]]
04:34:24.950214: LR: 
               precision    recall  f1-score   support

           0       1.00      0.71      0.83       588
           1       0.01      0.50      0.01         2

    accuracy                           0.71       590
   macro avg       0.50      0.60      0.42       590
weighted avg       0.99      0.71      0.83       590
04:34:24.951904: Validation Seq.Label F1: 0.5472002345353268; Log.Reg F1: 0.41964463397299223; train loss: 0.01781858317553997; Language: japanese 

04:34:24.953901: Combined F1 SeqLab: 0.5773339314547704; train loss: 0.01781858317553997
04:34:26.973817: Combined F1 LogReg: 0.3791674614462415; train loss: 0.01781858317553997 

04:34:26.975837: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 39/40
04:37:09.409750: Evaluating Language: english
04:37:09.409889: ----------
04:37:14.327158: OBI: 
 [[2698   32  125]
 [   3    8    1]
 [  42    2   66]]
04:37:14.331151: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96      2855
           1       0.19      0.67      0.30        12
           2       0.34      0.60      0.44       110

    accuracy                           0.93      2977
   macro avg       0.51      0.74      0.57      2977
weighted avg       0.96      0.93      0.94      2977
04:37:14.331203: ----------
04:37:14.332016: LR: 
 [[454 479]
 [  4   8]]
04:37:14.334905: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.65       933
           1       0.02      0.67      0.03        12

    accuracy                           0.49       945
   macro avg       0.50      0.58      0.34       945
weighted avg       0.98      0.49      0.64       945
04:37:14.336802: Validation Seq.Label F1: 0.5657660243948156; Log.Reg F1: 0.3424159606056109; train loss: 0.020280780270695686; Language: english 

04:37:14.336869: Evaluating Language: finnish
04:37:14.336922: ----------
04:37:21.295565: OBI: 
 [[3381   27  159]
 [   4   11    3]
 [ 111    7   89]]
04:37:21.299912: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.95      0.96      3567
           1       0.24      0.61      0.35        18
           2       0.35      0.43      0.39       207

    accuracy                           0.92      3792
   macro avg       0.52      0.66      0.57      3792
weighted avg       0.93      0.92      0.92      3792
04:37:21.299955: ----------
04:37:21.300841: LR: 
 [[899 679]
 [  2  16]]
04:37:21.304069: LR: 
               precision    recall  f1-score   support

           0       1.00      0.57      0.73      1578
           1       0.02      0.89      0.04        18

    accuracy                           0.57      1596
   macro avg       0.51      0.73      0.39      1596
weighted avg       0.99      0.57      0.72      1596
04:37:21.305809: Validation Seq.Label F1: 0.5650787284944498; Log.Reg F1: 0.38508662102474245; train loss: 0.020280780270695686; Language: finnish 

04:37:21.305862: Evaluating Language: japanese
04:37:21.305906: ----------
04:37:24.427652: OBI: 
 [[536   1  21]
 [  0   0   0]
 [  6   0   0]]
04:37:24.431421: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97       558
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         6

    accuracy                           0.95       564
   macro avg       0.33      0.32      0.32       564
weighted avg       0.98      0.95      0.96       564
04:37:24.431489: ----------
04:37:24.432318: LR: 
 [[440 150]
 [  0   0]]
04:37:24.436249: LR: 
               precision    recall  f1-score   support

           0       1.00      0.75      0.85       590
           1       0.00      0.00      0.00         0

    accuracy                           0.75       590
   macro avg       0.50      0.37      0.43       590
weighted avg       1.00      0.75      0.85       590
04:37:24.438847: Validation Seq.Label F1: 0.32484848484848483; Log.Reg F1: 0.42718446601941745; train loss: 0.020280780270695686; Language: japanese 

04:37:24.440923: Combined F1 SeqLab: 0.4983077034205457; train loss: 0.020280780270695686
04:37:24.443093: Combined F1 LogReg: 0.38644834229083874; train loss: 0.020280780270695686 

04:37:24.444348: Model: lab6_xlm-roberta-base_english.pt; Language: english; Epoch 40/40
04:40:09.892529: Evaluating Language: english
04:40:09.892677: ----------
04:40:14.793413: OBI: 
 [[4065   74  198]
 [   3    8    2]
 [  76    5  123]]
04:40:14.798294: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      4337
           1       0.09      0.62      0.16        13
           2       0.38      0.60      0.47       204

    accuracy                           0.92      4554
   macro avg       0.48      0.72      0.53      4554
weighted avg       0.95      0.92      0.93      4554
04:40:14.798342: ----------
04:40:14.799015: LR: 
 [[493 439]
 [  1  12]]
04:40:14.801701: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.69       932
           1       0.03      0.92      0.05        13

    accuracy                           0.53       945
   macro avg       0.51      0.73      0.37       945
weighted avg       0.98      0.53      0.68       945
04:40:14.804251: Validation Seq.Label F1: 0.5284688466483961; Log.Reg F1: 0.3715843691057697; train loss: 0.030643418431282043; Language: english 

04:40:14.804320: Evaluating Language: finnish
04:40:14.804365: ----------
04:40:21.747450: OBI: 
 [[2827   39  174]
 [   5   10    2]
 [  45    6   76]]
04:40:21.751331: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.96      3040
           1       0.18      0.59      0.28        17
           2       0.30      0.60      0.40       127

    accuracy                           0.91      3184
   macro avg       0.49      0.71      0.54      3184
weighted avg       0.95      0.91      0.93      3184
04:40:21.751375: ----------
04:40:21.752233: LR: 
 [[947 632]
 [  6  11]]
04:40:21.755449: LR: 
               precision    recall  f1-score   support

           0       0.99      0.60      0.75      1579
           1       0.02      0.65      0.03        17

    accuracy                           0.60      1596
   macro avg       0.51      0.62      0.39      1596
weighted avg       0.98      0.60      0.74      1596
04:40:21.757164: Validation Seq.Label F1: 0.544794995549117; Log.Reg F1: 0.3906793048973144; train loss: 0.030643418431282043; Language: finnish 

04:40:21.757218: Evaluating Language: japanese
04:40:21.757262: ----------
04:40:24.716021: OBI: 
 [[1204   14   33]
 [   0    0    0]
 [   7    0    0]]
04:40:24.718837: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      1251
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         7

    accuracy                           0.96      1258
   macro avg       0.33      0.32      0.33      1258
weighted avg       0.99      0.96      0.97      1258
04:40:24.718881: ----------
04:40:24.719444: LR: 
 [[524  66]
 [  0   0]]
04:40:24.721988: LR: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94       590
           1       0.00      0.00      0.00         0

    accuracy                           0.89       590
   macro avg       0.50      0.44      0.47       590
weighted avg       1.00      0.89      0.94       590
04:40:24.723619: Validation Seq.Label F1: 0.32602220417005146; Log.Reg F1: 0.4703770197486535; train loss: 0.030643418431282043; Language: japanese 

04:40:24.724925: Combined F1 SeqLab: 0.4769246574548042; train loss: 0.030643418431282043
04:40:24.726221: Combined F1 LogReg: 0.41310200650945234; train loss: 0.030643418431282043 

04:40:24.726281: Learning rates: []
04:40:29.458255: -- Data Parsing FINNISH; Type: TRAIN--
04:41:18.213300: Unanswerable questions: 6813
04:41:18.313236: Balance of labels: dict_keys([-100, 0, 1, 2]):dict_values([145052, 1448121, 6256, 54554])
04:41:18.313305: Entries skipped due to too long sequence length (>512): 78
04:41:18.313378: Failed to map answer and to context: 554
04:41:18.403743: Label counts: O: 1448121, B: 6256, I: 54554
04:41:18.403978: Final length: 13069 

04:41:18.426632: Language: finnish; Class weights: [0.00386068 0.89365868 0.10248064 0.        ]
04:41:18.537913: Training model: lab6_xlm-roberta-base_finnish.pt
04:41:18.538053: Loading model: xlm-roberta-base
04:41:21.778039: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 1/40
04:46:12.711139: Evaluating Language: english
04:46:12.711370: ----------
04:46:17.685665: OBI: 
 [[1238  136 1409]
 [   0    8    2]
 [   2    2  136]]
04:46:17.689623: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.44      0.62      2783
           1       0.05      0.80      0.10        10
           2       0.09      0.97      0.16       140

    accuracy                           0.47      2933
   macro avg       0.38      0.74      0.29      2933
weighted avg       0.95      0.47      0.59      2933
04:46:17.689672: ----------
04:46:17.690375: LR: 
 [[689 246]
 [  6   4]]
04:46:17.693079: LR: 
               precision    recall  f1-score   support

           0       0.99      0.74      0.85       935
           1       0.02      0.40      0.03        10

    accuracy                           0.73       945
   macro avg       0.50      0.57      0.44       945
weighted avg       0.98      0.73      0.84       945
04:46:17.698425: Validation Seq.Label F1: 0.29308605305337787; Log.Reg F1: 0.4380840018876829; train loss: 0.5231245756149292; Language: english 

04:46:17.698498: Evaluating Language: finnish
04:46:17.698551: ----------
04:46:24.719680: OBI: 
 [[1894  119  810]
 [   2   13    4]
 [   7    4  159]]
04:46:24.723533: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.67      0.80      2823
           1       0.10      0.68      0.17        19
           2       0.16      0.94      0.28       170

    accuracy                           0.69      3012
   macro avg       0.42      0.76      0.42      3012
weighted avg       0.94      0.69      0.77      3012
04:46:24.723581: ----------
04:46:24.724454: LR: 
 [[826 751]
 [  7  12]]
04:46:24.727701: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.69      1577
           1       0.02      0.63      0.03        19

    accuracy                           0.53      1596
   macro avg       0.50      0.58      0.36      1596
weighted avg       0.98      0.53      0.68      1596
04:46:24.730592: Validation Seq.Label F1: 0.4158268818912209; Log.Reg F1: 0.35808385775381774; train loss: 0.5231245756149292; Language: finnish 

04:46:24.730653: Evaluating Language: japanese
04:46:24.730701: ----------
04:46:27.914139: OBI: 
 [[158   4  44]
 [  0   0   0]
 [  6   1   5]]
04:46:27.916410: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.77      0.85       206
           1       0.00      0.00      0.00         0
           2       0.10      0.42      0.16        12

    accuracy                           0.75       218
   macro avg       0.36      0.39      0.34       218
weighted avg       0.92      0.75      0.82       218
04:46:27.916462: ----------
04:46:27.917026: LR: 
 [[544  46]
 [  0   0]]
04:46:27.919599: LR: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96       590
           1       0.00      0.00      0.00         0

    accuracy                           0.92       590
   macro avg       0.50      0.46      0.48       590
weighted avg       1.00      0.92      0.96       590
04:46:27.922356: Validation Seq.Label F1: 0.33932949342785407; Log.Reg F1: 0.47971781305114636; train loss: 0.5231245756149292; Language: japanese 

04:46:27.924588: Combined F1 SeqLab: 0.35306087072334846; train loss: 0.5231245756149292
04:46:29.755591: Combined F1 LogReg: 0.4282798236559669; train loss: 0.5231245756149292 

04:46:29.760481: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 2/40
04:51:18.144608: Evaluating Language: english
04:51:18.144821: ----------
04:51:22.868823: OBI: 
 [[2243  330 1365]
 [   0   19    2]
 [   3    3  113]]
04:51:22.873586: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.57      0.73      3938
           1       0.05      0.90      0.10        21
           2       0.08      0.95      0.14       119

    accuracy                           0.58      4078
   macro avg       0.38      0.81      0.32      4078
weighted avg       0.97      0.58      0.71      4078
04:51:22.873641: ----------
04:51:22.874362: LR: 
 [[489 435]
 [  3  18]]
04:51:22.877085: LR: 
               precision    recall  f1-score   support

           0       0.99      0.53      0.69       924
           1       0.04      0.86      0.08        21

    accuracy                           0.54       945
   macro avg       0.52      0.69      0.38       945
weighted avg       0.97      0.54      0.68       945
04:51:22.882364: Validation Seq.Label F1: 0.3228784839694218; Log.Reg F1: 0.38331366659515126; train loss: 0.3392159640789032; Language: english 

04:51:22.882439: Evaluating Language: finnish
04:51:22.882488: ----------
04:51:29.913585: OBI: 
 [[3537  364 1154]
 [   0   27    1]
 [  25   16  268]]
04:51:29.919009: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.70      0.82      5055
           1       0.07      0.96      0.12        28
           2       0.19      0.87      0.31       309

    accuracy                           0.71      5392
   macro avg       0.42      0.84      0.42      5392
weighted avg       0.94      0.71      0.79      5392
04:51:29.919060: ----------
04:51:29.919950: LR: 
 [[709 859]
 [  1  27]]
04:51:29.923218: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62      1568
           1       0.03      0.96      0.06        28

    accuracy                           0.46      1596
   macro avg       0.51      0.71      0.34      1596
weighted avg       0.98      0.46      0.61      1596
04:51:29.926270: Validation Seq.Label F1: 0.41818070451320216; Log.Reg F1: 0.34077840940746135; train loss: 0.3392159640789032; Language: finnish 

04:51:29.926336: Evaluating Language: japanese
04:51:29.926383: ----------
04:51:33.031736: OBI: 
 [[637  29  84]
 [  0   1   0]
 [  0   1   4]]
04:51:33.034165: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.85      0.92       750
           1       0.03      1.00      0.06         1
           2       0.05      0.80      0.09         5

    accuracy                           0.85       756
   macro avg       0.36      0.88      0.36       756
weighted avg       0.99      0.85      0.91       756
04:51:33.034213: ----------
04:51:33.034807: LR: 
 [[506  83]
 [  0   1]]
04:51:33.037211: LR: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92       589
           1       0.01      1.00      0.02         1

    accuracy                           0.86       590
   macro avg       0.51      0.93      0.47       590
weighted avg       1.00      0.86      0.92       590
04:51:33.039999: Validation Seq.Label F1: 0.35568356836265064; Log.Reg F1: 0.47386516250335753; train loss: 0.3392159640789032; Language: japanese 

04:51:33.042315: Combined F1 SeqLab: 0.3677120330914481; train loss: 0.3392159640789032
04:51:35.032674: Combined F1 LogReg: 0.4031573239448969; train loss: 0.3392159640789032 

04:51:35.033518: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 3/40
04:56:23.026001: Evaluating Language: english
04:56:23.026205: ----------
04:56:27.791092: OBI: 
 [[2888  149  611]
 [   0   10    0]
 [  22    8  116]]
04:56:27.795622: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.79      0.88      3648
           1       0.06      1.00      0.11        10
           2       0.16      0.79      0.27       146

    accuracy                           0.79      3804
   macro avg       0.40      0.86      0.42      3804
weighted avg       0.96      0.79      0.86      3804
04:56:27.795670: ----------
04:56:27.796358: LR: 
 [[526 409]
 [  3   7]]
04:56:27.799062: LR: 
               precision    recall  f1-score   support

           0       0.99      0.56      0.72       935
           1       0.02      0.70      0.03        10

    accuracy                           0.56       945
   macro avg       0.51      0.63      0.38       945
weighted avg       0.98      0.56      0.71       945
04:56:27.805061: Validation Seq.Label F1: 0.4198336549333849; Log.Reg F1: 0.37572154236896793; train loss: 0.261093407869339; Language: english 

04:56:27.805128: Evaluating Language: finnish
04:56:27.805174: ----------
04:56:34.865942: OBI: 
 [[2784   87  355]
 [   0   13    0]
 [  54   15  200]]
04:56:34.870139: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.86      0.92      3226
           1       0.11      1.00      0.20        13
           2       0.36      0.74      0.49       269

    accuracy                           0.85      3508
   macro avg       0.48      0.87      0.54      3508
weighted avg       0.93      0.85      0.88      3508
04:56:34.870189: ----------
04:56:34.871076: LR: 
 [[632 951]
 [  0  13]]
04:56:34.874316: LR: 
               precision    recall  f1-score   support

           0       1.00      0.40      0.57      1583
           1       0.01      1.00      0.03        13

    accuracy                           0.40      1596
   macro avg       0.51      0.70      0.30      1596
weighted avg       0.99      0.40      0.57      1596
04:56:34.877198: Validation Seq.Label F1: 0.5355892326510746; Log.Reg F1: 0.2986333526643269; train loss: 0.261093407869339; Language: finnish 

04:56:34.877256: Evaluating Language: japanese
04:56:34.877301: ----------
04:56:38.094331: OBI: 
 [[467   5  33]
 [  0   0   0]
 [  0   0   1]]
04:56:38.096754: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96       505
           1       0.00      0.00      0.00         0
           2       0.03      1.00      0.06         1

    accuracy                           0.92       506
   macro avg       0.34      0.64      0.34       506
weighted avg       1.00      0.92      0.96       506
04:56:38.096800: ----------
04:56:38.097367: LR: 
 [[580  10]
 [  0   0]]
04:56:38.099897: LR: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99       590
           1       0.00      0.00      0.00         0

    accuracy                           0.98       590
   macro avg       0.50      0.49      0.50       590
weighted avg       1.00      0.98      0.99       590
04:56:38.102749: Validation Seq.Label F1: 0.3393494023123653; Log.Reg F1: 0.49572649572649574; train loss: 0.261093407869339; Language: japanese 

04:56:38.104992: Combined F1 SeqLab: 0.43904219265588096; train loss: 0.261093407869339
04:56:40.082598: Combined F1 LogReg: 0.39836888905005446; train loss: 0.261093407869339 

04:56:40.084184: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 4/40
05:01:26.450522: Evaluating Language: english
05:01:26.450735: ----------
05:01:31.304881: OBI: 
 [[3011  219 1330]
 [   0   14    2]
 [   0    3   67]]
05:01:31.309975: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.66      0.80      4560
           1       0.06      0.88      0.11        16
           2       0.05      0.96      0.09        70

    accuracy                           0.67      4646
   macro avg       0.37      0.83      0.33      4646
weighted avg       0.98      0.67      0.78      4646
05:01:31.310022: ----------
05:01:31.310724: LR: 
 [[470 459]
 [  2  14]]
05:01:31.313458: LR: 
               precision    recall  f1-score   support

           0       1.00      0.51      0.67       929
           1       0.03      0.88      0.06        16

    accuracy                           0.51       945
   macro avg       0.51      0.69      0.36       945
weighted avg       0.98      0.51      0.66       945
05:01:31.319144: Validation Seq.Label F1: 0.3325777135049358; Log.Reg F1: 0.36410451780717545; train loss: 0.2069201022386551; Language: english 

05:01:31.319211: Evaluating Language: finnish
05:01:31.319257: ----------
05:01:38.372745: OBI: 
 [[1490   78  388]
 [   0    8    0]
 [   5    1   78]]
05:01:38.376032: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.76      0.86      1956
           1       0.09      1.00      0.17         8
           2       0.17      0.93      0.28        84

    accuracy                           0.77      2048
   macro avg       0.42      0.90      0.44      2048
weighted avg       0.96      0.77      0.84      2048
05:01:38.376080: ----------
05:01:38.376959: LR: 
 [[670 918]
 [  0   8]]
05:01:38.380252: LR: 
               precision    recall  f1-score   support

           0       1.00      0.42      0.59      1588
           1       0.01      1.00      0.02         8

    accuracy                           0.42      1596
   macro avg       0.50      0.71      0.31      1596
weighted avg       1.00      0.42      0.59      1596
05:01:38.383227: Validation Seq.Label F1: 0.43852507906313826; Log.Reg F1: 0.30528807400003416; train loss: 0.2069201022386551; Language: finnish 

05:01:38.383289: Evaluating Language: japanese
05:01:38.383345: ----------
05:01:41.453600: OBI: 
 [[914  12 114]
 [  0   0   0]
 [  0   0   0]]
05:01:41.456323: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.94      1040
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.88      1040
   macro avg       0.33      0.29      0.31      1040
weighted avg       1.00      0.88      0.94      1040
05:01:41.456368: ----------
05:01:41.456944: LR: 
 [[483 107]
 [  0   0]]
05:01:41.459531: LR: 
               precision    recall  f1-score   support

           0       1.00      0.82      0.90       590
           1       0.00      0.00      0.00         0

    accuracy                           0.82       590
   macro avg       0.50      0.41      0.45       590
weighted avg       1.00      0.82      0.90       590
05:01:41.462351: Validation Seq.Label F1: 0.3118389628113272; Log.Reg F1: 0.4501397949673812; train loss: 0.2069201022386551; Language: japanese 

05:01:41.464643: Combined F1 SeqLab: 0.3652194405261706; train loss: 0.2069201022386551
05:01:41.466918: Combined F1 LogReg: 0.37788831816976565; train loss: 0.2069201022386551 

05:01:41.467528: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 5/40
05:06:27.526396: Evaluating Language: english
05:06:27.526575: ----------
05:06:32.460167: OBI: 
 [[4032  194  982]
 [   2   15    5]
 [   5    6  157]]
05:06:32.465566: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.77      0.87      5208
           1       0.07      0.68      0.13        22
           2       0.14      0.93      0.24       168

    accuracy                           0.78      5398
   macro avg       0.40      0.80      0.41      5398
weighted avg       0.97      0.78      0.85      5398
05:06:32.465611: ----------
05:06:32.466282: LR: 
 [[555 368]
 [  6  16]]
05:06:32.468994: LR: 
               precision    recall  f1-score   support

           0       0.99      0.60      0.75       923
           1       0.04      0.73      0.08        22

    accuracy                           0.60       945
   macro avg       0.52      0.66      0.41       945
weighted avg       0.97      0.60      0.73       945
05:06:32.472319: Validation Seq.Label F1: 0.4126593876578481; Log.Reg F1: 0.41339808532391487; train loss: 0.17296184599399567; Language: english 

05:06:32.472382: Evaluating Language: finnish
05:06:32.472435: ----------
05:06:39.528181: OBI: 
 [[2981  107  442]
 [   1   10    3]
 [  14    5  105]]
05:06:39.532477: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.84      0.91      3530
           1       0.08      0.71      0.15        14
           2       0.19      0.85      0.31       124

    accuracy                           0.84      3668
   macro avg       0.42      0.80      0.46      3668
weighted avg       0.96      0.84      0.89      3668
05:06:39.532522: ----------
05:06:39.533399: LR: 
 [[726 856]
 [  2  12]]
05:06:39.536658: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63      1582
           1       0.01      0.86      0.03        14

    accuracy                           0.46      1596
   macro avg       0.51      0.66      0.33      1596
weighted avg       0.99      0.46      0.62      1596
05:06:39.539594: Validation Seq.Label F1: 0.457402662401136; Log.Reg F1: 0.32789115646258504; train loss: 0.17296184599399567; Language: finnish 

05:06:39.539653: Evaluating Language: japanese
05:06:39.539698: ----------
05:06:42.574557: OBI: 
 [[1324   15  110]
 [   0    1    0]
 [   4    0    4]]
05:06:42.577763: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.91      0.95      1449
           1       0.06      1.00      0.12         1
           2       0.04      0.50      0.07         8

    accuracy                           0.91      1458
   macro avg       0.36      0.80      0.38      1458
weighted avg       0.99      0.91      0.95      1458
05:06:42.577814: ----------
05:06:42.578476: LR: 
 [[570  19]
 [  1   0]]
05:06:42.581126: LR: 
               precision    recall  f1-score   support

           0       1.00      0.97      0.98       589
           1       0.00      0.00      0.00         1

    accuracy                           0.97       590
   macro avg       0.50      0.48      0.49       590
weighted avg       1.00      0.97      0.98       590
05:06:42.584843: Validation Seq.Label F1: 0.378922607491139; Log.Reg F1: 0.4913793103448276; train loss: 0.17296184599399567; Language: japanese 

05:06:42.587563: Combined F1 SeqLab: 0.4175672833056095; train loss: 0.17296184599399567
05:06:42.589941: Combined F1 LogReg: 0.41627883846880354; train loss: 0.17296184599399567 

05:06:42.590533: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 6/40
05:11:30.577605: Evaluating Language: english
05:11:30.581696: ----------
05:11:35.483284: OBI: 
 [[2558   63  326]
 [   0    9    3]
 [   4    2  103]]
05:11:35.487289: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93      2947
           1       0.12      0.75      0.21        12
           2       0.24      0.94      0.38       109

    accuracy                           0.87      3068
   macro avg       0.45      0.85      0.51      3068
weighted avg       0.97      0.87      0.91      3068
05:11:35.487342: ----------
05:11:35.488028: LR: 
 [[547 386]
 [  1  11]]
05:11:35.490746: LR: 
               precision    recall  f1-score   support

           0       1.00      0.59      0.74       933
           1       0.03      0.92      0.05        12

    accuracy                           0.59       945
   macro avg       0.51      0.75      0.40       945
weighted avg       0.99      0.59      0.73       945
05:11:35.496486: Validation Seq.Label F1: 0.5062469516124455; Log.Reg F1: 0.39623990266274195; train loss: 0.1438353955745697; Language: english 

05:11:35.496561: Evaluating Language: finnish
05:11:35.496608: ----------
05:11:42.434607: OBI: 
 [[3399   70  314]
 [   2   16    1]
 [  15    4  223]]
05:11:42.439134: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.94      3783
           1       0.18      0.84      0.29        19
           2       0.41      0.92      0.57       242

    accuracy                           0.90      4044
   macro avg       0.53      0.89      0.60      4044
weighted avg       0.96      0.90      0.92      4044
05:11:42.439181: ----------
05:11:42.440064: LR: 
 [[852 725]
 [  3  16]]
05:11:42.443337: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70      1577
           1       0.02      0.84      0.04        19

    accuracy                           0.54      1596
   macro avg       0.51      0.69      0.37      1596
weighted avg       0.98      0.54      0.69      1596
05:11:42.446256: Validation Seq.Label F1: 0.6032235575292652; Log.Reg F1: 0.37138157894736845; train loss: 0.1438353955745697; Language: finnish 

05:11:42.446322: Evaluating Language: japanese
05:11:42.446369: ----------
05:11:45.556550: OBI: 
 [[76  3  9]
 [ 0  1  0]
 [ 1  0  2]]
05:11:45.558921: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92        88
           1       0.25      1.00      0.40         1
           2       0.18      0.67      0.29         3

    accuracy                           0.86        92
   macro avg       0.47      0.84      0.54        92
weighted avg       0.95      0.86      0.89        92
05:11:45.558978: ----------
05:11:45.559665: LR: 
 [[564  25]
 [  1   0]]
05:11:45.562490: LR: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98       589
           1       0.00      0.00      0.00         1

    accuracy                           0.96       590
   macro avg       0.50      0.48      0.49       590
weighted avg       1.00      0.96      0.98       590
05:11:45.565214: Validation Seq.Label F1: 0.5356421356421357; Log.Reg F1: 0.488734835355286; train loss: 0.1438353955745697; Language: japanese 

05:11:45.567470: Combined F1 SeqLab: 0.5498718438116359; train loss: 0.1438353955745697
05:11:47.665201: Combined F1 LogReg: 0.42181831670889547; train loss: 0.1438353955745697 

05:11:47.666405: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 7/40
05:16:46.058915: Evaluating Language: english
05:16:46.059081: ----------
05:16:51.025558: OBI: 
 [[3421  114  600]
 [   0   12    3]
 [   0    3  147]]
05:16:51.030399: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.91      4135
           1       0.09      0.80      0.17        15
           2       0.20      0.98      0.33       150

    accuracy                           0.83      4300
   macro avg       0.43      0.87      0.47      4300
weighted avg       0.97      0.83      0.88      4300
05:16:51.030450: ----------
05:16:51.031166: LR: 
 [[457 473]
 [  0  15]]
05:16:51.033893: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       930
           1       0.03      1.00      0.06        15

    accuracy                           0.50       945
   macro avg       0.52      0.75      0.36       945
weighted avg       0.98      0.50      0.65       945
05:16:51.039773: Validation Seq.Label F1: 0.46627963060996414; Log.Reg F1: 0.3593091773798449; train loss: 0.14240355789661407; Language: english 

05:16:51.039844: Evaluating Language: finnish
05:16:51.039893: ----------
05:16:58.060806: OBI: 
 [[1911   38  238]
 [   1   17    1]
 [   6    3  121]]
05:16:58.064230: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93      2187
           1       0.29      0.89      0.44        19
           2       0.34      0.93      0.49       130

    accuracy                           0.88      2336
   macro avg       0.54      0.90      0.62      2336
weighted avg       0.95      0.88      0.90      2336
05:16:58.064291: ----------
05:16:58.065345: LR: 
 [[817 760]
 [  4  15]]
05:16:58.068801: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.68      1577
           1       0.02      0.79      0.04        19

    accuracy                           0.52      1596
   macro avg       0.51      0.65      0.36      1596
weighted avg       0.98      0.52      0.67      1596
05:16:58.071870: Validation Seq.Label F1: 0.6221652252972942; Log.Reg F1: 0.35959227147728057; train loss: 0.14240355789661407; Language: finnish 

05:16:58.071928: Evaluating Language: japanese
05:16:58.071973: ----------
05:17:01.202570: OBI: 
 [[580   8  42]
 [  0   0   0]
 [  0   0   0]]
05:17:01.205032: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96       630
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.92       630
   macro avg       0.33      0.31      0.32       630
weighted avg       1.00      0.92      0.96       630
05:17:01.205074: ----------
05:17:01.205643: LR: 
 [[486 104]
 [  0   0]]
05:17:01.208598: LR: 
               precision    recall  f1-score   support

           0       1.00      0.82      0.90       590
           1       0.00      0.00      0.00         0

    accuracy                           0.82       590
   macro avg       0.50      0.41      0.45       590
weighted avg       1.00      0.82      0.90       590
05:17:01.211919: Validation Seq.Label F1: 0.31955922865013775; Log.Reg F1: 0.45167286245353155; train loss: 0.14240355789661407; Language: japanese 

05:17:01.214381: Combined F1 SeqLab: 0.48532613162232413; train loss: 0.14240355789661407
05:17:01.216861: Combined F1 LogReg: 0.3926058504117235; train loss: 0.14240355789661407 

05:17:01.217908: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 8/40
05:21:48.663483: Evaluating Language: english
05:21:48.663645: ----------
05:21:53.415483: OBI: 
 [[3298   89  790]
 [   1    8    3]
 [   1    1  129]]
05:21:53.421049: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.79      0.88      4177
           1       0.08      0.67      0.15        12
           2       0.14      0.98      0.25       131

    accuracy                           0.80      4320
   macro avg       0.41      0.81      0.42      4320
weighted avg       0.97      0.80      0.86      4320
05:21:53.421103: ----------
05:21:53.421909: LR: 
 [[508 425]
 [  3   9]]
05:21:53.425148: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70       933
           1       0.02      0.75      0.04        12

    accuracy                           0.55       945
   macro avg       0.51      0.65      0.37       945
weighted avg       0.98      0.55      0.70       945
05:21:53.428997: Validation Seq.Label F1: 0.42421359486135907; Log.Reg F1: 0.3719799262139299; train loss: 0.12726029753684998; Language: english 

05:21:53.429070: Evaluating Language: finnish
05:21:53.429125: ----------
05:22:00.383220: OBI: 
 [[3205   66  458]
 [   1   14    3]
 [  25    2  162]]
05:22:00.387666: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      3729
           1       0.17      0.78      0.28        18
           2       0.26      0.86      0.40       189

    accuracy                           0.86      3936
   macro avg       0.47      0.83      0.53      3936
weighted avg       0.95      0.86      0.89      3936
05:22:00.387710: ----------
05:22:00.388578: LR: 
 [[827 751]
 [  3  15]]
05:22:00.391852: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.69      1578
           1       0.02      0.83      0.04        18

    accuracy                           0.53      1596
   macro avg       0.51      0.68      0.36      1596
weighted avg       0.99      0.53      0.68      1596
05:22:00.394679: Validation Seq.Label F1: 0.5333305966064587; Log.Reg F1: 0.36257119126720455; train loss: 0.12726029753684998; Language: finnish 

05:22:00.394734: Evaluating Language: japanese
05:22:00.394778: ----------
05:22:03.510136: OBI: 
 [[1355   17  148]
 [   0    2    0]
 [   0    2   10]]
05:22:03.513225: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94      1520
           1       0.10      1.00      0.17         2
           2       0.06      0.83      0.12        12

    accuracy                           0.89      1534
   macro avg       0.39      0.91      0.41      1534
weighted avg       0.99      0.89      0.94      1534
05:22:03.513270: ----------
05:22:03.513828: LR: 
 [[521  67]
 [  0   2]]
05:22:03.516228: LR: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94       588
           1       0.03      1.00      0.06         2

    accuracy                           0.89       590
   macro avg       0.51      0.94      0.50       590
weighted avg       1.00      0.89      0.94       590
05:22:03.519065: Validation Seq.Label F1: 0.4113895993179881; Log.Reg F1: 0.4979616200358145; train loss: 0.12726029753684998; Language: japanese 

05:22:03.521371: Combined F1 SeqLab: 0.4595795548719188; train loss: 0.12726029753684998
05:22:03.523665: Combined F1 LogReg: 0.4154486367257022; train loss: 0.12726029753684998 

05:22:03.524254: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 9/40
05:26:51.402509: Evaluating Language: english
05:26:51.402674: ----------
05:26:56.199894: OBI: 
 [[2623  101  831]
 [   1   14    2]
 [  14    1  146]]
05:26:56.204303: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.74      0.85      3555
           1       0.12      0.82      0.21        17
           2       0.15      0.91      0.26       161

    accuracy                           0.75      3733
   macro avg       0.42      0.82      0.44      3733
weighted avg       0.95      0.75      0.82      3733
05:26:56.204356: ----------
05:26:56.205033: LR: 
 [[513 415]
 [  6  11]]
05:26:56.207763: LR: 
               precision    recall  f1-score   support

           0       0.99      0.55      0.71       928
           1       0.03      0.65      0.05        17

    accuracy                           0.55       945
   macro avg       0.51      0.60      0.38       945
weighted avg       0.97      0.55      0.70       945
05:26:56.211546: Validation Seq.Label F1: 0.43791736189604746; Log.Reg F1: 0.3793573065468994; train loss: 0.1099415272474289; Language: english 

05:26:56.211605: Evaluating Language: finnish
05:26:56.211652: ----------
05:27:03.483071: OBI: 
 [[2939   83  447]
 [   1   14    4]
 [  29    8  211]]
05:27:03.487373: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.85      0.91      3469
           1       0.13      0.74      0.23        19
           2       0.32      0.85      0.46       248

    accuracy                           0.85      3736
   macro avg       0.48      0.81      0.53      3736
weighted avg       0.94      0.85      0.88      3736
05:27:03.487418: ----------
05:27:03.488281: LR: 
 [[787 790]
 [  2  17]]
05:27:03.491535: LR: 
               precision    recall  f1-score   support

           0       1.00      0.50      0.67      1577
           1       0.02      0.89      0.04        19

    accuracy                           0.50      1596
   macro avg       0.51      0.70      0.35      1596
weighted avg       0.99      0.50      0.66      1596
05:27:03.494418: Validation Seq.Label F1: 0.5341863933632566; Log.Reg F1: 0.35321002335343926; train loss: 0.1099415272474289; Language: finnish 

05:27:03.494481: Evaluating Language: japanese
05:27:03.494528: ----------
05:27:06.578023: OBI: 
 [[932  14  65]
 [  0   1   0]
 [  0   0   0]]
05:27:06.580992: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96      1011
           1       0.07      1.00      0.12         1
           2       0.00      0.00      0.00         0

    accuracy                           0.92      1012
   macro avg       0.36      0.64      0.36      1012
weighted avg       1.00      0.92      0.96      1012
05:27:06.581043: ----------
05:27:06.581742: LR: 
 [[504  85]
 [  0   1]]
05:27:06.584185: LR: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92       589
           1       0.01      1.00      0.02         1

    accuracy                           0.86       590
   macro avg       0.51      0.93      0.47       590
weighted avg       1.00      0.86      0.92       590
05:27:06.586973: Validation Seq.Label F1: 0.3614470749699777; Log.Reg F1: 0.4726104468351368; train loss: 0.1099415272474289; Language: japanese 

05:27:06.589288: Combined F1 SeqLab: 0.4501002505771317; train loss: 0.1099415272474289
05:27:06.591589: Combined F1 LogReg: 0.40498144858152163; train loss: 0.1099415272474289 

05:27:06.592163: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 10/40
05:32:06.207124: Evaluating Language: english
05:32:06.207286: ----------
05:32:11.104423: OBI: 
 [[4646  138  702]
 [   0   20    2]
 [   1   15  214]]
05:32:11.110126: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.85      0.92      5486
           1       0.12      0.91      0.21        22
           2       0.23      0.93      0.37       230

    accuracy                           0.85      5738
   macro avg       0.45      0.90      0.50      5738
weighted avg       0.97      0.85      0.89      5738
05:32:11.110169: ----------
05:32:11.110868: LR: 
 [[320 603]
 [  0  22]]
05:32:11.113579: LR: 
               precision    recall  f1-score   support

           0       1.00      0.35      0.51       923
           1       0.04      1.00      0.07        22

    accuracy                           0.36       945
   macro avg       0.52      0.67      0.29       945
weighted avg       0.98      0.36      0.50       945
05:32:11.120669: Validation Seq.Label F1: 0.4983181178635298; Log.Reg F1: 0.2914447645609851; train loss: 0.10308699309825897; Language: english 

05:32:11.120736: Evaluating Language: finnish
05:32:11.120781: ----------
05:32:18.095897: OBI: 
 [[2772   72  397]
 [   2   19    2]
 [  24    3  129]]
05:32:18.099967: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      3241
           1       0.20      0.83      0.32        23
           2       0.24      0.83      0.38       156

    accuracy                           0.85      3420
   macro avg       0.48      0.84      0.54      3420
weighted avg       0.95      0.85      0.89      3420
05:32:18.100012: ----------
05:32:18.100882: LR: 
 [[666 907]
 [  2  21]]
05:32:18.104138: LR: 
               precision    recall  f1-score   support

           0       1.00      0.42      0.59      1573
           1       0.02      0.91      0.04        23

    accuracy                           0.43      1596
   macro avg       0.51      0.67      0.32      1596
weighted avg       0.98      0.43      0.59      1596
05:32:18.107025: Validation Seq.Label F1: 0.5400040313759037; Log.Reg F1: 0.31927077394752507; train loss: 0.10308699309825897; Language: finnish 

05:32:18.107081: Evaluating Language: japanese
05:32:18.107131: ----------
05:32:21.201313: OBI: 
 [[761   9  59]
 [  0   0   0]
 [  0   0   3]]
05:32:21.203890: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96       829
           1       0.00      0.00      0.00         0
           2       0.05      1.00      0.09         3

    accuracy                           0.92       832
   macro avg       0.35      0.64      0.35       832
weighted avg       1.00      0.92      0.95       832
05:32:21.203933: ----------
05:32:21.204495: LR: 
 [[425 165]
 [  0   0]]
05:32:21.207047: LR: 
               precision    recall  f1-score   support

           0       1.00      0.72      0.84       590
           1       0.00      0.00      0.00         0

    accuracy                           0.72       590
   macro avg       0.50      0.36      0.42       590
weighted avg       1.00      0.72      0.84       590
05:32:21.209885: Validation Seq.Label F1: 0.3498467989034027; Log.Reg F1: 0.41871921182266014; train loss: 0.10308699309825897; Language: japanese 

05:32:21.215783: Combined F1 SeqLab: 0.46986454899124447; train loss: 0.10308699309825897
05:32:21.218098: Combined F1 LogReg: 0.3474668599240554; train loss: 0.10308699309825897 

05:32:21.218735: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 11/40
05:37:07.735634: Evaluating Language: english
05:37:07.735776: ----------
05:37:12.353933: OBI: 
 [[2682   98  718]
 [   0   13    3]
 [  43    8  154]]
05:37:12.358234: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.77      0.86      3498
           1       0.11      0.81      0.19        16
           2       0.18      0.75      0.29       205

    accuracy                           0.77      3719
   macro avg       0.42      0.78      0.45      3719
weighted avg       0.94      0.77      0.83      3719
05:37:12.358280: ----------
05:37:12.358964: LR: 
 [[355 574]
 [  0  16]]
05:37:12.361670: LR: 
               precision    recall  f1-score   support

           0       1.00      0.38      0.55       929
           1       0.03      1.00      0.05        16

    accuracy                           0.39       945
   macro avg       0.51      0.69      0.30       945
weighted avg       0.98      0.39      0.54       945
05:37:12.365245: Validation Seq.Label F1: 0.4465804869629391; Log.Reg F1: 0.3028823910428426; train loss: 0.07863414287567139; Language: english 

05:37:12.365304: Evaluating Language: finnish
05:37:12.365357: ----------
05:37:19.288328: OBI: 
 [[4321   92  597]
 [   0   23    2]
 [  15    6  296]]
05:37:19.293663: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92      5010
           1       0.19      0.92      0.32        25
           2       0.33      0.93      0.49       317

    accuracy                           0.87      5352
   macro avg       0.51      0.91      0.58      5352
weighted avg       0.95      0.87      0.90      5352
05:37:19.293711: ----------
05:37:19.294596: LR: 
 [[700 871]
 [  2  23]]
05:37:19.297854: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62      1571
           1       0.03      0.92      0.05        25

    accuracy                           0.45      1596
   macro avg       0.51      0.68      0.33      1596
weighted avg       0.98      0.45      0.61      1596
05:37:19.300863: Validation Seq.Label F1: 0.5760636650715718; Log.Reg F1: 0.3329902479167135; train loss: 0.07863414287567139; Language: finnish 

05:37:19.300918: Evaluating Language: japanese
05:37:19.300963: ----------
05:37:22.568292: OBI: 
 [[1598   14  319]
 [   0    0    0]
 [   0    0   21]]
05:37:22.571588: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.91      1931
           1       0.00      0.00      0.00         0
           2       0.06      1.00      0.12        21

    accuracy                           0.83      1952
   macro avg       0.35      0.61      0.34      1952
weighted avg       0.99      0.83      0.90      1952
05:37:22.571632: ----------
05:37:22.572190: LR: 
 [[433 157]
 [  0   0]]
05:37:22.574773: LR: 
               precision    recall  f1-score   support

           0       1.00      0.73      0.85       590
           1       0.00      0.00      0.00         0

    accuracy                           0.73       590
   macro avg       0.50      0.37      0.42       590
weighted avg       1.00      0.73      0.85       590
05:37:22.577696: Validation Seq.Label F1: 0.34066082717345036; Log.Reg F1: 0.42326490713587483; train loss: 0.07863414287567139; Language: japanese 

05:37:22.580248: Combined F1 SeqLab: 0.4645188466654671; train loss: 0.07863414287567139
05:37:22.582545: Combined F1 LogReg: 0.35673212621620554; train loss: 0.07863414287567139 

05:37:22.583124: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 12/40
05:42:15.310810: Evaluating Language: english
05:42:15.310972: ----------
05:42:20.226516: OBI: 
 [[2401   39  223]
 [   0    7    1]
 [   9    3  107]]
05:42:20.230288: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.95      2663
           1       0.14      0.88      0.25         8
           2       0.32      0.90      0.48       119

    accuracy                           0.90      2790
   macro avg       0.49      0.89      0.56      2790
weighted avg       0.97      0.90      0.92      2790
05:42:20.230338: ----------
05:42:20.231012: LR: 
 [[478 459]
 [  0   8]]
05:42:20.233695: LR: 
               precision    recall  f1-score   support

           0       1.00      0.51      0.68       937
           1       0.02      1.00      0.03         8

    accuracy                           0.51       945
   macro avg       0.51      0.76      0.35       945
weighted avg       0.99      0.51      0.67       945
05:42:20.240469: Validation Seq.Label F1: 0.5559165078739295; Log.Reg F1: 0.3546512925423098; train loss: 0.07431955635547638; Language: english 

05:42:20.240535: Evaluating Language: finnish
05:42:20.240580: ----------
05:42:27.112542: OBI: 
 [[2472   28  197]
 [   1   14    1]
 [  33    1  129]]
05:42:27.116297: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95      2697
           1       0.33      0.88      0.47        16
           2       0.39      0.79      0.53       163

    accuracy                           0.91      2876
   macro avg       0.57      0.86      0.65      2876
weighted avg       0.95      0.91      0.92      2876
05:42:27.116352: ----------
05:42:27.117214: LR: 
 [[854 726]
 [  4  12]]
05:42:27.120506: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70      1580
           1       0.02      0.75      0.03        16

    accuracy                           0.54      1596
   macro avg       0.51      0.65      0.37      1596
weighted avg       0.99      0.54      0.69      1596
05:42:27.123460: Validation Seq.Label F1: 0.6504426365874338; Log.Reg F1: 0.3662022399540433; train loss: 0.07431955635547638; Language: finnish 

05:42:27.123517: Evaluating Language: japanese
05:42:27.123562: ----------
05:42:30.185817: OBI: 
 [[1547    7   38]
 [   1    2    0]
 [   5    0    0]]
05:42:30.188707: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.97      0.98      1592
           1       0.22      0.67      0.33         3
           2       0.00      0.00      0.00         5

    accuracy                           0.97      1600
   macro avg       0.41      0.55      0.44      1600
weighted avg       0.99      0.97      0.98      1600
05:42:30.188751: ----------
05:42:30.189315: LR: 
 [[555  32]
 [  2   1]]
05:42:30.191704: LR: 
               precision    recall  f1-score   support

           0       1.00      0.95      0.97       587
           1       0.03      0.33      0.06         3

    accuracy                           0.94       590
   macro avg       0.51      0.64      0.51       590
weighted avg       0.99      0.94      0.97       590
05:42:30.194543: Validation Seq.Label F1: 0.439039039039039; Log.Reg F1: 0.5129176379176379; train loss: 0.07431955635547638; Language: japanese 

05:42:30.196830: Combined F1 SeqLab: 0.5552399076128804; train loss: 0.07431955635547638
05:42:32.256566: Combined F1 LogReg: 0.4175189110033615; train loss: 0.07431955635547638 

05:42:32.258072: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 13/40
05:47:30.131639: Evaluating Language: english
05:47:30.131796: ----------
05:47:34.978528: OBI: 
 [[3225   72  798]
 [   1   11    7]
 [  11    2  106]]
05:47:34.983266: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.79      0.88      4095
           1       0.13      0.58      0.21        19
           2       0.12      0.89      0.21       119

    accuracy                           0.79      4233
   macro avg       0.41      0.75      0.43      4233
weighted avg       0.97      0.79      0.86      4233
05:47:34.983320: ----------
05:47:34.984014: LR: 
 [[401 525]
 [  1  18]]
05:47:34.986738: LR: 
               precision    recall  f1-score   support

           0       1.00      0.43      0.60       926
           1       0.03      0.95      0.06        19

    accuracy                           0.44       945
   macro avg       0.52      0.69      0.33       945
weighted avg       0.98      0.44      0.59       945
05:47:34.993707: Validation Seq.Label F1: 0.4323563684129683; Log.Reg F1: 0.3339863010761909; train loss: 0.0672384649515152; Language: english 

05:47:34.993771: Evaluating Language: finnish
05:47:34.993816: ----------
05:47:42.005046: OBI: 
 [[5429   80  602]
 [   2   34    3]
 [  56    4  306]]
05:47:42.011846: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      6111
           1       0.29      0.87      0.43        39
           2       0.34      0.84      0.48       366

    accuracy                           0.89      6516
   macro avg       0.54      0.87      0.62      6516
weighted avg       0.95      0.89      0.91      6516
05:47:42.011890: ----------
05:47:42.012763: LR: 
 [[761 796]
 [  2  37]]
05:47:42.016436: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66      1557
           1       0.04      0.95      0.08        39

    accuracy                           0.50      1596
   macro avg       0.52      0.72      0.37      1596
weighted avg       0.97      0.50      0.64      1596
05:47:42.020000: Validation Seq.Label F1: 0.6161883843367799; Log.Reg F1: 0.3704484340398608; train loss: 0.0672384649515152; Language: finnish 

05:47:42.020054: Evaluating Language: japanese
05:47:42.020099: ----------
05:47:45.146741: OBI: 
 [[653   5  88]
 [  0   0   0]
 [  0   0   0]]
05:47:45.149274: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.93       746
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.88       746
   macro avg       0.33      0.29      0.31       746
weighted avg       1.00      0.88      0.93       746
05:47:45.149323: ----------
05:47:45.149888: LR: 
 [[368 222]
 [  0   0]]
05:47:45.152677: LR: 
               precision    recall  f1-score   support

           0       1.00      0.62      0.77       590
           1       0.00      0.00      0.00         0

    accuracy                           0.62       590
   macro avg       0.50      0.31      0.38       590
weighted avg       1.00      0.62      0.77       590
05:47:45.155712: Validation Seq.Label F1: 0.31117464855849414; Log.Reg F1: 0.384133611691023; train loss: 0.0672384649515152; Language: japanese 

05:47:45.158103: Combined F1 SeqLab: 0.47026581710217324; train loss: 0.0672384649515152
05:47:45.160676: Combined F1 LogReg: 0.36347284319461465; train loss: 0.0672384649515152 

05:47:45.161406: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 14/40
05:52:32.569976: Evaluating Language: english
05:52:32.570120: ----------
05:52:37.259330: OBI: 
 [[2167   54  302]
 [   0   12    1]
 [  17    5  101]]
05:52:37.263073: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      2523
           1       0.17      0.92      0.29        13
           2       0.25      0.82      0.38       123

    accuracy                           0.86      2659
   macro avg       0.47      0.87      0.53      2659
weighted avg       0.95      0.86      0.89      2659
05:52:37.263117: ----------
05:52:37.263809: LR: 
 [[328 604]
 [  0  13]]
05:52:37.266520: LR: 
               precision    recall  f1-score   support

           0       1.00      0.35      0.52       932
           1       0.02      1.00      0.04        13

    accuracy                           0.36       945
   macro avg       0.51      0.68      0.28       945
weighted avg       0.99      0.36      0.51       945
05:52:37.273199: Validation Seq.Label F1: 0.5299241046226943; Log.Reg F1: 0.28095238095238095; train loss: 0.06203600764274597; Language: english 

05:52:37.273269: Evaluating Language: finnish
05:52:37.273326: ----------
05:52:44.325295: OBI: 
 [[3079   46  205]
 [   2   15    4]
 [  25    4  196]]
05:52:44.329481: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.96      3330
           1       0.23      0.71      0.35        21
           2       0.48      0.87      0.62       225

    accuracy                           0.92      3576
   macro avg       0.57      0.84      0.64      3576
weighted avg       0.95      0.92      0.93      3576
05:52:44.329523: ----------
05:52:44.330388: LR: 
 [[762 813]
 [  3  18]]
05:52:44.333632: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65      1575
           1       0.02      0.86      0.04        21

    accuracy                           0.49      1596
   macro avg       0.51      0.67      0.35      1596
weighted avg       0.98      0.49      0.64      1596
05:52:44.336763: Validation Seq.Label F1: 0.6426216335866992; Log.Reg F1: 0.34676778620440596; train loss: 0.06203600764274597; Language: finnish 

05:52:44.336826: Evaluating Language: japanese
05:52:44.336872: ----------
05:52:47.447859: OBI: 
 [[485   6  24]
 [  0   0   0]
 [  0   0   5]]
05:52:47.450268: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97       515
           1       0.00      0.00      0.00         0
           2       0.17      1.00      0.29         5

    accuracy                           0.94       520
   macro avg       0.39      0.65      0.42       520
weighted avg       0.99      0.94      0.96       520
05:52:47.450317: ----------
05:52:47.450880: LR: 
 [[440 150]
 [  0   0]]
05:52:47.453450: LR: 
               precision    recall  f1-score   support

           0       1.00      0.75      0.85       590
           1       0.00      0.00      0.00         0

    accuracy                           0.75       590
   macro avg       0.50      0.37      0.43       590
weighted avg       1.00      0.75      0.85       590
05:52:47.456390: Validation Seq.Label F1: 0.42137254901960786; Log.Reg F1: 0.42718446601941745; train loss: 0.06203600764274597; Language: japanese 

05:52:47.458782: Combined F1 SeqLab: 0.5389300961723712; train loss: 0.06203600764274597
05:52:47.461127: Combined F1 LogReg: 0.356683195529876; train loss: 0.06203600764274597 

05:52:47.461741: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 15/40
05:57:33.469846: Evaluating Language: english
05:57:33.469993: ----------
05:57:38.398189: OBI: 
 [[2490   37  661]
 [   0    8    6]
 [   7    1  117]]
05:57:38.403130: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.78      0.88      3188
           1       0.17      0.57      0.27        14
           2       0.15      0.94      0.26       125

    accuracy                           0.79      3327
   macro avg       0.44      0.76      0.47      3327
weighted avg       0.96      0.79      0.85      3327
05:57:38.403182: ----------
05:57:38.403997: LR: 
 [[428 503]
 [  0  14]]
05:57:38.407003: LR: 
               precision    recall  f1-score   support

           0       1.00      0.46      0.63       931
           1       0.03      1.00      0.05        14

    accuracy                           0.47       945
   macro avg       0.51      0.73      0.34       945
weighted avg       0.99      0.47      0.62       945
05:57:38.414542: Validation Seq.Label F1: 0.46669395171707145; Log.Reg F1: 0.3413028024095484; train loss: 0.05828147381544113; Language: english 

05:57:38.414624: Evaluating Language: finnish
05:57:38.414679: ----------
05:57:45.483498: OBI: 
 [[4548   40  405]
 [   4   20    5]
 [  46    5  271]]
05:57:45.488770: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      4993
           1       0.31      0.69      0.43        29
           2       0.40      0.84      0.54       322

    accuracy                           0.91      5344
   macro avg       0.56      0.81      0.64      5344
weighted avg       0.95      0.91      0.92      5344
05:57:45.488812: ----------
05:57:45.489681: LR: 
 [[836 731]
 [  3  26]]
05:57:45.492956: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.69      1567
           1       0.03      0.90      0.07        29

    accuracy                           0.54      1596
   macro avg       0.52      0.72      0.38      1596
weighted avg       0.98      0.54      0.68      1596
05:57:45.495870: Validation Seq.Label F1: 0.6380999643661693; Log.Reg F1: 0.38054355206132257; train loss: 0.05828147381544113; Language: finnish 

05:57:45.495930: Evaluating Language: japanese
05:57:45.495974: ----------
05:57:48.665369: OBI: 
 [[139  13]
 [  0   0]]
05:57:48.667640: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.91      0.96       152
           2       0.00      0.00      0.00         0

    accuracy                           0.91       152
   macro avg       0.50      0.46      0.48       152
weighted avg       1.00      0.91      0.96       152
05:57:48.667684: ----------
05:57:48.668243: LR: 
 [[424 166]
 [  0   0]]
05:57:48.670803: LR: 
               precision    recall  f1-score   support

           0       1.00      0.72      0.84       590
           1       0.00      0.00      0.00         0

    accuracy                           0.72       590
   macro avg       0.50      0.36      0.42       590
weighted avg       1.00      0.72      0.84       590
05:57:48.673640: Validation Seq.Label F1: 0.47766323024054985; Log.Reg F1: 0.41814595660749504; train loss: 0.05828147381544113; Language: japanese 

05:57:48.675971: Combined F1 SeqLab: 0.5332719664540285; train loss: 0.05828147381544113
05:57:48.678286: Combined F1 LogReg: 0.38129037009225086; train loss: 0.05828147381544113 

05:57:48.678876: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 16/40
06:02:42.490088: Evaluating Language: english
06:02:42.490233: ----------
06:02:47.307133: OBI: 
 [[4701  109 1014]
 [   1   18    6]
 [   8    3  229]]
06:02:47.313048: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.81      0.89      5824
           1       0.14      0.72      0.23        25
           2       0.18      0.95      0.31       240

    accuracy                           0.81      6089
   macro avg       0.44      0.83      0.48      6089
weighted avg       0.96      0.81      0.87      6089
06:02:47.313090: ----------
06:02:47.313795: LR: 
 [[415 505]
 [  2  23]]
06:02:47.316540: LR: 
               precision    recall  f1-score   support

           0       1.00      0.45      0.62       920
           1       0.04      0.92      0.08        25

    accuracy                           0.46       945
   macro avg       0.52      0.69      0.35       945
weighted avg       0.97      0.46      0.61       945
06:02:47.324066: Validation Seq.Label F1: 0.47746183244881407; Log.Reg F1: 0.3519877299451824; train loss: 0.0600380040705204; Language: english 

06:02:47.324139: Evaluating Language: finnish
06:02:47.324185: ----------
06:02:54.383476: OBI: 
 [[2557   53  298]
 [   3   14    3]
 [  22    5  117]]
06:02:54.387361: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      2908
           1       0.19      0.70      0.30        20
           2       0.28      0.81      0.42       144

    accuracy                           0.88      3072
   macro avg       0.49      0.80      0.55      3072
weighted avg       0.95      0.88      0.90      3072
06:02:54.387407: ----------
06:02:54.388263: LR: 
 [[773 803]
 [  4  16]]
06:02:54.391519: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.66      1576
           1       0.02      0.80      0.04        20

    accuracy                           0.49      1596
   macro avg       0.51      0.65      0.35      1596
weighted avg       0.98      0.49      0.65      1596
06:02:54.394462: Validation Seq.Label F1: 0.5507432575190279; Log.Reg F1: 0.3475871088920035; train loss: 0.0600380040705204; Language: finnish 

06:02:54.394519: Evaluating Language: japanese
06:02:54.394563: ----------
06:02:57.667159: OBI: 
 [[1336   11   50]
 [   0    1    0]
 [   4    0    6]]
06:02:57.669947: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98      1397
           1       0.08      1.00      0.15         1
           2       0.11      0.60      0.18        10

    accuracy                           0.95      1408
   macro avg       0.40      0.85      0.44      1408
weighted avg       0.99      0.95      0.97      1408
06:02:57.669989: ----------
06:02:57.670571: LR: 
 [[494  95]
 [  0   1]]
06:02:57.672946: LR: 
               precision    recall  f1-score   support

           0       1.00      0.84      0.91       589
           1       0.01      1.00      0.02         1

    accuracy                           0.84       590
   macro avg       0.51      0.92      0.47       590
weighted avg       1.00      0.84      0.91       590
06:02:57.675839: Validation Seq.Label F1: 0.43730523525919945; Log.Reg F1: 0.46644962922770844; train loss: 0.0600380040705204; Language: japanese 

06:02:57.678183: Combined F1 SeqLab: 0.4907558136633579; train loss: 0.0600380040705204
06:02:57.680529: Combined F1 LogReg: 0.39255038611050974; train loss: 0.0600380040705204 

06:02:57.681122: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 17/40
06:07:44.806328: Evaluating Language: english
06:07:44.806495: ----------
06:07:49.784918: OBI: 
 [[3953   94  573]
 [   2   12    4]
 [   4    0  185]]
06:07:49.790026: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92      4620
           1       0.11      0.67      0.19        18
           2       0.24      0.98      0.39       189

    accuracy                           0.86      4827
   macro avg       0.45      0.83      0.50      4827
weighted avg       0.97      0.86      0.90      4827
06:07:49.790070: ----------
06:07:49.790774: LR: 
 [[427 500]
 [  3  15]]
06:07:49.793522: LR: 
               precision    recall  f1-score   support

           0       0.99      0.46      0.63       927
           1       0.03      0.83      0.06        18

    accuracy                           0.47       945
   macro avg       0.51      0.65      0.34       945
weighted avg       0.97      0.47      0.62       945
06:07:49.799005: Validation Seq.Label F1: 0.5013883862052054; Log.Reg F1: 0.34280729066573024; train loss: 0.06134713068604469; Language: english 

06:07:49.799069: Evaluating Language: finnish
06:07:49.799115: ----------
06:07:56.849430: OBI: 
 [[4101   61  381]
 [   4   18    0]
 [  51    7  209]]
06:07:56.854455: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      4543
           1       0.21      0.82      0.33        22
           2       0.35      0.78      0.49       267

    accuracy                           0.90      4832
   macro avg       0.52      0.83      0.59      4832
weighted avg       0.95      0.90      0.91      4832
06:07:56.854500: ----------
06:07:56.855368: LR: 
 [[827 747]
 [  6  16]]
06:07:56.858621: LR: 
               precision    recall  f1-score   support

           0       0.99      0.53      0.69      1574
           1       0.02      0.73      0.04        22

    accuracy                           0.53      1596
   macro avg       0.51      0.63      0.36      1596
weighted avg       0.98      0.53      0.68      1596
06:07:56.861525: Validation Seq.Label F1: 0.587982762510931; Log.Reg F1: 0.36396338704256953; train loss: 0.06134713068604469; Language: finnish 

06:07:56.861584: Evaluating Language: japanese
06:07:56.861627: ----------
06:08:00.029189: OBI: 
 [[320   4  26]
 [  0   0   0]
 [  0   0   2]]
06:08:00.031516: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.91      0.96       350
           1       0.00      0.00      0.00         0
           2       0.07      1.00      0.13         2

    accuracy                           0.91       352
   macro avg       0.36      0.64      0.36       352
weighted avg       0.99      0.91      0.95       352
06:08:00.031560: ----------
06:08:00.032121: LR: 
 [[482 108]
 [  0   0]]
06:08:00.034709: LR: 
               precision    recall  f1-score   support

           0       1.00      0.82      0.90       590
           1       0.00      0.00      0.00         0

    accuracy                           0.82       590
   macro avg       0.50      0.41      0.45       590
weighted avg       1.00      0.82      0.90       590
06:08:00.037480: Validation Seq.Label F1: 0.3628524046434494; Log.Reg F1: 0.4496268656716418; train loss: 0.06134713068604469; Language: japanese 

06:08:00.039776: Combined F1 SeqLab: 0.4928745311560809; train loss: 0.06134713068604469
06:08:00.042067: Combined F1 LogReg: 0.38822266118589827; train loss: 0.06134713068604469 

06:08:00.042680: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 18/40
06:12:46.095352: Evaluating Language: english
06:12:46.095498: ----------
06:12:50.943098: OBI: 
 [[2376   46  290]
 [   1    8    2]
 [   7    1   51]]
06:12:50.946952: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.93      2712
           1       0.15      0.73      0.24        11
           2       0.15      0.86      0.25        59

    accuracy                           0.88      2782
   macro avg       0.43      0.82      0.48      2782
weighted avg       0.98      0.88      0.92      2782
06:12:50.947000: ----------
06:12:50.947714: LR: 
 [[470 464]
 [  3   8]]
06:12:50.950444: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.67       934
           1       0.02      0.73      0.03        11

    accuracy                           0.51       945
   macro avg       0.51      0.62      0.35       945
weighted avg       0.98      0.51      0.66       945
06:12:50.958867: Validation Seq.Label F1: 0.4762172203536809; Log.Reg F1: 0.3506072123852786; train loss: 0.05339011922478676; Language: english 

06:12:50.958934: Evaluating Language: finnish
06:12:50.958980: ----------
06:12:58.061706: OBI: 
 [[3123   42  180]
 [   1   19    4]
 [   9    3  187]]
06:12:58.065859: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96      3345
           1       0.30      0.79      0.43        24
           2       0.50      0.94      0.66       199

    accuracy                           0.93      3568
   macro avg       0.60      0.89      0.68      3568
weighted avg       0.96      0.93      0.94      3568
06:12:58.065903: ----------
06:12:58.066785: LR: 
 [[801 771]
 [  4  20]]
06:12:58.070018: LR: 
               precision    recall  f1-score   support

           0       1.00      0.51      0.67      1572
           1       0.03      0.83      0.05        24

    accuracy                           0.51      1596
   macro avg       0.51      0.67      0.36      1596
weighted avg       0.98      0.51      0.66      1596
06:12:58.072875: Validation Seq.Label F1: 0.6840483366677287; Log.Reg F1: 0.36151926308100896; train loss: 0.05339011922478676; Language: finnish 

06:12:58.072931: Evaluating Language: japanese
06:12:58.072976: ----------
06:13:01.148291: OBI: 
 [[545   4   7]
 [  0   0   0]
 [  0   0   4]]
06:13:01.150736: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99       556
           1       0.00      0.00      0.00         0
           2       0.36      1.00      0.53         4

    accuracy                           0.98       560
   macro avg       0.45      0.66      0.51       560
weighted avg       1.00      0.98      0.99       560
06:13:01.150780: ----------
06:13:01.151371: LR: 
 [[536  54]
 [  0   0]]
06:13:01.153954: LR: 
               precision    recall  f1-score   support

           0       1.00      0.91      0.95       590
           1       0.00      0.00      0.00         0

    accuracy                           0.91       590
   macro avg       0.50      0.45      0.48       590
weighted avg       1.00      0.91      0.95       590
06:13:01.156800: Validation Seq.Label F1: 0.5077808053284892; Log.Reg F1: 0.4760213143872114; train loss: 0.05339011922478676; Language: japanese 

06:13:01.159228: Combined F1 SeqLab: 0.5634850823577976; train loss: 0.05339011922478676
06:13:03.270280: Combined F1 LogReg: 0.4000907758272448; train loss: 0.05339011922478676 

06:13:03.271439: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 19/40
06:17:55.737675: Evaluating Language: english
06:17:55.737819: ----------
06:18:00.564760: OBI: 
 [[4941   86  500]
 [   0   26    1]
 [  30    6  201]]
06:18:00.570479: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      5527
           1       0.22      0.96      0.36        27
           2       0.29      0.85      0.43       237

    accuracy                           0.89      5791
   macro avg       0.50      0.90      0.58      5791
weighted avg       0.96      0.89      0.92      5791
06:18:00.570522: ----------
06:18:00.571212: LR: 
 [[440 478]
 [  0  27]]
06:18:00.573966: LR: 
               precision    recall  f1-score   support

           0       1.00      0.48      0.65       918
           1       0.05      1.00      0.10        27

    accuracy                           0.49       945
   macro avg       0.53      0.74      0.37       945
weighted avg       0.97      0.49      0.63       945
06:18:00.582657: Validation Seq.Label F1: 0.5760192874102902; Log.Reg F1: 0.3747577707154484; train loss: 0.05509057641029358; Language: english 

06:18:00.582719: Evaluating Language: finnish
06:18:00.582764: ----------
06:18:07.797020: OBI: 
 [[3207   34  212]
 [   5   13    2]
 [  86    7  146]]
06:18:07.801293: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.93      0.95      3453
           1       0.24      0.65      0.35        20
           2       0.41      0.61      0.49       239

    accuracy                           0.91      3712
   macro avg       0.54      0.73      0.60      3712
weighted avg       0.93      0.91      0.92      3712
06:18:07.801348: ----------
06:18:07.802216: LR: 
 [[785 791]
 [  4  16]]
06:18:07.805479: LR: 
               precision    recall  f1-score   support

           0       0.99      0.50      0.66      1576
           1       0.02      0.80      0.04        20

    accuracy                           0.50      1596
   macro avg       0.51      0.65      0.35      1596
weighted avg       0.98      0.50      0.66      1596
06:18:07.808445: Validation Seq.Label F1: 0.5963039842165893; Log.Reg F1: 0.35127092754831013; train loss: 0.05509057641029358; Language: finnish 

06:18:07.808499: Evaluating Language: japanese
06:18:07.808547: ----------
06:18:10.974746: OBI: 
 [[319   3   9]
 [  0   0   0]
 [  0   0   1]]
06:18:10.977002: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98       331
           1       0.00      0.00      0.00         0
           2       0.10      1.00      0.18         1

    accuracy                           0.96       332
   macro avg       0.37      0.65      0.39       332
weighted avg       1.00      0.96      0.98       332
06:18:10.977044: ----------
06:18:10.977610: LR: 
 [[303 287]
 [  0   0]]
06:18:10.980174: LR: 
               precision    recall  f1-score   support

           0       1.00      0.51      0.68       590
           1       0.00      0.00      0.00         0

    accuracy                           0.51       590
   macro avg       0.50      0.26      0.34       590
weighted avg       1.00      0.51      0.68       590
06:18:10.983001: Validation Seq.Label F1: 0.3877855477855478; Log.Reg F1: 0.3393057110862262; train loss: 0.05509057641029358; Language: japanese 

06:18:10.985340: Combined F1 SeqLab: 0.5284424573317875; train loss: 0.05509057641029358
06:18:10.987660: Combined F1 LogReg: 0.3554166647884294; train loss: 0.05509057641029358 

06:18:10.988245: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 20/40
06:22:58.436018: Evaluating Language: english
06:22:58.436154: ----------
06:23:03.346496: OBI: 
 [[2974   92  312]
 [   2   18    2]
 [  48    6  109]]
06:23:03.350765: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.88      0.93      3378
           1       0.16      0.82      0.26        22
           2       0.26      0.67      0.37       163

    accuracy                           0.87      3563
   macro avg       0.47      0.79      0.52      3563
weighted avg       0.95      0.87      0.90      3563
06:23:03.350808: ----------
06:23:03.351499: LR: 
 [[450 473]
 [  5  17]]
06:23:03.354227: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.65       923
           1       0.03      0.77      0.07        22

    accuracy                           0.49       945
   macro avg       0.51      0.63      0.36       945
weighted avg       0.97      0.49      0.64       945
06:23:03.362972: Validation Seq.Label F1: 0.5206559593793161; Log.Reg F1: 0.3597633572206096; train loss: 0.04690397530794144; Language: english 

06:23:03.363035: Evaluating Language: finnish
06:23:03.363080: ----------
06:23:10.604196: OBI: 
 [[2916   38  121]
 [   3   16    0]
 [  16    6  144]]
06:23:10.608206: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      3075
           1       0.27      0.84      0.41        19
           2       0.54      0.87      0.67       166

    accuracy                           0.94      3260
   macro avg       0.60      0.89      0.68      3260
weighted avg       0.97      0.94      0.95      3260
06:23:10.608251: ----------
06:23:10.609129: LR: 
 [[813 764]
 [  6  13]]
06:23:10.612418: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.68      1577
           1       0.02      0.68      0.03        19

    accuracy                           0.52      1596
   macro avg       0.50      0.60      0.36      1596
weighted avg       0.98      0.52      0.67      1596
06:23:10.615318: Validation Seq.Label F1: 0.6812198145744314; Log.Reg F1: 0.3556471841679181; train loss: 0.04690397530794144; Language: finnish 

06:23:10.615375: Evaluating Language: japanese
06:23:10.615425: ----------
06:23:13.705957: OBI: 
 [[1708    8   17]
 [   0    1    0]
 [   7    0   29]]
06:23:13.708942: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.99      0.99      1733
           1       0.11      1.00      0.20         1
           2       0.63      0.81      0.71        36

    accuracy                           0.98      1770
   macro avg       0.58      0.93      0.63      1770
weighted avg       0.99      0.98      0.98      1770
06:23:13.708985: ----------
06:23:13.709545: LR: 
 [[533  56]
 [  1   0]]
06:23:13.711940: LR: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.95       589
           1       0.00      0.00      0.00         1

    accuracy                           0.90       590
   macro avg       0.50      0.45      0.47       590
weighted avg       1.00      0.90      0.95       590
06:23:13.714851: Validation Seq.Label F1: 0.6326787769037784; Log.Reg F1: 0.4746215494211932; train loss: 0.04690397530794144; Language: japanese 

06:23:13.717193: Combined F1 SeqLab: 0.6152033535210071; train loss: 0.04690397530794144
06:23:15.826115: Combined F1 LogReg: 0.40049145141945586; train loss: 0.04690397530794144 

06:23:15.826932: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 21/40
06:28:05.739382: Evaluating Language: english
06:28:05.739510: ----------
06:28:10.617057: OBI: 
 [[2863   54  327]
 [   0   12    0]
 [  20    3  105]]
06:28:10.621426: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      3244
           1       0.17      1.00      0.30        12
           2       0.24      0.82      0.38       128

    accuracy                           0.88      3384
   macro avg       0.47      0.90      0.54      3384
weighted avg       0.96      0.88      0.91      3384
06:28:10.621468: ----------
06:28:10.622146: LR: 
 [[458 475]
 [  1  11]]
06:28:10.624876: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66       933
           1       0.02      0.92      0.04        12

    accuracy                           0.50       945
   macro avg       0.51      0.70      0.35       945
weighted avg       0.99      0.50      0.65       945
06:28:10.634232: Validation Seq.Label F1: 0.5352827597740824; Log.Reg F1: 0.35111134191940174; train loss: 0.037504248321056366; Language: english 

06:28:10.634296: Evaluating Language: finnish
06:28:10.634351: ----------
06:28:17.752621: OBI: 
 [[2921   40  171]
 [   0   13    2]
 [  22    6  181]]
06:28:17.756625: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      3132
           1       0.22      0.87      0.35        15
           2       0.51      0.87      0.64       209

    accuracy                           0.93      3356
   macro avg       0.57      0.89      0.65      3356
weighted avg       0.96      0.93      0.94      3356
06:28:17.756667: ----------
06:28:17.757529: LR: 
 [[748 833]
 [  3  12]]
06:28:17.760777: LR: 
               precision    recall  f1-score   support

           0       1.00      0.47      0.64      1581
           1       0.01      0.80      0.03        15

    accuracy                           0.48      1596
   macro avg       0.51      0.64      0.33      1596
weighted avg       0.99      0.48      0.64      1596
06:28:17.763661: Validation Seq.Label F1: 0.6519938186986408; Log.Reg F1: 0.3347082053532251; train loss: 0.037504248321056366; Language: finnish 

06:28:17.763718: Evaluating Language: japanese
06:28:17.763762: ----------
06:28:20.921151: OBI: 
 [[878   7  20]
 [  0   0   0]
 [  0   0   3]]
06:28:20.923771: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.97      0.98       905
           1       0.00      0.00      0.00         0
           2       0.13      1.00      0.23         3

    accuracy                           0.97       908
   macro avg       0.38      0.66      0.41       908
weighted avg       1.00      0.97      0.98       908
06:28:20.923814: ----------
06:28:20.924382: LR: 
 [[364 226]
 [  0   0]]
06:28:20.926947: LR: 
               precision    recall  f1-score   support

           0       1.00      0.62      0.76       590
           1       0.00      0.00      0.00         0

    accuracy                           0.62       590
   macro avg       0.50      0.31      0.38       590
weighted avg       1.00      0.62      0.76       590
06:28:20.929731: Validation Seq.Label F1: 0.40520873779426775; Log.Reg F1: 0.38155136268343814; train loss: 0.037504248321056366; Language: japanese 

06:28:20.932046: Combined F1 SeqLab: 0.5403140116998071; train loss: 0.037504248321056366
06:28:20.934379: Combined F1 LogReg: 0.35631923866144166; train loss: 0.037504248321056366 

06:28:20.934978: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 22/40
06:33:12.500277: Evaluating Language: english
06:33:12.500445: ----------
06:33:17.335076: OBI: 
 [[3447   61  160]
 [   0   15    5]
 [  13    3   84]]
06:33:17.339557: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97      3668
           1       0.19      0.75      0.30        20
           2       0.34      0.84      0.48       100

    accuracy                           0.94      3788
   macro avg       0.51      0.84      0.58      3788
weighted avg       0.97      0.94      0.95      3788
06:33:17.339600: ----------
06:33:17.340287: LR: 
 [[624 301]
 [  6  14]]
06:33:17.343024: LR: 
               precision    recall  f1-score   support

           0       0.99      0.67      0.80       925
           1       0.04      0.70      0.08        20

    accuracy                           0.68       945
   macro avg       0.52      0.69      0.44       945
weighted avg       0.97      0.68      0.79       945
06:33:17.351555: Validation Seq.Label F1: 0.5838591261227365; Log.Reg F1: 0.44307721840955994; train loss: 0.035974327474832535; Language: english 

06:33:17.351619: Evaluating Language: finnish
06:33:17.351665: ----------
06:33:24.398368: OBI: 
 [[4804   53  179]
 [   6   26    1]
 [  92    2  185]]
06:33:24.403677: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.97      5036
           1       0.32      0.79      0.46        33
           2       0.51      0.66      0.57       279

    accuracy                           0.94      5348
   macro avg       0.60      0.80      0.67      5348
weighted avg       0.95      0.94      0.94      5348
06:33:24.403722: ----------
06:33:24.404603: LR: 
 [[924 639]
 [  9  24]]
06:33:24.407901: LR: 
               precision    recall  f1-score   support

           0       0.99      0.59      0.74      1563
           1       0.04      0.73      0.07        33

    accuracy                           0.59      1596
   macro avg       0.51      0.66      0.40      1596
weighted avg       0.97      0.59      0.73      1596
06:33:24.411150: Validation Seq.Label F1: 0.6658228786446622; Log.Reg F1: 0.40467506631299743; train loss: 0.035974327474832535; Language: finnish 

06:33:24.411205: Evaluating Language: japanese
06:33:24.411254: ----------
06:33:27.445800: OBI: 
 [[668   2]
 [  0   0]]
06:33:27.448907: OBI: 
               precision    recall  f1-score   support

           0       1.00      1.00      1.00       670
           2       0.00      0.00      0.00         0

    accuracy                           1.00       670
   macro avg       0.50      0.50      0.50       670
weighted avg       1.00      1.00      1.00       670
06:33:27.448956: ----------
06:33:27.449628: LR: 
 [[559  31]
 [  0   0]]
06:33:27.452676: LR: 
               precision    recall  f1-score   support

           0       1.00      0.95      0.97       590
           1       0.00      0.00      0.00         0

    accuracy                           0.95       590
   macro avg       0.50      0.47      0.49       590
weighted avg       1.00      0.95      0.97       590
06:33:27.455904: Validation Seq.Label F1: 0.4992526158445441; Log.Reg F1: 0.4865100087032202; train loss: 0.035974327474832535; Language: japanese 

06:33:27.458590: Combined F1 SeqLab: 0.5869312166716784; train loss: 0.035974327474832535
06:33:27.461263: Combined F1 LogReg: 0.44600871416650933; train loss: 0.035974327474832535 

06:33:27.463932: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 23/40
06:38:13.748685: Evaluating Language: english
06:38:13.748847: ----------
06:38:18.640995: OBI: 
 [[4665   58  230]
 [   6   20    4]
 [  81    2  164]]
06:38:18.646374: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      4953
           1       0.25      0.67      0.36        30
           2       0.41      0.66      0.51       247

    accuracy                           0.93      5230
   macro avg       0.55      0.76      0.61      5230
weighted avg       0.95      0.93      0.94      5230
06:38:18.646419: ----------
06:38:18.647107: LR: 
 [[556 359]
 [  8  22]]
06:38:18.649819: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.75       915
           1       0.06      0.73      0.11        30

    accuracy                           0.61       945
   macro avg       0.52      0.67      0.43       945
weighted avg       0.96      0.61      0.73       945
06:38:18.657855: Validation Seq.Label F1: 0.6111745396889713; Log.Reg F1: 0.4294576627529945; train loss: 0.03729589283466339; Language: english 

06:38:18.657919: Evaluating Language: finnish
06:38:18.657965: ----------
06:38:25.842797: OBI: 
 [[3346   35  127]
 [   1   23    1]
 [  57    1  121]]
06:38:25.847066: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.97      3508
           1       0.39      0.92      0.55        25
           2       0.49      0.68      0.57       179

    accuracy                           0.94      3712
   macro avg       0.62      0.85      0.69      3712
weighted avg       0.95      0.94      0.95      3712
06:38:25.847109: ----------
06:38:25.847978: LR: 
 [[854 717]
 [  5  20]]
06:38:25.851500: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70      1571
           1       0.03      0.80      0.05        25

    accuracy                           0.55      1596
   macro avg       0.51      0.67      0.38      1596
weighted avg       0.98      0.55      0.69      1596
06:38:25.854347: Validation Seq.Label F1: 0.6937369682210025; Log.Reg F1: 0.377687048378212; train loss: 0.03729589283466339; Language: finnish 

06:38:25.854407: Evaluating Language: japanese
06:38:25.854451: ----------
06:38:28.990401: OBI: 
 [[864   2   1]
 [  2   0   0]
 [  3   0   0]]
06:38:28.992821: OBI: 
               precision    recall  f1-score   support

           0       0.99      1.00      1.00       867
           1       0.00      0.00      0.00         2
           2       0.00      0.00      0.00         3

    accuracy                           0.99       872
   macro avg       0.33      0.33      0.33       872
weighted avg       0.99      0.99      0.99       872
06:38:28.992863: ----------
06:38:28.993440: LR: 
 [[546  42]
 [  1   1]]
06:38:28.995846: LR: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96       588
           1       0.02      0.50      0.04         2

    accuracy                           0.93       590
   macro avg       0.51      0.71      0.50       590
weighted avg       0.99      0.93      0.96       590
06:38:28.998702: Validation Seq.Label F1: 0.3317972350230415; Log.Reg F1: 0.5032794909446893; train loss: 0.03729589283466339; Language: japanese 

06:38:29.001384: Combined F1 SeqLab: 0.5671257074668806; train loss: 0.03729589283466339
06:38:29.003829: Combined F1 LogReg: 0.4398377112130701; train loss: 0.03729589283466339 

06:38:29.004444: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 24/40
06:43:16.907044: Evaluating Language: english
06:43:16.907198: ----------
06:43:21.876966: OBI: 
 [[2992   37  248]
 [   1   11    4]
 [  28    2  164]]
06:43:21.882096: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      3277
           1       0.22      0.69      0.33        16
           2       0.39      0.85      0.54       194

    accuracy                           0.91      3487
   macro avg       0.53      0.82      0.61      3487
weighted avg       0.95      0.91      0.92      3487
06:43:21.882146: ----------
06:43:21.882968: LR: 
 [[504 425]
 [  5  11]]
06:43:21.886218: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70       929
           1       0.03      0.69      0.05        16

    accuracy                           0.54       945
   macro avg       0.51      0.62      0.37       945
weighted avg       0.97      0.54      0.69       945
06:43:21.896547: Validation Seq.Label F1: 0.607060384624951; Log.Reg F1: 0.3748230703902913; train loss: 0.04326999559998512; Language: english 

06:43:21.896622: Evaluating Language: finnish
06:43:21.896675: ----------
06:43:29.144246: OBI: 
 [[2984   25  108]
 [   2   10    5]
 [  25    0  129]]
06:43:29.148251: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97      3117
           1       0.29      0.59      0.38        17
           2       0.53      0.84      0.65       154

    accuracy                           0.95      3288
   macro avg       0.60      0.79      0.67      3288
weighted avg       0.97      0.95      0.96      3288
06:43:29.148296: ----------
06:43:29.149172: LR: 
 [[888 691]
 [  3  14]]
06:43:29.152454: LR: 
               precision    recall  f1-score   support

           0       1.00      0.56      0.72      1579
           1       0.02      0.82      0.04        17

    accuracy                           0.57      1596
   macro avg       0.51      0.69      0.38      1596
weighted avg       0.99      0.57      0.71      1596
06:43:29.155455: Validation Seq.Label F1: 0.6700069585187078; Log.Reg F1: 0.37890475175793736; train loss: 0.04326999559998512; Language: finnish 

06:43:29.155514: Evaluating Language: japanese
06:43:29.155563: ----------
06:43:32.270139: OBI: 
 [[627   7  27]
 [  0   0   0]
 [  2   0   3]]
06:43:32.272626: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.95      0.97       661
           1       0.00      0.00      0.00         0
           2       0.10      0.60      0.17         5

    accuracy                           0.95       666
   macro avg       0.37      0.52      0.38       666
weighted avg       0.99      0.95      0.97       666
06:43:32.272673: ----------
06:43:32.273233: LR: 
 [[512  78]
 [  0   0]]
06:43:32.275781: LR: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93       590
           1       0.00      0.00      0.00         0

    accuracy                           0.87       590
   macro avg       0.50      0.43      0.46       590
weighted avg       1.00      0.87      0.93       590
06:43:32.278618: Validation Seq.Label F1: 0.3811738648947951; Log.Reg F1: 0.4646098003629764; train loss: 0.04326999559998512; Language: japanese 

06:43:32.280989: Combined F1 SeqLab: 0.5664877610691216; train loss: 0.04326999559998512
06:43:32.283333: Combined F1 LogReg: 0.40821702218096123; train loss: 0.04326999559998512 

06:43:32.283932: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 25/40
06:48:21.013892: Evaluating Language: english
06:48:21.014036: ----------
06:48:25.873051: OBI: 
 [[3378   40  215]
 [   1   14    2]
 [  12    0   93]]
06:48:25.877942: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96      3633
           1       0.26      0.82      0.39        17
           2       0.30      0.89      0.45       105

    accuracy                           0.93      3755
   macro avg       0.52      0.88      0.60      3755
weighted avg       0.97      0.93      0.94      3755
06:48:25.877984: ----------
06:48:25.878677: LR: 
 [[510 418]
 [  2  15]]
06:48:25.881398: LR: 
               precision    recall  f1-score   support

           0       1.00      0.55      0.71       928
           1       0.03      0.88      0.07        17

    accuracy                           0.56       945
   macro avg       0.52      0.72      0.39       945
weighted avg       0.98      0.56      0.70       945
06:48:25.891088: Validation Seq.Label F1: 0.6014680235910435; Log.Reg F1: 0.38749999999999996; train loss: 0.04246533289551735; Language: english 

06:48:25.891155: Evaluating Language: finnish
06:48:25.891199: ----------
06:48:33.013218: OBI: 
 [[3428   15  150]
 [   5   13    2]
 [  65    0  194]]
06:48:33.017583: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.97      3593
           1       0.46      0.65      0.54        20
           2       0.56      0.75      0.64       259

    accuracy                           0.94      3872
   macro avg       0.67      0.78      0.72      3872
weighted avg       0.95      0.94      0.94      3872
06:48:33.017627: ----------
06:48:33.018495: LR: 
 [[883 693]
 [  4  16]]
06:48:33.021734: LR: 
               precision    recall  f1-score   support

           0       1.00      0.56      0.72      1576
           1       0.02      0.80      0.04        20

    accuracy                           0.56      1596
   macro avg       0.51      0.68      0.38      1596
weighted avg       0.98      0.56      0.71      1596
06:48:33.024741: Validation Seq.Label F1: 0.716616126651575; Log.Reg F1: 0.3804537609292425; train loss: 0.04246533289551735; Language: finnish 

06:48:33.024794: Evaluating Language: japanese
06:48:33.024839: ----------
06:48:36.001561: OBI: 
 [[1699    4   63]
 [   1    1    0]
 [   3    0    5]]
06:48:36.004596: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98      1766
           1       0.20      0.50      0.29         2
           2       0.07      0.62      0.13         8

    accuracy                           0.96      1776
   macro avg       0.42      0.70      0.47      1776
weighted avg       0.99      0.96      0.97      1776
06:48:36.004643: ----------
06:48:36.005197: LR: 
 [[554  34]
 [  1   1]]
06:48:36.007590: LR: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97       588
           1       0.03      0.50      0.05         2

    accuracy                           0.94       590
   macro avg       0.51      0.72      0.51       590
weighted avg       0.99      0.94      0.97       590
06:48:36.010469: Validation Seq.Label F1: 0.46560874657095314; Log.Reg F1: 0.5117164408502991; train loss: 0.04246533289551735; Language: japanese 

06:48:36.012833: Combined F1 SeqLab: 0.6033500811477519; train loss: 0.04246533289551735
06:48:36.015173: Combined F1 LogReg: 0.4307957869036104; train loss: 0.04246533289551735 

06:48:36.015801: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 26/40
06:53:28.138353: Evaluating Language: english
06:53:28.138491: ----------
06:53:32.984602: OBI: 
 [[3301   43  202]
 [   1   12    4]
 [  12    3  134]]
06:53:32.989075: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96      3546
           1       0.21      0.71      0.32        17
           2       0.39      0.90      0.55       149

    accuracy                           0.93      3712
   macro avg       0.53      0.85      0.61      3712
weighted avg       0.97      0.93      0.94      3712
06:53:32.989126: ----------
06:53:32.989843: LR: 
 [[616 312]
 [  4  13]]
06:53:32.992595: LR: 
               precision    recall  f1-score   support

           0       0.99      0.66      0.80       928
           1       0.04      0.76      0.08        17

    accuracy                           0.67       945
   macro avg       0.52      0.71      0.44       945
weighted avg       0.98      0.67      0.78       945
06:53:33.002738: Validation Seq.Label F1: 0.6101493100892125; Log.Reg F1: 0.43594451244390053; train loss: 0.036146532744169235; Language: english 

06:53:33.002807: Evaluating Language: finnish
06:53:33.002854: ----------
06:53:39.993050: OBI: 
 [[3081   40   78]
 [   1   13    0]
 [  52    3  116]]
06:53:39.997134: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      3199
           1       0.23      0.93      0.37        14
           2       0.60      0.68      0.64       171

    accuracy                           0.95      3384
   macro avg       0.60      0.86      0.66      3384
weighted avg       0.96      0.95      0.95      3384
06:53:39.997176: ----------
06:53:39.998042: LR: 
 [[929 653]
 [  3  11]]
06:53:40.001302: LR: 
               precision    recall  f1-score   support

           0       1.00      0.59      0.74      1582
           1       0.02      0.79      0.03        14

    accuracy                           0.59      1596
   macro avg       0.51      0.69      0.39      1596
weighted avg       0.99      0.59      0.73      1596
06:53:40.004291: Validation Seq.Label F1: 0.660014529552436; Log.Reg F1: 0.3857548172710696; train loss: 0.036146532744169235; Language: finnish 

06:53:40.004361: Evaluating Language: japanese
06:53:40.004408: ----------
06:53:43.214966: OBI: 
 [[1000    0   22]
 [   1    1    0]
 [   0    0   28]]
06:53:43.217537: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99      1022
           1       1.00      0.50      0.67         2
           2       0.56      1.00      0.72        28

    accuracy                           0.98      1052
   macro avg       0.85      0.83      0.79      1052
weighted avg       0.99      0.98      0.98      1052
06:53:43.217579: ----------
06:53:43.218132: LR: 
 [[554  34]
 [  2   0]]
06:53:43.220534: LR: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97       588
           1       0.00      0.00      0.00         2

    accuracy                           0.94       590
   macro avg       0.50      0.47      0.48       590
weighted avg       0.99      0.94      0.97       590
06:53:43.223413: Validation Seq.Label F1: 0.7910820436771994; Log.Reg F1: 0.4842657342657343; train loss: 0.036146532744169235; Language: japanese 

06:53:43.225754: Combined F1 SeqLab: 0.6913060488792596; train loss: 0.036146532744169235
06:53:44.685851: Combined F1 LogReg: 0.4371756696347275; train loss: 0.036146532744169235 

06:53:44.688451: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 27/40
06:58:31.226438: Evaluating Language: english
06:58:31.226611: ----------
06:58:36.204130: OBI: 
 [[4001   44  220]
 [   3   12    1]
 [  65    5  114]]
06:58:36.209003: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      4265
           1       0.20      0.75      0.31        16
           2       0.34      0.62      0.44       184

    accuracy                           0.92      4465
   macro avg       0.51      0.77      0.57      4465
weighted avg       0.95      0.92      0.94      4465
06:58:36.209047: ----------
06:58:36.209743: LR: 
 [[566 363]
 [  3  13]]
06:58:36.212473: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.76       929
           1       0.03      0.81      0.07        16

    accuracy                           0.61       945
   macro avg       0.51      0.71      0.41       945
weighted avg       0.98      0.61      0.74       945
06:58:36.221322: Validation Seq.Label F1: 0.5703859523382864; Log.Reg F1: 0.41100038146099566; train loss: 0.03942996263504028; Language: english 

06:58:36.221387: Evaluating Language: finnish
06:58:36.221434: ----------
06:58:43.372479: OBI: 
 [[3679   28  162]
 [   3   12    3]
 [  54    2  149]]
06:58:43.377330: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.97      3869
           1       0.29      0.67      0.40        18
           2       0.47      0.73      0.57       205

    accuracy                           0.94      4092
   macro avg       0.58      0.78      0.65      4092
weighted avg       0.96      0.94      0.95      4092
06:58:43.377374: ----------
06:58:43.378231: LR: 
 [[889 689]
 [  5  13]]
06:58:43.381784: LR: 
               precision    recall  f1-score   support

           0       0.99      0.56      0.72      1578
           1       0.02      0.72      0.04        18

    accuracy                           0.57      1596
   macro avg       0.51      0.64      0.38      1596
weighted avg       0.98      0.57      0.71      1596
06:58:43.386706: Validation Seq.Label F1: 0.6472341616850287; Log.Reg F1: 0.37768338727076584; train loss: 0.03942996263504028; Language: finnish 

06:58:43.386775: Evaluating Language: japanese
06:58:43.386827: ----------
06:58:46.442901: OBI: 
 [[229   1]
 [  0   0]]
06:58:46.445196: OBI: 
               precision    recall  f1-score   support

           0       1.00      1.00      1.00       230
           2       0.00      0.00      0.00         0

    accuracy                           1.00       230
   macro avg       0.50      0.50      0.50       230
weighted avg       1.00      1.00      1.00       230
06:58:46.445238: ----------
06:58:46.445801: LR: 
 [[558  32]
 [  0   0]]
06:58:46.448355: LR: 
               precision    recall  f1-score   support

           0       1.00      0.95      0.97       590
           1       0.00      0.00      0.00         0

    accuracy                           0.95       590
   macro avg       0.50      0.47      0.49       590
weighted avg       1.00      0.95      0.97       590
06:58:46.451200: Validation Seq.Label F1: 0.4989106753812636; Log.Reg F1: 0.48606271777003485; train loss: 0.03942996263504028; Language: japanese 

06:58:46.453503: Combined F1 SeqLab: 0.5753735183010437; train loss: 0.03942996263504028
06:58:46.455779: Combined F1 LogReg: 0.42732619086103135; train loss: 0.03942996263504028 

06:58:46.456373: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 28/40
07:03:32.859787: Evaluating Language: english
07:03:32.859952: ----------
07:03:37.823104: OBI: 
 [[3745   26  154]
 [   2   10    0]
 [  39    1  140]]
07:03:37.827772: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      3925
           1       0.27      0.83      0.41        12
           2       0.48      0.78      0.59       180

    accuracy                           0.95      4117
   macro avg       0.58      0.86      0.66      4117
weighted avg       0.96      0.95      0.95      4117
07:03:37.827814: ----------
07:03:37.828503: LR: 
 [[493 440]
 [  4   8]]
07:03:37.831252: LR: 
               precision    recall  f1-score   support

           0       0.99      0.53      0.69       933
           1       0.02      0.67      0.03        12

    accuracy                           0.53       945
   macro avg       0.50      0.60      0.36       945
weighted avg       0.98      0.53      0.68       945
07:03:37.840327: Validation Seq.Label F1: 0.6567400698492164; Log.Reg F1: 0.3621465491030708; train loss: 0.03026619367301464; Language: english 

07:03:37.840393: Evaluating Language: finnish
07:03:37.840440: ----------
07:03:45.063369: OBI: 
 [[1966   21  109]
 [   0   15    2]
 [  65    3  171]]
07:03:45.066797: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.94      0.95      2096
           1       0.38      0.88      0.54        17
           2       0.61      0.72      0.66       239

    accuracy                           0.91      2352
   macro avg       0.65      0.85      0.71      2352
weighted avg       0.93      0.91      0.92      2352
07:03:45.066840: ----------
07:03:45.067705: LR: 
 [[814 765]
 [  2  15]]
07:03:45.070962: LR: 
               precision    recall  f1-score   support

           0       1.00      0.52      0.68      1579
           1       0.02      0.88      0.04        17

    accuracy                           0.52      1596
   macro avg       0.51      0.70      0.36      1596
weighted avg       0.99      0.52      0.67      1596
07:03:45.075816: Validation Seq.Label F1: 0.7149648032875939; Log.Reg F1: 0.3586953162040322; train loss: 0.03026619367301464; Language: finnish 

07:03:45.075875: Evaluating Language: japanese
07:03:45.075926: ----------
07:03:48.223124: OBI: 
 [[777   2  17]
 [  0   0   0]
 [  0   0   4]]
07:03:48.225662: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99       796
           1       0.00      0.00      0.00         0
           2       0.19      1.00      0.32         4

    accuracy                           0.98       800
   macro avg       0.40      0.66      0.44       800
weighted avg       1.00      0.98      0.98       800
07:03:48.225704: ----------
07:03:48.226264: LR: 
 [[452 138]
 [  0   0]]
07:03:48.228836: LR: 
               precision    recall  f1-score   support

           0       1.00      0.77      0.87       590
           1       0.00      0.00      0.00         0

    accuracy                           0.77       590
   macro avg       0.50      0.38      0.43       590
weighted avg       1.00      0.77      0.87       590
07:03:48.231719: Validation Seq.Label F1: 0.4359737232464505; Log.Reg F1: 0.4337811900191939; train loss: 0.03026619367301464; Language: japanese 

07:03:48.234084: Combined F1 SeqLab: 0.6144252806883829; train loss: 0.03026619367301464
07:03:48.236471: Combined F1 LogReg: 0.3864274721550568; train loss: 0.03026619367301464 

07:03:48.237070: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 29/40
07:08:37.067920: Evaluating Language: english
07:08:37.068077: ----------
07:08:41.923019: OBI: 
 [[2376   35  342]
 [   1    6    3]
 [   6    2   97]]
07:08:41.926916: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.93      2753
           1       0.14      0.60      0.23        10
           2       0.22      0.92      0.35       105

    accuracy                           0.86      2868
   macro avg       0.45      0.80      0.50      2868
weighted avg       0.97      0.86      0.90      2868
07:08:41.926960: ----------
07:08:41.927655: LR: 
 [[505 430]
 [  1   9]]
07:08:41.930363: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70       935
           1       0.02      0.90      0.04        10

    accuracy                           0.54       945
   macro avg       0.51      0.72      0.37       945
weighted avg       0.99      0.54      0.69       945
07:08:41.939633: Validation Seq.Label F1: 0.5021035102633098; Log.Reg F1: 0.3704956190717594; train loss: 0.029264066368341446; Language: english 

07:08:41.939700: Evaluating Language: finnish
07:08:41.939746: ----------
07:08:49.073628: OBI: 
 [[4111   38  298]
 [   3   23    3]
 [  24    3  169]]
07:08:49.078506: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.96      4447
           1       0.36      0.79      0.49        29
           2       0.36      0.86      0.51       196

    accuracy                           0.92      4672
   macro avg       0.57      0.86      0.65      4672
weighted avg       0.96      0.92      0.94      4672
07:08:49.078552: ----------
07:08:49.079424: LR: 
 [[774 793]
 [  1  28]]
07:08:49.082677: LR: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66      1567
           1       0.03      0.97      0.07        29

    accuracy                           0.50      1596
   macro avg       0.52      0.73      0.36      1596
weighted avg       0.98      0.50      0.65      1596
07:08:49.087349: Validation Seq.Label F1: 0.6532827038622969; Log.Reg F1: 0.363427939920631; train loss: 0.029264066368341446; Language: finnish 

07:08:49.087409: Evaluating Language: japanese
07:08:49.087456: ----------
07:08:52.149173: OBI: 
 [[1074    3   77]
 [   0    0    0]
 [   0    1    3]]
07:08:52.151954: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96      1154
           1       0.00      0.00      0.00         0
           2       0.04      0.75      0.07         4

    accuracy                           0.93      1158
   macro avg       0.35      0.56      0.35      1158
weighted avg       1.00      0.93      0.96      1158
07:08:52.151996: ----------
07:08:52.152567: LR: 
 [[479 111]
 [  0   0]]
07:08:52.155391: LR: 
               precision    recall  f1-score   support

           0       1.00      0.81      0.90       590
           1       0.00      0.00      0.00         0

    accuracy                           0.81       590
   macro avg       0.50      0.41      0.45       590
weighted avg       1.00      0.81      0.90       590
07:08:52.158217: Validation Seq.Label F1: 0.3451739762332222; Log.Reg F1: 0.4480823199251637; train loss: 0.029264066368341446; Language: japanese 

07:08:52.160523: Combined F1 SeqLab: 0.5157619929298862; train loss: 0.029264066368341446
07:08:52.162805: Combined F1 LogReg: 0.39586388093882163; train loss: 0.029264066368341446 

07:08:52.163396: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 30/40
07:13:40.269652: Evaluating Language: english
07:13:40.270008: ----------
07:13:45.285337: OBI: 
 [[3724   39  223]
 [   3    9    2]
 [  19    4  106]]
07:13:45.290073: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      3986
           1       0.17      0.64      0.27        14
           2       0.32      0.82      0.46       129

    accuracy                           0.93      4129
   macro avg       0.50      0.80      0.57      4129
weighted avg       0.97      0.93      0.95      4129
07:13:45.290116: ----------
07:13:45.290810: LR: 
 [[393 538]
 [  0  14]]
07:13:45.293568: LR: 
               precision    recall  f1-score   support

           0       1.00      0.42      0.59       931
           1       0.03      1.00      0.05        14

    accuracy                           0.43       945
   macro avg       0.51      0.71      0.32       945
weighted avg       0.99      0.43      0.59       945
07:13:45.303109: Validation Seq.Label F1: 0.5656221223912805; Log.Reg F1: 0.321562776894089; train loss: 0.03286166489124298; Language: english 

07:13:45.303172: Evaluating Language: finnish
07:13:45.303218: ----------
07:13:52.477708: OBI: 
 [[3592   25  132]
 [   2   21    1]
 [  90    4  193]]
07:13:52.482197: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      3749
           1       0.42      0.88      0.57        24
           2       0.59      0.67      0.63       287

    accuracy                           0.94      4060
   macro avg       0.66      0.84      0.72      4060
weighted avg       0.94      0.94      0.94      4060
07:13:52.482240: ----------
07:13:52.483107: LR: 
 [[825 747]
 [  5  19]]
07:13:52.486357: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.69      1572
           1       0.02      0.79      0.05        24

    accuracy                           0.53      1596
   macro avg       0.51      0.66      0.37      1596
weighted avg       0.98      0.53      0.68      1596
07:13:52.491063: Validation Seq.Label F1: 0.7212527854835681; Log.Reg F1: 0.36751441309457317; train loss: 0.03286166489124298; Language: finnish 

07:13:52.491120: Evaluating Language: japanese
07:13:52.491163: ----------
07:13:55.443850: OBI: 
 [[298   2   0]
 [  0   0   0]
 [  4   0   0]]
07:13:55.446349: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.99      0.99       300
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         4

    accuracy                           0.98       304
   macro avg       0.33      0.33      0.33       304
weighted avg       0.97      0.98      0.98       304
07:13:55.446396: ----------
07:13:55.446954: LR: 
 [[496  94]
 [  0   0]]
07:13:55.449504: LR: 
               precision    recall  f1-score   support

           0       1.00      0.84      0.91       590
           1       0.00      0.00      0.00         0

    accuracy                           0.84       590
   macro avg       0.50      0.42      0.46       590
weighted avg       1.00      0.84      0.91       590
07:13:55.452288: Validation Seq.Label F1: 0.3300110741971207; Log.Reg F1: 0.45672191528545114; train loss: 0.03286166489124298; Language: japanese 

07:13:55.454941: Combined F1 SeqLab: 0.5624474123563198; train loss: 0.03286166489124298
07:13:55.457352: Combined F1 LogReg: 0.38603297407436454; train loss: 0.03286166489124298 

07:13:55.458049: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 31/40
07:18:44.194026: Evaluating Language: english
07:18:44.194146: ----------
07:18:49.061180: OBI: 
 [[3580   63  353]
 [   1   10    2]
 [   2    0  117]]
07:18:49.065874: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.94      3996
           1       0.14      0.77      0.23        13
           2       0.25      0.98      0.40       119

    accuracy                           0.90      4128
   macro avg       0.46      0.88      0.52      4128
weighted avg       0.97      0.90      0.93      4128
07:18:49.065919: ----------
07:18:49.066610: LR: 
 [[470 462]
 [  0  13]]
07:18:49.069345: LR: 
               precision    recall  f1-score   support

           0       1.00      0.50      0.67       932
           1       0.03      1.00      0.05        13

    accuracy                           0.51       945
   macro avg       0.51      0.75      0.36       945
weighted avg       0.99      0.51      0.66       945
07:18:49.079324: Validation Seq.Label F1: 0.5244042958420313; Log.Reg F1: 0.36187472229367884; train loss: 0.03108701854944229; Language: english 

07:18:49.079388: Evaluating Language: finnish
07:18:49.079434: ----------
07:18:56.083053: OBI: 
 [[3712   37  307]
 [   2   11    4]
 [  19    0  164]]
07:18:56.087700: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95      4056
           1       0.23      0.65      0.34        17
           2       0.35      0.90      0.50       183

    accuracy                           0.91      4256
   macro avg       0.52      0.82      0.60      4256
weighted avg       0.96      0.91      0.93      4256
07:18:56.087744: ----------
07:18:56.088610: LR: 
 [[834 745]
 [  1  16]]
07:18:56.091845: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.69      1579
           1       0.02      0.94      0.04        17

    accuracy                           0.53      1596
   macro avg       0.51      0.73      0.37      1596
weighted avg       0.99      0.53      0.68      1596
07:18:56.096787: Validation Seq.Label F1: 0.5966936079538959; Log.Reg F1: 0.3660502254415651; train loss: 0.03108701854944229; Language: finnish 

07:18:56.096844: Evaluating Language: japanese
07:18:56.096889: ----------
07:18:59.292881: OBI: 
 [[520   4  38]
 [  0   0   0]
 [  0   0   0]]
07:18:59.295561: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96       562
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.93       562
   macro avg       0.33      0.31      0.32       562
weighted avg       1.00      0.93      0.96       562
07:18:59.295612: ----------
07:18:59.296276: LR: 
 [[528  62]
 [  0   0]]
07:18:59.299362: LR: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94       590
           1       0.00      0.00      0.00         0

    accuracy                           0.89       590
   macro avg       0.50      0.45      0.47       590
weighted avg       1.00      0.89      0.94       590
07:18:59.302452: Validation Seq.Label F1: 0.3203943314849045; Log.Reg F1: 0.47227191413237923; train loss: 0.03108701854944229; Language: japanese 

07:18:59.305136: Combined F1 SeqLab: 0.49453535597173537; train loss: 0.03108701854944229
07:18:59.307800: Combined F1 LogReg: 0.4033141220187268; train loss: 0.03108701854944229 

07:18:59.308499: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 32/40
07:23:58.784117: Evaluating Language: english
07:23:58.784328: ----------
07:24:03.699340: OBI: 
 [[4005   54  192]
 [   4   12    3]
 [  28    3  132]]
07:24:03.704176: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.97      4251
           1       0.17      0.63      0.27        19
           2       0.40      0.81      0.54       163

    accuracy                           0.94      4433
   macro avg       0.52      0.79      0.59      4433
weighted avg       0.97      0.94      0.95      4433
07:24:03.704221: ----------
07:24:03.705012: LR: 
 [[562 364]
 [  5  14]]
07:24:03.708054: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.75       926
           1       0.04      0.74      0.07        19

    accuracy                           0.61       945
   macro avg       0.51      0.67      0.41       945
weighted avg       0.97      0.61      0.74       945
07:24:03.719177: Validation Seq.Label F1: 0.5926534372962945; Log.Reg F1: 0.411687792401484; train loss: 0.02590489387512207; Language: english 

07:24:03.719241: Evaluating Language: finnish
07:24:03.719288: ----------
07:24:10.934600: OBI: 
 [[3059   38  133]
 [   4   21    2]
 [  73    4  166]]
07:24:10.938697: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96      3230
           1       0.33      0.78      0.47        27
           2       0.55      0.68      0.61       243

    accuracy                           0.93      3500
   macro avg       0.62      0.80      0.68      3500
weighted avg       0.94      0.93      0.93      3500
07:24:10.938739: ----------
07:24:10.939661: LR: 
 [[889 680]
 [  6  21]]
07:24:10.943163: LR: 
               precision    recall  f1-score   support

           0       0.99      0.57      0.72      1569
           1       0.03      0.78      0.06        27

    accuracy                           0.57      1596
   macro avg       0.51      0.67      0.39      1596
weighted avg       0.98      0.57      0.71      1596
07:24:10.948291: Validation Seq.Label F1: 0.6793346084899557; Log.Reg F1: 0.38964160839160833; train loss: 0.02590489387512207; Language: finnish 

07:24:10.948365: Evaluating Language: japanese
07:24:10.948417: ----------
07:24:14.167629: OBI: 
 [[636   4  19]
 [  0   1   0]
 [  0   1   3]]
07:24:14.170235: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.97      0.98       659
           1       0.17      1.00      0.29         1
           2       0.14      0.75      0.23         4

    accuracy                           0.96       664
   macro avg       0.43      0.91      0.50       664
weighted avg       0.99      0.96      0.98       664
07:24:14.170281: ----------
07:24:14.170845: LR: 
 [[515  74]
 [  0   1]]
07:24:14.173404: LR: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93       589
           1       0.01      1.00      0.03         1

    accuracy                           0.87       590
   macro avg       0.51      0.94      0.48       590
weighted avg       1.00      0.87      0.93       590
07:24:14.176333: Validation Seq.Label F1: 0.49957429957429955; Log.Reg F1: 0.4796434019832189; train loss: 0.02590489387512207; Language: japanese 

07:24:14.178892: Combined F1 SeqLab: 0.5950652871258375; train loss: 0.02590489387512207
07:24:14.181316: Combined F1 LogReg: 0.428705498941656; train loss: 0.02590489387512207 

07:24:14.182044: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 33/40
07:29:09.095197: Evaluating Language: english
07:29:09.095377: ----------
07:29:14.000550: OBI: 
 [[4282   59  579]
 [   4   13    3]
 [  18    4  186]]
07:29:14.006332: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.87      0.93      4920
           1       0.17      0.65      0.27        20
           2       0.24      0.89      0.38       208

    accuracy                           0.87      5148
   macro avg       0.47      0.80      0.53      5148
weighted avg       0.96      0.87      0.90      5148
07:29:14.006385: ----------
07:29:14.007228: LR: 
 [[365 560]
 [  3  17]]
07:29:14.010078: LR: 
               precision    recall  f1-score   support

           0       0.99      0.39      0.56       925
           1       0.03      0.85      0.06        20

    accuracy                           0.40       945
   macro avg       0.51      0.62      0.31       945
weighted avg       0.97      0.40      0.55       945
07:29:14.020633: Validation Seq.Label F1: 0.5268094675014258; Log.Reg F1: 0.3107649616994485; train loss: 0.03106207586824894; Language: english 

07:29:14.020699: Evaluating Language: finnish
07:29:14.020748: ----------
07:29:21.239474: OBI: 
 [[3579   32  209]
 [   0   19    2]
 [  23    2  158]]
07:29:21.243973: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      3820
           1       0.36      0.90      0.51        21
           2       0.43      0.86      0.57       183

    accuracy                           0.93      4024
   macro avg       0.59      0.90      0.68      4024
weighted avg       0.96      0.93      0.94      4024
07:29:21.244017: ----------
07:29:21.244886: LR: 
 [[736 839]
 [  1  20]]
07:29:21.248157: LR: 
               precision    recall  f1-score   support

           0       1.00      0.47      0.64      1575
           1       0.02      0.95      0.05        21

    accuracy                           0.47      1596
   macro avg       0.51      0.71      0.34      1596
weighted avg       0.99      0.47      0.63      1596
07:29:21.253249: Validation Seq.Label F1: 0.6834691181287083; Log.Reg F1: 0.3410663730732935; train loss: 0.03106207586824894; Language: finnish 

07:29:21.253305: Evaluating Language: japanese
07:29:21.253366: ----------
07:29:24.409097: OBI: 
 [[1154    8   88]
 [   1    0    0]
 [   3    0    0]]
07:29:24.411819: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96      1250
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         3

    accuracy                           0.92      1254
   macro avg       0.33      0.31      0.32      1254
weighted avg       0.99      0.92      0.96      1254
07:29:24.411863: ----------
07:29:24.412432: LR: 
 [[494  95]
 [  0   1]]
07:29:24.414846: LR: 
               precision    recall  f1-score   support

           0       1.00      0.84      0.91       589
           1       0.01      1.00      0.02         1

    accuracy                           0.84       590
   macro avg       0.51      0.92      0.47       590
weighted avg       1.00      0.84      0.91       590
07:29:24.419703: Validation Seq.Label F1: 0.3194905869324474; Log.Reg F1: 0.46644962922770844; train loss: 0.03106207586824894; Language: japanese 

07:29:24.422245: Combined F1 SeqLab: 0.5312665638588628; train loss: 0.03106207586824894
07:29:24.424786: Combined F1 LogReg: 0.37880355017172046; train loss: 0.03106207586824894 

07:29:24.425391: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 34/40
07:34:14.579190: Evaluating Language: english
07:34:14.579385: ----------
07:34:19.494441: OBI: 
 [[1923   26   87]
 [   3    6    1]
 [  16    1   57]]
07:34:19.497843: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.97      2036
           1       0.18      0.60      0.28        10
           2       0.39      0.77      0.52        74

    accuracy                           0.94      2120
   macro avg       0.52      0.77      0.59      2120
weighted avg       0.97      0.94      0.95      2120
07:34:19.497887: ----------
07:34:19.498569: LR: 
 [[496 439]
 [  1   9]]
07:34:19.501260: LR: 
               precision    recall  f1-score   support

           0       1.00      0.53      0.69       935
           1       0.02      0.90      0.04        10

    accuracy                           0.53       945
   macro avg       0.51      0.72      0.37       945
weighted avg       0.99      0.53      0.69       945
07:34:19.511386: Validation Seq.Label F1: 0.5888117362922003; Log.Reg F1: 0.3660193701056329; train loss: 0.024317830801010132; Language: english 

07:34:19.511452: Evaluating Language: finnish
07:34:19.511498: ----------
07:34:26.740461: OBI: 
 [[3710   26  116]
 [   7    9    4]
 [  95    3  146]]
07:34:26.744979: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.97      3852
           1       0.24      0.45      0.31        20
           2       0.55      0.60      0.57       244

    accuracy                           0.94      4116
   macro avg       0.59      0.67      0.62      4116
weighted avg       0.94      0.94      0.94      4116
07:34:26.745021: ----------
07:34:26.745886: LR: 
 [[875 701]
 [  6  14]]
07:34:26.749167: LR: 
               precision    recall  f1-score   support

           0       0.99      0.56      0.71      1576
           1       0.02      0.70      0.04        20

    accuracy                           0.56      1596
   macro avg       0.51      0.63      0.38      1596
weighted avg       0.98      0.56      0.70      1596
07:34:26.754340: Validation Seq.Label F1: 0.6170188954808281; Log.Reg F1: 0.3751729751729752; train loss: 0.024317830801010132; Language: finnish 

07:34:26.754396: Evaluating Language: japanese
07:34:26.754440: ----------
07:34:29.894302: OBI: 
 [[1230    8   23]
 [   0    0    0]
 [   0    0   39]]
07:34:29.897144: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99      1261
           1       0.00      0.00      0.00         0
           2       0.63      1.00      0.77        39

    accuracy                           0.98      1300
   macro avg       0.54      0.66      0.59      1300
weighted avg       0.99      0.98      0.98      1300
07:34:29.897186: ----------
07:34:29.897752: LR: 
 [[489 101]
 [  0   0]]
07:34:29.900327: LR: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.91       590
           1       0.00      0.00      0.00         0

    accuracy                           0.83       590
   macro avg       0.50      0.41      0.45       590
weighted avg       1.00      0.83      0.91       590
07:34:29.905233: Validation Seq.Label F1: 0.5866108088127159; Log.Reg F1: 0.45319740500463396; train loss: 0.024317830801010132; Language: japanese 

07:34:29.909588: Combined F1 SeqLab: 0.5976408674088828; train loss: 0.024317830801010132
07:34:29.913972: Combined F1 LogReg: 0.4000470091108462; train loss: 0.024317830801010132 

07:34:29.914588: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 35/40
07:39:18.236264: Evaluating Language: english
07:39:18.236624: ----------
07:39:23.027925: OBI: 
 [[3624   38  223]
 [   3   16    3]
 [  33    5  114]]
07:39:23.032565: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      3885
           1       0.27      0.73      0.40        22
           2       0.34      0.75      0.46       152

    accuracy                           0.92      4059
   macro avg       0.53      0.80      0.61      4059
weighted avg       0.96      0.92      0.94      4059
07:39:23.032611: ----------
07:39:23.033306: LR: 
 [[501 422]
 [  2  20]]
07:39:23.036041: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70       923
           1       0.05      0.91      0.09        22

    accuracy                           0.55       945
   macro avg       0.52      0.73      0.39       945
weighted avg       0.97      0.55      0.69       945
07:39:23.046028: Validation Seq.Label F1: 0.6063708484813293; Log.Reg F1: 0.3944358465928326; train loss: 0.027808785438537598; Language: english 

07:39:23.046092: Evaluating Language: finnish
07:39:23.046141: ----------
07:39:30.294801: OBI: 
 [[2335   20  128]
 [   3   10    1]
 [  36    0   91]]
07:39:30.298419: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      2483
           1       0.33      0.71      0.45        14
           2       0.41      0.72      0.52       127

    accuracy                           0.93      2624
   macro avg       0.58      0.79      0.65      2624
weighted avg       0.95      0.93      0.94      2624
07:39:30.298472: ----------
07:39:30.299542: LR: 
 [[855 727]
 [  6   8]]
07:39:30.303090: LR: 
               precision    recall  f1-score   support

           0       0.99      0.54      0.70      1582
           1       0.01      0.57      0.02        14

    accuracy                           0.54      1596
   macro avg       0.50      0.56      0.36      1596
weighted avg       0.98      0.54      0.69      1596
07:39:30.308952: Validation Seq.Label F1: 0.6468466664642124; Log.Reg F1: 0.3606604412377918; train loss: 0.027808785438537598; Language: finnish 

07:39:30.309021: Evaluating Language: japanese
07:39:30.309077: ----------
07:39:33.362374: OBI: 
 [[1712    6   89]
 [   0    0    0]
 [   4    0   11]]
07:39:33.365798: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.95      0.97      1807
           1       0.00      0.00      0.00         0
           2       0.11      0.73      0.19        15

    accuracy                           0.95      1822
   macro avg       0.37      0.56      0.39      1822
weighted avg       0.99      0.95      0.97      1822
07:39:33.365864: ----------
07:39:33.366450: LR: 
 [[554  36]
 [  0   0]]
07:39:33.369104: LR: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97       590
           1       0.00      0.00      0.00         0

    accuracy                           0.94       590
   macro avg       0.50      0.47      0.48       590
weighted avg       1.00      0.94      0.97       590
07:39:33.374149: Validation Seq.Label F1: 0.3877344325282717; Log.Reg F1: 0.4842657342657342; train loss: 0.027808785438537598; Language: japanese 

07:39:33.379276: Combined F1 SeqLab: 0.5586991456266518; train loss: 0.027808785438537598
07:39:33.383787: Combined F1 LogReg: 0.4164008054487783; train loss: 0.027808785438537598 

07:39:33.384392: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 36/40
07:44:21.729931: Evaluating Language: english
07:44:21.730120: ----------
07:44:26.683298: OBI: 
 [[3774   56  304]
 [   3   12    9]
 [  36    1  205]]
07:44:26.688169: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.91      0.95      4134
           1       0.17      0.50      0.26        24
           2       0.40      0.85      0.54       242

    accuracy                           0.91      4400
   macro avg       0.52      0.75      0.58      4400
weighted avg       0.95      0.91      0.92      4400
07:44:26.688215: ----------
07:44:26.688924: LR: 
 [[547 374]
 [  4  20]]
07:44:26.691668: LR: 
               precision    recall  f1-score   support

           0       0.99      0.59      0.74       921
           1       0.05      0.83      0.10        24

    accuracy                           0.60       945
   macro avg       0.52      0.71      0.42       945
weighted avg       0.97      0.60      0.73       945
07:44:26.702240: Validation Seq.Label F1: 0.5824435249401649; Log.Reg F1: 0.41945015082171827; train loss: 0.031383153051137924; Language: english 

07:44:26.702303: Evaluating Language: finnish
07:44:26.702359: ----------
07:44:33.832387: OBI: 
 [[3931   36  143]
 [   5   18    2]
 [  63    2  120]]
07:44:33.837029: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      4110
           1       0.32      0.72      0.44        25
           2       0.45      0.65      0.53       185

    accuracy                           0.94      4320
   macro avg       0.59      0.78      0.65      4320
weighted avg       0.96      0.94      0.95      4320
07:44:33.837075: ----------
07:44:33.837959: LR: 
 [[866 705]
 [  2  23]]
07:44:33.841193: LR: 
               precision    recall  f1-score   support

           0       1.00      0.55      0.71      1571
           1       0.03      0.92      0.06        25

    accuracy                           0.56      1596
   macro avg       0.51      0.74      0.39      1596
weighted avg       0.98      0.56      0.70      1596
07:44:33.846351: Validation Seq.Label F1: 0.6491059316808485; Log.Reg F1: 0.3856080393473256; train loss: 0.031383153051137924; Language: finnish 

07:44:33.846409: Evaluating Language: japanese
07:44:33.846453: ----------
07:44:36.967544: OBI: 
 [[1256    9   76]
 [   0    0    0]
 [   0    0   13]]
07:44:36.970414: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97      1341
           1       0.00      0.00      0.00         0
           2       0.15      1.00      0.25        13

    accuracy                           0.94      1354
   macro avg       0.38      0.65      0.41      1354
weighted avg       0.99      0.94      0.96      1354
07:44:36.970458: ----------
07:44:36.971027: LR: 
 [[540  50]
 [  0   0]]
07:44:36.973574: LR: 
               precision    recall  f1-score   support

           0       1.00      0.92      0.96       590
           1       0.00      0.00      0.00         0

    accuracy                           0.92       590
   macro avg       0.50      0.46      0.48       590
weighted avg       1.00      0.92      0.96       590
07:44:36.978600: Validation Seq.Label F1: 0.4073906292076579; Log.Reg F1: 0.4778761061946903; train loss: 0.031383153051137924; Language: japanese 

07:44:36.983573: Combined F1 SeqLab: 0.5557415751510764; train loss: 0.031383153051137924
07:44:36.988288: Combined F1 LogReg: 0.4293396331986484; train loss: 0.031383153051137924 

07:44:36.988901: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 37/40
07:49:29.423702: Evaluating Language: english
07:49:29.423884: ----------
07:49:34.375197: OBI: 
 [[3538   47  269]
 [   3   14    5]
 [  26    1  116]]
07:49:34.379766: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95      3854
           1       0.23      0.64      0.33        22
           2       0.30      0.81      0.44       143

    accuracy                           0.91      4019
   macro avg       0.51      0.79      0.57      4019
weighted avg       0.96      0.91      0.93      4019
07:49:34.379808: ----------
07:49:34.380493: LR: 
 [[492 431]
 [  6  16]]
07:49:34.383226: LR: 
               precision    recall  f1-score   support

           0       0.99      0.53      0.69       923
           1       0.04      0.73      0.07        22

    accuracy                           0.54       945
   macro avg       0.51      0.63      0.38       945
weighted avg       0.97      0.54      0.68       945
07:49:34.394072: Validation Seq.Label F1: 0.5740385623150749; Log.Reg F1: 0.3803501843351854; train loss: 0.03256693854928017; Language: english 

07:49:34.394138: Evaluating Language: finnish
07:49:34.394183: ----------
07:49:41.693617: OBI: 
 [[3305   30  174]
 [   6   20    3]
 [  79    3  184]]
07:49:41.697940: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.94      0.96      3509
           1       0.38      0.69      0.49        29
           2       0.51      0.69      0.59       266

    accuracy                           0.92      3804
   macro avg       0.62      0.77      0.68      3804
weighted avg       0.94      0.92      0.93      3804
07:49:41.697981: ----------
07:49:41.698846: LR: 
 [[822 745]
 [  6  23]]
07:49:41.702096: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.69      1567
           1       0.03      0.79      0.06        29

    accuracy                           0.53      1596
   macro avg       0.51      0.66      0.37      1596
weighted avg       0.98      0.53      0.68      1596
07:49:41.705077: Validation Seq.Label F1: 0.6776121997081074; Log.Reg F1: 0.3720732496339352; train loss: 0.03256693854928017; Language: finnish 

07:49:41.705134: Evaluating Language: japanese
07:49:41.705178: ----------
07:49:44.867853: OBI: 
 [[399   3  27]
 [  1   0   0]
 [  5   0   1]]
07:49:44.870472: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96       429
           1       0.00      0.00      0.00         1
           2       0.04      0.17      0.06         6

    accuracy                           0.92       436
   macro avg       0.34      0.37      0.34       436
weighted avg       0.97      0.92      0.94       436
07:49:44.870527: ----------
07:49:44.871173: LR: 
 [[530  59]
 [  1   0]]
07:49:44.873575: LR: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.95       589
           1       0.00      0.00      0.00         1

    accuracy                           0.90       590
   macro avg       0.50      0.45      0.47       590
weighted avg       1.00      0.90      0.94       590
07:49:44.876411: Validation Seq.Label F1: 0.3385526872619551; Log.Reg F1: 0.4732142857142857; train loss: 0.03256693854928017; Language: japanese 

07:49:44.878741: Combined F1 SeqLab: 0.548724729492639; train loss: 0.03256693854928017
07:49:44.881063: Combined F1 LogReg: 0.4111109039424147; train loss: 0.03256693854928017 

07:49:44.881647: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 38/40
07:54:42.524025: Evaluating Language: english
07:54:42.524183: ----------
07:54:47.444578: OBI: 
 [[3439   64  500]
 [   3   15    5]
 [  19    1  149]]
07:54:47.449692: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      4003
           1       0.19      0.65      0.29        23
           2       0.23      0.88      0.36       169

    accuracy                           0.86      4195
   macro avg       0.47      0.80      0.52      4195
weighted avg       0.96      0.86      0.90      4195
07:54:47.449743: ----------
07:54:47.450527: LR: 
 [[448 474]
 [  3  20]]
07:54:47.453232: LR: 
               precision    recall  f1-score   support

           0       0.99      0.49      0.65       922
           1       0.04      0.87      0.08        23

    accuracy                           0.50       945
   macro avg       0.52      0.68      0.36       945
weighted avg       0.97      0.50      0.64       945
07:54:47.463484: Validation Seq.Label F1: 0.5249472895532402; Log.Reg F1: 0.3649775090478008; train loss: 0.02729845978319645; Language: english 

07:54:47.463547: Evaluating Language: finnish
07:54:47.463592: ----------
07:54:54.478244: OBI: 
 [[4318   35  195]
 [   8   22    4]
 [  87    6  165]]
07:54:54.483213: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96      4548
           1       0.35      0.65      0.45        34
           2       0.45      0.64      0.53       258

    accuracy                           0.93      4840
   macro avg       0.59      0.75      0.65      4840
weighted avg       0.95      0.93      0.94      4840
07:54:54.483257: ----------
07:54:54.484125: LR: 
 [[812 750]
 [  7  27]]
07:54:54.487402: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.68      1562
           1       0.03      0.79      0.07        34

    accuracy                           0.53      1596
   macro avg       0.51      0.66      0.37      1596
weighted avg       0.97      0.53      0.67      1596
07:54:54.490374: Validation Seq.Label F1: 0.6492955325289058; Log.Reg F1: 0.3743254111489904; train loss: 0.02729845978319645; Language: finnish 

07:54:54.490427: Evaluating Language: japanese
07:54:54.490471: ----------
07:54:57.472749: OBI: 
 [[333   1  24]
 [  0   0   0]
 [  0   0   0]]
07:54:57.475057: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96       358
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.93       358
   macro avg       0.33      0.31      0.32       358
weighted avg       1.00      0.93      0.96       358
07:54:57.475104: ----------
07:54:57.475669: LR: 
 [[515  75]
 [  0   0]]
07:54:57.478195: LR: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93       590
           1       0.00      0.00      0.00         0

    accuracy                           0.87       590
   macro avg       0.50      0.44      0.47       590
weighted avg       1.00      0.87      0.93       590
07:54:57.481175: Validation Seq.Label F1: 0.32127351664254705; Log.Reg F1: 0.4660633484162896; train loss: 0.02729845978319645; Language: japanese 

07:54:57.483517: Combined F1 SeqLab: 0.5165175111155986; train loss: 0.02729845978319645
07:54:57.485854: Combined F1 LogReg: 0.4043691136736344; train loss: 0.02729845978319645 

07:54:57.486446: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 39/40
07:59:58.900990: Evaluating Language: english
07:59:58.901162: ----------
08:00:03.668647: OBI: 
 [[3350   44  164]
 [   6    7    1]
 [  21    4  123]]
08:00:03.673036: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.97      3558
           1       0.13      0.50      0.20        14
           2       0.43      0.83      0.56       148

    accuracy                           0.94      3720
   macro avg       0.52      0.76      0.58      3720
weighted avg       0.97      0.94      0.95      3720
08:00:03.673079: ----------
08:00:03.673775: LR: 
 [[481 450]
 [  3  11]]
08:00:03.676499: LR: 
               precision    recall  f1-score   support

           0       0.99      0.52      0.68       931
           1       0.02      0.79      0.05        14

    accuracy                           0.52       945
   macro avg       0.51      0.65      0.36       945
weighted avg       0.98      0.52      0.67       945
08:00:03.688207: Validation Seq.Label F1: 0.5777442163783911; Log.Reg F1: 0.3630872233587502; train loss: 0.025613000616431236; Language: english 

08:00:03.688273: Evaluating Language: finnish
08:00:03.688327: ----------
08:00:10.757112: OBI: 
 [[4739   40  146]
 [   0   21    5]
 [ 105    2  218]]
08:00:10.762407: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      4925
           1       0.33      0.81      0.47        26
           2       0.59      0.67      0.63       325

    accuracy                           0.94      5276
   macro avg       0.63      0.81      0.69      5276
weighted avg       0.95      0.94      0.95      5276
08:00:10.762452: ----------
08:00:10.763327: LR: 
 [[852 718]
 [  1  25]]
08:00:10.766658: LR: 
               precision    recall  f1-score   support

           0       1.00      0.54      0.70      1570
           1       0.03      0.96      0.07        26

    accuracy                           0.55      1596
   macro avg       0.52      0.75      0.38      1596
weighted avg       0.98      0.55      0.69      1596
08:00:10.770065: Validation Seq.Label F1: 0.6901213606855574; Log.Reg F1: 0.3841399634087503; train loss: 0.025613000616431236; Language: finnish 

08:00:10.770123: Evaluating Language: japanese
08:00:10.770171: ----------
08:00:13.978738: OBI: 
 [[737   1  16]
 [  0   0   0]
 [  0   0   6]]
08:00:13.981243: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99       754
           1       0.00      0.00      0.00         0
           2       0.27      1.00      0.43         6

    accuracy                           0.98       760
   macro avg       0.42      0.66      0.47       760
weighted avg       0.99      0.98      0.98       760
08:00:13.981286: ----------
08:00:13.981849: LR: 
 [[536  54]
 [  0   0]]
08:00:13.984398: LR: 
               precision    recall  f1-score   support

           0       1.00      0.91      0.95       590
           1       0.00      0.00      0.00         0

    accuracy                           0.91       590
   macro avg       0.50      0.45      0.48       590
weighted avg       1.00      0.91      0.95       590
08:00:13.987475: Validation Seq.Label F1: 0.4723898949251062; Log.Reg F1: 0.4760213143872114; train loss: 0.025613000616431236; Language: japanese 

08:00:13.989772: Combined F1 SeqLab: 0.5868583261346016; train loss: 0.025613000616431236
08:00:13.992037: Combined F1 LogReg: 0.41068728371068064; train loss: 0.025613000616431236 

08:00:13.992635: Model: lab6_xlm-roberta-base_finnish.pt; Language: finnish; Epoch 40/40
08:05:04.545582: Evaluating Language: english
08:05:04.545761: ----------
08:05:09.247097: OBI: 
 [[3496   38  182]
 [   1   12    2]
 [  18    4  150]]
08:05:09.251718: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.97      3716
           1       0.22      0.80      0.35        15
           2       0.45      0.87      0.59       172

    accuracy                           0.94      3903
   macro avg       0.56      0.87      0.64      3903
weighted avg       0.97      0.94      0.95      3903
08:05:09.251765: ----------
08:05:09.252475: LR: 
 [[557 373]
 [  3  12]]
08:05:09.255185: LR: 
               precision    recall  f1-score   support

           0       0.99      0.60      0.75       930
           1       0.03      0.80      0.06        15

    accuracy                           0.60       945
   macro avg       0.51      0.70      0.40       945
weighted avg       0.98      0.60      0.74       945
08:05:09.265587: Validation Seq.Label F1: 0.6358864419388852; Log.Reg F1: 0.40382550335570466; train loss: 0.023486478254199028; Language: english 

08:05:09.265651: Evaluating Language: finnish
08:05:09.265697: ----------
08:05:16.400551: OBI: 
 [[4054   30  204]
 [   3   17    1]
 [  40    1  178]]
08:05:16.405329: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      4288
           1       0.35      0.81      0.49        21
           2       0.46      0.81      0.59       219

    accuracy                           0.94      4528
   macro avg       0.60      0.86      0.68      4528
weighted avg       0.96      0.94      0.95      4528
08:05:16.405374: ----------
08:05:16.406237: LR: 
 [[865 710]
 [  6  15]]
08:05:16.409502: LR: 
               precision    recall  f1-score   support

           0       0.99      0.55      0.71      1575
           1       0.02      0.71      0.04        21

    accuracy                           0.55      1596
   macro avg       0.51      0.63      0.37      1596
weighted avg       0.98      0.55      0.70      1596
08:05:16.412290: Validation Seq.Label F1: 0.6836935225206205; Log.Reg F1: 0.37374583222813856; train loss: 0.023486478254199028; Language: finnish 

08:05:16.412357: Evaluating Language: japanese
08:05:16.412403: ----------
08:05:19.504936: OBI: 
 [[1380    6   32]
 [   0    0    0]
 [   0    0    0]]
08:05:19.507850: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.97      0.99      1418
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.97      1418
   macro avg       0.33      0.32      0.33      1418
weighted avg       1.00      0.97      0.99      1418
08:05:19.507895: ----------
08:05:19.508471: LR: 
 [[548  42]
 [  0   0]]
08:05:19.510984: LR: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96       590
           1       0.00      0.00      0.00         0

    accuracy                           0.93       590
   macro avg       0.50      0.46      0.48       590
weighted avg       1.00      0.93      0.96       590
08:05:19.513796: Validation Seq.Label F1: 0.32880629020729096; Log.Reg F1: 0.48154657293497366; train loss: 0.023486478254199028; Language: japanese 

08:05:19.516075: Combined F1 SeqLab: 0.5715190216310189; train loss: 0.023486478254199028
08:05:19.518314: Combined F1 LogReg: 0.42215640315480635; train loss: 0.023486478254199028 

08:05:19.518378: Learning rates: []
08:05:29.563818: -- Data Parsing JAPANESE; Type: TRAIN--
08:05:44.117049: Unanswerable questions: 4284
08:05:44.161520: Balance of labels: dict_keys([-100, 1, 2, 0]):dict_values([65949, 671, 4295, 610938])
08:05:44.161587: Entries skipped due to too long sequence length (>512): 284
08:05:44.161640: Failed to map answer and to context: 3539
08:05:44.198877: Label counts: O: 610938, B: 671, I: 4295
08:05:44.199014: Final length: 4955 

08:05:44.214256: Language: japanese; Class weights: [0.00094901 0.86406041 0.13499058 0.        ]
08:05:44.412508: Training model: lab6_xlm-roberta-base_japanese.pt
08:05:44.418418: Loading model: xlm-roberta-base
08:05:46.466304: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 1/40
08:07:45.950401: Evaluating Language: english
08:07:45.950536: ----------
08:07:50.831448: OBI: 
 [[2301   50 1257]
 [   3    3   17]
 [  73    4  101]]
08:07:50.835926: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.64      0.77      3608
           1       0.05      0.13      0.07        23
           2       0.07      0.57      0.13       178

    accuracy                           0.63      3809
   macro avg       0.36      0.45      0.32      3809
weighted avg       0.92      0.63      0.73      3809
08:07:50.835978: ----------
08:07:50.836662: LR: 
 [[833  89]
 [ 18   5]]
08:07:50.839378: LR: 
               precision    recall  f1-score   support

           0       0.98      0.90      0.94       922
           1       0.05      0.22      0.09        23

    accuracy                           0.89       945
   macro avg       0.52      0.56      0.51       945
weighted avg       0.96      0.89      0.92       945
08:07:50.840847: Validation Seq.Label F1: 0.3246643788049217; Log.Reg F1: 0.5125601978393857; train loss: 0.3809022605419159; Language: english 

08:07:50.840918: Evaluating Language: finnish
08:07:50.840971: ----------
08:07:57.965620: OBI: 
 [[3270   88 1230]
 [   4    5    9]
 [ 116    0   78]]
08:07:57.970846: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.71      0.82      4588
           1       0.05      0.28      0.09        18
           2       0.06      0.40      0.10       194

    accuracy                           0.70      4800
   macro avg       0.36      0.46      0.34      4800
weighted avg       0.92      0.70      0.79      4800
08:07:57.970903: ----------
08:07:57.971807: LR: 
 [[669 909]
 [  7  11]]
08:07:57.975090: LR: 
               precision    recall  f1-score   support

           0       0.99      0.42      0.59      1578
           1       0.01      0.61      0.02        18

    accuracy                           0.43      1596
   macro avg       0.50      0.52      0.31      1596
weighted avg       0.98      0.43      0.59      1596
08:07:57.976537: Validation Seq.Label F1: 0.3376957666628185; Log.Reg F1: 0.30853275768451444; train loss: 0.3809022605419159; Language: finnish 

08:07:57.976611: Evaluating Language: japanese
08:07:57.976668: ----------
08:08:01.075610: OBI: 
 [[38  2 38]
 [ 0  0  0]
 [ 0  0  0]]
08:08:01.077779: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.49      0.66        78
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.49        78
   macro avg       0.33      0.16      0.22        78
weighted avg       1.00      0.49      0.66        78
08:08:01.077833: ----------
08:08:01.078400: LR: 
 [[511  79]
 [  0   0]]
08:08:01.080992: LR: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93       590
           1       0.00      0.00      0.00         0

    accuracy                           0.87       590
   macro avg       0.50      0.43      0.46       590
weighted avg       1.00      0.87      0.93       590
08:08:01.082218: Validation Seq.Label F1: 0.21839080459770113; Log.Reg F1: 0.4641235240690282; train loss: 0.3809022605419159; Language: japanese 

08:08:01.083176: Combined F1 SeqLab: 0.2984068437662502; train loss: 0.3809022605419159
08:08:01.955509: Combined F1 LogReg: 0.4371578908387736; train loss: 0.3809022605419159 

08:08:01.957322: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 2/40
08:10:00.895247: Evaluating Language: english
08:10:00.895456: ----------
08:10:05.827668: OBI: 
 [[4429   30  138]
 [  17    1    4]
 [ 224    3    7]]
08:10:05.832963: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.96      0.96      4597
           1       0.03      0.05      0.04        22
           2       0.05      0.03      0.04       234

    accuracy                           0.91      4853
   macro avg       0.34      0.35      0.34      4853
weighted avg       0.90      0.91      0.91      4853
08:10:05.833019: ----------
08:10:05.833729: LR: 
 [[899  24]
 [ 21   1]]
08:10:05.836438: LR: 
               precision    recall  f1-score   support

           0       0.98      0.97      0.98       923
           1       0.04      0.05      0.04        22

    accuracy                           0.95       945
   macro avg       0.51      0.51      0.51       945
weighted avg       0.96      0.95      0.95       945
08:10:05.839754: Validation Seq.Label F1: 0.3427109024882054; Log.Reg F1: 0.509068239803281; train loss: 0.26451805233955383; Language: english 

08:10:05.839833: Evaluating Language: finnish
08:10:05.839888: ----------
08:10:12.817819: OBI: 
 [[3464   31   93]
 [  13    2    2]
 [ 207    3   13]]
08:10:12.822232: OBI: 
               precision    recall  f1-score   support

           0       0.94      0.97      0.95      3588
           1       0.06      0.12      0.08        17
           2       0.12      0.06      0.08       223

    accuracy                           0.91      3828
   macro avg       0.37      0.38      0.37      3828
weighted avg       0.89      0.91      0.90      3828
08:10:12.822287: ----------
08:10:12.823159: LR: 
 [[908 671]
 [  8   9]]
08:10:12.826428: LR: 
               precision    recall  f1-score   support

           0       0.99      0.58      0.73      1579
           1       0.01      0.53      0.03        17

    accuracy                           0.57      1596
   macro avg       0.50      0.55      0.38      1596
weighted avg       0.98      0.57      0.72      1596
08:10:12.827782: Validation Seq.Label F1: 0.3689056055275861; Log.Reg F1: 0.37684033777742; train loss: 0.26451805233955383; Language: finnish 

08:10:12.827848: Evaluating Language: japanese
08:10:12.827902: ----------
08:10:16.072440: OBI: 
 [[328  16  42]
 [  0   0   0]
 [  0   0   4]]
08:10:16.074817: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.85      0.92       386
           1       0.00      0.00      0.00         0
           2       0.09      1.00      0.16         4

    accuracy                           0.85       390
   macro avg       0.36      0.62      0.36       390
weighted avg       0.99      0.85      0.91       390
08:10:16.074870: ----------
08:10:16.075453: LR: 
 [[508  82]
 [  0   0]]
08:10:16.078188: LR: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.93       590
           1       0.00      0.00      0.00         0

    accuracy                           0.86       590
   macro avg       0.50      0.43      0.46       590
weighted avg       1.00      0.86      0.93       590
08:10:16.079423: Validation Seq.Label F1: 0.3595891690009337; Log.Reg F1: 0.46265938069216755; train loss: 0.26451805233955383; Language: japanese 

08:10:16.080382: Combined F1 SeqLab: 0.35723310733876895; train loss: 0.26451805233955383
08:10:16.989185: Combined F1 LogReg: 0.45284758859726404; train loss: 0.26451805233955383 

08:10:16.993184: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 3/40
08:12:17.248569: Evaluating Language: english
08:12:17.248746: ----------
08:12:22.033128: OBI: 
 [[3030    8  212]
 [  10    0    2]
 [ 107    2   38]]
08:12:22.037518: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.93      0.95      3250
           1       0.00      0.00      0.00        12
           2       0.15      0.26      0.19       147

    accuracy                           0.90      3409
   macro avg       0.37      0.40      0.38      3409
weighted avg       0.92      0.90      0.91      3409
08:12:22.037572: ----------
08:12:22.038255: LR: 
 [[683 250]
 [ 11   1]]
08:12:22.041000: LR: 
               precision    recall  f1-score   support

           0       0.98      0.73      0.84       933
           1       0.00      0.08      0.01        12

    accuracy                           0.72       945
   macro avg       0.49      0.41      0.42       945
weighted avg       0.97      0.72      0.83       945
08:12:22.042489: Validation Seq.Label F1: 0.3792650820945334; Log.Reg F1: 0.4235933077978317; train loss: 0.19201642274856567; Language: english 

08:12:22.042560: Evaluating Language: finnish
08:12:22.042613: ----------
08:12:29.159889: OBI: 
 [[4325   21  262]
 [  17    2   12]
 [ 227    2   72]]
08:12:29.165597: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.94      0.94      4608
           1       0.08      0.06      0.07        31
           2       0.21      0.24      0.22       301

    accuracy                           0.89      4940
   macro avg       0.41      0.41      0.41      4940
weighted avg       0.90      0.89      0.89      4940
08:12:29.165650: ----------
08:12:29.166532: LR: 
 [[1008  557]
 [  13   18]]
08:12:29.169876: LR: 
               precision    recall  f1-score   support

           0       0.99      0.64      0.78      1565
           1       0.03      0.58      0.06        31

    accuracy                           0.64      1596
   macro avg       0.51      0.61      0.42      1596
weighted avg       0.97      0.64      0.77      1596
08:12:29.171448: Validation Seq.Label F1: 0.41218936169579695; Log.Reg F1: 0.4194941535916933; train loss: 0.19201642274856567; Language: finnish 

08:12:29.171515: Evaluating Language: japanese
08:12:29.171568: ----------
08:12:32.234173: OBI: 
 [[1027    9   69]
 [   0    2    0]
 [   0    0   15]]
08:12:32.236803: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96      1105
           1       0.18      1.00      0.31         2
           2       0.18      1.00      0.30        15

    accuracy                           0.93      1122
   macro avg       0.45      0.98      0.52      1122
weighted avg       0.99      0.93      0.95      1122
08:12:32.236858: ----------
08:12:32.237426: LR: 
 [[521  67]
 [  1   1]]
08:12:32.239833: LR: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94       588
           1       0.01      0.50      0.03         2

    accuracy                           0.88       590
   macro avg       0.51      0.69      0.48       590
weighted avg       0.99      0.88      0.94       590
08:12:32.241031: Validation Seq.Label F1: 0.5247124149563174; Log.Reg F1: 0.4836550836550837; train loss: 0.19201642274856567; Language: japanese 

08:12:32.241979: Combined F1 SeqLab: 0.4431196944395695; train loss: 0.19201642274856567
08:12:33.197349: Combined F1 LogReg: 0.44321886062987204; train loss: 0.19201642274856567 

08:12:33.198975: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 4/40
08:14:32.938080: Evaluating Language: english
08:14:32.938234: ----------
08:14:37.706692: OBI: 
 [[2105   13  562]
 [   3    0    6]
 [  60    2   95]]
08:14:37.710807: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.79      0.87      2680
           1       0.00      0.00      0.00         9
           2       0.14      0.61      0.23       157

    accuracy                           0.77      2846
   macro avg       0.37      0.46      0.37      2846
weighted avg       0.92      0.77      0.83      2846
08:14:37.710860: ----------
08:14:37.711542: LR: 
 [[727 209]
 [  7   2]]
08:14:37.714249: LR: 
               precision    recall  f1-score   support

           0       0.99      0.78      0.87       936
           1       0.01      0.22      0.02         9

    accuracy                           0.77       945
   macro avg       0.50      0.50      0.44       945
weighted avg       0.98      0.77      0.86       945
08:14:37.715715: Validation Seq.Label F1: 0.36670221900238803; Log.Reg F1: 0.44442025040827443; train loss: 0.15592846274375916; Language: english 

08:14:37.715786: Evaluating Language: finnish
08:14:37.715842: ----------
08:14:44.606646: OBI: 
 [[1548   10  378]
 [   8    2   10]
 [  52    0   68]]
08:14:44.609955: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.80      0.87      1936
           1       0.17      0.10      0.12        20
           2       0.15      0.57      0.24       120

    accuracy                           0.78      2076
   macro avg       0.43      0.49      0.41      2076
weighted avg       0.91      0.78      0.83      2076
08:14:44.610009: ----------
08:14:44.610895: LR: 
 [[628 948]
 [  7  13]]
08:14:44.614148: LR: 
               precision    recall  f1-score   support

           0       0.99      0.40      0.57      1576
           1       0.01      0.65      0.03        20

    accuracy                           0.40      1596
   macro avg       0.50      0.52      0.30      1596
weighted avg       0.98      0.40      0.56      1596
08:14:44.615502: Validation Seq.Label F1: 0.41156675863222136; Log.Reg F1: 0.2972861574805981; train loss: 0.15592846274375916; Language: finnish 

08:14:44.615568: Evaluating Language: japanese
08:14:44.615621: ----------
08:14:47.740102: OBI: 
 [[901   4  93]
 [  0   1   0]
 [  0   0   3]]
08:14:47.742703: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.95       998
           1       0.20      1.00      0.33         1
           2       0.03      1.00      0.06         3

    accuracy                           0.90      1002
   macro avg       0.41      0.97      0.45      1002
weighted avg       1.00      0.90      0.95      1002
08:14:47.742755: ----------
08:14:47.743322: LR: 
 [[474 115]
 [  1   0]]
08:14:47.745746: LR: 
               precision    recall  f1-score   support

           0       1.00      0.80      0.89       589
           1       0.00      0.00      0.00         1

    accuracy                           0.80       590
   macro avg       0.50      0.40      0.45       590
weighted avg       1.00      0.80      0.89       590
08:14:47.746941: Validation Seq.Label F1: 0.44761995946830063; Log.Reg F1: 0.44548872180451127; train loss: 0.15592846274375916; Language: japanese 

08:14:47.747906: Combined F1 SeqLab: 0.40996802409729133; train loss: 0.15592846274375916
08:14:47.748864: Combined F1 LogReg: 0.40180783950272775; train loss: 0.15592846274375916 

08:14:47.749489: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 5/40
08:16:48.034275: Evaluating Language: english
08:16:48.034447: ----------
08:16:52.864438: OBI: 
 [[3851   10  411]
 [  10    0    5]
 [  71    0   61]]
08:16:52.869197: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.90      0.94      4272
           1       0.00      0.00      0.00        15
           2       0.13      0.46      0.20       132

    accuracy                           0.89      4419
   macro avg       0.37      0.45      0.38      4419
weighted avg       0.95      0.89      0.91      4419
08:16:52.869250: ----------
08:16:52.869930: LR: 
 [[539 391]
 [  9   6]]
08:16:52.872641: LR: 
               precision    recall  f1-score   support

           0       0.98      0.58      0.73       930
           1       0.02      0.40      0.03        15

    accuracy                           0.58       945
   macro avg       0.50      0.49      0.38       945
weighted avg       0.97      0.58      0.72       945
08:16:52.874097: Validation Seq.Label F1: 0.379712914548739; Log.Reg F1: 0.3792451095024765; train loss: 0.13203012943267822; Language: english 

08:16:52.874165: Evaluating Language: finnish
08:16:52.874216: ----------
08:16:59.937326: OBI: 
 [[3671   20  408]
 [   9    3   13]
 [ 106    1  121]]
08:16:59.942135: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.90      0.93      4099
           1       0.12      0.12      0.12        25
           2       0.22      0.53      0.31       228

    accuracy                           0.87      4352
   macro avg       0.44      0.52      0.46      4352
weighted avg       0.93      0.87      0.89      4352
08:16:59.942190: ----------
08:16:59.943056: LR: 
 [[1491   80]
 [  19    6]]
08:16:59.946245: LR: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      1571
           1       0.07      0.24      0.11        25

    accuracy                           0.94      1596
   macro avg       0.53      0.59      0.54      1596
weighted avg       0.97      0.94      0.95      1596
08:16:59.947599: Validation Seq.Label F1: 0.4559565868198896; Log.Reg F1: 0.5379878417853101; train loss: 0.13203012943267822; Language: finnish 

08:16:59.947672: Evaluating Language: japanese
08:16:59.947724: ----------
08:17:03.171003: OBI: 
 [[1869   16  209]
 [   0    1    0]
 [   0    0    9]]
08:17:03.174248: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94      2094
           1       0.06      1.00      0.11         1
           2       0.04      1.00      0.08         9

    accuracy                           0.89      2104
   macro avg       0.37      0.96      0.38      2104
weighted avg       1.00      0.89      0.94      2104
08:17:03.174298: ----------
08:17:03.174865: LR: 
 [[494  95]
 [  0   1]]
08:17:03.177682: LR: 
               precision    recall  f1-score   support

           0       1.00      0.84      0.91       589
           1       0.01      1.00      0.02         1

    accuracy                           0.84       590
   macro avg       0.51      0.92      0.47       590
weighted avg       1.00      0.84      0.91       590
08:17:03.178976: Validation Seq.Label F1: 0.37787703165687403; Log.Reg F1: 0.46644962922770844; train loss: 0.13203012943267822; Language: japanese 

08:17:03.180037: Combined F1 SeqLab: 0.40614831346580427; train loss: 0.13203012943267822
08:17:03.181163: Combined F1 LogReg: 0.46577284434833965; train loss: 0.13203012943267822 

08:17:03.186298: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 6/40
08:19:03.590185: Evaluating Language: english
08:19:03.590337: ----------
08:19:08.383843: OBI: 
 [[3370   15  105]
 [  12    1    6]
 [ 148    4   20]]
08:19:08.388105: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.97      0.96      3490
           1       0.05      0.05      0.05        19
           2       0.15      0.12      0.13       172

    accuracy                           0.92      3681
   macro avg       0.39      0.38      0.38      3681
weighted avg       0.91      0.92      0.92      3681
08:19:08.388157: ----------
08:19:08.388836: LR: 
 [[813 113]
 [ 16   3]]
08:19:08.391510: LR: 
               precision    recall  f1-score   support

           0       0.98      0.88      0.93       926
           1       0.03      0.16      0.04        19

    accuracy                           0.86       945
   macro avg       0.50      0.52      0.49       945
weighted avg       0.96      0.86      0.91       945
08:19:08.393007: Validation Seq.Label F1: 0.3811364042387145; Log.Reg F1: 0.48547008547008547; train loss: 0.11398907005786896; Language: english 

08:19:08.393075: Evaluating Language: finnish
08:19:08.393131: ----------
08:19:15.348422: OBI: 
 [[3231   27  143]
 [  12    3    4]
 [ 167    3   46]]
08:19:15.352642: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.95      0.95      3401
           1       0.09      0.16      0.12        19
           2       0.24      0.21      0.22       216

    accuracy                           0.90      3636
   macro avg       0.43      0.44      0.43      3636
weighted avg       0.90      0.90      0.90      3636
08:19:15.352692: ----------
08:19:15.353564: LR: 
 [[1481   96]
 [  15    4]]
08:19:15.356724: LR: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      1577
           1       0.04      0.21      0.07        19

    accuracy                           0.93      1596
   macro avg       0.51      0.57      0.52      1596
weighted avg       0.98      0.93      0.95      1596
08:19:15.358094: Validation Seq.Label F1: 0.4296942835164301; Log.Reg F1: 0.5155529182060068; train loss: 0.11398907005786896; Language: finnish 

08:19:15.358161: Evaluating Language: japanese
08:19:15.358211: ----------
08:19:18.461214: OBI: 
 [[615   8  24]
 [  0   0   0]
 [  9   0   0]]
08:19:18.463705: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97       647
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         9

    accuracy                           0.94       656
   macro avg       0.33      0.32      0.32       656
weighted avg       0.97      0.94      0.95       656
08:19:18.466609: ----------
08:19:18.467248: LR: 
 [[499  91]
 [  0   0]]
08:19:18.470015: LR: 
               precision    recall  f1-score   support

           0       1.00      0.85      0.92       590
           1       0.00      0.00      0.00         0

    accuracy                           0.85       590
   macro avg       0.50      0.42      0.46       590
weighted avg       1.00      0.85      0.92       590
08:19:18.471321: Validation Seq.Label F1: 0.32258064516129037; Log.Reg F1: 0.45821854912764004; train loss: 0.11398907005786896; Language: japanese 

08:19:18.472300: Combined F1 SeqLab: 0.38033336629654657; train loss: 0.11398907005786896
08:19:18.473275: Combined F1 LogReg: 0.48697715693233534; train loss: 0.11398907005786896 

08:19:18.475740: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 7/40
08:21:16.432609: Evaluating Language: english
08:21:16.432746: ----------
08:21:21.444393: OBI: 
 [[4010   19  227]
 [  15    1    7]
 [ 131    1   28]]
08:21:21.449120: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.94      0.95      4256
           1       0.05      0.04      0.05        23
           2       0.11      0.17      0.13       160

    accuracy                           0.91      4439
   macro avg       0.37      0.39      0.38      4439
weighted avg       0.93      0.91      0.92      4439
08:21:21.449173: ----------
08:21:21.449849: LR: 
 [[889  33]
 [ 23   0]]
08:21:21.452514: LR: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.97       922
           1       0.00      0.00      0.00        23

    accuracy                           0.94       945
   macro avg       0.49      0.48      0.48       945
weighted avg       0.95      0.94      0.95       945
08:21:21.454054: Validation Seq.Label F1: 0.3771852907177528; Log.Reg F1: 0.4847328244274809; train loss: 0.07916943728923798; Language: english 

08:21:21.454120: Evaluating Language: finnish
08:21:21.454173: ----------
08:21:28.543920: OBI: 
 [[4082   27  229]
 [   9    3    6]
 [ 203    0   49]]
08:21:28.548758: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.94      0.95      4338
           1       0.10      0.17      0.12        18
           2       0.17      0.19      0.18       252

    accuracy                           0.90      4608
   macro avg       0.41      0.43      0.42      4608
weighted avg       0.90      0.90      0.90      4608
08:21:28.548813: ----------
08:21:28.549685: LR: 
 [[1421  157]
 [  13    5]]
08:21:28.552837: LR: 
               precision    recall  f1-score   support

           0       0.99      0.90      0.94      1578
           1       0.03      0.28      0.06        18

    accuracy                           0.89      1596
   macro avg       0.51      0.59      0.50      1596
weighted avg       0.98      0.89      0.93      1596
08:21:28.554147: Validation Seq.Label F1: 0.4178729844752143; Log.Reg F1: 0.4995573262505534; train loss: 0.07916943728923798; Language: finnish 

08:21:28.554216: Evaluating Language: japanese
08:21:28.554266: ----------
08:21:31.747992: OBI: 
 [[1528    7   23]
 [   0    0    0]
 [   0    0    0]]
08:21:31.751282: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99      1558
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.98      1558
   macro avg       0.33      0.33      0.33      1558
weighted avg       1.00      0.98      0.99      1558
08:21:31.751337: ----------
08:21:31.751888: LR: 
 [[511  79]
 [  0   0]]
08:21:31.754429: LR: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93       590
           1       0.00      0.00      0.00         0

    accuracy                           0.87       590
   macro avg       0.50      0.43      0.46       590
weighted avg       1.00      0.87      0.93       590
08:21:31.755644: Validation Seq.Label F1: 0.33009289263339814; Log.Reg F1: 0.4641235240690282; train loss: 0.07916943728923798; Language: japanese 

08:21:31.756615: Combined F1 SeqLab: 0.37676159236982676; train loss: 0.07916943728923798
08:21:31.757770: Combined F1 LogReg: 0.48302314605765306; train loss: 0.07916943728923798 

08:21:31.758362: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 8/40
08:23:31.754326: Evaluating Language: english
08:23:31.754460: ----------
08:23:36.615831: OBI: 
 [[3115   12   45]
 [  13    1    4]
 [ 104    0    5]]
08:23:36.619759: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.98      0.97      3172
           1       0.08      0.06      0.06        18
           2       0.09      0.05      0.06       109

    accuracy                           0.95      3299
   macro avg       0.38      0.36      0.37      3299
weighted avg       0.93      0.95      0.94      3299
08:23:36.619810: ----------
08:23:36.620476: LR: 
 [[889  38]
 [ 17   1]]
08:23:36.623116: LR: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97       927
           1       0.03      0.06      0.04        18

    accuracy                           0.94       945
   macro avg       0.50      0.51      0.50       945
weighted avg       0.96      0.94      0.95       945
08:23:36.624608: Validation Seq.Label F1: 0.36623176795260276; Log.Reg F1: 0.5025411318804376; train loss: 0.04906146973371506; Language: english 

08:23:36.624672: Evaluating Language: finnish
08:23:36.624722: ----------
08:23:43.620754: OBI: 
 [[2367   11   45]
 [  11    3    6]
 [  78    2   25]]
08:23:43.624273: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.98      0.97      2423
           1       0.19      0.15      0.17        20
           2       0.33      0.24      0.28       105

    accuracy                           0.94      2548
   macro avg       0.49      0.45      0.47      2548
weighted avg       0.93      0.94      0.94      2548
08:23:43.624329: ----------
08:23:43.625179: LR: 
 [[1517   59]
 [  17    3]]
08:23:43.628320: LR: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98      1576
           1       0.05      0.15      0.07        20

    accuracy                           0.95      1596
   macro avg       0.52      0.56      0.52      1596
weighted avg       0.98      0.95      0.96      1596
08:23:43.629624: Validation Seq.Label F1: 0.4710635186114153; Log.Reg F1: 0.5243667163359736; train loss: 0.04906146973371506; Language: finnish 

08:23:43.629686: Evaluating Language: japanese
08:23:43.629736: ----------
08:23:46.731258: OBI: 
 [[768   7  23]
 [  0   0   0]
 [  0   0   2]]
08:23:46.733826: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98       798
           1       0.00      0.00      0.00         0
           2       0.08      1.00      0.15         2

    accuracy                           0.96       800
   macro avg       0.36      0.65      0.38       800
weighted avg       1.00      0.96      0.98       800
08:23:46.733877: ----------
08:23:46.734444: LR: 
 [[538  52]
 [  0   0]]
08:23:46.736985: LR: 
               precision    recall  f1-score   support

           0       1.00      0.91      0.95       590
           1       0.00      0.00      0.00         0

    accuracy                           0.91       590
   macro avg       0.50      0.46      0.48       590
weighted avg       1.00      0.91      0.95       590
08:23:46.738193: Validation Seq.Label F1: 0.3763303533418476; Log.Reg F1: 0.476950354609929; train loss: 0.04906146973371506; Language: japanese 

08:23:46.739158: Combined F1 SeqLab: 0.40728821951645666; train loss: 0.04906146973371506
08:23:46.740120: Combined F1 LogReg: 0.5016604705692154; train loss: 0.04906146973371506 

08:23:46.742660: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 9/40
08:25:46.558304: Evaluating Language: english
08:25:46.558440: ----------
08:25:51.276962: OBI: 
 [[3785   31  105]
 [  12    1    7]
 [ 107    2   20]]
08:25:51.281498: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.97      0.97      3921
           1       0.03      0.05      0.04        20
           2       0.15      0.16      0.15       129

    accuracy                           0.94      4070
   macro avg       0.38      0.39      0.39      4070
weighted avg       0.94      0.94      0.94      4070
08:25:51.281552: ----------
08:25:51.282226: LR: 
 [[793 132]
 [ 15   5]]
08:25:51.284934: LR: 
               precision    recall  f1-score   support

           0       0.98      0.86      0.92       925
           1       0.04      0.25      0.06        20

    accuracy                           0.84       945
   macro avg       0.51      0.55      0.49       945
weighted avg       0.96      0.84      0.90       945
08:25:51.286415: Validation Seq.Label F1: 0.38590196086431994; Log.Reg F1: 0.4894351314498256; train loss: 0.04405661299824715; Language: english 

08:25:51.286481: Evaluating Language: finnish
08:25:51.286533: ----------
08:25:58.149159: OBI: 
 [[3697   42   99]
 [  16    5    5]
 [ 140    3   37]]
08:25:58.154122: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.96      0.96      3838
           1       0.10      0.19      0.13        26
           2       0.26      0.21      0.23       180

    accuracy                           0.92      4044
   macro avg       0.44      0.45      0.44      4044
weighted avg       0.92      0.92      0.92      4044
08:25:58.154180: ----------
08:25:58.155214: LR: 
 [[1378  192]
 [  20    6]]
08:25:58.158814: LR: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93      1570
           1       0.03      0.23      0.05        26

    accuracy                           0.87      1596
   macro avg       0.51      0.55      0.49      1596
weighted avg       0.97      0.87      0.91      1596
08:25:58.160246: Validation Seq.Label F1: 0.4411639925226596; Log.Reg F1: 0.4910714285714286; train loss: 0.04405661299824715; Language: finnish 

08:25:58.160313: Evaluating Language: japanese
08:25:58.160365: ----------
08:26:01.414030: OBI: 
 [[1189    3   22]
 [   0    0    0]
 [   3    0    5]]
08:26:01.416846: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99      1214
           1       0.00      0.00      0.00         0
           2       0.19      0.62      0.29         8

    accuracy                           0.98      1222
   macro avg       0.39      0.53      0.42      1222
weighted avg       0.99      0.98      0.98      1222
08:26:01.416895: ----------
08:26:01.417460: LR: 
 [[491  99]
 [  0   0]]
08:26:01.420371: LR: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.91       590
           1       0.00      0.00      0.00         0

    accuracy                           0.83       590
   macro avg       0.50      0.42      0.45       590
weighted avg       1.00      0.83      0.91       590
08:26:01.421599: Validation Seq.Label F1: 0.4246922376598187; Log.Reg F1: 0.45420906567992597; train loss: 0.04405661299824715; Language: japanese 

08:26:01.422569: Combined F1 SeqLab: 0.4178953172051442; train loss: 0.04405661299824715
08:26:01.423539: Combined F1 LogReg: 0.47854075800023665; train loss: 0.04405661299824715 

08:26:01.424128: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 10/40
08:28:01.308232: Evaluating Language: english
08:28:01.308378: ----------
08:28:06.125230: OBI: 
 [[3873   27   43]
 [  10    1    2]
 [  78    1    9]]
08:28:06.129709: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.98      0.98      3943
           1       0.03      0.08      0.05        13
           2       0.17      0.10      0.13        88

    accuracy                           0.96      4044
   macro avg       0.39      0.39      0.38      4044
weighted avg       0.96      0.96      0.96      4044
08:28:06.129761: ----------
08:28:06.130435: LR: 
 [[910  22]
 [ 13   0]]
08:28:06.133084: LR: 
               precision    recall  f1-score   support

           0       0.99      0.98      0.98       932
           1       0.00      0.00      0.00        13

    accuracy                           0.96       945
   macro avg       0.49      0.49      0.49       945
weighted avg       0.97      0.96      0.97       945
08:28:06.134577: Validation Seq.Label F1: 0.3847965774856064; Log.Reg F1: 0.49056603773584906; train loss: 0.06790008395910263; Language: english 

08:28:06.134640: Evaluating Language: finnish
08:28:06.134692: ----------
08:28:13.069413: OBI: 
 [[2782   30   16]
 [   8    1    2]
 [ 129    1    3]]
08:28:13.073163: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.98      0.97      2828
           1       0.03      0.09      0.05        11
           2       0.14      0.02      0.04       133

    accuracy                           0.94      2972
   macro avg       0.38      0.37      0.35      2972
weighted avg       0.91      0.94      0.92      2972
08:28:13.073212: ----------
08:28:13.074081: LR: 
 [[1339  246]
 [   8    3]]
08:28:13.077237: LR: 
               precision    recall  f1-score   support

           0       0.99      0.84      0.91      1585
           1       0.01      0.27      0.02        11

    accuracy                           0.84      1596
   macro avg       0.50      0.56      0.47      1596
weighted avg       0.99      0.84      0.91      1596
08:28:13.078604: Validation Seq.Label F1: 0.3512099887762013; Log.Reg F1: 0.4682233182915312; train loss: 0.06790008395910263; Language: finnish 

08:28:13.078664: Evaluating Language: japanese
08:28:13.078713: ----------
08:28:16.125090: OBI: 
 [[833   6   8]
 [  0   1   0]
 [ 10   0   6]]
08:28:16.127546: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.98      0.99       847
           1       0.14      1.00      0.25         1
           2       0.43      0.38      0.40        16

    accuracy                           0.97       864
   macro avg       0.52      0.79      0.55       864
weighted avg       0.98      0.97      0.97       864
08:28:16.127595: ----------
08:28:16.128148: LR: 
 [[503  86]
 [  0   1]]
08:28:16.130739: LR: 
               precision    recall  f1-score   support

           0       1.00      0.85      0.92       589
           1       0.01      1.00      0.02         1

    accuracy                           0.85       590
   macro avg       0.51      0.93      0.47       590
weighted avg       1.00      0.85      0.92       590
08:28:16.132116: Validation Seq.Label F1: 0.5452662721893491; Log.Reg F1: 0.47198634698634695; train loss: 0.06790008395910263; Language: japanese 

08:28:16.133090: Combined F1 SeqLab: 0.43540485751695707; train loss: 0.06790008395910263
08:28:16.134051: Combined F1 LogReg: 0.4770252351512442; train loss: 0.06790008395910263 

08:28:16.134646: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 11/40
08:30:18.963986: Evaluating Language: english
08:30:18.964114: ----------
08:30:23.777835: OBI: 
 [[2382   41  831]
 [   4    1    6]
 [  28    2   97]]
08:30:23.781982: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.73      0.84      3254
           1       0.02      0.09      0.04        11
           2       0.10      0.76      0.18       127

    accuracy                           0.73      3392
   macro avg       0.37      0.53      0.35      3392
weighted avg       0.95      0.73      0.81      3392
08:30:23.782032: ----------
08:30:23.782702: LR: 
 [[706 228]
 [  7   4]]
08:30:23.785390: LR: 
               precision    recall  f1-score   support

           0       0.99      0.76      0.86       934
           1       0.02      0.36      0.03        11

    accuracy                           0.75       945
   macro avg       0.50      0.56      0.45       945
weighted avg       0.98      0.75      0.85       945
08:30:23.786851: Validation Seq.Label F1: 0.353239374482965; Log.Reg F1: 0.4451190717128786; train loss: 0.19937364757061005; Language: english 

08:30:23.786917: Evaluating Language: finnish
08:30:23.786970: ----------
08:30:30.651007: OBI: 
 [[3641   78 1373]
 [   9   11    8]
 [ 154    4  158]]
08:30:30.656619: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.72      0.82      5092
           1       0.12      0.39      0.18        28
           2       0.10      0.50      0.17       316

    accuracy                           0.70      5436
   macro avg       0.39      0.54      0.39      5436
weighted avg       0.90      0.70      0.78      5436
08:30:30.656667: ----------
08:30:30.657540: LR: 
 [[1062  506]
 [  15   13]]
08:30:30.660756: LR: 
               precision    recall  f1-score   support

           0       0.99      0.68      0.80      1568
           1       0.03      0.46      0.05        28

    accuracy                           0.67      1596
   macro avg       0.51      0.57      0.43      1596
weighted avg       0.97      0.67      0.79      1596
08:30:30.662088: Validation Seq.Label F1: 0.39024624333858077; Log.Reg F1: 0.4252782836782864; train loss: 0.19937364757061005; Language: finnish 

08:30:30.662147: Evaluating Language: japanese
08:30:30.662195: ----------
08:30:33.899651: OBI: 
 [[1110   19  169]
 [   0    0    0]
 [   0    0   10]]
08:30:33.902556: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92      1298
           1       0.00      0.00      0.00         0
           2       0.06      1.00      0.11        10

    accuracy                           0.86      1308
   macro avg       0.35      0.62      0.34      1308
weighted avg       0.99      0.86      0.92      1308
08:30:33.902604: ----------
08:30:33.903155: LR: 
 [[529  61]
 [  0   0]]
08:30:33.905706: LR: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.95       590
           1       0.00      0.00      0.00         0

    accuracy                           0.90       590
   macro avg       0.50      0.45      0.47       590
weighted avg       1.00      0.90      0.95       590
08:30:33.906911: Validation Seq.Label F1: 0.3425823387063697; Log.Reg F1: 0.4727435210008936; train loss: 0.19937364757061005; Language: japanese 

08:30:33.907868: Combined F1 SeqLab: 0.36259842108431606; train loss: 0.19937364757061005
08:30:33.908816: Combined F1 LogReg: 0.44813652801321097; train loss: 0.19937364757061005 

08:30:33.909423: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 12/40
08:32:33.435680: Evaluating Language: english
08:32:33.435810: ----------
08:32:38.390785: OBI: 
 [[2795   39  463]
 [   8    5   10]
 [  60    5   90]]
08:32:38.395256: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.85      0.91      3297
           1       0.10      0.22      0.14        23
           2       0.16      0.58      0.25       155

    accuracy                           0.83      3475
   macro avg       0.41      0.55      0.43      3475
weighted avg       0.93      0.83      0.87      3475
08:32:38.395305: ----------
08:32:38.395978: LR: 
 [[761 161]
 [ 18   5]]
08:32:38.398661: LR: 
               precision    recall  f1-score   support

           0       0.98      0.83      0.89       922
           1       0.03      0.22      0.05        23

    accuracy                           0.81       945
   macro avg       0.50      0.52      0.47       945
weighted avg       0.95      0.81      0.87       945
08:32:38.400154: Validation Seq.Label F1: 0.4323509333955016; Log.Reg F1: 0.4738389182833627; train loss: 0.16241195797920227; Language: english 

08:32:38.400218: Evaluating Language: finnish
08:32:38.400267: ----------
08:32:45.341511: OBI: 
 [[3440   71  513]
 [  10    3    8]
 [  90    6  135]]
08:32:45.346201: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.85      0.91      4024
           1       0.04      0.14      0.06        21
           2       0.21      0.58      0.30       231

    accuracy                           0.84      4276
   macro avg       0.41      0.53      0.42      4276
weighted avg       0.93      0.84      0.87      4276
08:32:45.346249: ----------
08:32:45.347130: LR: 
 [[736 839]
 [  8  13]]
08:32:45.350405: LR: 
               precision    recall  f1-score   support

           0       0.99      0.47      0.63      1575
           1       0.02      0.62      0.03        21

    accuracy                           0.47      1596
   macro avg       0.50      0.54      0.33      1596
weighted avg       0.98      0.47      0.63      1596
08:32:45.351775: Validation Seq.Label F1: 0.4244581463649797; Log.Reg F1: 0.3322693600897413; train loss: 0.16241195797920227; Language: finnish 

08:32:45.351836: Evaluating Language: japanese
08:32:45.351884: ----------
08:32:48.464247: OBI: 
 [[351   3  11]
 [  0   1   0]
 [  0   0   0]]
08:32:48.466576: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98       365
           1       0.25      1.00      0.40         1
           2       0.00      0.00      0.00         0

    accuracy                           0.96       366
   macro avg       0.42      0.65      0.46       366
weighted avg       1.00      0.96      0.98       366
08:32:48.466642: ----------
08:32:48.467329: LR: 
 [[523  66]
 [  1   0]]
08:32:48.470006: LR: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94       589
           1       0.00      0.00      0.00         1

    accuracy                           0.89       590
   macro avg       0.50      0.44      0.47       590
weighted avg       1.00      0.89      0.94       590
08:32:48.471281: Validation Seq.Label F1: 0.46014897579143393; Log.Reg F1: 0.4699011680143756; train loss: 0.16241195797920227; Language: japanese 

08:32:48.472280: Combined F1 SeqLab: 0.43925282300191754; train loss: 0.16241195797920227
08:32:48.473250: Combined F1 LogReg: 0.4304003391555618; train loss: 0.16241195797920227 

08:32:48.473856: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 13/40
08:34:48.915273: Evaluating Language: english
08:34:48.915698: ----------
08:34:53.743105: OBI: 
 [[2042   43  162]
 [   7    1    6]
 [  82    1   28]]
08:34:53.746961: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.91      0.93      2247
           1       0.02      0.07      0.03        14
           2       0.14      0.25      0.18       111

    accuracy                           0.87      2372
   macro avg       0.37      0.41      0.38      2372
weighted avg       0.91      0.87      0.89      2372
08:34:53.747010: ----------
08:34:53.747697: LR: 
 [[855  76]
 [ 13   1]]
08:34:53.750362: LR: 
               precision    recall  f1-score   support

           0       0.99      0.92      0.95       931
           1       0.01      0.07      0.02        14

    accuracy                           0.91       945
   macro avg       0.50      0.49      0.49       945
weighted avg       0.97      0.91      0.94       945
08:34:53.753217: Validation Seq.Label F1: 0.3830515923204841; Log.Reg F1: 0.48625304656433066; train loss: 0.0808500200510025; Language: english 

08:34:53.753289: Evaluating Language: finnish
08:34:53.753353: ----------
08:35:00.882938: OBI: 
 [[3453   75  233]
 [   8    8    4]
 [ 176    3   40]]
08:35:00.887481: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.92      0.93      3761
           1       0.09      0.40      0.15        20
           2       0.14      0.18      0.16       219

    accuracy                           0.88      4000
   macro avg       0.40      0.50      0.42      4000
weighted avg       0.90      0.88      0.89      4000
08:35:00.887531: ----------
08:35:00.888387: LR: 
 [[1405  171]
 [  15    5]]
08:35:00.891538: LR: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      1576
           1       0.03      0.25      0.05        20

    accuracy                           0.88      1596
   macro avg       0.51      0.57      0.49      1596
weighted avg       0.98      0.88      0.93      1596
08:35:00.893301: Validation Seq.Label F1: 0.4152430860473386; Log.Reg F1: 0.49446881556360855; train loss: 0.0808500200510025; Language: finnish 

08:35:00.893378: Evaluating Language: japanese
08:35:00.893428: ----------
08:35:03.866849: OBI: 
 [[333   2   1]
 [  0   0   0]
 [  0   0   0]]
08:35:03.869180: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.99      1.00       336
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.99       336
   macro avg       0.33      0.33      0.33       336
weighted avg       1.00      0.99      1.00       336
08:35:03.869230: ----------
08:35:03.869806: LR: 
 [[512  78]
 [  0   0]]
08:35:03.872357: LR: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93       590
           1       0.00      0.00      0.00         0

    accuracy                           0.87       590
   macro avg       0.50      0.43      0.46       590
weighted avg       1.00      0.87      0.93       590
08:35:03.873587: Validation Seq.Label F1: 0.33183856502242154; Log.Reg F1: 0.4646098003629764; train loss: 0.0808500200510025; Language: japanese 

08:35:03.874571: Combined F1 SeqLab: 0.3782733474290409; train loss: 0.0808500200510025
08:35:03.875550: Combined F1 LogReg: 0.4819418019675874; train loss: 0.0808500200510025 

08:35:03.876232: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 14/40
08:37:04.035615: Evaluating Language: english
08:37:04.035753: ----------
08:37:08.902820: OBI: 
 [[4497   60  463]
 [  10    1   11]
 [  95    2   98]]
08:37:08.908116: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.90      0.93      5020
           1       0.02      0.05      0.02        22
           2       0.17      0.50      0.26       195

    accuracy                           0.88      5237
   macro avg       0.39      0.48      0.40      5237
weighted avg       0.94      0.88      0.91      5237
08:37:08.908170: ----------
08:37:08.908850: LR: 
 [[729 194]
 [ 18   4]]
08:37:08.911520: LR: 
               precision    recall  f1-score   support

           0       0.98      0.79      0.87       923
           1       0.02      0.18      0.04        22

    accuracy                           0.78       945
   macro avg       0.50      0.49      0.45       945
weighted avg       0.95      0.78      0.85       945
08:37:08.913014: Validation Seq.Label F1: 0.4046011282091029; Log.Reg F1: 0.45470876428960266; train loss: 0.10620077699422836; Language: english 

08:37:08.913079: Evaluating Language: finnish
08:37:08.913128: ----------
08:37:16.052320: OBI: 
 [[3488   70  389]
 [   6    9    6]
 [ 119    2   79]]
08:37:16.056912: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.88      0.92      3947
           1       0.11      0.43      0.18        21
           2       0.17      0.40      0.23       200

    accuracy                           0.86      4168
   macro avg       0.41      0.57      0.44      4168
weighted avg       0.92      0.86      0.89      4168
08:37:16.056959: ----------
08:37:16.057829: LR: 
 [[1505   70]
 [  18    3]]
08:37:16.060955: LR: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97      1575
           1       0.04      0.14      0.06        21

    accuracy                           0.94      1596
   macro avg       0.51      0.55      0.52      1596
weighted avg       0.98      0.94      0.96      1596
08:37:16.062259: Validation Seq.Label F1: 0.44454775865726; Log.Reg F1: 0.5177121821902945; train loss: 0.10620077699422836; Language: finnish 

08:37:16.062324: Evaluating Language: japanese
08:37:16.062373: ----------
08:37:19.118209: OBI: 
 [[1018   15   53]
 [   0    1    0]
 [   8    0    1]]
08:37:19.121289: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      1086
           1       0.06      1.00      0.12         1
           2       0.02      0.11      0.03         9

    accuracy                           0.93      1096
   macro avg       0.36      0.68      0.37      1096
weighted avg       0.98      0.93      0.96      1096
08:37:19.121355: ----------
08:37:19.122023: LR: 
 [[513  76]
 [  0   1]]
08:37:19.124869: LR: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93       589
           1       0.01      1.00      0.03         1

    accuracy                           0.87       590
   macro avg       0.51      0.94      0.48       590
weighted avg       1.00      0.87      0.93       590
08:37:19.126266: Validation Seq.Label F1: 0.37113608069490417; Log.Reg F1: 0.47833775419982316; train loss: 0.10620077699422836; Language: japanese 

08:37:19.127411: Combined F1 SeqLab: 0.4078671242242367; train loss: 0.10620077699422836
08:37:19.128532: Combined F1 LogReg: 0.4842839976029714; train loss: 0.10620077699422836 

08:37:19.129233: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 15/40
08:39:19.925856: Evaluating Language: english
08:39:19.926827: ----------
08:39:24.875509: OBI: 
 [[3849   66  249]
 [   9    6    3]
 [ 128    3   39]]
08:39:24.880263: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.92      0.94      4164
           1       0.08      0.33      0.13        18
           2       0.13      0.23      0.17       170

    accuracy                           0.89      4352
   macro avg       0.39      0.50      0.41      4352
weighted avg       0.93      0.89      0.91      4352
08:39:24.880316: ----------
08:39:24.880973: LR: 
 [[859  68]
 [ 18   0]]
08:39:24.883624: LR: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95       927
           1       0.00      0.00      0.00        18

    accuracy                           0.91       945
   macro avg       0.49      0.46      0.48       945
weighted avg       0.96      0.91      0.93       945
08:39:24.885392: Validation Seq.Label F1: 0.4142565107760845; Log.Reg F1: 0.4761640798226164; train loss: 0.1013990044593811; Language: english 

08:39:24.885453: Evaluating Language: finnish
08:39:24.885500: ----------
08:39:31.991880: OBI: 
 [[2247   48  160]
 [   5    4    3]
 [ 113    3   37]]
08:39:31.995512: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.92      0.93      2455
           1       0.07      0.33      0.12        12
           2       0.18      0.24      0.21       153

    accuracy                           0.87      2620
   macro avg       0.40      0.50      0.42      2620
weighted avg       0.90      0.87      0.89      2620
08:39:31.995561: ----------
08:39:31.996425: LR: 
 [[1570   14]
 [  11    1]]
08:39:31.999504: LR: 
               precision    recall  f1-score   support

           0       0.99      0.99      0.99      1584
           1       0.07      0.08      0.07        12

    accuracy                           0.98      1596
   macro avg       0.53      0.54      0.53      1596
weighted avg       0.99      0.98      0.99      1596
08:39:32.001010: Validation Seq.Label F1: 0.4204666194493894; Log.Reg F1: 0.5330875899596279; train loss: 0.1013990044593811; Language: finnish 

08:39:32.001070: Evaluating Language: japanese
08:39:32.001116: ----------
08:39:35.173887: OBI: 
 [[1863    5   79]
 [   0    2    0]
 [   0    0   51]]
08:39:35.177076: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98      1947
           1       0.29      1.00      0.44         2
           2       0.39      1.00      0.56        51

    accuracy                           0.96      2000
   macro avg       0.56      0.99      0.66      2000
weighted avg       0.98      0.96      0.97      2000
08:39:35.177129: ----------
08:39:35.177728: LR: 
 [[510  78]
 [  1   1]]
08:39:35.180118: LR: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93       588
           1       0.01      0.50      0.02         2

    accuracy                           0.87       590
   macro avg       0.51      0.68      0.48       590
weighted avg       0.99      0.87      0.93       590
08:39:35.181572: Validation Seq.Label F1: 0.6619777039840554; Log.Reg F1: 0.4764039137712173; train loss: 0.1013990044593811; Language: japanese 

08:39:35.182592: Combined F1 SeqLab: 0.5120596043963292; train loss: 0.1013990044593811
08:39:36.097145: Combined F1 LogReg: 0.4959419651998329; train loss: 0.1013990044593811 

08:39:36.098765: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 16/40
08:41:36.813593: Evaluating Language: english
08:41:36.813969: ----------
08:41:41.614600: OBI: 
 [[3503   45  969]
 [   7    3    6]
 [  35    1  145]]
08:41:41.619688: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.78      0.87      4517
           1       0.06      0.19      0.09        16
           2       0.13      0.80      0.22       181

    accuracy                           0.77      4714
   macro avg       0.39      0.59      0.39      4714
weighted avg       0.95      0.77      0.84      4714
08:41:41.619737: ----------
08:41:41.620429: LR: 
 [[861  68]
 [ 15   1]]
08:41:41.623084: LR: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95       929
           1       0.01      0.06      0.02        16

    accuracy                           0.91       945
   macro avg       0.50      0.49      0.49       945
weighted avg       0.97      0.91      0.94       945
08:41:41.624581: Validation Seq.Label F1: 0.39474276078986953; Log.Reg F1: 0.48877301613166046; train loss: 0.05338092893362045; Language: english 

08:41:41.624653: Evaluating Language: finnish
08:41:41.624703: ----------
08:41:48.603166: OBI: 
 [[3093   46  709]
 [   8   10    7]
 [  96    4  123]]
08:41:48.607732: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.80      0.88      3848
           1       0.17      0.40      0.24        25
           2       0.15      0.55      0.23       223

    accuracy                           0.79      4096
   macro avg       0.43      0.59      0.45      4096
weighted avg       0.92      0.79      0.84      4096
08:41:48.607779: ----------
08:41:48.608632: LR: 
 [[1457  114]
 [  24    1]]
08:41:48.611791: LR: 
               precision    recall  f1-score   support

           0       0.98      0.93      0.95      1571
           1       0.01      0.04      0.01        25

    accuracy                           0.91      1596
   macro avg       0.50      0.48      0.48      1596
weighted avg       0.97      0.91      0.94      1596
08:41:48.613131: Validation Seq.Label F1: 0.44833402953351126; Log.Reg F1: 0.4845347313237221; train loss: 0.05338092893362045; Language: finnish 

08:41:48.613194: Evaluating Language: japanese
08:41:48.613242: ----------
08:41:51.796083: OBI: 
 [[1439   13   99]
 [   0    2    0]
 [   0    0   11]]
08:41:51.798961: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96      1551
           1       0.13      1.00      0.24         2
           2       0.10      1.00      0.18        11

    accuracy                           0.93      1564
   macro avg       0.41      0.98      0.46      1564
weighted avg       0.99      0.93      0.96      1564
08:41:51.799007: ----------
08:41:51.799578: LR: 
 [[503  85]
 [  0   2]]
08:41:51.801973: LR: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92       588
           1       0.02      1.00      0.04         2

    accuracy                           0.86       590
   macro avg       0.51      0.93      0.48       590
weighted avg       1.00      0.86      0.92       590
08:41:51.803226: Validation Seq.Label F1: 0.4598847018284358; Log.Reg F1: 0.4835168230362826; train loss: 0.05338092893362045; Language: japanese 

08:41:51.804195: Combined F1 SeqLab: 0.4352467454251641; train loss: 0.05338092893362045
08:41:51.805167: Combined F1 LogReg: 0.48561352442605765; train loss: 0.05338092893362045 

08:41:51.805785: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 17/40
08:43:51.743889: Evaluating Language: english
08:43:51.744039: ----------
08:43:56.567421: OBI: 
 [[2321   11  109]
 [   7    1    3]
 [  80    1   34]]
08:43:56.570985: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.95      0.96      2441
           1       0.08      0.09      0.08        11
           2       0.23      0.30      0.26       115

    accuracy                           0.92      2567
   macro avg       0.42      0.45      0.43      2567
weighted avg       0.93      0.92      0.92      2567
08:43:56.571031: ----------
08:43:56.571698: LR: 
 [[895  39]
 [ 11   0]]
08:43:56.574740: LR: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.97       934
           1       0.00      0.00      0.00        11

    accuracy                           0.95       945
   macro avg       0.49      0.48      0.49       945
weighted avg       0.98      0.95      0.96       945
08:43:56.576145: Validation Seq.Label F1: 0.4337268391765942; Log.Reg F1: 0.4864130434782609; train loss: 0.04436042159795761; Language: english 

08:43:56.576209: Evaluating Language: finnish
08:43:56.576263: ----------
08:44:03.578457: OBI: 
 [[3695   29  192]
 [  19    4    3]
 [ 190    5   87]]
08:44:03.583060: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.94      0.95      3916
           1       0.11      0.15      0.12        26
           2       0.31      0.31      0.31       282

    accuracy                           0.90      4224
   macro avg       0.45      0.47      0.46      4224
weighted avg       0.90      0.90      0.90      4224
08:44:03.583106: ----------
08:44:03.583970: LR: 
 [[1254  316]
 [  19    7]]
08:44:03.587158: LR: 
               precision    recall  f1-score   support

           0       0.99      0.80      0.88      1570
           1       0.02      0.27      0.04        26

    accuracy                           0.79      1596
   macro avg       0.50      0.53      0.46      1596
weighted avg       0.97      0.79      0.87      1596
08:44:03.588484: Validation Seq.Label F1: 0.4595078086738859; Log.Reg F1: 0.46114066923535113; train loss: 0.04436042159795761; Language: finnish 

08:44:03.588546: Evaluating Language: japanese
08:44:03.588593: ----------
08:44:06.580199: OBI: 
 [[1610    5   18]
 [   0    3    0]
 [   0    0   16]]
08:44:06.583100: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.99      0.99      1633
           1       0.38      1.00      0.55         3
           2       0.47      1.00      0.64        16

    accuracy                           0.99      1652
   macro avg       0.62      1.00      0.73      1652
weighted avg       0.99      0.99      0.99      1652
08:44:06.583147: ----------
08:44:06.583701: LR: 
 [[528  59]
 [  1   2]]
08:44:06.586440: LR: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.95       587
           1       0.03      0.67      0.06         3

    accuracy                           0.90       590
   macro avg       0.52      0.78      0.50       590
weighted avg       0.99      0.90      0.94       590
08:44:06.587663: Validation Seq.Label F1: 0.7261207822909951; Log.Reg F1: 0.5043682795698925; train loss: 0.04436042159795761; Language: japanese 

08:44:06.588624: Combined F1 SeqLab: 0.5557330857312955; train loss: 0.04436042159795761
08:44:07.464512: Combined F1 LogReg: 0.4842987119278436; train loss: 0.04436042159795761 

08:44:07.465626: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 18/40
08:46:08.483368: Evaluating Language: english
08:46:08.483979: ----------
08:46:13.222205: OBI: 
 [[3167   19  266]
 [  11    3    2]
 [ 129    5   41]]
08:46:13.226588: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.92      0.94      3452
           1       0.11      0.19      0.14        16
           2       0.13      0.23      0.17       175

    accuracy                           0.88      3643
   macro avg       0.40      0.45      0.42      3643
weighted avg       0.91      0.88      0.90      3643
08:46:13.226635: ----------
08:46:13.227320: LR: 
 [[785 144]
 [ 12   4]]
08:46:13.230038: LR: 
               precision    recall  f1-score   support

           0       0.98      0.84      0.91       929
           1       0.03      0.25      0.05        16

    accuracy                           0.83       945
   macro avg       0.51      0.55      0.48       945
weighted avg       0.97      0.83      0.90       945
08:46:13.232263: Validation Seq.Label F1: 0.41535908239781577; Log.Reg F1: 0.4791990503914309; train loss: 0.036143798381090164; Language: english 

08:46:13.232341: Evaluating Language: finnish
08:46:13.232391: ----------
08:46:20.385526: OBI: 
 [[5356   51  270]
 [  23    3    6]
 [ 270    1   72]]
08:46:20.391384: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.94      0.95      5677
           1       0.05      0.09      0.07        32
           2       0.21      0.21      0.21       343

    accuracy                           0.90      6052
   macro avg       0.40      0.42      0.41      6052
weighted avg       0.90      0.90      0.90      6052
08:46:20.391439: ----------
08:46:20.392449: LR: 
 [[1340  224]
 [  16   16]]
08:46:20.395868: LR: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      1564
           1       0.07      0.50      0.12        32

    accuracy                           0.85      1596
   macro avg       0.53      0.68      0.52      1596
weighted avg       0.97      0.85      0.90      1596
08:46:20.397383: Validation Seq.Label F1: 0.4077158670030135; Log.Reg F1: 0.5177276390008058; train loss: 0.036143798381090164; Language: finnish 

08:46:20.397440: Evaluating Language: japanese
08:46:20.397488: ----------
08:46:23.508320: OBI: 
 [[422   4   4]
 [  0   0   0]
 [  0   0   0]]
08:46:23.510695: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99       430
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.98       430
   macro avg       0.33      0.33      0.33       430
weighted avg       1.00      0.98      0.99       430
08:46:23.510740: ----------
08:46:23.511304: LR: 
 [[484 106]
 [  0   0]]
08:46:23.513881: LR: 
               precision    recall  f1-score   support

           0       1.00      0.82      0.90       590
           1       0.00      0.00      0.00         0

    accuracy                           0.82       590
   macro avg       0.50      0.41      0.45       590
weighted avg       1.00      0.82      0.90       590
08:46:23.515160: Validation Seq.Label F1: 0.33020344287949915; Log.Reg F1: 0.45065176908752325; train loss: 0.036143798381090164; Language: japanese 

08:46:23.516134: Combined F1 SeqLab: 0.38634600607307484; train loss: 0.036143798381090164
08:46:23.517099: Combined F1 LogReg: 0.4833082712110744; train loss: 0.036143798381090164 

08:46:23.517756: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 19/40
08:48:25.579143: Evaluating Language: english
08:48:25.579265: ----------
08:48:30.474295: OBI: 
 [[2724   11   93]
 [   6    3    3]
 [  61    3   16]]
08:48:30.478777: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.96      0.97      2828
           1       0.18      0.25      0.21        12
           2       0.14      0.20      0.17        80

    accuracy                           0.94      2920
   macro avg       0.43      0.47      0.45      2920
weighted avg       0.95      0.94      0.94      2920
08:48:30.478832: ----------
08:48:30.479624: LR: 
 [[869  64]
 [ 12   0]]
08:48:30.482821: LR: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96       933
           1       0.00      0.00      0.00        12

    accuracy                           0.92       945
   macro avg       0.49      0.47      0.48       945
weighted avg       0.97      0.92      0.95       945
08:48:30.484321: Validation Seq.Label F1: 0.4477102523662533; Log.Reg F1: 0.4790518191841235; train loss: 0.030208049342036247; Language: english 

08:48:30.484402: Evaluating Language: finnish
08:48:30.484462: ----------
08:48:37.511469: OBI: 
 [[4428   36  159]
 [  24    2    5]
 [ 206    2   50]]
08:48:37.516496: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.96      0.95      4623
           1       0.05      0.06      0.06        31
           2       0.23      0.19      0.21       258

    accuracy                           0.91      4912
   macro avg       0.41      0.41      0.41      4912
weighted avg       0.91      0.91      0.91      4912
08:48:37.516543: ----------
08:48:37.517408: LR: 
 [[1375  190]
 [  23    8]]
08:48:37.520582: LR: 
               precision    recall  f1-score   support

           0       0.98      0.88      0.93      1565
           1       0.04      0.26      0.07        31

    accuracy                           0.87      1596
   macro avg       0.51      0.57      0.50      1596
weighted avg       0.97      0.87      0.91      1596
08:48:37.521964: Validation Seq.Label F1: 0.4074699852299915; Log.Reg F1: 0.4989911971078528; train loss: 0.030208049342036247; Language: finnish 

08:48:37.522022: Evaluating Language: japanese
08:48:37.522069: ----------
08:48:40.665695: OBI: 
 [[1387    1   10]
 [   0    2    0]
 [  11    0    9]]
08:48:40.668462: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.99      0.99      1398
           1       0.67      1.00      0.80         2
           2       0.47      0.45      0.46        20

    accuracy                           0.98      1420
   macro avg       0.71      0.81      0.75      1420
weighted avg       0.98      0.98      0.98      1420
08:48:40.668509: ----------
08:48:40.669060: LR: 
 [[520  68]
 [  0   2]]
08:48:40.671762: LR: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.94       588
           1       0.03      1.00      0.06         2

    accuracy                           0.88       590
   macro avg       0.51      0.94      0.50       590
weighted avg       1.00      0.88      0.94       590
08:48:40.673020: Validation Seq.Label F1: 0.7512233593778658; Log.Reg F1: 0.4970918572001604; train loss: 0.030208049342036247; Language: japanese 

08:48:40.673995: Combined F1 SeqLab: 0.5570196868490227; train loss: 0.030208049342036247
08:48:41.625694: Combined F1 LogReg: 0.4917937151385903; train loss: 0.030208049342036247 

08:48:41.626823: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 20/40
08:50:41.165956: Evaluating Language: english
08:50:41.166097: ----------
08:50:46.008334: OBI: 
 [[2280   22   81]
 [  10    2    1]
 [  88    4   29]]
08:50:46.011871: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.96      0.96      2383
           1       0.07      0.15      0.10        13
           2       0.26      0.24      0.25       121

    accuracy                           0.92      2517
   macro avg       0.43      0.45      0.44      2517
weighted avg       0.92      0.92      0.92      2517
08:50:46.011921: ----------
08:50:46.012589: LR: 
 [[833  99]
 [ 12   1]]
08:50:46.015264: LR: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94       932
           1       0.01      0.08      0.02        13

    accuracy                           0.88       945
   macro avg       0.50      0.49      0.48       945
weighted avg       0.97      0.88      0.92       945
08:50:46.016606: Validation Seq.Label F1: 0.4351143180618952; Log.Reg F1: 0.4776171433409196; train loss: 0.02431240864098072; Language: english 

08:50:46.016668: Evaluating Language: finnish
08:50:46.016716: ----------
08:50:53.038453: OBI: 
 [[2682   21   75]
 [   8    3    0]
 [ 147    5   27]]
08:50:53.042183: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.97      0.96      2778
           1       0.10      0.27      0.15        11
           2       0.26      0.15      0.19       179

    accuracy                           0.91      2968
   macro avg       0.44      0.46      0.43      2968
weighted avg       0.90      0.91      0.91      2968
08:50:53.042228: ----------
08:50:53.043089: LR: 
 [[1410  175]
 [  10    1]]
08:50:53.046230: LR: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.94      1585
           1       0.01      0.09      0.01        11

    accuracy                           0.88      1596
   macro avg       0.50      0.49      0.47      1596
weighted avg       0.99      0.88      0.93      1596
08:50:53.047590: Validation Seq.Label F1: 0.4324897088695443; Log.Reg F1: 0.4745655636328045; train loss: 0.02431240864098072; Language: finnish 

08:50:53.047648: Evaluating Language: japanese
08:50:53.047695: ----------
08:50:56.202940: OBI: 
 [[471   7  25]
 [  0   1   0]
 [  1   0   5]]
08:50:56.205231: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.94      0.97       503
           1       0.12      1.00      0.22         1
           2       0.17      0.83      0.28         6

    accuracy                           0.94       510
   macro avg       0.43      0.92      0.49       510
weighted avg       0.99      0.94      0.96       510
08:50:56.205277: ----------
08:50:56.205834: LR: 
 [[514  75]
 [  0   1]]
08:50:56.208232: LR: 
               precision    recall  f1-score   support

           0       1.00      0.87      0.93       589
           1       0.01      1.00      0.03         1

    accuracy                           0.87       590
   macro avg       0.51      0.94      0.48       590
weighted avg       1.00      0.87      0.93       590
08:50:56.209695: Validation Seq.Label F1: 0.48871794871794866; Log.Reg F1: 0.47898882622364036; train loss: 0.02431240864098072; Language: japanese 

08:50:56.210887: Combined F1 SeqLab: 0.45284914760495787; train loss: 0.02431240864098072
08:50:56.211914: Combined F1 LogReg: 0.47706075973833867; train loss: 0.02431240864098072 

08:50:56.212523: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 21/40
08:52:56.755170: Evaluating Language: english
08:52:56.755299: ----------
08:53:01.579995: OBI: 
 [[4150   29  221]
 [  11    3    2]
 [ 125    2   83]]
08:53:01.584866: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.94      0.96      4400
           1       0.09      0.19      0.12        16
           2       0.27      0.40      0.32       210

    accuracy                           0.92      4626
   macro avg       0.44      0.51      0.47      4626
weighted avg       0.93      0.92      0.92      4626
08:53:01.584917: ----------
08:53:01.585589: LR: 
 [[797 132]
 [ 16   0]]
08:53:01.588241: LR: 
               precision    recall  f1-score   support

           0       0.98      0.86      0.92       929
           1       0.00      0.00      0.00        16

    accuracy                           0.84       945
   macro avg       0.49      0.43      0.46       945
weighted avg       0.96      0.84      0.90       945
08:53:01.589780: Validation Seq.Label F1: 0.46575536623429775; Log.Reg F1: 0.4575200918484501; train loss: 0.038367170840501785; Language: english 

08:53:01.589841: Evaluating Language: finnish
08:53:01.589888: ----------
08:53:08.625342: OBI: 
 [[4922   36  168]
 [  16    6    0]
 [ 142    2   60]]
08:53:08.630597: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.96      5126
           1       0.14      0.27      0.18        22
           2       0.26      0.29      0.28       204

    accuracy                           0.93      5352
   macro avg       0.46      0.51      0.47      5352
weighted avg       0.94      0.93      0.94      5352
08:53:08.630644: ----------
08:53:08.631494: LR: 
 [[1545   29]
 [  21    1]]
08:53:08.634624: LR: 
               precision    recall  f1-score   support

           0       0.99      0.98      0.98      1574
           1       0.03      0.05      0.04        22

    accuracy                           0.97      1596
   macro avg       0.51      0.51      0.51      1596
weighted avg       0.97      0.97      0.97      1596
08:53:08.636025: Validation Seq.Label F1: 0.47470887594344385; Log.Reg F1: 0.5112689857912788; train loss: 0.038367170840501785; Language: finnish 

08:53:08.636083: Evaluating Language: japanese
08:53:08.636129: ----------
08:53:11.686172: OBI: 
 [[940   1  10]
 [  0   0   0]
 [  1   0   4]]
08:53:11.688842: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.99      0.99       951
           1       0.00      0.00      0.00         0
           2       0.29      0.80      0.42         5

    accuracy                           0.99       956
   macro avg       0.43      0.60      0.47       956
weighted avg       1.00      0.99      0.99       956
08:53:11.688888: ----------
08:53:11.689447: LR: 
 [[492  98]
 [  0   0]]
08:53:11.692007: LR: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.91       590
           1       0.00      0.00      0.00         0

    accuracy                           0.83       590
   macro avg       0.50      0.42      0.45       590
weighted avg       1.00      0.83      0.91       590
08:53:11.693247: Validation Seq.Label F1: 0.47157004562145316; Log.Reg F1: 0.45471349353049906; train loss: 0.038367170840501785; Language: japanese 

08:53:11.694203: Combined F1 SeqLab: 0.4706927115089533; train loss: 0.038367170840501785
08:53:11.695143: Combined F1 LogReg: 0.47521397688331524; train loss: 0.038367170840501785 

08:53:11.695744: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 22/40
08:55:09.502283: Evaluating Language: english
08:55:09.502422: ----------
08:55:14.303438: OBI: 
 [[3576    8   23]
 [  16    2    1]
 [ 115    0    8]]
08:55:14.307708: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.99      0.98      3607
           1       0.20      0.11      0.14        19
           2       0.25      0.07      0.10       123

    accuracy                           0.96      3749
   macro avg       0.47      0.39      0.41      3749
weighted avg       0.94      0.96      0.94      3749
08:55:14.307754: ----------
08:55:14.308423: LR: 
 [[824 102]
 [ 16   3]]
08:55:14.311081: LR: 
               precision    recall  f1-score   support

           0       0.98      0.89      0.93       926
           1       0.03      0.16      0.05        19

    accuracy                           0.88       945
   macro avg       0.50      0.52      0.49       945
weighted avg       0.96      0.88      0.92       945
08:55:14.312583: Validation Seq.Label F1: 0.4063358460757449; Log.Reg F1: 0.49078471486501296; train loss: 0.028066813945770264; Language: english 

08:55:14.312646: Evaluating Language: finnish
08:55:14.312692: ----------
08:55:21.451392: OBI: 
 [[2851   12   13]
 [  14    4    0]
 [ 162    0   16]]
08:55:21.455219: OBI: 
               precision    recall  f1-score   support

           0       0.94      0.99      0.97      2876
           1       0.25      0.22      0.24        18
           2       0.55      0.09      0.15       178

    accuracy                           0.93      3072
   macro avg       0.58      0.43      0.45      3072
weighted avg       0.92      0.93      0.91      3072
08:55:21.455265: ----------
08:55:21.456129: LR: 
 [[1472  106]
 [  14    4]]
08:55:21.459302: LR: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      1578
           1       0.04      0.22      0.06        18

    accuracy                           0.92      1596
   macro avg       0.51      0.58      0.51      1596
weighted avg       0.98      0.92      0.95      1596
08:55:21.460695: Validation Seq.Label F1: 0.4519443356074606; Log.Reg F1: 0.5116677545691906; train loss: 0.028066813945770264; Language: finnish 

08:55:21.460754: Evaluating Language: japanese
08:55:21.460807: ----------
08:55:24.629984: OBI: 
 [[1191    1    7]
 [   0    2    0]
 [  30    0    3]]
08:55:24.632656: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.99      0.98      1199
           1       0.67      1.00      0.80         2
           2       0.30      0.09      0.14        33

    accuracy                           0.97      1234
   macro avg       0.65      0.69      0.64      1234
weighted avg       0.96      0.97      0.96      1234
08:55:24.632702: ----------
08:55:24.633253: LR: 
 [[502  86]
 [  2   0]]
08:55:24.635652: LR: 
               precision    recall  f1-score   support

           0       1.00      0.85      0.92       588
           1       0.00      0.00      0.00         2

    accuracy                           0.85       590
   macro avg       0.50      0.43      0.46       590
weighted avg       0.99      0.85      0.92       590
08:55:24.636868: Validation Seq.Label F1: 0.6412774681273625; Log.Reg F1: 0.4597069597069597; train loss: 0.028066813945770264; Language: japanese 

08:55:24.637834: Combined F1 SeqLab: 0.5100977989306237; train loss: 0.028066813945770264
08:55:24.638796: Combined F1 LogReg: 0.4878538087767775; train loss: 0.028066813945770264 

08:55:24.639390: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 23/40
08:57:24.057103: Evaluating Language: english
08:57:24.057250: ----------
08:57:28.735356: OBI: 
 [[3878   16  112]
 [  11    0    4]
 [  80    0   19]]
08:57:28.739865: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.97      0.97      4006
           1       0.00      0.00      0.00        15
           2       0.14      0.19      0.16        99

    accuracy                           0.95      4120
   macro avg       0.37      0.39      0.38      4120
weighted avg       0.95      0.95      0.95      4120
08:57:28.739912: ----------
08:57:28.740581: LR: 
 [[819 111]
 [ 10   5]]
08:57:28.743247: LR: 
               precision    recall  f1-score   support

           0       0.99      0.88      0.93       930
           1       0.04      0.33      0.08        15

    accuracy                           0.87       945
   macro avg       0.52      0.61      0.50       945
weighted avg       0.97      0.87      0.92       945
08:57:28.744762: Validation Seq.Label F1: 0.37831078244871347; Log.Reg F1: 0.5037733965776877; train loss: 0.01726638898253441; Language: english 

08:57:28.744822: Evaluating Language: finnish
08:57:28.744869: ----------
08:57:35.742570: OBI: 
 [[3078    8   38]
 [  14    2    1]
 [ 151    0   28]]
08:57:35.746529: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.99      0.97      3124
           1       0.20      0.12      0.15        17
           2       0.42      0.16      0.23       179

    accuracy                           0.94      3320
   macro avg       0.52      0.42      0.45      3320
weighted avg       0.92      0.94      0.92      3320
08:57:35.746575: ----------
08:57:35.747423: LR: 
 [[1501   78]
 [  16    1]]
08:57:35.750552: LR: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      1579
           1       0.01      0.06      0.02        17

    accuracy                           0.94      1596
   macro avg       0.50      0.50      0.50      1596
weighted avg       0.98      0.94      0.96      1596
08:57:35.751898: Validation Seq.Label F1: 0.44755026612444365; Log.Reg F1: 0.4952357881136951; train loss: 0.01726638898253441; Language: finnish 

08:57:35.751956: Evaluating Language: japanese
08:57:35.752003: ----------
08:57:38.889645: OBI: 
 [[501   1   5]
 [  0   0   0]
 [  3   0   0]]
08:57:38.892034: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.99      0.99       507
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         3

    accuracy                           0.98       510
   macro avg       0.33      0.33      0.33       510
weighted avg       0.99      0.98      0.99       510
08:57:38.892081: ----------
08:57:38.892635: LR: 
 [[503  87]
 [  0   0]]
08:57:38.895182: LR: 
               precision    recall  f1-score   support

           0       1.00      0.85      0.92       590
           1       0.00      0.00      0.00         0

    accuracy                           0.85       590
   macro avg       0.50      0.43      0.46       590
weighted avg       1.00      0.85      0.92       590
08:57:38.896477: Validation Seq.Label F1: 0.3303659742828883; Log.Reg F1: 0.4602012808783166; train loss: 0.01726638898253441; Language: japanese 

08:57:38.897447: Combined F1 SeqLab: 0.388399264412666; train loss: 0.01726638898253441
08:57:38.898418: Combined F1 LogReg: 0.48676871299418856; train loss: 0.01726638898253441 

08:57:38.899008: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 24/40
08:59:40.628183: Evaluating Language: english
08:59:40.628325: ----------
08:59:45.265347: OBI: 
 [[3297   11   98]
 [  15    2    3]
 [ 127    2   29]]
08:59:45.269509: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.97      0.96      3406
           1       0.13      0.10      0.11        20
           2       0.22      0.18      0.20       158

    accuracy                           0.93      3584
   macro avg       0.44      0.42      0.43      3584
weighted avg       0.92      0.93      0.93      3584
08:59:45.269556: ----------
08:59:45.270208: LR: 
 [[737 188]
 [ 14   6]]
08:59:45.272877: LR: 
               precision    recall  f1-score   support

           0       0.98      0.80      0.88       925
           1       0.03      0.30      0.06        20

    accuracy                           0.79       945
   macro avg       0.51      0.55      0.47       945
weighted avg       0.96      0.79      0.86       945
08:59:45.274377: Validation Seq.Label F1: 0.42633516721354553; Log.Reg F1: 0.4677748533446346; train loss: 0.02135632373392582; Language: english 

08:59:45.274438: Evaluating Language: finnish
08:59:45.274483: ----------
08:59:52.337657: OBI: 
 [[2691   12   53]
 [  10    3    0]
 [ 144    1   14]]
08:59:52.341527: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.98      0.96      2756
           1       0.19      0.23      0.21        13
           2       0.21      0.09      0.12       159

    accuracy                           0.92      2928
   macro avg       0.45      0.43      0.43      2928
weighted avg       0.90      0.92      0.91      2928
08:59:52.341572: ----------
08:59:52.342433: LR: 
 [[1383  200]
 [  10    3]]
08:59:52.345601: LR: 
               precision    recall  f1-score   support

           0       0.99      0.87      0.93      1583
           1       0.01      0.23      0.03        13

    accuracy                           0.87      1596
   macro avg       0.50      0.55      0.48      1596
weighted avg       0.98      0.87      0.92      1596
08:59:52.346918: Validation Seq.Label F1: 0.4305633987827602; Log.Reg F1: 0.47860663082437277; train loss: 0.02135632373392582; Language: finnish 

08:59:52.346975: Evaluating Language: japanese
08:59:52.347022: ----------
08:59:55.480448: OBI: 
 [[1313    0   13]
 [   0    1    0]
 [   0    0    5]]
08:59:55.483191: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.99      1.00      1326
           1       1.00      1.00      1.00         1
           2       0.28      1.00      0.43         5

    accuracy                           0.99      1332
   macro avg       0.76      1.00      0.81      1332
weighted avg       1.00      0.99      0.99      1332
08:59:55.483237: ----------
08:59:55.483795: LR: 
 [[504  85]
 [  0   1]]
08:59:55.486183: LR: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92       589
           1       0.01      1.00      0.02         1

    accuracy                           0.86       590
   macro avg       0.51      0.93      0.47       590
weighted avg       1.00      0.86      0.92       590
08:59:55.487416: Validation Seq.Label F1: 0.809952166773756; Log.Reg F1: 0.4726104468351368; train loss: 0.02135632373392582; Language: japanese 

08:59:55.488365: Combined F1 SeqLab: 0.5840002932750024; train loss: 0.02135632373392582
08:59:56.419574: Combined F1 LogReg: 0.47301805989072604; train loss: 0.02135632373392582 

08:59:56.421149: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 25/40
09:01:55.542982: Evaluating Language: english
09:01:55.543142: ----------
09:02:00.401039: OBI: 
 [[5754   14   33]
 [  20    2    2]
 [ 145    2   16]]
09:02:00.406743: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.99      0.98      5801
           1       0.11      0.08      0.10        24
           2       0.31      0.10      0.15       163

    accuracy                           0.96      5988
   macro avg       0.47      0.39      0.41      5988
weighted avg       0.95      0.96      0.96      5988
09:02:00.406794: ----------
09:02:00.407489: LR: 
 [[828  93]
 [ 23   1]]
09:02:00.410198: LR: 
               precision    recall  f1-score   support

           0       0.97      0.90      0.93       921
           1       0.01      0.04      0.02        24

    accuracy                           0.88       945
   macro avg       0.49      0.47      0.48       945
weighted avg       0.95      0.88      0.91       945
09:02:00.411885: Validation Seq.Label F1: 0.408894022772368; Log.Reg F1: 0.47574319929601716; train loss: 0.019214019179344177; Language: english 

09:02:00.411959: Evaluating Language: finnish
09:02:00.412006: ----------
09:02:07.401395: OBI: 
 [[3454    7   26]
 [  12    2    0]
 [ 232    1    6]]
09:02:07.405658: OBI: 
               precision    recall  f1-score   support

           0       0.93      0.99      0.96      3487
           1       0.20      0.14      0.17        14
           2       0.19      0.03      0.04       239

    accuracy                           0.93      3740
   macro avg       0.44      0.39      0.39      3740
weighted avg       0.88      0.93      0.90      3740
09:02:07.405705: ----------
09:02:07.406554: LR: 
 [[1508   74]
 [  13    1]]
09:02:07.409695: LR: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      1582
           1       0.01      0.07      0.02        14

    accuracy                           0.95      1596
   macro avg       0.50      0.51      0.50      1596
weighted avg       0.98      0.95      0.96      1596
09:02:07.411070: Validation Seq.Label F1: 0.39079818981905895; Log.Reg F1: 0.4972172634673947; train loss: 0.019214019179344177; Language: finnish 

09:02:07.411127: Evaluating Language: japanese
09:02:07.411174: ----------
09:02:10.528618: OBI: 
 [[1618    2    2]
 [   0    0    0]
 [   5    0    1]]
09:02:10.531689: OBI: 
               precision    recall  f1-score   support

           0       1.00      1.00      1.00      1622
           1       0.00      0.00      0.00         0
           2       0.33      0.17      0.22         6

    accuracy                           0.99      1628
   macro avg       0.44      0.39      0.41      1628
weighted avg       0.99      0.99      0.99      1628
09:02:10.531737: ----------
09:02:10.532300: LR: 
 [[528  62]
 [  0   0]]
09:02:10.534874: LR: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94       590
           1       0.00      0.00      0.00         0

    accuracy                           0.89       590
   macro avg       0.50      0.45      0.47       590
weighted avg       1.00      0.89      0.94       590
09:02:10.536182: Validation Seq.Label F1: 0.40648290817782345; Log.Reg F1: 0.47227191413237923; train loss: 0.019214019179344177; Language: japanese 

09:02:10.537167: Combined F1 SeqLab: 0.4021384096989178; train loss: 0.019214019179344177
09:02:10.538137: Combined F1 LogReg: 0.48187043889572495; train loss: 0.019214019179344177 

09:02:10.538932: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 26/40
09:04:09.153246: Evaluating Language: english
09:04:09.153400: ----------
09:04:13.895034: OBI: 
 [[2299    4   30]
 [   9    1    1]
 [  67    0   10]]
09:04:13.898491: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.99      0.98      2333
           1       0.20      0.09      0.13        11
           2       0.24      0.13      0.17        77

    accuracy                           0.95      2421
   macro avg       0.47      0.40      0.42      2421
weighted avg       0.94      0.95      0.95      2421
09:04:13.898536: ----------
09:04:13.899201: LR: 
 [[570 364]
 [  7   4]]
09:04:13.901903: LR: 
               precision    recall  f1-score   support

           0       0.99      0.61      0.75       934
           1       0.01      0.36      0.02        11

    accuracy                           0.61       945
   macro avg       0.50      0.49      0.39       945
weighted avg       0.98      0.61      0.75       945
09:04:13.903411: Validation Seq.Label F1: 0.42370901314747345; Log.Reg F1: 0.38778770982888894; train loss: 0.016058949753642082; Language: english 

09:04:13.903474: Evaluating Language: finnish
09:04:13.903521: ----------
09:04:20.985335: OBI: 
 [[2131    4   59]
 [   9    0    0]
 [ 108    0   25]]
09:04:20.988765: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.97      0.96      2194
           1       0.00      0.00      0.00         9
           2       0.30      0.19      0.23       133

    accuracy                           0.92      2336
   macro avg       0.42      0.39      0.40      2336
weighted avg       0.91      0.92      0.91      2336
09:04:20.988812: ----------
09:04:20.989672: LR: 
 [[1353  234]
 [   6    3]]
09:04:20.992865: LR: 
               precision    recall  f1-score   support

           0       1.00      0.85      0.92      1587
           1       0.01      0.33      0.02         9

    accuracy                           0.85      1596
   macro avg       0.50      0.59      0.47      1596
weighted avg       0.99      0.85      0.91      1596
09:04:20.994238: Validation Seq.Label F1: 0.3966308197619289; Log.Reg F1: 0.47146192439521145; train loss: 0.016058949753642082; Language: finnish 

09:04:20.994300: Evaluating Language: japanese
09:04:20.994353: ----------
09:04:24.015583: OBI: 
 [[1245    3   18]
 [   0    2    0]
 [   0    0   14]]
09:04:24.018272: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.98      0.99      1266
           1       0.40      1.00      0.57         2
           2       0.44      1.00      0.61        14

    accuracy                           0.98      1282
   macro avg       0.61      0.99      0.72      1282
weighted avg       0.99      0.98      0.99      1282
09:04:24.018324: ----------
09:04:24.018870: LR: 
 [[526  62]
 [  0   2]]
09:04:24.021256: LR: 
               precision    recall  f1-score   support

           0       1.00      0.89      0.94       588
           1       0.03      1.00      0.06         2

    accuracy                           0.89       590
   macro avg       0.52      0.95      0.50       590
weighted avg       1.00      0.89      0.94       590
09:04:24.022489: Validation Seq.Label F1: 0.723920340563632; Log.Reg F1: 0.502475382188129; train loss: 0.016058949753642082; Language: japanese 

09:04:24.023453: Combined F1 SeqLab: 0.5356945630018379; train loss: 0.016058949753642082
09:04:24.024408: Combined F1 LogReg: 0.45648554696137494; train loss: 0.016058949753642082 

09:04:24.025007: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 27/40
09:06:25.098227: Evaluating Language: english
09:06:25.098365: ----------
09:06:29.844470: OBI: 
 [[3174    6   90]
 [  10    1    2]
 [  77    0   24]]
09:06:29.848490: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.97      0.97      3270
           1       0.14      0.08      0.10        13
           2       0.21      0.24      0.22       101

    accuracy                           0.95      3384
   macro avg       0.44      0.43      0.43      3384
weighted avg       0.95      0.95      0.95      3384
09:06:29.848535: ----------
09:06:29.849195: LR: 
 [[825 107]
 [ 10   3]]
09:06:29.851871: LR: 
               precision    recall  f1-score   support

           0       0.99      0.89      0.93       932
           1       0.03      0.23      0.05        13

    accuracy                           0.88       945
   macro avg       0.51      0.56      0.49       945
weighted avg       0.97      0.88      0.92       945
09:06:29.853401: Validation Seq.Label F1: 0.43105931512735784; Log.Reg F1: 0.491283282951675; train loss: 0.03657558560371399; Language: english 

09:06:29.853463: Evaluating Language: finnish
09:06:29.853511: ----------
09:06:36.890598: OBI: 
 [[2964    8   60]
 [  13    2    0]
 [ 190    1   14]]
09:06:36.894531: OBI: 
               precision    recall  f1-score   support

           0       0.94      0.98      0.96      3032
           1       0.18      0.13      0.15        15
           2       0.19      0.07      0.10       205

    accuracy                           0.92      3252
   macro avg       0.44      0.39      0.40      3252
weighted avg       0.89      0.92      0.90      3252
09:06:36.894580: ----------
09:06:36.895446: LR: 
 [[1233  348]
 [  12    3]]
09:06:36.898650: LR: 
               precision    recall  f1-score   support

           0       0.99      0.78      0.87      1581
           1       0.01      0.20      0.02        15

    accuracy                           0.77      1596
   macro avg       0.50      0.49      0.44      1596
weighted avg       0.98      0.77      0.86      1596
09:06:36.900014: Validation Seq.Label F1: 0.40349594942687483; Log.Reg F1: 0.44450245379555187; train loss: 0.03657558560371399; Language: finnish 

09:06:36.900076: Evaluating Language: japanese
09:06:36.900123: ----------
09:06:40.046624: OBI: 
 [[126   1  17]
 [  0   0   0]
 [  0   0   0]]
09:06:40.048812: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.93       144
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.88       144
   macro avg       0.33      0.29      0.31       144
weighted avg       1.00      0.88      0.93       144
09:06:40.048859: ----------
09:06:40.049421: LR: 
 [[497  93]
 [  0   0]]
09:06:40.051961: LR: 
               precision    recall  f1-score   support

           0       1.00      0.84      0.91       590
           1       0.00      0.00      0.00         0

    accuracy                           0.84       590
   macro avg       0.50      0.42      0.46       590
weighted avg       1.00      0.84      0.91       590
09:06:40.053184: Validation Seq.Label F1: 0.3111111111111111; Log.Reg F1: 0.45722171113155474; train loss: 0.03657558560371399; Language: japanese 

09:06:40.054331: Combined F1 SeqLab: 0.3853185858562375; train loss: 0.03657558560371399
09:06:40.055460: Combined F1 LogReg: 0.4647556306519622; train loss: 0.03657558560371399 

09:06:40.056055: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 28/40
09:08:40.397393: Evaluating Language: english
09:08:40.397522: ----------
09:08:45.295980: OBI: 
 [[3189   21  198]
 [   7    1    4]
 [  56    3   23]]
09:08:45.300125: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      3408
           1       0.04      0.08      0.05        12
           2       0.10      0.28      0.15        82

    accuracy                           0.92      3502
   macro avg       0.37      0.43      0.39      3502
weighted avg       0.96      0.92      0.94      3502
09:08:45.300172: ----------
09:08:45.300856: LR: 
 [[666 267]
 [  8   4]]
09:08:45.303583: LR: 
               precision    recall  f1-score   support

           0       0.99      0.71      0.83       933
           1       0.01      0.33      0.03        12

    accuracy                           0.71       945
   macro avg       0.50      0.52      0.43       945
weighted avg       0.98      0.71      0.82       945
09:08:45.305094: Validation Seq.Label F1: 0.3871829484207334; Log.Reg F1: 0.4285711144484928; train loss: 0.025317048653960228; Language: english 

09:08:45.305156: Evaluating Language: finnish
09:08:45.305204: ----------
09:08:52.456986: OBI: 
 [[3777   31  262]
 [  19    7    4]
 [ 157    4   91]]
09:08:52.461690: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.93      0.94      4070
           1       0.17      0.23      0.19        30
           2       0.25      0.36      0.30       252

    accuracy                           0.89      4352
   macro avg       0.46      0.51      0.48      4352
weighted avg       0.91      0.89      0.90      4352
09:08:52.461739: ----------
09:08:52.462628: LR: 
 [[1096  470]
 [  15   15]]
09:08:52.466166: LR: 
               precision    recall  f1-score   support

           0       0.99      0.70      0.82      1566
           1       0.03      0.50      0.06        30

    accuracy                           0.70      1596
   macro avg       0.51      0.60      0.44      1596
weighted avg       0.97      0.70      0.80      1596
09:08:52.467695: Validation Seq.Label F1: 0.478279360949658; Log.Reg F1: 0.43853973619215825; train loss: 0.025317048653960228; Language: finnish 

09:08:52.467753: Evaluating Language: japanese
09:08:52.467800: ----------
09:08:55.505787: OBI: 
 [[728   2  28]
 [  0   0   0]
 [  6   0   0]]
09:08:55.508345: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.96      0.98       758
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         6

    accuracy                           0.95       764
   macro avg       0.33      0.32      0.33       764
weighted avg       0.98      0.95      0.97       764
09:08:55.508391: ----------
09:08:55.508953: LR: 
 [[472 118]
 [  0   0]]
09:08:55.511540: LR: 
               precision    recall  f1-score   support

           0       1.00      0.80      0.89       590
           1       0.00      0.00      0.00         0

    accuracy                           0.80       590
   macro avg       0.50      0.40      0.44       590
weighted avg       1.00      0.80      0.89       590
09:08:55.512784: Validation Seq.Label F1: 0.32529043789097406; Log.Reg F1: 0.4444444444444445; train loss: 0.025317048653960228; Language: japanese 

09:08:55.513780: Combined F1 SeqLab: 0.401860527895557; train loss: 0.025317048653960228
09:08:55.514748: Combined F1 LogReg: 0.43723417240522333; train loss: 0.025317048653960228 

09:08:55.515338: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 29/40
09:10:55.949395: Evaluating Language: english
09:10:55.949518: ----------
09:11:00.658635: OBI: 
 [[2607   29  174]
 [  10    3    3]
 [  81    4   40]]
09:11:00.662420: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.93      0.95      2810
           1       0.08      0.19      0.12        16
           2       0.18      0.32      0.23       125

    accuracy                           0.90      2951
   macro avg       0.41      0.48      0.43      2951
weighted avg       0.93      0.90      0.91      2951
09:11:00.662466: ----------
09:11:00.663129: LR: 
 [[475 454]
 [  7   9]]
09:11:00.666167: LR: 
               precision    recall  f1-score   support

           0       0.99      0.51      0.67       929
           1       0.02      0.56      0.04        16

    accuracy                           0.51       945
   macro avg       0.50      0.54      0.36       945
weighted avg       0.97      0.51      0.66       945
09:11:00.667623: Validation Seq.Label F1: 0.4319752792405011; Log.Reg F1: 0.35542982441863735; train loss: 0.041321996599435806; Language: english 

09:11:00.667684: Evaluating Language: finnish
09:11:00.667730: ----------
09:11:07.915769: OBI: 
 [[3008   37  187]
 [  13    6    1]
 [ 122    2   36]]
09:11:07.919836: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.93      0.94      3232
           1       0.13      0.30      0.18        20
           2       0.16      0.23      0.19       160

    accuracy                           0.89      3412
   macro avg       0.42      0.49      0.44      3412
weighted avg       0.91      0.89      0.90      3412
09:11:07.919881: ----------
09:11:07.920741: LR: 
 [[1313  263]
 [  16    4]]
09:11:07.923937: LR: 
               precision    recall  f1-score   support

           0       0.99      0.83      0.90      1576
           1       0.01      0.20      0.03        20

    accuracy                           0.83      1596
   macro avg       0.50      0.52      0.47      1596
weighted avg       0.98      0.83      0.89      1596
09:11:07.925293: Validation Seq.Label F1: 0.43860055304172946; Log.Reg F1: 0.4659166281852147; train loss: 0.041321996599435806; Language: finnish 

09:11:07.925357: Evaluating Language: japanese
09:11:07.925403: ----------
09:11:11.100929: OBI: 
 [[1182    9   40]
 [   0    1    0]
 [   0    1   11]]
09:11:11.103618: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98      1231
           1       0.09      1.00      0.17         1
           2       0.22      0.92      0.35        12

    accuracy                           0.96      1244
   macro avg       0.44      0.96      0.50      1244
weighted avg       0.99      0.96      0.97      1244
09:11:11.103664: ----------
09:11:11.104214: LR: 
 [[493  96]
 [  0   1]]
09:11:11.106632: LR: 
               precision    recall  f1-score   support

           0       1.00      0.84      0.91       589
           1       0.01      1.00      0.02         1

    accuracy                           0.84       590
   macro avg       0.51      0.92      0.47       590
weighted avg       1.00      0.84      0.91       590
09:11:11.107910: Validation Seq.Label F1: 0.49852211456024137; Log.Reg F1: 0.46584178958089706; train loss: 0.041321996599435806; Language: japanese 

09:11:11.108896: Combined F1 SeqLab: 0.4573464717654928; train loss: 0.041321996599435806
09:11:11.109877: Combined F1 LogReg: 0.4322103027561451; train loss: 0.041321996599435806 

09:11:11.110481: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 30/40
09:13:10.799952: Evaluating Language: english
09:13:10.800066: ----------
09:13:15.584381: OBI: 
 [[3821   23  170]
 [  15    0    4]
 [ 166    5   43]]
09:13:15.588973: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.95      0.95      4014
           1       0.00      0.00      0.00        19
           2       0.20      0.20      0.20       214

    accuracy                           0.91      4247
   macro avg       0.38      0.38      0.38      4247
weighted avg       0.91      0.91      0.91      4247
09:13:15.589018: ----------
09:13:15.589682: LR: 
 [[881  45]
 [ 19   0]]
09:13:15.592344: LR: 
               precision    recall  f1-score   support

           0       0.98      0.95      0.96       926
           1       0.00      0.00      0.00        19

    accuracy                           0.93       945
   macro avg       0.49      0.48      0.48       945
weighted avg       0.96      0.93      0.95       945
09:13:15.593822: Validation Seq.Label F1: 0.38429309208342793; Log.Reg F1: 0.48247535596933194; train loss: 0.035935815423727036; Language: english 

09:13:15.593881: Evaluating Language: finnish
09:13:15.593925: ----------
09:13:22.675358: OBI: 
 [[3294   24  119]
 [  17    4    1]
 [ 129    2   22]]
09:13:22.679558: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.96      0.96      3437
           1       0.13      0.18      0.15        22
           2       0.15      0.14      0.15       153

    accuracy                           0.92      3612
   macro avg       0.42      0.43      0.42      3612
weighted avg       0.92      0.92      0.92      3612
09:13:22.679601: ----------
09:13:22.680454: LR: 
 [[1492   82]
 [  20    2]]
09:13:22.683835: LR: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      1574
           1       0.02      0.09      0.04        22

    accuracy                           0.94      1596
   macro avg       0.51      0.52      0.50      1596
weighted avg       0.97      0.94      0.95      1596
09:13:22.685297: Validation Seq.Label F1: 0.4203248525955264; Log.Reg F1: 0.5023416769586324; train loss: 0.035935815423727036; Language: finnish 

09:13:22.685361: Evaluating Language: japanese
09:13:22.685405: ----------
09:13:25.881421: OBI: 
 [[763   2  19]
 [  0   0   0]
 [ 16   0   0]]
09:13:25.883973: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.97      0.98       784
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00        16

    accuracy                           0.95       800
   macro avg       0.33      0.32      0.33       800
weighted avg       0.96      0.95      0.96       800
09:13:25.884018: ----------
09:13:25.884573: LR: 
 [[507  83]
 [  0   0]]
09:13:25.887120: LR: 
               precision    recall  f1-score   support

           0       1.00      0.86      0.92       590
           1       0.00      0.00      0.00         0

    accuracy                           0.86       590
   macro avg       0.50      0.43      0.46       590
weighted avg       1.00      0.86      0.92       590
09:13:25.888388: Validation Seq.Label F1: 0.3254425250586479; Log.Reg F1: 0.4621695533272561; train loss: 0.035935815423727036; Language: japanese 

09:13:25.889394: Combined F1 SeqLab: 0.37871141143313936; train loss: 0.035935815423727036
09:13:25.890353: Combined F1 LogReg: 0.48260761340522457; train loss: 0.035935815423727036 

09:13:25.890945: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 31/40
09:15:27.199322: Evaluating Language: english
09:15:27.199444: ----------
09:15:31.935914: OBI: 
 [[3155   60  275]
 [   7    5    3]
 [ 102    4   37]]
09:15:31.940922: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.90      0.93      3490
           1       0.07      0.33      0.12        15
           2       0.12      0.26      0.16       143

    accuracy                           0.88      3648
   macro avg       0.39      0.50      0.40      3648
weighted avg       0.93      0.88      0.90      3648
09:15:31.940969: ----------
09:15:31.941640: LR: 
 [[803 127]
 [ 11   4]]
09:15:31.944287: LR: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92       930
           1       0.03      0.27      0.05        15

    accuracy                           0.85       945
   macro avg       0.51      0.57      0.49       945
weighted avg       0.97      0.85      0.91       945
09:15:31.945962: Validation Seq.Label F1: 0.40496028333673945; Log.Reg F1: 0.4878330400904864; train loss: 0.025814279913902283; Language: english 

09:15:31.946025: Evaluating Language: finnish
09:15:31.946070: ----------
09:15:38.987963: OBI: 
 [[2706   69  307]
 [   7    4    3]
 [ 135    1   32]]
09:15:38.991943: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.88      0.91      3082
           1       0.05      0.29      0.09        14
           2       0.09      0.19      0.13       168

    accuracy                           0.84      3264
   macro avg       0.37      0.45      0.38      3264
weighted avg       0.90      0.84      0.87      3264
09:15:38.991992: ----------
09:15:38.992861: LR: 
 [[1374  208]
 [   8    6]]
09:15:38.996050: LR: 
               precision    recall  f1-score   support

           0       0.99      0.87      0.93      1582
           1       0.03      0.43      0.05        14

    accuracy                           0.86      1596
   macro avg       0.51      0.65      0.49      1596
weighted avg       0.99      0.86      0.92      1596
09:15:38.997404: Validation Seq.Label F1: 0.376348947264531; Log.Reg F1: 0.48987854251012153; train loss: 0.025814279913902283; Language: finnish 

09:15:38.997460: Evaluating Language: japanese
09:15:38.997504: ----------
09:15:42.242064: OBI: 
 [[1091   14   92]
 [   0    1    0]
 [   1    0   11]]
09:15:42.244752: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.91      0.95      1197
           1       0.07      1.00      0.12         1
           2       0.11      0.92      0.19        12

    accuracy                           0.91      1210
   macro avg       0.39      0.94      0.42      1210
weighted avg       0.99      0.91      0.95      1210
09:15:42.244802: ----------
09:15:42.245363: LR: 
 [[477 112]
 [  0   1]]
09:15:42.247767: LR: 
               precision    recall  f1-score   support

           0       1.00      0.81      0.89       589
           1       0.01      1.00      0.02         1

    accuracy                           0.81       590
   macro avg       0.50      0.90      0.46       590
weighted avg       1.00      0.81      0.89       590
09:15:42.249014: Validation Seq.Label F1: 0.42318634806668315; Log.Reg F1: 0.4562390968039235; train loss: 0.025814279913902283; Language: japanese 

09:15:42.249992: Combined F1 SeqLab: 0.40196104553273526; train loss: 0.025814279913902283
09:15:42.250954: Combined F1 LogReg: 0.4782315251243296; train loss: 0.025814279913902283 

09:15:42.251572: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 32/40
09:17:42.043418: Evaluating Language: english
09:17:42.043526: ----------
09:17:47.011712: OBI: 
 [[4305   42  226]
 [  13    3    5]
 [  97    4   50]]
09:17:47.016703: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.94      0.96      4573
           1       0.06      0.14      0.09        21
           2       0.18      0.33      0.23       151

    accuracy                           0.92      4745
   macro avg       0.40      0.47      0.43      4745
weighted avg       0.95      0.92      0.93      4745
09:17:47.016750: ----------
09:17:47.017428: LR: 
 [[609 315]
 [  9  12]]
09:17:47.020124: LR: 
               precision    recall  f1-score   support

           0       0.99      0.66      0.79       924
           1       0.04      0.57      0.07        21

    accuracy                           0.66       945
   macro avg       0.51      0.62      0.43       945
weighted avg       0.96      0.66      0.77       945
09:17:47.021667: Validation Seq.Label F1: 0.4250465641431374; Log.Reg F1: 0.4294243928619348; train loss: 0.038945890963077545; Language: english 

09:17:47.021728: Evaluating Language: finnish
09:17:47.021772: ----------
09:17:54.020652: OBI: 
 [[3983   26  163]
 [  11    8    6]
 [ 193    9   37]]
09:17:54.025352: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.95      0.95      4172
           1       0.19      0.32      0.24        25
           2       0.18      0.15      0.17       239

    accuracy                           0.91      4436
   macro avg       0.44      0.48      0.45      4436
weighted avg       0.91      0.91      0.91      4436
09:17:54.025401: ----------
09:17:54.026275: LR: 
 [[1354  217]
 [  18    7]]
09:17:54.029485: LR: 
               precision    recall  f1-score   support

           0       0.99      0.86      0.92      1571
           1       0.03      0.28      0.06        25

    accuracy                           0.85      1596
   macro avg       0.51      0.57      0.49      1596
weighted avg       0.97      0.85      0.91      1596
09:17:54.030898: Validation Seq.Label F1: 0.45152368642453017; Log.Reg F1: 0.4881872034519321; train loss: 0.038945890963077545; Language: finnish 

09:17:54.030955: Evaluating Language: japanese
09:17:54.030999: ----------
09:17:57.085590: OBI: 
 [[536   3  11]
 [  0   0   0]
 [  0   0   0]]
09:17:57.088007: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.97      0.99       550
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         0

    accuracy                           0.97       550
   macro avg       0.33      0.32      0.33       550
weighted avg       1.00      0.97      0.99       550
09:17:57.088053: ----------
09:17:57.088610: LR: 
 [[517  73]
 [  0   0]]
09:17:57.091158: LR: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.93       590
           1       0.00      0.00      0.00         0

    accuracy                           0.88       590
   macro avg       0.50      0.44      0.47       590
weighted avg       1.00      0.88      0.93       590
09:17:57.092426: Validation Seq.Label F1: 0.32903621853898096; Log.Reg F1: 0.46702800361336944; train loss: 0.038945890963077545; Language: japanese 

09:17:57.093411: Combined F1 SeqLab: 0.40529950004193016; train loss: 0.038945890963077545
09:17:57.094378: Combined F1 LogReg: 0.4621858251678102; train loss: 0.038945890963077545 

09:17:57.094959: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 33/40
09:19:56.815363: Evaluating Language: english
09:19:56.817072: ----------
09:20:01.616703: OBI: 
 [[4053   23   62]
 [  14    3    5]
 [ 144    5   21]]
09:20:01.621335: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.98      0.97      4138
           1       0.10      0.14      0.11        22
           2       0.24      0.12      0.16       170

    accuracy                           0.94      4330
   macro avg       0.43      0.41      0.42      4330
weighted avg       0.93      0.94      0.93      4330
09:20:01.621382: ----------
09:20:01.622047: LR: 
 [[649 274]
 [ 12  10]]
09:20:01.624762: LR: 
               precision    recall  f1-score   support

           0       0.98      0.70      0.82       923
           1       0.04      0.45      0.07        22

    accuracy                           0.70       945
   macro avg       0.51      0.58      0.44       945
weighted avg       0.96      0.70      0.80       945
09:20:01.626249: Validation Seq.Label F1: 0.415630987591507; Log.Reg F1: 0.44240196078431376; train loss: 0.02871876023709774; Language: english 

09:20:01.626316: Evaluating Language: finnish
09:20:01.626367: ----------
09:20:08.624531: OBI: 
 [[4007   26   85]
 [  19    2    1]
 [ 206    2   12]]
09:20:08.629171: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.97      0.96      4118
           1       0.07      0.09      0.08        22
           2       0.12      0.05      0.08       220

    accuracy                           0.92      4360
   macro avg       0.38      0.37      0.37      4360
weighted avg       0.90      0.92      0.91      4360
09:20:08.629218: ----------
09:20:08.630088: LR: 
 [[1482   92]
 [  19    3]]
09:20:08.633241: LR: 
               precision    recall  f1-score   support

           0       0.99      0.94      0.96      1574
           1       0.03      0.14      0.05        22

    accuracy                           0.93      1596
   macro avg       0.51      0.54      0.51      1596
weighted avg       0.97      0.93      0.95      1596
09:20:08.634567: Validation Seq.Label F1: 0.3707184180260668; Log.Reg F1: 0.5075922451532208; train loss: 0.02871876023709774; Language: finnish 

09:20:08.634627: Evaluating Language: japanese
09:20:08.634672: ----------
09:20:11.594551: OBI: 
 [[236   1   2]
 [  0   0   0]
 [  1   0   0]]
09:20:11.596742: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.99      0.99       239
           1       0.00      0.00      0.00         0
           2       0.00      0.00      0.00         1

    accuracy                           0.98       240
   macro avg       0.33      0.33      0.33       240
weighted avg       0.99      0.98      0.99       240
09:20:11.596786: ----------
09:20:11.597333: LR: 
 [[520  70]
 [  0   0]]
09:20:11.599846: LR: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.94       590
           1       0.00      0.00      0.00         0

    accuracy                           0.88       590
   macro avg       0.50      0.44      0.47       590
weighted avg       1.00      0.88      0.94       590
09:20:11.601042: Validation Seq.Label F1: 0.33053221288515405; Log.Reg F1: 0.4684684684684685; train loss: 0.02871876023709774; Language: japanese 

09:20:11.601998: Combined F1 SeqLab: 0.37391300550832135; train loss: 0.02871876023709774
09:20:11.602951: Combined F1 LogReg: 0.47357930986431596; train loss: 0.02871876023709774 

09:20:11.603554: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 34/40
09:22:11.901605: Evaluating Language: english
09:22:11.901744: ----------
09:22:16.770522: OBI: 
 [[4472   18   86]
 [  10    2    5]
 [  96    0   42]]
09:22:16.775532: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.98      0.98      4576
           1       0.10      0.12      0.11        17
           2       0.32      0.30      0.31       138

    accuracy                           0.95      4731
   macro avg       0.46      0.47      0.47      4731
weighted avg       0.95      0.95      0.95      4731
09:22:16.775576: ----------
09:22:16.776252: LR: 
 [[824 104]
 [ 13   4]]
09:22:16.778915: LR: 
               precision    recall  f1-score   support

           0       0.98      0.89      0.93       928
           1       0.04      0.24      0.06        17

    accuracy                           0.88       945
   macro avg       0.51      0.56      0.50       945
weighted avg       0.97      0.88      0.92       945
09:22:16.781342: Validation Seq.Label F1: 0.46504347227600906; Log.Reg F1: 0.4988555240793201; train loss: 0.029327526688575745; Language: english 

09:22:16.781410: Evaluating Language: finnish
09:22:16.781454: ----------
09:22:23.845878: OBI: 
 [[3786   36  182]
 [  22    3    3]
 [ 203    2   79]]
09:22:23.850533: OBI: 
               precision    recall  f1-score   support

           0       0.94      0.95      0.94      4004
           1       0.07      0.11      0.09        28
           2       0.30      0.28      0.29       284

    accuracy                           0.90      4316
   macro avg       0.44      0.44      0.44      4316
weighted avg       0.90      0.90      0.90      4316
09:22:23.850579: ----------
09:22:23.851436: LR: 
 [[1519   49]
 [  27    1]]
09:22:23.854619: LR: 
               precision    recall  f1-score   support

           0       0.98      0.97      0.98      1568
           1       0.02      0.04      0.03        28

    accuracy                           0.95      1596
   macro avg       0.50      0.50      0.50      1596
weighted avg       0.97      0.95      0.96      1596
09:22:23.856224: Validation Seq.Label F1: 0.44000210781131505; Log.Reg F1: 0.5006175584210266; train loss: 0.029327526688575745; Language: finnish 

09:22:23.856303: Evaluating Language: japanese
09:22:23.856375: ----------
09:22:26.940199: OBI: 
 [[1422    5   24]
 [   0    2    0]
 [  36    0    7]]
09:22:26.943021: OBI: 
               precision    recall  f1-score   support

           0       0.98      0.98      0.98      1451
           1       0.29      1.00      0.44         2
           2       0.23      0.16      0.19        43

    accuracy                           0.96      1496
   macro avg       0.50      0.71      0.54      1496
weighted avg       0.95      0.96      0.95      1496
09:22:26.943066: ----------
09:22:26.943629: LR: 
 [[548  40]
 [  1   1]]
09:22:26.945997: LR: 
               precision    recall  f1-score   support

           0       1.00      0.93      0.96       588
           1       0.02      0.50      0.05         2

    accuracy                           0.93       590
   macro avg       0.51      0.72      0.51       590
weighted avg       0.99      0.93      0.96       590
09:22:26.947344: Validation Seq.Label F1: 0.5370963951232085; Log.Reg F1: 0.5052259106993108; train loss: 0.029327526688575745; Language: japanese 

09:22:26.948327: Combined F1 SeqLab: 0.4824727362381122; train loss: 0.029327526688575745
09:22:26.949289: Combined F1 LogReg: 0.501573522209799; train loss: 0.029327526688575745 

09:22:26.949896: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 35/40
09:24:27.679070: Evaluating Language: english
09:24:27.679235: ----------
09:24:32.470416: OBI: 
 [[3307   12   75]
 [   7    2    1]
 [  90    1   34]]
09:24:32.474564: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.97      0.97      3394
           1       0.13      0.20      0.16        10
           2       0.31      0.27      0.29       125

    accuracy                           0.95      3529
   macro avg       0.47      0.48      0.47      3529
weighted avg       0.95      0.95      0.95      3529
09:24:32.474610: ----------
09:24:32.475270: LR: 
 [[588 347]
 [  5   5]]
09:24:32.477962: LR: 
               precision    recall  f1-score   support

           0       0.99      0.63      0.77       935
           1       0.01      0.50      0.03        10

    accuracy                           0.63       945
   macro avg       0.50      0.56      0.40       945
weighted avg       0.98      0.63      0.76       945
09:24:32.479354: Validation Seq.Label F1: 0.4740983059264406; Log.Reg F1: 0.39862890862283423; train loss: 0.018506793305277824; Language: english 

09:24:32.479412: Evaluating Language: finnish
09:24:32.479456: ----------
09:24:39.537016: OBI: 
 [[3261   22  117]
 [   9    5    1]
 [ 159    3   39]]
09:24:39.541227: OBI: 
               precision    recall  f1-score   support

           0       0.95      0.96      0.96      3400
           1       0.17      0.33      0.22        15
           2       0.25      0.19      0.22       201

    accuracy                           0.91      3616
   macro avg       0.46      0.50      0.47      3616
weighted avg       0.91      0.91      0.91      3616
09:24:39.541277: ----------
09:24:39.542144: LR: 
 [[1341  240]
 [  10    5]]
09:24:39.545302: LR: 
               precision    recall  f1-score   support

           0       0.99      0.85      0.91      1581
           1       0.02      0.33      0.04        15

    accuracy                           0.84      1596
   macro avg       0.51      0.59      0.48      1596
weighted avg       0.98      0.84      0.91      1596
09:24:39.546702: Validation Seq.Label F1: 0.46504799322105733; Log.Reg F1: 0.4765977542239479; train loss: 0.018506793305277824; Language: finnish 

09:24:39.546760: Evaluating Language: japanese
09:24:39.546804: ----------
09:24:42.617710: OBI: 
 [[939   2   8]
 [  0   1   0]
 [  5   0  11]]
09:24:42.620215: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.99      0.99       949
           1       0.33      1.00      0.50         1
           2       0.58      0.69      0.63        16

    accuracy                           0.98       966
   macro avg       0.64      0.89      0.71       966
weighted avg       0.99      0.98      0.99       966
09:24:42.620259: ----------
09:24:42.620813: LR: 
 [[520  69]
 [  0   1]]
09:24:42.623201: LR: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.94       589
           1       0.01      1.00      0.03         1

    accuracy                           0.88       590
   macro avg       0.51      0.94      0.48       590
weighted avg       1.00      0.88      0.94       590
09:24:42.624499: Validation Seq.Label F1: 0.7068824994340049; Log.Reg F1: 0.48297539973837617; train loss: 0.018506793305277824; Language: japanese 

09:24:42.625473: Combined F1 SeqLab: 0.5599766982316673; train loss: 0.018506793305277824
09:24:42.626440: Combined F1 LogReg: 0.45435509713350375; train loss: 0.018506793305277824 

09:24:42.627021: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 36/40
09:26:43.214869: Evaluating Language: english
09:26:43.215022: ----------
09:26:47.998491: OBI: 
 [[2301   24 1287]
 [   6    1   13]
 [  15    3   99]]
09:26:48.002977: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.64      0.78      3612
           1       0.04      0.05      0.04        20
           2       0.07      0.85      0.13       117

    accuracy                           0.64      3749
   macro avg       0.37      0.51      0.32      3749
weighted avg       0.96      0.64      0.75      3749
09:26:48.003030: ----------
09:26:48.003709: LR: 
 [[832  93]
 [ 19   1]]
09:26:48.006396: LR: 
               precision    recall  f1-score   support

           0       0.98      0.90      0.94       925
           1       0.01      0.05      0.02        20

    accuracy                           0.88       945
   macro avg       0.49      0.47      0.48       945
weighted avg       0.96      0.88      0.92       945
09:26:48.009328: Validation Seq.Label F1: 0.31593478868550834; Log.Reg F1: 0.4772403982930299; train loss: 0.08162280172109604; Language: english 

09:26:48.009400: Evaluating Language: finnish
09:26:48.009449: ----------
09:26:55.036327: OBI: 
 [[2288   30 1293]
 [   3    3   14]
 [  31    2  144]]
09:26:55.040746: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.63      0.77      3611
           1       0.09      0.15      0.11        20
           2       0.10      0.81      0.18       177

    accuracy                           0.64      3808
   macro avg       0.39      0.53      0.35      3808
weighted avg       0.94      0.64      0.74      3808
09:26:55.040791: ----------
09:26:55.041642: LR: 
 [[1497   79]
 [  19    1]]
09:26:55.044806: LR: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      1576
           1       0.01      0.05      0.02        20

    accuracy                           0.94      1596
   macro avg       0.50      0.50      0.49      1596
weighted avg       0.98      0.94      0.96      1596
09:26:55.046257: Validation Seq.Label F1: 0.3524247904493985; Log.Reg F1: 0.4941526520051746; train loss: 0.08162280172109604; Language: finnish 

09:26:55.046320: Evaluating Language: japanese
09:26:55.046365: ----------
09:26:58.139665: OBI: 
 [[519   4 106]
 [  0   0   0]
 [  0   0   9]]
09:26:58.142158: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.90       629
           1       0.00      0.00      0.00         0
           2       0.08      1.00      0.15         9

    accuracy                           0.83       638
   macro avg       0.36      0.61      0.35       638
weighted avg       0.99      0.83      0.89       638
09:26:58.142203: ----------
09:26:58.142771: LR: 
 [[491  99]
 [  0   0]]
09:26:58.145326: LR: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.91       590
           1       0.00      0.00      0.00         0

    accuracy                           0.83       590
   macro avg       0.50      0.42      0.45       590
weighted avg       1.00      0.83      0.91       590
09:26:58.146591: Validation Seq.Label F1: 0.3497808249971901; Log.Reg F1: 0.45420906567992597; train loss: 0.08162280172109604; Language: japanese 

09:26:58.147588: Combined F1 SeqLab: 0.339786525709292; train loss: 0.08162280172109604
09:26:58.148601: Combined F1 LogReg: 0.47548260276357407; train loss: 0.08162280172109604 

09:26:58.149207: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 37/40
09:28:58.845897: Evaluating Language: english
09:28:58.846021: ----------
09:29:03.742999: OBI: 
 [[4478   11  141]
 [  17    2    2]
 [ 142    0   47]]
09:29:03.747964: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.97      0.97      4630
           1       0.15      0.10      0.12        21
           2       0.25      0.25      0.25       189

    accuracy                           0.94      4840
   macro avg       0.46      0.44      0.44      4840
weighted avg       0.93      0.94      0.93      4840
09:29:03.748011: ----------
09:29:03.748683: LR: 
 [[811 113]
 [ 18   3]]
09:29:03.751355: LR: 
               precision    recall  f1-score   support

           0       0.98      0.88      0.93       924
           1       0.03      0.14      0.04        21

    accuracy                           0.86       945
   macro avg       0.50      0.51      0.48       945
weighted avg       0.96      0.86      0.91       945
09:29:03.752751: Validation Seq.Label F1: 0.4440360743720127; Log.Reg F1: 0.4845332922497825; train loss: 0.04249551519751549; Language: english 

09:29:03.752810: Evaluating Language: finnish
09:29:03.752854: ----------
09:29:10.762449: OBI: 
 [[2304   10   83]
 [  16    2    2]
 [ 152    0   31]]
09:29:10.766012: OBI: 
               precision    recall  f1-score   support

           0       0.93      0.96      0.95      2397
           1       0.17      0.10      0.12        20
           2       0.27      0.17      0.21       183

    accuracy                           0.90      2600
   macro avg       0.46      0.41      0.43      2600
weighted avg       0.88      0.90      0.89      2600
09:29:10.766057: ----------
09:29:10.766915: LR: 
 [[1273  303]
 [  17    3]]
09:29:10.770101: LR: 
               precision    recall  f1-score   support

           0       0.99      0.81      0.89      1576
           1       0.01      0.15      0.02        20

    accuracy                           0.80      1596
   macro avg       0.50      0.48      0.45      1596
weighted avg       0.97      0.80      0.88      1596
09:29:10.771502: Validation Seq.Label F1: 0.4262511411008558; Log.Reg F1: 0.45337551749087035; train loss: 0.04249551519751549; Language: finnish 

09:29:10.771557: Evaluating Language: japanese
09:29:10.771602: ----------
09:29:13.954764: OBI: 
 [[1293    1   40]
 [   0    1    0]
 [   0    0    5]]
09:29:13.958020: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.97      0.98      1334
           1       0.50      1.00      0.67         1
           2       0.11      1.00      0.20         5

    accuracy                           0.97      1340
   macro avg       0.54      0.99      0.62      1340
weighted avg       1.00      0.97      0.98      1340
09:29:13.958072: ----------
09:29:13.958732: LR: 
 [[467 122]
 [  0   1]]
09:29:13.961629: LR: 
               precision    recall  f1-score   support

           0       1.00      0.79      0.88       589
           1       0.01      1.00      0.02         1

    accuracy                           0.79       590
   macro avg       0.50      0.90      0.45       590
weighted avg       1.00      0.79      0.88       590
09:29:13.963070: Validation Seq.Label F1: 0.6170198367381465; Log.Reg F1: 0.45029936461388076; train loss: 0.04249551519751549; Language: japanese 

09:29:13.964227: Combined F1 SeqLab: 0.5031804015664952; train loss: 0.04249551519751549
09:29:13.965384: Combined F1 LogReg: 0.46299438043032887; train loss: 0.04249551519751549 

09:29:13.966076: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 38/40
09:31:13.257315: Evaluating Language: english
09:31:13.257424: ----------
09:31:18.101998: OBI: 
 [[3774   17  143]
 [  17    2    2]
 [  94    3   21]]
09:31:18.106499: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.96      0.97      3934
           1       0.09      0.10      0.09        21
           2       0.13      0.18      0.15       118

    accuracy                           0.93      4073
   macro avg       0.40      0.41      0.40      4073
weighted avg       0.94      0.93      0.94      4073
09:31:18.106543: ----------
09:31:18.107202: LR: 
 [[529 395]
 [ 11  10]]
09:31:18.109909: LR: 
               precision    recall  f1-score   support

           0       0.98      0.57      0.72       924
           1       0.02      0.48      0.05        21

    accuracy                           0.57       945
   macro avg       0.50      0.52      0.38       945
weighted avg       0.96      0.57      0.71       945
09:31:18.111473: Validation Seq.Label F1: 0.40208380539390354; Log.Reg F1: 0.3848129762179635; train loss: 0.03595949709415436; Language: english 

09:31:18.111531: Evaluating Language: finnish
09:31:18.111576: ----------
09:31:25.253174: OBI: 
 [[3032   17   97]
 [  12    1    1]
 [ 118    1   17]]
09:31:25.257633: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.96      0.96      3146
           1       0.05      0.07      0.06        14
           2       0.15      0.12      0.14       136

    accuracy                           0.93      3296
   macro avg       0.39      0.39      0.39      3296
weighted avg       0.92      0.93      0.92      3296
09:31:25.257684: ----------
09:31:25.258716: LR: 
 [[1309  273]
 [  11    3]]
09:31:25.262275: LR: 
               precision    recall  f1-score   support

           0       0.99      0.83      0.90      1582
           1       0.01      0.21      0.02        14

    accuracy                           0.82      1596
   macro avg       0.50      0.52      0.46      1596
weighted avg       0.98      0.82      0.89      1596
09:31:25.263851: Validation Seq.Label F1: 0.3857943959958224; Log.Reg F1: 0.46141305639392577; train loss: 0.03595949709415436; Language: finnish 

09:31:25.263914: Evaluating Language: japanese
09:31:25.263966: ----------
09:31:28.492085: OBI: 
 [[2027    5   46]
 [   0    0    0]
 [  13    0   17]]
09:31:28.495443: OBI: 
               precision    recall  f1-score   support

           0       0.99      0.98      0.98      2078
           1       0.00      0.00      0.00         0
           2       0.27      0.57      0.37        30

    accuracy                           0.97      2108
   macro avg       0.42      0.51      0.45      2108
weighted avg       0.98      0.97      0.98      2108
09:31:28.495488: ----------
09:31:28.496037: LR: 
 [[531  59]
 [  0   0]]
09:31:28.498578: LR: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.95       590
           1       0.00      0.00      0.00         0

    accuracy                           0.90       590
   macro avg       0.50      0.45      0.47       590
weighted avg       1.00      0.90      0.95       590
09:31:28.499883: Validation Seq.Label F1: 0.4500166242791068; Log.Reg F1: 0.4736842105263158; train loss: 0.03595949709415436; Language: japanese 

09:31:28.500868: Combined F1 SeqLab: 0.4135310003169398; train loss: 0.03595949709415436
09:31:28.501847: Combined F1 LogReg: 0.44172380759114255; train loss: 0.03595949709415436 

09:31:28.502450: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 39/40
09:33:30.181219: Evaluating Language: english
09:33:30.181344: ----------
09:33:34.925824: OBI: 
 [[3402   49  371]
 [   9    4    1]
 [  81    4   39]]
09:33:34.930295: OBI: 
               precision    recall  f1-score   support

           0       0.97      0.89      0.93      3822
           1       0.07      0.29      0.11        14
           2       0.09      0.31      0.15       124

    accuracy                           0.87      3960
   macro avg       0.38      0.50      0.40      3960
weighted avg       0.94      0.87      0.90      3960
09:33:34.930347: ----------
09:33:34.931000: LR: 
 [[870  61]
 [ 13   1]]
09:33:34.933661: LR: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96       931
           1       0.02      0.07      0.03        14

    accuracy                           0.92       945
   macro avg       0.50      0.50      0.49       945
weighted avg       0.97      0.92      0.95       945
09:33:34.935232: Validation Seq.Label F1: 0.3962470541870488; Log.Reg F1: 0.4927609818371729; train loss: 0.028981134295463562; Language: english 

09:33:34.935289: Evaluating Language: finnish
09:33:34.935342: ----------
09:33:42.070071: OBI: 
 [[3822   60  258]
 [   9   10    6]
 [ 168    3   76]]
09:33:42.074808: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.92      0.94      4140
           1       0.14      0.40      0.20        25
           2       0.22      0.31      0.26       247

    accuracy                           0.89      4412
   macro avg       0.44      0.54      0.47      4412
weighted avg       0.91      0.89      0.90      4412
09:33:42.074854: ----------
09:33:42.075710: LR: 
 [[1492   79]
 [  21    4]]
09:33:42.078854: LR: 
               precision    recall  f1-score   support

           0       0.99      0.95      0.97      1571
           1       0.05      0.16      0.07        25

    accuracy                           0.94      1596
   macro avg       0.52      0.55      0.52      1596
weighted avg       0.97      0.94      0.95      1596
09:33:42.080210: Validation Seq.Label F1: 0.46740237741695706; Log.Reg F1: 0.5208243262717971; train loss: 0.028981134295463562; Language: finnish 

09:33:42.080264: Evaluating Language: japanese
09:33:42.080307: ----------
09:33:45.108010: OBI: 
 [[545   2  18]
 [  0   2   0]
 [  0   0   5]]
09:33:45.110291: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.96      0.98       565
           1       0.50      1.00      0.67         2
           2       0.22      1.00      0.36         5

    accuracy                           0.97       572
   macro avg       0.57      0.99      0.67       572
weighted avg       0.99      0.97      0.98       572
09:33:45.110341: ----------
09:33:45.110888: LR: 
 [[515  73]
 [  1   1]]
09:33:45.113278: LR: 
               precision    recall  f1-score   support

           0       1.00      0.88      0.93       588
           1       0.01      0.50      0.03         2

    accuracy                           0.87       590
   macro avg       0.51      0.69      0.48       590
weighted avg       0.99      0.87      0.93       590
09:33:45.114585: Validation Seq.Label F1: 0.6685971685971687; Log.Reg F1: 0.47964340198321886; train loss: 0.028981134295463562; Language: japanese 

09:33:45.115580: Combined F1 SeqLab: 0.5236089139243424; train loss: 0.028981134295463562
09:33:45.116571: Combined F1 LogReg: 0.49803920766797793; train loss: 0.028981134295463562 

09:33:45.117158: Model: lab6_xlm-roberta-base_japanese.pt; Language: japanese; Epoch 40/40
09:35:44.907566: Evaluating Language: english
09:35:44.907673: ----------
09:35:49.702690: OBI: 
 [[3403   30  544]
 [  12    0    4]
 [ 123    0  106]]
09:35:49.707301: OBI: 
               precision    recall  f1-score   support

           0       0.96      0.86      0.91      3977
           1       0.00      0.00      0.00        16
           2       0.16      0.46      0.24       229

    accuracy                           0.83      4222
   macro avg       0.37      0.44      0.38      4222
weighted avg       0.91      0.83      0.87      4222
09:35:49.707350: ----------
09:35:49.708007: LR: 
 [[815 114]
 [ 15   1]]
09:35:49.710670: LR: 
               precision    recall  f1-score   support

           0       0.98      0.88      0.93       929
           1       0.01      0.06      0.02        16

    accuracy                           0.86       945
   macro avg       0.50      0.47      0.47       945
weighted avg       0.97      0.86      0.91       945
09:35:49.712285: Validation Seq.Label F1: 0.3819153187270859; Log.Reg F1: 0.4709650261034853; train loss: 0.030615098774433136; Language: english 

09:35:49.712351: Evaluating Language: finnish
09:35:49.712395: ----------
09:35:56.690773: OBI: 
 [[1682   12  207]
 [   4    3    3]
 [  98    3   80]]
09:35:56.694023: OBI: 
               precision    recall  f1-score   support

           0       0.94      0.88      0.91      1901
           1       0.17      0.30      0.21        10
           2       0.28      0.44      0.34       181

    accuracy                           0.84      2092
   macro avg       0.46      0.54      0.49      2092
weighted avg       0.88      0.84      0.86      2092
09:35:56.694064: ----------
09:35:56.694917: LR: 
 [[1472  114]
 [   8    2]]
09:35:56.698064: LR: 
               precision    recall  f1-score   support

           0       0.99      0.93      0.96      1586
           1       0.02      0.20      0.03        10

    accuracy                           0.92      1596
   macro avg       0.51      0.56      0.50      1596
weighted avg       0.99      0.92      0.95      1596
09:35:56.699384: Validation Seq.Label F1: 0.48895952311676233; Log.Reg F1: 0.49597738638834526; train loss: 0.030615098774433136; Language: finnish 

09:35:56.699436: Evaluating Language: japanese
09:35:56.699479: ----------
09:35:59.676512: OBI: 
 [[1680   19  171]
 [   0    2    0]
 [   5    0    5]]
09:35:59.679568: OBI: 
               precision    recall  f1-score   support

           0       1.00      0.90      0.95      1870
           1       0.10      1.00      0.17         2
           2       0.03      0.50      0.05        10

    accuracy                           0.90      1882
   macro avg       0.37      0.80      0.39      1882
weighted avg       0.99      0.90      0.94      1882
09:35:59.679610: ----------
09:35:59.680154: LR: 
 [[538  50]
 [  1   1]]
09:35:59.682558: LR: 
               precision    recall  f1-score   support

           0       1.00      0.91      0.95       588
           1       0.02      0.50      0.04         2

    accuracy                           0.91       590
   macro avg       0.51      0.71      0.50       590
weighted avg       0.99      0.91      0.95       590
09:35:59.683828: Validation Seq.Label F1: 0.3909413878877901; Log.Reg F1: 0.4962414826472016; train loss: 0.030615098774433136; Language: japanese 

09:35:59.684834: Combined F1 SeqLab: 0.42338945613096174; train loss: 0.030615098774433136
09:35:59.685782: Combined F1 LogReg: 0.4878719889209885; train loss: 0.030615098774433136 

09:35:59.685835: Learning rates: []
09:36:04.766046: Finished successfully!
